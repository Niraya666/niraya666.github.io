<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>LZY Blog</title>
    <link>https://niraya666.github.io/</link>
    <description>Recent content on LZY Blog</description>
    <image>
      <title>LZY Blog</title>
      <url>https://niraya666.github.io/images/papermod-cover.png</url>
      <link>https://niraya666.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 11 Jun 2025 15:04:00 +0800</lastBuildDate>
    <atom:link href="https://niraya666.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>从下半场开始，对于评估的重新思考: 一些概念</title>
      <link>https://niraya666.github.io/posts/eval_1/</link>
      <pubDate>Wed, 11 Jun 2025 15:04:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/eval_1/</guid>
      <description>&lt;h2 id=&#34;引子&#34;&gt;引子&lt;/h2&gt;
&lt;p&gt;前一段时间，OpenAI 研究员姚顺雨在一篇广受关注的文章《&lt;a href=&#34;https://ysymyth.github.io/The-Second-Half/&#34;&gt;The Second Half&lt;/a&gt;》中提出：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“I think we should fundamentally re-think evaluation. It means not just to create new and harder benchmarks, but to fundamentally question existing evaluation setups and create new ones, so that we are forced to invent new methods beyond the working recipe.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;指出，AI 发展的“下半场”已经到来，而其中一个核心议题，就是对 evaluation的重新思考。我们需要的不再是单纯地创造更难的 benchmark，然后在这些 benchmark 上“刷分”，而是要更加关注评测的实用性、创新性，以及其与真实世界的契合度。&lt;/p&gt;
&lt;p&gt;过去，我们往往过于关注模型本身、训练方法以及各种fancy的技术手段，却忽略了模型与真实世界的交互和落地应用。而 evaluation，正是连接模型能力与实际需求的关键环节。&lt;/p&gt;
&lt;p&gt;本文最初的出发点，是梳理 &lt;a href=&#34;https://github.com/huggingface/evaluation-guidebook/tree/main&#34;&gt;Hugging Face Evaluation &lt;/a&gt;系列文章中的一些要点。需要说明的是，HF 的文章主要聚焦于如何评测LLM的能力，考虑到其成文的时间，其中部分内容在当前 LLM 能力飞速提升的背景下，显得有些滞后。但这也为我们提供了一个契机，从后来者的视角重新思考 evaluation 的意义，并尝试将这些理念应用到更加复杂和多样化的 AI 系统中，如RAG和AI-agent。&lt;/p&gt;
&lt;p&gt;在机器学习和深度学习的流程中，Evaluation是衡量模型性能的核心环节。它贯穿于模型开发的始终：从训练阶段的实时监控，到上线前的最终验证，再到部署后的持续追踪。&lt;br&gt;
&lt;br&gt;
简单来说，评估的目标是回答两个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;模型是否有效？&lt;/strong&gt;（性能指标）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;模型是否可靠？&lt;/strong&gt;（鲁棒性、泛化能力）&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以经典的猫狗分类任务为例，在训练前，我们可能将数据集划分为trainingset，evalset，和testset （经典的7:2:1）保证训练数据与测试数据无重叠；对于分类问题，可能选择Accuracy、Precision和Recall 作为metrics，在训练过程中监控模型在evalset上的情况（是否存在overfitting之类的问题）；训练结束后，在testset上验证模型的最终性能，判断是否达到预期目标。&lt;/p&gt;</description>
    </item>
    <item>
      <title>2025-05 月刊</title>
      <link>https://niraya666.github.io/monthly/2025-05-%E6%9C%88%E5%88%8A/</link>
      <pubDate>Fri, 30 May 2025 14:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/monthly/2025-05-%E6%9C%88%E5%88%8A/</guid>
      <description>&lt;h1 id=&#34;值得关注的模型和新技术&#34;&gt;值得关注的模型和新技术&lt;/h1&gt;
&lt;h2 id=&#34;google-2025-io-大会&#34;&gt;Google 2025 I/O 大会：&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.google/technology/developers/google-io-2025-collection/&#34;&gt;I/O 2025&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Google在2025年I/O大会上全面展示了AI的最新进展和深度整合战略，涵盖基础模型迭代（如Gemini 2.5、Gemini Diffusion、Gemma 3n、Veo 3和Imagen 4）及多模态创新&lt;/p&gt;
&lt;h2 id=&#34;openai-codex&#34;&gt;OpenAI codex&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/introducing-codex/&#34;&gt;Introducing Codex&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;OpenAI 于 2025年5月16日推出了 Codex 软件工程代理及其驱动模型 codex-1 和 codex-mini-latest，专注提升软件开发的自动化与效率。codex-1 基于 o3 模型，优化并行处理、多轮测试和复杂项目支持，擅长代码生成、Bug 修复等任务；codex-mini-latest 则主打低延迟，适合快速命令行操作。Codex 平台通过云端隔离沙箱，安全模拟真实开发环境，自动化完成如重构、测试编写等任务，支持细致行为定制。&lt;/p&gt;
&lt;h2 id=&#34;claude-4&#34;&gt;Claude 4&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.anthropic.com/news/claude-4&#34;&gt;Introducing Claude 4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Anthropic 于2025年5月22日发布了新一代 Claude 4 系列模型，包括 Claude Opus 4 和 Claude Sonnet 4，重点提升了编码、高级推理和对AI代理的支持能力。Opus 4 在行业编码基准测试中表现领先，拥有更强的内存与持续任务能力，并大幅减少“抄近路”行为，专注于高复杂任务和AI代理核心场景。Sonnet 4 则在提升推理与指令遵循能力的同时，平衡了性能与效率。&lt;/p&gt;
&lt;h2 id=&#34;deepseek-r1-0528&#34;&gt;&lt;strong&gt;DeepSeek-R1-0528&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Huggingface： &lt;a href=&#34;https://huggingface.co/deepseek-ai/DeepSeek-R1-0528&#34;&gt;deepseek-ai/DeepSeek-R1-0528&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;通过强化学习与算法优化实现推理能力提升，单问题推理深度翻倍（平均Token量从12K→23K），更强的数学、编码能力，并支持工具调用，大幅降低幻觉。同时开源了蒸馏小模型模型 &lt;a href=&#34;https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B&#34;&gt;deepseek-ai/DeepSeek-R1-0528-Qwen3-8B&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;flowith-neo&#34;&gt;&lt;strong&gt;Flowith Neo&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Flowith Neo 是 Flowith 团队推出的新一代 AI 智能代理，专为自动化复杂、长流程任务设计。其核心技术包括支持无限步骤的持续云端执行、强大的上下文保持能力、灵活调用多种外部工具，以及可视化工作流和自反思机制，显著提升流程的连贯性和可靠性。&lt;/p&gt;
&lt;h1 id=&#34;值得关注的开源项目&#34;&gt;值得关注的开源项目&lt;/h1&gt;
&lt;h2 id=&#34;deerflow&#34;&gt;&lt;strong&gt;DeerFlow&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Github: &lt;a href=&#34;https://github.com/bytedance/deer-flow&#34;&gt;github.com/bytedance/deer-flow&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;由字节跳动开源的，基于LangStack 开发的Deep Research 开源项目，支持深度研究、MCP 集成、报告 AI 增强编辑以及播客生成等功能，通过Docker compose一键启动。&lt;/p&gt;</description>
    </item>
    <item>
      <title>初探 Mem0</title>
      <link>https://niraya666.github.io/posts/%E5%88%9D%E6%8E%A2mem0/</link>
      <pubDate>Tue, 20 May 2025 18:44:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/%E5%88%9D%E6%8E%A2mem0/</guid>
      <description>&lt;h2 id=&#34;写在开头&#34;&gt;写在开头&lt;/h2&gt;
&lt;p&gt;本文是对于&lt;a href=&#34;https://github.com/mem0ai/mem0&#34;&gt;Mem0&lt;/a&gt;的论文解读和使用记录；&lt;/p&gt;
&lt;p&gt;Mem0 是一款面向LLM应用的memory layer框架，同时是开源的。虽然它最早在 2024 年中旬亮相，起初的框架设计并没有太多亮眼之处，不过在最近，发布了一次比较重大的更新（基本上是重构了）采用了基于 AI-agent 的对话记忆提取、更新和查询等机制，实际体验下来，算是目前为止比较好用的了。&lt;/p&gt;
&lt;h2 id=&#34;paper笔记&#34;&gt;Paper笔记&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2504.19413&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;创新点&#34;&gt;&lt;strong&gt;创新点&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Mem0架构&lt;/strong&gt;：提出了一种可扩展的、以记忆为中心的AI代理架构，能够动态地从对话中抽取、整合和检索关键信息，实现长期、跨会话的记忆&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Mem0g（图记忆扩展）&lt;/strong&gt;：在基础架构上进一步引入“图结构记忆”，用有向标注图（节点为实体，边为关系）来捕捉对话中复杂的实体关系和事件顺序，提升多跳推理和时序推理能力&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mem0实现&#34;&gt;&lt;strong&gt;Mem0实现&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%88%9d%e6%8e%a2Mem0-assets/Pasted%202025-05-20-16-29-02.png&#34; alt=&#34;Pasted 2025-05-20-16-29-02.png&#34;  /&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;extraction phase:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每当有一对新的消息$(m_{t},m_{t−1})$进入系统时，系统会启动记忆抽取流程&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;系统会同时参考两类上下文信息: &lt;strong&gt;全局对话摘要（S）和 最近的消息序列&lt;/strong&gt;${m_{t−m}, &amp;hellip;, m_{t−2}}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;组合成一个完整的提示（prompt）&lt;strong&gt;P&lt;/strong&gt;，输入给LLM实现的抽取函数&lt;strong&gt;ϕ&lt;/strong&gt;。LLM会基于这些信息，抽取出本轮对话中值得记忆的关键信息（$Ω = (ω_1,&amp;hellip;,ω_n )$），作为候选事实，准备加入知识库&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为保障S始终是最新的，使用异步摘要生成模块，定期刷新摘要内容&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;update phase：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;核心任务：检查这些新事实和已有记忆之间的关系和证知识库的内容既不重复，也不矛盾，始终保持一致和精简&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对每一个新抽取的事实（$ω_i$），系统会&lt;strong&gt;检索数据库中与之最相似的s条已有记忆&lt;/strong&gt;（用向量嵌入做语义相似度检索）, 将$ω_i$ 和相似记忆一起交给LLM，由LLM从以下4种工具选择并执行（tool-using）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ADD&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DELETE&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NOOP&lt;/strong&gt; （什么也不做）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体算法&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%88%9d%e6%8e%a2Mem0-assets/%e6%88%aa%e5%b1%8f2025-05-10%20%e4%b8%8b%e5%8d%883.13.17.png&#34; alt=&#34;截屏2025-05-10 下午3.13.17.png&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;mem0g实现&#34;&gt;&lt;strong&gt;Mem0g实现&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%88%9d%e6%8e%a2Mem0-assets/Pasted%202025-05-20-16-31-40.png&#34; alt=&#34;Pasted 2025-05-20-16-31-40.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;以图$G = ( V , E , L )$ 建模记忆，(实体、关系、和语义label)&lt;/p&gt;
&lt;p&gt;每个entity（node）包含三部分信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;entity type classification：用于标记这个实体属于哪一类&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;embedding vector：实体语义含义的向量表示，便于后续做语义相似度检索和推理&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;metadata： 主要包括创建时间戳（creation timestamp），用于记录这个实体被加入知识图谱的时间，有助于时序推理&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;relationships 用triplet的表示：&lt;/p&gt;</description>
    </item>
    <item>
      <title>2025-04 月刊</title>
      <link>https://niraya666.github.io/monthly/2025-04-%E6%9C%88%E5%88%8A/</link>
      <pubDate>Mon, 28 Apr 2025 19:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/monthly/2025-04-%E6%9C%88%E5%88%8A/</guid>
      <description>&lt;h1 id=&#34;值得关注的模型和新技术&#34;&gt;值得关注的模型和新技术&lt;/h1&gt;
&lt;h2 id=&#34;openai-更新系列模型&#34;&gt;OpenAI 更新系列模型&lt;/h2&gt;
&lt;p&gt;发布了多款新一代AI模型，包括o3、o4-mini、GPT-4.1及其mini和nano版本。这些模型在推理能力、成本效益和多模态处理等方面实现了提升。o3专注于复杂推理和工具使用，已在ChatGPT Plus等产品中取代前代模型。o4-mini则以高性价比和多模态能力为亮点。GPT-4.1系列主打超长上下文和高效编码，mini和nano版本进一步降低成本和延迟。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/gpt-4-1/&#34;&gt;Introducing GPT-4.1 in the API&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/introducing-o3-and-o4-mini/&#34;&gt;Introducing OpenAI o3 and o4-mini&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;kimi-vl-和-kimi-vl-thinking&#34;&gt;Kimi-VL 和 Kimi-VL-Thinking&lt;/h2&gt;
&lt;p&gt;由Moonshot AI推出了新一代视觉语言模型Kimi-VL及其，主打高效多模态推理高级版本Kimi-VL-Thinking。采用轻量级混合专家架构（16B总参数量，2.8B的激活参数），支持128K上下文窗口和超高分辨率视觉输入，Kimi-VL-Thinking通过链式思考和强化学习训练，专注于复杂推理和数学任务。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking&#34;&gt;Hugging Face Kimi-VL-Thinking 模型页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2504.07491&#34;&gt;Kimi-VL Technical Report&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;a2a协议&#34;&gt;A2A协议&lt;/h2&gt;
&lt;p&gt;A2A协议（Agent2Agent Protocol）是由谷歌于2025年4月10日在Google Cloud Next 2025大会上宣布开源的标准智能体交互协议，旨在实现跨平台、跨供应商的AI智能体（AI Agent）无缝通信与协作。功能与特点：A2A协议通过统一规则支持多模态协作，允许智能体共享和处理文本、音频、视频等多种数据格式，兼容HTTP、SSE、JSON-RPC等现有标准，降低企业集成成本。其核心机制包括Agent Card，用于智能体能力发现与协作对接，支持自然、非结构化协作模式，即使智能体不共享内存或上下文也能协同工作。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/&#34;&gt;Announcing the Agent2Agent Protocol (A2A)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;qwen3&#34;&gt;Qwen3&lt;/h2&gt;
&lt;p&gt;Qwen3 是Qwen的第三代大语言模型系列，于2025年4月正式发布，包含6个稠密模型（0.6B至32B参数）和2个混合专家（MoE）模型（30B-A3B和235B-A22B）。功能与特点：Qwen3支持119种语言，训练数据高达36万亿token，具备自然语言理解、文本生成、工具调用、复杂推理及多模态交互能力。模型采用混合推理模式，可根据任务复杂度自动切换“思考”与“快速响应”模式，优化计算效率与响应速度。支持128K token上下文长度，适用于长文档处理、编程、数学推理及智能体任务。创新点：Qwen3引入动态可调MoE架构，通过分层稀疏调度和动态专家激活（最多128个专家，单token激活8个），显著降低推理耗时（15B模型推理效率提升42%）和显存占用（从28GB降至18GB）。新增Qwen3RMSNorm归一化层优化注意力机制，支持多种RoPE变体（dynamic、yarn、llama3）以提升长序列处理能力。词表优化引入动态加权合并算法，增强高频词组处理，并新增智能体专用控制符。效果：旗舰模型Qwen3-235B-A22B在Codeforces编程竞赛、AIME数学基准及BFCL推理测试中超越OpenAI的o3-mini和谷歌Gemini 2.5 Pro，Qwen3-32B在LiveCodeBench编码任务中优于OpenAI o1。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://qwenlm.github.io/zh/blog/qwen3/&#34;&gt;Blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f&#34;&gt;Huggingface&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;值得关注的开源项目&#34;&gt;值得关注的开源项目&lt;/h1&gt;
&lt;h2 id=&#34;inbox-zero&#34;&gt;Inbox Zero&lt;/h2&gt;
&lt;p&gt;Inbox Zero 是一个开源的 AI 邮件管理工具，旨在通过智能化功能帮助用户快速清空收件箱并高效处理邮件。项目包含两部分：&lt;strong&gt;AI 邮件助手&lt;/strong&gt;与&lt;strong&gt;开源邮件客户端&lt;/strong&gt;。其核心功能包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AI 个人助理&lt;/strong&gt;：基于用户自定义的文本指令，可自动执行邮件管理操作（如起草回复、标记分类、归档、标记垃圾邮件或触发网络钩子），显著减少手动处理时间。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reply Zero 跟踪&lt;/strong&gt;：实时追踪需用户回复的邮件及等待他人回复的邮件，提升沟通效率。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;智能分类与退订&lt;/strong&gt;：自动整理联系人邮件并智能归类，支持一键批量退订低价值订阅。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;冷邮件拦截与分析&lt;/strong&gt;：自动过滤陌生发件人邮件，并提供每日/周/月邮件活动统计，帮助用户优化收件箱管理。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;技术优势与适用场景&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;项目采用 Next.js、Tailwind CSS 等现代技术栈构建，支持通过 Vercel 快速部署或自托管，兼容 Anthropic、OpenAI 等 LLM 模型，甚至可集成本地 Ollama 服务以降低成本。&lt;/p&gt;</description>
    </item>
    <item>
      <title>LangMem: 一些学习笔记</title>
      <link>https://niraya666.github.io/posts/langmem-%E4%B8%80%E4%BA%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 10 Apr 2025 10:44:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/langmem-%E4%B8%80%E4%BA%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;p&gt;本文是我在阅读 LangMem 的源码与相关文档过程中整理的一些学习笔记。&lt;/p&gt;
&lt;p&gt;一直以来，我对智能体（Agent）的记忆机制充满好奇：理想的 memory 应该具备怎样的结构？又该如何设计？目前市面上关于 memory 的实现大多中规中矩，尚未看到令人眼前一亮的方案。为此，我决定多参考一些开源项目，以期获得新的灵感。&lt;/p&gt;
&lt;p&gt;总体来看，LangMem 作为 LangChain 推出的一款 memory 框架，设计上较为常规，虽有部分值得借鉴之处，但亮点不多，不建议投入过多时间深入研究。同时，与 LangChain 的其他项目类似，其代码结构和文档编写较为混乱，阅读体验不佳。&lt;/p&gt;
&lt;h2 id=&#34;core-concepts&#34;&gt;Core-Concepts&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://langchain-ai.github.io/langmem/concepts/conceptual_guide/&#34;&gt;core-concepts &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在LangMem所设计的memory体系中， 定义了几种不同的&lt;strong&gt;Typical Storage Pattern&lt;/strong&gt;：&lt;strong&gt;Collection 、 Profiles和Procedural&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;collection&#34;&gt;Collection&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Collection&lt;/strong&gt; 主要用于存储&lt;strong&gt;不受限制的知识&lt;/strong&gt;，适用于需要长期积累和检索的信息。每条记忆被存储为&lt;strong&gt;独立的文档或记录&lt;/strong&gt;，可以在需要时进行搜索和回忆；&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/LangMem!%20%e4%b8%80%e4%ba%9b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0-assets/Pasted%202025-03-25-14-52-31.png&#34; alt=&#34;Pasted 2025-03-25-14-52-31.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：记录用户的长期知识，例如用户的兴趣、职业背景、技能等&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更新方式&lt;/strong&gt;：需要&lt;strong&gt;合并新信息&lt;/strong&gt;，避免重复或冲突&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;检索方式&lt;/strong&gt;：通过&lt;strong&gt;语义搜索&lt;/strong&gt;或&lt;strong&gt;关键词匹配&lt;/strong&gt;来查找，结合&lt;strong&gt;记忆的重要性&lt;/strong&gt;和&lt;strong&gt;使用频率&lt;/strong&gt;来优化检索结果&lt;/p&gt;
&lt;h3 id=&#34;profiles&#34;&gt;&lt;strong&gt;Profiles&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;存储&lt;strong&gt;结构化的用户信息&lt;/strong&gt;，例如用户的姓名、语言偏好、沟通风格等。与 Collection 不同，Profile 只存储&lt;strong&gt;最新的状态&lt;/strong&gt;，而不是累积所有历史信息。Profile 作为&lt;strong&gt;单一文档&lt;/strong&gt;存储，每次更新时都会&lt;strong&gt;覆盖旧数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/LangMem!%20%e4%b8%80%e4%ba%9b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0-assets/Pasted%202025-03-25-14-52-31%201.png&#34; alt=&#34;Pasted 2025-03-25-14-52-31 1.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：适用于需要&lt;strong&gt;快速访问当前状态&lt;/strong&gt;的应用，例如个性化推荐、用户设置；适用于&lt;strong&gt;需要严格定义数据结构&lt;/strong&gt;的场景，例如用户档案、系统配置；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更新方式：不会创建新记录&lt;/strong&gt;，而是直接&lt;strong&gt;更新现有的 Profile；&lt;strong&gt;适用于&lt;/strong&gt;只关心最新状态&lt;/strong&gt;的应用，而不是历史；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;检索方式&lt;/strong&gt;：直接查找用户的 Profile&lt;/p&gt;
&lt;h3 id=&#34;procedural-memory&#34;&gt;&lt;strong&gt;Procedural Memory&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;类似于人类的工作记忆，用于存储如何执行任务的知识，主要体现在&lt;strong&gt;system prompts 和行为优化&lt;/strong&gt;上&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/LangMem!%20%e4%b8%80%e4%ba%9b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0-assets/Pasted%202025-03-25-14-52-31%202.png&#34; alt=&#34;Pasted 2025-03-25-14-52-31 2.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：需要长期优化 Agent行为和交互方式，少走弯路&lt;/p&gt;
&lt;p&gt;总结&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;Memory Type&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;用途&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;智能体示例&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;典型存储模式&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Semantic&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Facts &amp;amp; Knowledge&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;User preferences; knowledge triplets&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Profile或Collection&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Episodic&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Past Experiences&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Few-shot examples; 过往对话摘要&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Collection&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Procedural&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;System Behavior&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Core personality and response patterns&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Prompt rules或Collection&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;writing-memories&#34;&gt;Writing memories&lt;/h2&gt;
&lt;p&gt;提供了两种写入memory的方法：&lt;strong&gt;及时写入&lt;/strong&gt;（适用于要求即时记忆反映的场景）和一段时间后的&lt;strong&gt;异步写入&lt;/strong&gt;（适用于高效处理和存储大量信息的场景）&lt;/p&gt;</description>
    </item>
    <item>
      <title>2025-03 月刊</title>
      <link>https://niraya666.github.io/monthly/2025-03-%E6%9C%88%E5%88%8A/</link>
      <pubDate>Sat, 29 Mar 2025 17:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/monthly/2025-03-%E6%9C%88%E5%88%8A/</guid>
      <description>&lt;h1 id=&#34;值得关注的模型和新技术&#34;&gt;值得关注的模型和新技术&lt;/h1&gt;
&lt;h2 id=&#34;deepseek-v3-0324&#34;&gt;DeepSeek V3 0324&lt;/h2&gt;
&lt;p&gt;DeepSeek V3模型的更新版本；在多个基准测试中表现出色，整体表现接近领先的闭源模型如Claude Sonnet 3.5（但价格便宜很多）；针对多项能力做了针对性提升，如function calling，推理能力，前端代码能力等。更新版本在DeepSeek的官方网站、移动应用可体验。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-V3&#34;&gt;Huggingface&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;qwq-32b&#34;&gt;QwQ-32B&lt;/h2&gt;
&lt;p&gt;由Qwen 团队开发的推理模型，性能同671B参数量的R1相当；通过两阶段RL训练，第一阶段专注于数学和编码任务，利用准确性验证器和代码执行服务器提供反馈；第二阶段提升通用能力，同时保持专业领域的表现。此外QwQ具备tool-using能力，具有131,072 token的上下文长度。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://qwenlm.github.io/zh/blog/qwq-32b/&#34;&gt;Blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/Qwen/QwQ-32B&#34;&gt;Huggingface&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;qwen25-omni&#34;&gt;Qwen2.5 Omni&lt;/h2&gt;
&lt;p&gt;Qwen2.5-Omni 是一个多模态 AI 模型，能够同时处理文本、图像、音频和视频输入；该模型的创新点包括 Thinker-Talker 架构，分为“Thinker”处理输入并生成表示或文本，“Talker”则输出语音token，共享上下文，实现端到端训练和推理。此外，它使用 TMRoPE（时间对齐多模态 RoPE）技术，同步视频和音频时间戳，确保多模态数据处理的一致性。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://qwenlm.github.io/zh/blog/qwen2.5-omni/&#34;&gt;Blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-Omni-7B&#34;&gt;Huggingface&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;gemma-3&#34;&gt;Gemma 3&lt;/h2&gt;
&lt;p&gt;Gemma家族的开源新作，包括 1B、4B、12B 和 27B 参数；4B、12B 和 27B 模型支持文本和图像输入，1B 模型仅限文本；1B 模型支持 32k token，4B、12B 和 27B 模型则扩展至 128k token；支持函数调用和结构化输出&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.google/technology/developers/gemma-3/&#34;&gt;Blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/google/gemma-3-27b-it&#34;&gt;Huggingface&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;phi-4-multimodal&#34;&gt;Phi-4-multimodal&lt;/h2&gt;
&lt;p&gt;具备文本、图像和音频输入的多模态模型；具有5.6B参数量；采用“混合 LoRAs”技术，将模态特定组件集成到基础语言模型中，而基础模型保持冻结状态，以确保了多模态数据处理的无缝性，避免了传统方法中因模态间干扰导致的性能下降。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/blog/empowering-innovation-the-next-generation-of-the-phi-family/&#34;&gt;Blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/microsoft/Phi-4-multimodal-instruct&#34;&gt;Huggingface&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;qwen25-vl-32b-instruct&#34;&gt;Qwen2.5-VL-32B-Instruct&lt;/h2&gt;
&lt;p&gt;32B参数量版本的Qwen2.5-VL多模态模型；&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;72B too big for VLM? 7B not strong enough! Teh you should use 32B model!&lt;/p&gt;</description>
    </item>
    <item>
      <title>2025·东京：音乐之旅的再出发</title>
      <link>https://niraya666.github.io/travel/2025%E4%B8%9C%E4%BA%AC%E9%9F%B3%E4%B9%90%E4%B9%8B%E6%97%85%E7%9A%84%E5%86%8D%E5%87%BA%E5%8F%91/</link>
      <pubDate>Tue, 18 Mar 2025 12:02:00 +0800</pubDate>
      <guid>https://niraya666.github.io/travel/2025%E4%B8%9C%E4%BA%AC%E9%9F%B3%E4%B9%90%E4%B9%8B%E6%97%85%E7%9A%84%E5%86%8D%E5%87%BA%E5%8F%91/</guid>
      <description>&lt;p&gt;当冰岛后摇乐队Sigur Rós宣布世界巡演时，东京站便成了我行程表上必须抵达的地方。当然，这趟旅程还承载很多和音乐、艺术有关的记忆。&lt;/p&gt;
&lt;p&gt;入关时，海关大厅的喧嚣依旧。排队时遇见一对中国夫妇，他们对着&amp;quot;外国人&amp;quot;汉字的标识犹豫不决，忽然意识到自己早已身处异国，相视而笑的瞬间让我想起去年同样忐忑的自己。指纹机这次顺利读取了我的手纹，或许因为少了初访时的紧张手汗。海关人员将新入境贴纸仔细贴在旧标签右侧，整齐的排列让强迫症狂喜了。&lt;/p&gt;
&lt;p&gt;选择上野作为落脚点，不仅因它毗邻机场快线的便利，更迷恋老城区特有的烟火气。从成田机场进城的交通选择颇多，最终搭乘号称日本最快非新干线列车的Skyliner。&lt;/p&gt;
&lt;p&gt;与大阪相比，东京街头的中国元素显得格外醒目。沙县小吃和杨国福麻辣烫这类国内常见的连锁招牌不时映入眼帘，而改良版的四川担担面更是在日本扎根多年，形成了独特的本土风味。&lt;/p&gt;
&lt;p&gt;拖着行李箱抄近道时，误入了名为仲町通り的小路。暮色中的街道霓虹渐起，酒吧与餐厅的招牌间夹杂着暧昧的粉色灯箱，手持宣传板的年轻女性在街角轻声招揽客人，几个西装革履却透着江湖气的男子在暗处徘徊。我加快脚步穿过这片区域，直到看见便利店明亮的灯光才松了口气。后来查阅资料得知，这条起源于江户时代宽永寺门前町的老街，历经三百年演变已成为东京著名的夜生活区。这里不仅延续着传统娱乐文化，更因拉客纠纷和醉汉闹事被列为治安重点区域，旅游指南都建议游客避免夜间单独深入巷弄。有趣的是，在鳞次栉比的霓虹招牌中，除了日文店名，还夹杂着不少泰语和菲律宾语的标识。&lt;/p&gt;
&lt;h2 id=&#34;day1&#34;&gt;Day1&lt;/h2&gt;
&lt;h3 id=&#34;东京都现代美术馆&#34;&gt;东京都现代美术馆&lt;/h3&gt;
&lt;p&gt;东京之行的首站，是提前数日才预约成功的特别展——《坂本龙一｜听音观时》。即便社交媒体上最出圈的《雾的雕塑》装置吸引着无数人前来打卡，但对我而言，这场展览更像是赴一场迟到的对话。作为教授生前为美术馆构思的最终企划，十二组装置艺术中流淌着他未完成的思考：当音乐脱离传统音阶束缚，当乐器回归自然物质的本质。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/travel/2025%c2%b7%e4%b8%9c%e4%ba%ac%ef%bc%9a%e9%9f%b3%e4%b9%90%e4%b9%8b%e6%97%85%e7%9a%84%e5%86%8d%e5%87%ba%e5%8f%91-assets/BE28B0B2-E428-4FB4-86E6-EDA0D8896E4B_1_105_c.jpeg&#34; alt=&#34;BE28B0B2-E428-4FB4-86E6-EDA0D8896E4B_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;《你的时间》（坂本龙一 with 高谷史郎）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;311海啸浸没过的钢琴正以另一种形态重生。曾出现在纪录片《终曲》中的这架&amp;quot;被自然调律的乐器&amp;quot;，此刻悬浮于水盘之上。头顶屏幕飘落的雪与地震数据转化的音符共振，琴槌敲击的已非人造音阶，而是地壳震颤的原始频率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;《异步——沉浸东京》（坂本龙一with高谷史郎 2024 ）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这也是我驻足最久的一个装置，因为其播放的是我最喜欢的一张专辑《Async》。 展厅正面是一面 18 米长的 LED墙，实时生成由高谷制作的影像。高谷的影像以拍摄坂本纽约工作室里的钢琴、书籍、打击乐器、后院盆栽等各种物品为基础构成。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Because we don&amp;rsquo;t know when we will die, we get to think of life as an inexhaustible well. Yet everything happens only a certain number of times, and a very small number really. How many more times will you remember a certain afternoon of your childhood, an afternoon that is so deeply a part of your being that you can&amp;rsquo;t even conceive of your life without it? Perhaps four, five times more, perhaps not even that. How many more times will you watch the full moon rise? Perhaps 20. And yet it all seems limitless.”&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAG工具箱：基于多模态大模型的文档解析方案（2025版）</title>
      <link>https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E6%96%B9%E6%A1%882025%E7%89%88/</link>
      <pubDate>Wed, 12 Mar 2025 16:44:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E6%96%B9%E6%A1%882025%E7%89%88/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E6%96%B9%E6%A1%882025%E7%89%88/#smoldocling&#34;&gt;Updated on 2025-03-29: Add SmolDocling &amp;amp; VLM Summary&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;技术迭代速度之快令人惊叹，前作 &lt;a href=&#34;https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E4%B8%8E%E8%A1%A8%E6%A0%BC%E5%A4%84%E7%90%86/&#34;&gt;RAG工具箱：文档解析与表格处理&lt;/a&gt; 在短短数月内已显现出代际差距，尽管前作也仅仅只是抛砖引玉式地讨论了pdf的解析方案，不过在新技术的面前，既有的复杂解析架构逐渐失去存在价值，也被端到端范式所取代。在笔者看来，基于多模态大模型的端到端文档解析方案，将成为最优解。&lt;/p&gt;
&lt;p&gt;本文将探讨文档解析的终极形态——基于多模态大模型（VLM）的解析技术，包括Mistral-OCR、OlmOCR等前沿工具的实现与实践，并展望该领域的技术发展趋势，和对于RAG的影响。&lt;/p&gt;
&lt;h2 id=&#34;过去的技术栈总结&#34;&gt;过去的技术栈总结&lt;/h2&gt;
&lt;p&gt;在RAG系统中，文档解析质量直接决定系统上限。不同场景下的文档形态差异显著，若不能有效解决&amp;quot;garbage in, garbage out&amp;quot;的输入质量问题，后续处理环节将难以发挥应有价值。&lt;/p&gt;
&lt;p&gt;传统文档解析技术长期受限于以下核心痛点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;结构化信息缺失：无法准确识别文档标题、副标题等层级结构&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特殊内容处理薄弱：数学公式、专业符号解析准确率低下&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;复杂表格解析困境：跨页表格、合并单元格等场景支持不足&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图像信息提取瓶颈：扫描文档、手写体识别效果欠佳&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;版式适应性问题：多栏布局、影印版本等文档格式兼容性差&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从技术角度，过去文档解析的底层逻辑和框架：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;纯文本解析: &lt;code&gt;PyPDF&lt;/code&gt;, &lt;code&gt;PyMuPDF&lt;/code&gt;只能解析pdf中的文字,对于公式表格和复杂排版解析无能,对于扫描版低质量的pdf无能为力&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OCR方案（PaddleOCR等）: 首先使用目标检测模型对文档布局进行分析，识别出标题、表格等关键元素的位置，然后在这些位置上使用OCR技术提取文字；由于需要调用多个模型，整套系统非常复杂；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;基于transformer 的解析方案（代表: Dount, Nougat）：专门针对英文的学术文章做的训练, 能够将pdf文章整理成Markdown或Latex格式；但对于其他语言和其他类型的文档泛化效果很差；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;随着模型能力提升，采用VLM做解析是非常自然的想法，尽管GPT-4o的发布使该技术获得广泛关注，但其高昂的API成本制约了实际应用。值得庆幸的是，开源社区的技术突破正在改变这一局面：不论是LLM基座模型多模态理解能力的增强，还是视觉编码器的提升，至少在当下，开源VLM已具备实用级文档解析能力，而无需针对下游任务的微调，同时成本上已经在可接受范围了。&lt;/p&gt;
&lt;h2 id=&#34;benchmark&#34;&gt;Benchmark&lt;/h2&gt;
&lt;p&gt;为了判断一个模型是否适合Document Parsing，需要benchmark测试分数，作为模型挑选的标准。&lt;/p&gt;
&lt;p&gt;现阶段，针对LLMs在OCR、文档信息提取场景下主要采用以下几个常见的bench&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/spaces/echo840/ocrbench-leaderboard&#34;&gt;OCRBench&lt;/a&gt;、&lt;a href=&#34;https://huggingface.co/spaces/ling99/OCRBench-v2-leaderboard&#34;&gt;OCRBench-V2&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/opendatalab/OmniDocBench&#34;&gt;OmniDocBench&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2412.02210&#34;&gt;CC-OCR&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;…and more&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（关于benchmark的具体内容见附录）&lt;/p&gt;
&lt;p&gt;这些bench都基本上包含了通用场景下的OCR能力， 多语言的文档解析能力的测试，能够一定程度上作为模型筛选的关注首选&lt;/p&gt;
&lt;p&gt;当然，除了模型能力以外，还需要关注模型的参数量，因为与其成本和latency息息相关。&lt;/p&gt;
&lt;p&gt;不过，对于每一个具体场景，还是需要构建自己的测试集用于判断模型是否能够胜任任务， 因为benchmark所包含的测试场景数据，分布语言等等和具体的场景不见得完全一样。&lt;/p&gt;
&lt;p&gt;根据benchmark和实际测试结果，目前几个值得关注的开源VLM：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://huggingface.co/collections/Qwen/qwen25-vl-6795ffac22b334a837c0f9a5&#34;&gt;Qwen2.5-VL&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/microsoft/Phi-4-multimodal-instruct&#34;&gt;Phi-4-multimodal&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct&#34;&gt;Llama 3.2 Vision&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/allenai/olmOCR-7B-0225-preview&#34;&gt;olmocr&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;and more …&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;qwen25-vl系列模型&#34;&gt;Qwen2.5-VL系列模型&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/QwenLM/Qwen2.5-VL/tree/main/cookbooks&#34;&gt;cookbook&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://qwenlm.github.io/zh/blog/qwen2.5-vl/&#34;&gt;Blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2502.13923&#34;&gt;Technical Report&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这应该是开源的模型中，效果排前列的多模态模型（截止至今），同时还具备了多种参数量（3B，7B，72B）可选择。&lt;/p&gt;
&lt;p&gt;在Technical Report 中一些和document-parse有关的内容：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在第一阶段视觉预训练中（仅训练ViT），针对&lt;strong&gt;Document Parsing&lt;/strong&gt;，设计了&lt;strong&gt;一套标准化的HTML标签体系&lt;/strong&gt;，包含：段落（&lt;code&gt;p&amp;gt;&lt;/code&gt;）、表格（&lt;code&gt;&amp;lt;table&amp;gt;&lt;/code&gt;）、图表（&lt;code&gt;&amp;lt;div class=&amp;quot;chart&amp;quot;&amp;gt;&lt;/code&gt;）、公式（&lt;code&gt;&amp;lt;div class=&amp;quot;formula&amp;quot;&amp;gt;&lt;/code&gt;）、图像标注（&lt;code&gt;&amp;lt;div class=&amp;quot;image caption&amp;quot;&amp;gt;&lt;/code&gt;）、OCR文本（&lt;code&gt;&amp;lt;div class=&amp;quot;image ocr&amp;quot;&amp;gt;&lt;/code&gt;）、乐谱（&lt;code&gt;&amp;lt;div class=&amp;quot;music sheet&amp;quot;&amp;gt;&lt;/code&gt;）、化学式（&lt;code&gt;&amp;lt;div class=&amp;quot;chemical formula&amp;quot;&amp;gt;&lt;/code&gt;）等模块。每个模块均通过 &lt;code&gt;data-bbox&lt;/code&gt; 属性标注其原始坐标位置，保留空间布局信息; 同时所有文档元素的布局信息（如位置、尺寸）通过原生分辨率下的绝对坐标直接编码到HTML标签中，使模型能同时学习内容语义和空间关系&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAG工具箱：RAG Tutorial for Beginner</title>
      <link>https://niraya666.github.io/posts/rag-tutorial-for-beginner/</link>
      <pubDate>Tue, 11 Mar 2025 19:24:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/rag-tutorial-for-beginner/</guid>
      <description>&lt;p&gt;一些适合入门的RAG材料&lt;/p&gt;
&lt;h2 id=&#34;原理科普&#34;&gt;原理、科普&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.promptingguide.ai/research/rag&#34;&gt;Retrieval Augmented Generation (RAG) for LLMs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://python.langchain.com/docs/concepts/rag/&#34;&gt;Langchain|Retrieval augmented generation (RAG)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cameronrwolfe.substack.com/p/a-practitioners-guide-to-retrieval&#34;&gt;A Practitioners Guide to Retrieval Augmented Generation (RAG)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.typingmind.com/rag-for-beginners/&#34;&gt;RAG for Beginners: The Complete Guide to Retrieval Augmented Generation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.datacamp.com/blog/what-is-retrieval-augmented-generation-rag&#34;&gt;What is Retrieval Augmented Generation (RAG)?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://python.langchain.com/docs/concepts/rag/&#34;&gt;Retrieval augmented generation (RAG)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;思考题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Why RAG？ RAG解决了什么问题？RAG和SFT如何选择？RAG的优势？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;什么样的问题是RAG无法解决的？什么样的数据适合使用RAG&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为什么要做chunking？chunk-size受那些因素制约？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;什么是embedding？向量库在做什么？一定要做语义匹配吗？什么是reranking？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何evaluate 检索效果的好坏 ？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RAG中，LLMs起到的作用？&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hands-on&#34;&gt;Hands-On&lt;/h2&gt;
&lt;h3 id=&#34;前置任务&#34;&gt;前置任务&lt;/h3&gt;
&lt;p&gt;获取模型服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;获得LLMs供应商API： 推荐 OpenRouter（仅LLMs，需要梯子，境外信用卡或Crypto），SilconFlow（LLMs+embedding,无需梯子,有送token），Groq（仅LLMs, 需梯子，速度快，免费）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;或采用本地部署： 推荐&lt;a href=&#34;https://ollama.com/&#34;&gt;Ollama&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例子,采用openRouter API实现LLM对话：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;openai&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenAI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OpenAI&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;base_url&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;https://openrouter.ai/api/v1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;api_key&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;lt;OPENROUTER_API_KEY&amp;gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;completion&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;completions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;openai/gpt-4o&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;What is the meaning of life?&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;completion&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;例子：基于本地ollama启动的deepseek R1（蒸馏版本）对话&lt;/p&gt;</description>
    </item>
    <item>
      <title>2025-02 月刊</title>
      <link>https://niraya666.github.io/monthly/2025-02-%E6%9C%88%E5%88%8A/</link>
      <pubDate>Fri, 28 Feb 2025 11:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/monthly/2025-02-%E6%9C%88%E5%88%8A/</guid>
      <description>&lt;h1 id=&#34;值得关注的模型和新技术&#34;&gt;值得关注的模型和新技术&lt;/h1&gt;
&lt;h2 id=&#34;o3-mini&#34;&gt;o3-mini&lt;/h2&gt;
&lt;p&gt;OpenAI o3-mini 是一款高效且成本优化的推理模型，专为科学（Science）、技术（Technology）、工程（Engineering）和数学（Mathematics）（STEM）领域优化。它在数学、编程和科学推理方面表现出色，能够在 AIME 2024 和 GPQA 等基准测试中达到或超过 OpenAI o1 的水平。o3-mini 具备三种推理模式（低、中、高），可根据需求在速度和准确性之间进行权衡。此外，它支持函数调用、结构化输出和视觉任务。相比 o1-mini，o3-mini 的响应速度提高了 24%，平均响应时间为 7.7 秒。它的上下文窗口为 200k tokens，输入成本为每百万 tokens 1.10 美元，输出成本为 4.40 美元。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/index/openai-o3-mini/&#34;&gt;OpenAI o3-mini&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;qwq-max-preview&#34;&gt;QwQ-Max-Preview&lt;/h2&gt;
&lt;p&gt;QwQ-Max-Preview是阿里巴巴Qwen系列的最新推理模型，基于Qwen2.5-Max架构开发，专注于提升数学、编码及多领域复杂问题的解决能力。该模型在LiveCodeBench代码评估中取得65.6分，超过OpenAI的o1中型模型（63.4分）和o3迷你低配版（60.9分），展现了卓越的代码生成与逻辑推理性能。其核心优势包括深度推理、Agent任务处理及通用领域适应性，特别适合需要实时响应的隐私敏感场景。作为预览版，QwQ-Max-Preview为后续开源版本铺路，未来将发布Apache 2.0许可证下的完整模型QwQ-Max及轻量级版本（如QwQ-32B），并计划推出iOS/Android端Qwen Chat应用以增强用户体验。阿里巴巴同时宣布未来三年投入530亿美元加强AI基础设施，进一步推动该模型在行业中的竞争力。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我们计划在不久的将来以 Apache 2.0 许可协议开源发布 QwQ-Max 以及 Qwen2.5-Max&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;官方blog：&lt;a href=&#34;https://qwenlm.github.io/zh/blog/qwq-max-preview/&#34;&gt;&lt;think&gt;&amp;hellip;&lt;/think&gt; QwQ-Max-Preview&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;claude-37-sonnet&#34;&gt;Claude 3.7 Sonnet&lt;/h2&gt;
&lt;p&gt;Claude 3.7 Sonnet 是 Anthropic 推出的首个“混合推理模型”，兼具快速响应和深入思考能力，能够根据任务需求在标准模式和扩展思考模式之间切换。其核心能力包括：在复杂任务中通过扩展思考模式进行详细分析和多角度考虑；在编码任务中表现出色，特别是在 SWE-bench Verified 测试中达到行业领先的 70.3%；支持多模态数据处理，展现强大的适应性；以及在 Amazon Bedrock 中提供可调整的推理预算，供开发者根据需求权衡速度、成本和性能。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.anthropic.com/news/claude-3-7-sonnet?utm_source=partner-aws&amp;utm_medium=referral&amp;utm_campaign=sonnet_3-7_launch&#34;&gt;Claude 3.7 Sonnet and Claude Code&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;grok-3&#34;&gt;Grok-3&lt;/h2&gt;
&lt;p&gt;Grok-3是由Elon Musk的xAI公司开发的第三代AI模型，具备2.7万亿参数和12.8万亿token的训练数据集，采用基于NVIDIA GPU的Colossus超级计算集群（20万张GPU）训练，计算能力比前代提升10倍。其性能表现优异，在MMLU（多任务语言理解）基准测试中达到92.7%，GSM8K（数学推理）89.3%，AIME 2025数学竞赛93.3%，GPQA科学推理84.6%。该模型支持128,000 token的上下文窗口（扩展版达100万token），响应延迟仅67毫秒，并具备多模态处理能力（文本、代码、图像）。独特功能包括DeepSearch实时网络研究代理、&amp;ldquo;Think&amp;quot;模式分步推理，以及&amp;quot;Big Brain&amp;quot;模式强化复杂问题解决，主要应用于STEM领域、代码生成和商业分析。目前通过X平台Premium+订阅（$40/月）和专属网站Grok.com提供访问，API接口即将开放。&lt;/p&gt;</description>
    </item>
    <item>
      <title>当AI开始展现&#34;顿悟时刻&#34;意味着什么</title>
      <link>https://niraya666.github.io/posts/%E5%BD%93ai%E5%BC%80%E5%A7%8B%E5%B1%95%E7%8E%B0%E9%A1%BF%E6%82%9F%E6%97%B6%E5%88%BB%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88/</link>
      <pubDate>Sun, 23 Feb 2025 23:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/%E5%BD%93ai%E5%BC%80%E5%A7%8B%E5%B1%95%E7%8E%B0%E9%A1%BF%E6%82%9F%E6%97%B6%E5%88%BB%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88/</guid>
      <description>&lt;h2 id=&#34;写在前面&#34;&gt;写在前面&lt;/h2&gt;
&lt;p&gt;本文是前段时间部门内技术分享的文字稿整理；&lt;/p&gt;
&lt;p&gt;主要包含2个方面：对于R1模型的简单科普，和开发团队的gen-AI使用指南；&lt;/p&gt;
&lt;p&gt;原以为春节假期能稍作休整，未曾料想deepSeek-R1在春节期间引发行业关注。节后复工，各层级领导便密集展开AI技术进展问询。&lt;/p&gt;
&lt;p&gt;原计划的&amp;quot;二月摸鱼指南&amp;quot;彻底落空，既要向管理层科普大语言模型技术原理，又要指正领导们被各种营销号洗脑所形成的错误认知；既要推进部门AI应用培训，又要加速系统上线进程；简直了，真是TM的谢谢 DeppSeek了。&lt;/p&gt;
&lt;h2 id=&#34;about-ds-r1&#34;&gt;About DS R1&lt;/h2&gt;
&lt;h3 id=&#34;什么是reasoning-model&#34;&gt;什么是Reasoning model&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；&lt;strong&gt;推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;In &lt;em&gt;Thinking, Fast and Slow&lt;/em&gt;, Daniel Kahneman defined System 1 as the automatic, intuitive mode of thinking, and System 2 as the slower, more analytical mode. In the context of autoregressive language models, the usual inference process is akin to System 1 — models generate answers directly. Reasoning is System 2 thinking - models or systems takes time to deliberate to solve more complex problems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>下洋：吃牛肉不止只有潮汕</title>
      <link>https://niraya666.github.io/travel/%E4%B8%8B%E6%B4%8B%E5%90%83%E7%89%9B%E8%82%89%E4%B8%8D%E6%AD%A2%E5%8F%AA%E6%9C%89%E6%BD%AE%E6%B1%95/</link>
      <pubDate>Tue, 04 Feb 2025 12:02:00 +0800</pubDate>
      <guid>https://niraya666.github.io/travel/%E4%B8%8B%E6%B4%8B%E5%90%83%E7%89%9B%E8%82%89%E4%B8%8D%E6%AD%A2%E5%8F%AA%E6%9C%89%E6%BD%AE%E6%B1%95/</guid>
      <description>&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;
&lt;p&gt;岁末年初,我随家中长辈踏访龙岩永定下洋镇。这座隐于闽粤交界的小镇于我们而言早有渊源——表妹昔年参加省际泳赛时,曾与当地少年结下一段水缘。正是这段萍水相逢的情谊,牵引着我们穿过蜿蜒山径,在爆竹声里叩开这座闽西小镇的门扉。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/305B62A0-F590-4665-BECB-C6B2BB22A7FB_1_105_c.jpeg&#34; alt=&#34;305B62A0-F590-4665-BECB-C6B2BB22A7FB_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;食肉&#34;&gt;食肉&lt;/h2&gt;
&lt;p&gt;下洋的牛肉滋味悄然攫住旅人的心神。虽未如潮汕牛肉般声名远扬,却自有一番山野的况味在舌尖流转。此地不饲黄牛,独以水牛入馔,经年累月的放养虽需时光的沉淀,却得肌理紧实如弦,脂少而肉丰。不同于黄牛肉那若隐若现的雪纹,水牛肉的肌纤维如琴弦般分明,在咀嚼间弹奏出质朴的韵律。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/70A41575-BDAD-481B-9D28-903FB2AF924A_1_105_c.jpeg&#34; alt=&#34;70A41575-BDAD-481B-9D28-903FB2AF924A_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;千锤百炼的牛肉丸堪称镇中绝艺,木杵起落间将肌理化作绕指柔,入口时竟生出云絮般的绵软,却又暗藏劲道。私心仍眷恋潮汕丸中跃动的纤维感,尤爱齿关破开肉丸时脂香在齿间迸裂的欢愉。然下洋的清汤亦非俗物,无论是现片的水牛肉汆汤,或是圆润的肉丸沉浮其间,总能在清而不寡的汤底里,尝出山岚水汽滋养的肌理——看似粗犷的纤维在文火慢煨中舒展,竟生出几分绸缎的柔滑,全无干涩之虞。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/0DF9F87A-79D6-4C8F-88CF-C46CF788E30A_1_105_c.jpeg&#34; alt=&#34;0DF9F87A-79D6-4C8F-88CF-C46CF788E30A_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;老饕们照例要碗肉沫拌面,配一盅牛肉清汤。现切的牛肉在刀刃起落间,水牛特有的粗纤维仍能在舌尖察觉,却已变得柔韧易嚼。肉片裹着若有似无的淀粉,锁住恰到好处的嫩滑,这般微妙火候,非得用本地师傅的巧劲才能拿捏——或许正是这份讲究,让下洋牛肉始终带着地域烙印。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/EB76A09C-2598-4FCE-85CB-BFEDD471BFE0_1_105_c.jpeg&#34; alt=&#34;EB76A09C-2598-4FCE-85CB-BFEDD471BFE0_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;宰牛的时辰多在清晨或者黄昏之时,以应早市与夜市所需;此地仍循古法宰牛解牛,在都市人眼中,这般场景未免过于粗犷直白。悬于铁钩的牛肉仍蒸腾着热气,残留的神经震颤犹自应和着心跳的余韵;这般未经排酸驯化的&amp;quot;活肉&amp;quot;,恰是当地人笃信的新鲜真谛。虽与潮汕牛肉同追本味之鲜,然此地牛肉虽按部位细分,却统一定价,倒也别具一番市井况味。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/0E36746F-7655-4A5C-BE63-5A93D6AE7835.jpeg&#34; alt=&#34;0E36746F-7655-4A5C-BE63-5A93D6AE7835.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;此地食牛之风盛行,尤重物尽其用之妙。席间尝遇全牛宴盛事,奈何只顾大快朵颐,竟忘了留影存念,今试凭味觉记忆描摹二三。&lt;/p&gt;
&lt;p&gt;首推牛肉片牛脊髓汤,较之寻常牛汤更添一段膏腴。白灼牛百叶与牛肉最见真章,非上品鲜货不敢如此素面朝天,薄切后以极简手法烹之,佐以秘制豉油,方不负这天地馈赠。最令人称奇者当属牛脊髓豆腐,滑若凝脂的质地与脑花豆腐堪称双璧。椒盐胸口油堪称席间至味,酥香盈口,然多食易生腻意。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/6CE52EEC-2B2B-4937-98DC-3CF371BF105D_1_105_c.jpeg&#34; alt=&#34;6CE52EEC-2B2B-4937-98DC-3CF371BF105D_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;饭后,点上一碗石花,这道形似冰粉的消暑佳品,沁人心脾的凉意最能化解油腻。所谓石花并非海石花,实乃晶莹剔透的爱玉冻,质地较之冰粉更似山间清泉。单食石花清雅素淡,仅余一缕若有似无的甘甜,唯有佐以浓醇的红糖绿豆汤,方显珠联璧合的妙处——琥珀色的糖浆裹着翡翠豆粒,与玉色石花相映成趣,方成就这道甜品的圆满境界。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/C1B250ED-9499-4309-8544-0B01EFA904F7_1_105_c.jpeg&#34; alt=&#34;C1B250ED-9499-4309-8544-0B01EFA904F7_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;温泉&#34;&gt;温泉&lt;/h2&gt;
&lt;p&gt;整条长街鳞次栉比地排列着温泉旅馆,温泉雾气滋养着这座小镇的旅游经济。行至街尾,略显斑驳的国营温泉度假酒店静立,虽价格不菲,却保留着旧时的体面。反观街边私营客栈,虽也殷勤待客,终是难掩设施简朴的窘态。这座声名在外的侨乡,仍镌刻着改革开放的春风初拂大地时,海外游子携资归乡的盛景。只是时光仿佛凝固在四十年前的琥珀里,连檐角褪色的琉璃瓦,都保持着当年初妆的模样。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/D3E726F7-D9D1-4D39-913C-34E0059BE1CF_1_201_a.jpeg&#34; alt=&#34;D3E726F7-D9D1-4D39-913C-34E0059BE1CF_1_201_a.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;结语&#34;&gt;结语&lt;/h2&gt;
&lt;p&gt;下洋，宛如一幅浸透乡土气息的画卷，牛肉与温泉交织成其独特的魅力。岁末的爆竹声在巷陌间此起彼伏,虽偶惊浅眠,倒恰成了这座小镇年俗画卷里最鲜活的钤印。对于那些钟爱牛肉的老饕们，下洋实乃值得踏访的味觉原乡。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;【和记牛肉丸】&lt;/p&gt;
&lt;p&gt;位置：G235永定区公安局下洋森林派出所东侧约100米&lt;/p&gt;
&lt;p&gt;【铭记石花】&lt;/p&gt;
&lt;p&gt;位置：沿河南路29号&lt;/p&gt;
&lt;p&gt;【阿敦大排档】&lt;/p&gt;
&lt;p&gt;位置：侨兴大道278号&lt;/p&gt;</description>
    </item>
    <item>
      <title>2025-01 月刊</title>
      <link>https://niraya666.github.io/monthly/2025-01-%E6%9C%88%E5%88%8A/</link>
      <pubDate>Mon, 27 Jan 2025 18:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/monthly/2025-01-%E6%9C%88%E5%88%8A/</guid>
      <description>&lt;h1 id=&#34;值得关注的新模型&#34;&gt;值得关注的新模型&lt;/h1&gt;
&lt;h2 id=&#34;deepseek-r1&#34;&gt;Deepseek R1&lt;/h2&gt;
&lt;p&gt;DeepSeek R1通过&lt;strong&gt;纯强化学习（RL）框架&lt;/strong&gt;实现了推理能力的突破，首次验证了无需依赖传统监督微调（SFT）或蒙特卡洛树搜索（MCTS）等复杂方法，仅通过两阶段RL优化即可显著提升模型逻辑推理性能。其综合能力直接对标OpenAI的o1模型，在数学（MATH-500达97.3%）、代码生成等核心指标上实现部分超越，同时&lt;strong&gt;全面开源模型权重、训练技术文档及6个蒸馏版本（1.5B-70B）&lt;/strong&gt;，使开发者可灵活适配不同算力场景。尤为引人注目的是，该模型在训练中展现出&lt;strong&gt;自发反思与多步骤验证能力&lt;/strong&gt;，研究者观察到其通过内部反馈机制主动修正推理路径的“顿悟时刻”，揭示了AI系统自我优化的新可能。此外，其研发成本仅为560万美元（基于2048块H800 GPU），相比同类模型降低1-2个数量级。&lt;/p&gt;
&lt;p&gt;技术报告: &lt;a href=&#34;https://arxiv.org/abs/2501.12948&#34;&gt;https://arxiv.org/abs/2501.12948&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Huggingface: &lt;a href=&#34;https://huggingface.co/deepseek-ai/DeepSeek-R1&#34;&gt;https://huggingface.co/deepseek-ai/DeepSeek-R1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一些基于和关于R1的开源复刻工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open-R1: &lt;a href=&#34;https://huggingface.co/blog/open-r1&#34;&gt;&lt;strong&gt;Open-R1: a fully open reproduction of DeepSeek-R1&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;RAGEN: &lt;a href=&#34;https://github.com/ZihanWang314/ragen/tree/main&#34;&gt;&lt;strong&gt;RAGEN: A General-Purpose Reasoning Agent Training Framework&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kimi-k1&#34;&gt;Kimi K1&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Kimi K1的核心创新在于通过强化学习驱动的多模态架构，首次实现端到端的视觉与推理深度融合。&lt;/strong&gt; 该模型突破传统分阶段处理模式，直接将图像输入与逻辑推演结合，支持模糊图像解析、手写题识别等复杂场景，并引入反思机制修正推理错误；其两阶段训练框架（预训练+强化学习规模化优化）显著提升思维链生成质量，使模型在数学、物理、化学等跨学科测试中超越国际主流视觉模型（如OpenAI o1）。&lt;/p&gt;
&lt;p&gt;Arxiv: &lt;a href=&#34;https://arxiv.org/abs/2501.12599&#34;&gt;Kimi k1.5: Scaling Reinforcement Learning with LLMs&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;qwen25-max&#34;&gt;Qwen2.5-Max&lt;/h2&gt;
&lt;p&gt;Qwen2.5-Max 是一款经过大规模预训练的专家混合（MoE）模型，训练数据量超过 20 万亿 tokens，并通过监督微调（SFT）和人类反馈强化学习（RLHF）进行优化。该模型在多个基准测试中表现优异，包括在 Arena-Hard、LiveBench、LiveCodeBench 和 GPQA-Diamond 等评估中超越了 DeepSeek V3，并在 MMLU-Pro 大学水平知识测试中展现出竞争力，同时在与其他领先模型（如 DeepSeek V3、GPT-4o 和 Claude-3.5-Sonnet）的对比中也表现突出。Qwen2.5-Max 已集成到 Qwen Chat，支持对话交互和功能体验，同时其 API（模型名称为 qwen-max-2025-01-25）已上线，用户可通过注册阿里云账户并激活相关服务进行调用。&lt;/p&gt;
&lt;p&gt;Blog: &lt;a href=&#34;https://qwenlm.github.io/blog/qwen2.5-max/&#34;&gt;https://qwenlm.github.io/blog/qwen2.5-max/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;qwen25-vl&#34;&gt;Qwen2.5-VL&lt;/h2&gt;
&lt;p&gt;Qwen2.5-VL是由阿里云通义千问团队于2025年1月28日推出的新一代视觉语言模型，专注于提升多模态处理与视觉理解能力。该模型具备五大核心功能：通过增强的视觉理解可识别常见物体并解析图像中的文本、图表及布局；作为视觉代理支持跨设备多步骤操作（如电脑修图、手机订票）；可精准定位超过1小时长视频的特定事件片段；通过生成边界框/点实现视觉定位并输出标准化JSON坐标；针对发票/表格等扫描件提供结构化数据输出，赋能金融商业场景。其创新架构采用动态FPS采样与时间维度mRoPE对齐技术，实现视频动态分辨率处理与时间序列学习，同时通过窗口注意力机制和SwiGLU-RMSNorm优化ViT编码器，保持与Qwen2.5大语言模型架构统一。模型提供3B、7B、72B三种参数规模。&lt;/p&gt;
&lt;p&gt;Blog: &lt;a href=&#34;https://qwenlm.github.io/blog/qwen2.5-vl/&#34;&gt;https://qwenlm.github.io/blog/qwen2.5-vl/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Huggingface: &lt;a href=&#34;https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct&#34;&gt;https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;qwen25-1m&#34;&gt;Qwen2.5-1M&lt;/h2&gt;
&lt;p&gt;Qwen2.5-1M系列模型是由Qwen团队于2025年1月27日发布的开源大语言模型，包含Qwen2.5-7B-Instruct-1M和Qwen2.5-14B-Instruct-1M两个版本，其核心突破在于支持高达100万Token的上下文处理能力。该模型通过三阶段技术实现长上下文支持：首先在预训练阶段采用Adjusted Base Frequency方法将RoPE基础频率提升至1000万，通过渐进式扩展策略将上下文从4K扩展到256K；随后在监督微调阶段采用短指令（32K）与长指令（256K）混合训练策略，平衡长短任务性能；最终通过创新性Dual Chunk Attention技术将上下文扩展至百万量级，该技术通过重映射超大相对位置值解决位置编码外推难题。为应对超长序列处理挑战，模型引入分块预填充技术（32K分块）降低显存消耗，结合稀疏注意力优化使百万级序列的精度损失显著降低，并通过算子效率优化和动态分块流水线并行实现3.2-6.7倍的预填充加速。在性能表现上，该系列模型不仅能在百万Token的&amp;quot;大海捞针&amp;quot;任务中精准检索信息，在RULER、LV-Eval等复杂长文本理解任务中超越前代128K版本，同时在短文本任务上保持与128K版本相当的性能，其中14B版本在保持GPT-4o-mini八倍上下文长度的前提下实现了相近的短文本处理能力。&lt;/p&gt;</description>
    </item>
    <item>
      <title>RLHF 之路：强化学习复习之上篇</title>
      <link>https://niraya666.github.io/posts/rlhf-%E4%B9%8B%E8%B7%AF%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0%E4%B9%8B%E4%B8%8A%E7%AF%87/</link>
      <pubDate>Thu, 23 Jan 2025 15:21:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/rlhf-%E4%B9%8B%E8%B7%AF%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0%E4%B9%8B%E4%B8%8A%E7%AF%87/</guid>
      <description>&lt;h2 id=&#34;写在前面&#34;&gt;写在前面&lt;/h2&gt;
&lt;p&gt;决定开启一个新系列，是时候系统性地学习一下 Alignment、RLHF 等相关内容了。&lt;/p&gt;
&lt;p&gt;学习过程中，经常会在一些公式推导上卡住，可能是因为之前的基础不够扎实，加上学过的内容遗忘较多。
于是，希望通过这一系列的笔记，帮助自己系统地回顾RL、和学习RLHF等内容。（顺带把之前手写的笔记电子化）&lt;/p&gt;
&lt;p&gt;主要的教材来自：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;a href=&#34;http://incompleteideas.net/book/RLbook2020.pdf&#34;&gt;Reinforcement Learning: An Introduction&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;B站UP主 shuhuai008 的系列推导视频&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本篇笔记将包含以下的内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;MDP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Monte Carlo Methods&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TD方法&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;马尔可夫决策过程markov-decision-processmdp&#34;&gt;马尔可夫决策过程(Markov Decision Process，MDP)&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;MDPs are meant to be a straightforward framing of the problem of learning from interaction to achieve a goal.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;相关概念&#34;&gt;相关概念&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;随机变量（Random Variance）&lt;/strong&gt;： ( $X, \ y, \ x \perp y$)，随机变量之间存在的独立性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;随机过程（Stochastic Process）&lt;/strong&gt;： ${S_t}_{t=1}^{\infty}$ 一个时间序列的随机变量集合，通常用来描述随着时间变化的状态。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Markov链/过程（Markov Chain/Process）&lt;/strong&gt;：强调了&lt;strong&gt;Markov性质&lt;/strong&gt;（Markov Property），即&lt;strong&gt;未来的状态仅依赖于当前状态而与过去无关&lt;/strong&gt;，形式化地表示为：&lt;/p&gt;
&lt;p&gt;$$
P(S_{t+1}|S_t, S_{t-1}, &amp;hellip;,S_1) = P(S_{t+1}|S_{t})
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;状态空间模型（State Space Model）：&lt;/strong&gt; Markov Chain + Observation； 如 HMM， Kalman Filter，particle Filter。&lt;/p&gt;</description>
    </item>
    <item>
      <title>2024年月度精选歌单汇总</title>
      <link>https://niraya666.github.io/musik/2024-%E6%AD%8C%E5%8D%95/</link>
      <pubDate>Sun, 19 Jan 2025 12:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/musik/2024-%E6%AD%8C%E5%8D%95/</guid>
      <description>&lt;p&gt;从2024年3月份之后，开始尝试构建每个月的精选歌单，为的是将一些和音乐有关的记忆存档，和记录一些让我眼前一亮的音乐。&lt;/p&gt;
&lt;iframe style=&#34;border-radius:12px&#34; src=&#34;https://open.spotify.com/embed/playlist/0CDpNxmeMlZ44uEPjjj0J6?utm_source=generator&#34; width=&#34;100%&#34; height=&#34;450&#34; frameBorder=&#34;0&#34; allowfullscreen=&#34;&#34; allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;
&lt;iframe style=&#34;border-radius:12px&#34; src=&#34;https://open.spotify.com/embed/playlist/7xtJgcGDlTxGnEO1jYwp0g?utm_source=generator&#34; width=&#34;100%&#34; height=&#34;450&#34; frameBorder=&#34;0&#34; allowfullscreen=&#34;&#34; allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;
&lt;iframe style=&#34;border-radius:15px&#34; src=&#34;https://open.spotify.com/embed/playlist/3SLnfD0aZWQvYhJlngqsH6?utm_source=generator&#34; width=&#34;100%&#34; height=&#34;450&#34; frameBorder=&#34;0&#34; allowfullscreen=&#34;&#34; allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;
&lt;iframe style=&#34;border-radius:12px&#34; src=&#34;https://open.spotify.com/embed/playlist/1QmQzNcu5zxjA6BGoaR3vA?utm_source=generator&#34; width=&#34;100%&#34; height=&#34;450&#34; frameBorder=&#34;0&#34; allowfullscreen=&#34;&#34; allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;
&lt;iframe style=&#34;border-radius:12px&#34; src=&#34;https://open.spotify.com/embed/playlist/2Xsf889pQZXddfnq9jF1HJ?utm_source=generator&#34; width=&#34;100%&#34; height=&#34;450&#34; frameBorder=&#34;0&#34; allowfullscreen=&#34;&#34; allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;
&lt;iframe style=&#34;border-radius:12px&#34; src=&#34;https://open.spotify.com/embed/playlist/59NQVa7T1cBZokI8bXgPjU?utm_source=generator&#34; width=&#34;100%&#34; height=&#34;450&#34; frameBorder=&#34;0&#34; allowfullscreen=&#34;&#34; allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;
&lt;iframe style=&#34;border-radius:12px&#34; src=&#34;https://open.spotify.com/embed/playlist/0sGtAzNzBkRuLg6FpEgqQX?utm_source=generator&#34; width=&#34;100%&#34; height=&#34;450&#34; frameBorder=&#34;0&#34; allowfullscreen=&#34;&#34; allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;
&lt;iframe style=&#34;border-radius:12px&#34; src=&#34;https://open.spotify.com/embed/playlist/4Tws2WJYczsgDXIfIHIAYY?utm_source=generator&#34; width=&#34;100%&#34; height=&#34;450&#34; frameBorder=&#34;0&#34; allowfullscreen=&#34;&#34; allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;
&lt;iframe style=&#34;border-radius:12px&#34; src=&#34;https://open.spotify.com/embed/playlist/5wsVrL1pkuglVcMcBnLcvI?utm_source=generator&#34; width=&#34;100%&#34; height=&#34;450&#34; frameBorder=&#34;0&#34; allowfullscreen=&#34;&#34; allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;
&lt;iframe style=&#34;border-radius:12px&#34; src=&#34;https://open.spotify.com/embed/playlist/7hoWMPwSASCb9li0eGHkM9?utm_source=generator&#34; width=&#34;100%&#34; height=&#34;450&#34; frameBorder=&#34;0&#34; allowfullscreen=&#34;&#34; allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;</description>
    </item>
    <item>
      <title>关于月刊的诞生</title>
      <link>https://niraya666.github.io/monthly/readme/</link>
      <pubDate>Thu, 09 Jan 2025 17:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/monthly/readme/</guid>
      <description>&lt;p&gt;这份月刊最初只是我的个人知识管理实验。过去一年里，我逐渐养成了每月底整理收藏夹的习惯——清理read-it-later 软件中里积压的链接，归档散落在各个平台的技术文章，把零碎的信息重新分类到Notion笔记中。&lt;/p&gt;
&lt;p&gt;面对每天涌现的新模型、论文和开源项目，这种月度整理成了对抗信息焦虑的锚点。与其被FOMO（错失恐惧症）驱使着追逐每个热点，不如让内容先经历时间筛选。留在月刊里的，通常是经过两周沉淀后仍值得反复阅读的内容。&lt;/p&gt;
&lt;p&gt;有三个主要原因推动我决定公开这些笔记：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;年初给自己定下的目标之一，多做一些public-writing，倒逼自己更认真地验证每个技术细节&lt;/li&gt;
&lt;li&gt;对抗数字囤积症&lt;/li&gt;
&lt;li&gt;如果能够帮助更多的人&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以，这个系列月刊将包含以下一些内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模型与技术&lt;/strong&gt;：一些新出的LLM，和相关技术&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;开源项目&lt;/strong&gt;：值得关注、有趣的、最近比较火的&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;研究和论文&lt;/strong&gt;：新出的论文以及我的阅读笔记(更多关注Agent、对齐、RAG、模型架构方面内容)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推荐内容&lt;/strong&gt;：可能是一些教程，工具、产品等&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;书摘&lt;/strong&gt;：正在阅读书籍文章的高亮内容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有次读到一段特别共鸣的话&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;你拿着相机在城市里穿行，看见一幕——光影交错，人情味流露。你按下快门。 没人关心。 但你并不是为了别人去做。你做，是因为你看到了什么。 写博客也是如此。你写，因为你思考，因为你观察，因为你需要一个“出口”来安放这些想法。 有人看吗？有就算赚到。没有也没关系。创作这件事，本身就已经完成了它的意义。 这才是重点所在。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这或许也是这一系列月刊的意义吧。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Milvus-2.5版本：学习笔记和备忘录</title>
      <link>https://niraya666.github.io/posts/milvus-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%92%8C%E5%A4%87%E5%BF%98%E5%BD%95%E4%BB%8E2.0-%E5%88%B02.5%E7%89%88%E6%9C%AC%E7%9A%84%E4%BB%8E%E5%A4%B4%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 25 Dec 2024 15:49:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/milvus-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%92%8C%E5%A4%87%E5%BF%98%E5%BD%95%E4%BB%8E2.0-%E5%88%B02.5%E7%89%88%E6%9C%AC%E7%9A%84%E4%BB%8E%E5%A4%B4%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;p&gt;几年前初识 Milvus 的契机，来源于开发一个图像相似检索的应用，当时市面上向量库的可选择项并不像现在这么多，且功能也仅限于单纯的向量检索。&lt;/p&gt;
&lt;p&gt;鉴于最近有业务更新的需要，和打算重构一下之前做的RAG项目，再次有机会深入学习 Milvus，探索其在新功能和实际应用上的更多可能性。&lt;/p&gt;
&lt;p&gt;本篇笔记，仅作为学习笔记，更多是记录一些 Milvus从2.0 到2.5 的变化， 和一些动手实践的记录，便于之后的查阅。&lt;/p&gt;
&lt;h2 id=&#34;一些概念&#34;&gt;一些概念&lt;/h2&gt;
&lt;h3 id=&#34;collections-schema-and-index&#34;&gt;Collections, Schema and index&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Collection&lt;/strong&gt;是Milvus中的一个二维表格，具有固定的列和可变的行。每一列代表一个字段(field)，每一行代表一个实体(entity)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Schema和字段&lt;/strong&gt; Collection需要一个schema来定义其结构&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;索引&lt;/strong&gt; 在特定字段上创建索引可以提高搜索效率。建议为服务所依赖的所有字段创建索引，其中向量字段的索引是必需的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分区(Partition)&lt;/strong&gt; 分区是Collection的子集，与其父Collection共享相同的字段集&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分片(Shard)&lt;/strong&gt; 分片是Collection的水平切片。每个分片对应一个数据输入通道。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shard vs Partition的区别&lt;/strong&gt; :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;分区(Partition)的作用是通过指定分区名称来减少读取负载&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;而分片(Shard)的作用是将写入负载分散到多个服务器&lt;strong&gt;分布式架构中的应用&lt;/strong&gt; 在分布式系统中，分片是实现水平扩展的重要机制。通过将数据分布到多个节点，可以充分利用集群的并行计算潜力，提高系统的写入性能&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;milvusclient-vs-connection&#34;&gt;&lt;strong&gt;MilvusClient vs Connection&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;MilvusClient&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定位&lt;/strong&gt;：更高级封装，提供一体化的操作接口。简化了与 Milvus 的交互流程， 提供更直观和结构化的操作方式，便于新手快速上手，内置了对连接的管理和操作，减少手动处理的复杂性。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pymilvus&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MilvusClient&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建客户端并连接到 Milvus&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MilvusClient&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;uri&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;http://localhost:19530&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建集合&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create_collection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;example_collection&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;schema&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;fields&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;vector&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;FLOAT_VECTOR&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;params&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;dim&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}}]}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 插入数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;insert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;example_collection&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;vector&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]})&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 搜索&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;example_collection&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Connection&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定位&lt;/strong&gt;：基础连接操作，需要通过 connect 方法创建并维护连接。提供更底层的控制，适合灵活、自定义的操作。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pymilvus&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;connections&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Collection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;FieldSchema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CollectionSchema&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建连接&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;connections&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;connect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;alias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;19530&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建集合&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;fields&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;FieldSchema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;vector&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;FLOAT_VECTOR&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;schema&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CollectionSchema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fields&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;example collection&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Collection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;example_collection&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;schema&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;schema&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 插入数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;insert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 搜索&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;search&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([[&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;anns_field&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;vector&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;limit&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;results&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;schema&#34;&gt;&lt;strong&gt;Schema&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Schema&lt;/strong&gt; 用于定义collection及其字段的属性&lt;/p&gt;</description>
    </item>
    <item>
      <title>读书笔记｜如何打造第二大脑</title>
      <link>https://niraya666.github.io/essay/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E5%A6%82%E4%BD%95%E6%89%93%E9%80%A0%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/</link>
      <pubDate>Sun, 17 Nov 2024 19:41:00 +0800</pubDate>
      <guid>https://niraya666.github.io/essay/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E5%A6%82%E4%BD%95%E6%89%93%E9%80%A0%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/</guid>
      <description>&lt;p&gt;去年疫情之后，我感觉记忆力明显下降，甚至一度担心会不可恢复。或许这也是年纪渐长的体现，只是我不愿意承认罢了。直到读到了一篇博文，了解了CODE信息管理框架，并因此接触到《第二大脑》这本书。虽然这本书并不长，但由于各种原因，今年我才真正开始阅读并实践。经过一年的探索，我决定整理这篇读书笔记，既是对书中理念的梳理，也是对个人实践的总结。&lt;/p&gt;
&lt;p&gt;值得一提的是，随着近年来大语言模型（LLM）的迅速发展，AI辅助可能会带来更高效的信息管理方式。&lt;/p&gt;
&lt;h2 id=&#34;信息过载的时代为什么需要笔记&#34;&gt;信息过载的时代，为什么需要笔记？&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;很多情况下，我们不过是一个个“人形存储器”，明明囤积了大量的心灵鸡汤，却反而让自己变得越发焦虑。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为什么要做笔记？在信息泛滥的今天，我们像“人形存储器”一样不断被信息填满，大脑的容量有限，信息过载只会增加焦虑。&lt;/p&gt;
&lt;p&gt;在25岁之前，我几乎不需要笔记，因为记忆力不错，而且接触的信息相对有限。工作后，尤其在AI领域，每天都被信息轰炸。尤其是ChatGPT问世后，信息的爆炸性增长让我常常感到FOMO（Fear of missing out，即错失恐惧症）：担心错过最新的模型、论文，或行业趋势。我习惯性地将感兴趣的网页放入同一窗口，但消化的速度远远跟不上积累的速度，导致未处理的内容堆积成山。&lt;/p&gt;
&lt;p&gt;我们无法容纳所有信息，因此需要新的信息管理方式——一个“第二大脑”。&lt;/p&gt;
&lt;p&gt;在《第二大脑》中，作者提出了“第二大脑”概念。这个概念的核心是解放大脑的记忆负担，将精力集中在创新上。为了实现这一目标，作者提供了一套实操框架，即“信管法则”CODE：抓取（Capture）、组织（Organize）、提炼（Distill）和表达（Express）。&lt;/p&gt;
&lt;h2 id=&#34;什么是信管法则-code&#34;&gt;什么是信管法则 CODE&lt;/h2&gt;
&lt;h3 id=&#34;1-信息抓取&#34;&gt;1. 信息抓取&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;因为普通人对于信息的利用并没有明确的规划，所以在信息的筛选问题上会显得有些无所适从。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;抓取信息的目的是捕捉对自己有意义的内容，而不是任意积累。有效筛选信息可以通过以下标准：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;信息抓取标准1：是否具有启发性&lt;/p&gt;
&lt;p&gt;信息抓取标准2：是否具有实用性&lt;/p&gt;
&lt;p&gt;信息抓取标准3：是否具有个性&lt;/p&gt;
&lt;p&gt;信息抓取标准4：是否具有新奇性&lt;/p&gt;
&lt;p&gt;信息抓取终极标准：是否让你为之共鸣&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从推荐系统的出现开始，可以看到现代人所面临的一个典型问题——&lt;strong&gt;信息茧房&lt;/strong&gt;。我们常常被动地接受信息，而非主动选择，导致思维越来越局限。这种信息茧房现象，使得我们只看到我们想看的，忽略了更多有价值的内容。在如今的&lt;strong&gt;注意力战争&lt;/strong&gt;中，我们的注意力被大量低质量的信息所吸引，而常常错过了高质量的信息。我们需要认识到，抓取信息的关键不在于多，而在于&lt;strong&gt;精&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;另外，抓取信息时要保持随时随地记录的习惯。无论是灵感闪现，还是对某篇文章的深刻思考，都应该马上记录下来，而不是随着时间逐渐遗忘。可以善用&lt;strong&gt;备忘录&lt;/strong&gt;、&lt;strong&gt;稍后阅读工具&lt;/strong&gt;等工具，以确保在需要时可以迅速获取信息。&lt;/p&gt;
&lt;h3 id=&#34;2-信息组织&#34;&gt;2. 信息组织&lt;/h3&gt;
&lt;p&gt;信息需要合理分类，以方便未来使用。相信我，你一定在备忘录中看到一些不知写的是什么的内容，或是看着收藏夹中多达上百条记录而不知所措，这时候你需要的是改变信息组织方式。&lt;/p&gt;
&lt;p&gt;作者推荐“以行动为导向”的PARA系统：项目（Projects）、领域（Areas）、资源（Resources）、存档（Archive）。这一系统的核心在于根据实际需求对信息进行分类存储，确保信息易于找到和利用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;PARA系统的运作机制：让你的思想（和笔记）向行动看齐&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在PARA系统中，每一条信息都可以被划入以下四大类别中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;项目（Projects）&lt;/strong&gt;：工作或生活中正在从事的短期活动；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;领域（Areas）&lt;/strong&gt;：致力于长期履行的责任；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;资源（Resources）&lt;/strong&gt;：具有潜在利用价值的课题或兴趣点；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;存档（Archive）&lt;/strong&gt;：除上述三项以外的休眠信息。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相比基于“信息来源”的组织方式，PARA系统以信息可能促成的结果为导向。这种方法可以让我们更加专注于将信息用于创造行动和产生价值，而不是无限期地积累信息。&lt;/p&gt;
&lt;p&gt;PARA系统的精髓在于：不要让信息变成无用的负担，而是让它们真正为你的行动服务。&lt;/p&gt;
&lt;h3 id=&#34;3-信息提炼&#34;&gt;&lt;strong&gt;3. 信息提炼&lt;/strong&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;毕竟笔记是要拿来用的，而不是当作收藏的。&lt;/p&gt;
&lt;p&gt;换言之，笔记的体量与可见性之间呈一种反比关系&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;去粗取精&lt;/strong&gt;。首先需要定义出“知识的骨架”。对原始文本进行分解，从过去一年来做的所谓“知识管理”有关的项目而言，这一部分的内容，更多的是将原始的文本进行分解，根据知识的骨架（schema），将各个分解而成的核心内容放置在各个位置上。例如，对于文献，可以使用来自cool-paper的论文分解框架：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;这篇论文试图解决什么问题？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有哪些相关研究？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;论文如何解决这个问题？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;……&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;渐进式归纳法&lt;/strong&gt;：渐进式归纳法的核心逻辑在于“断舍离”，而非“滴水不漏”。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;分层标注&lt;/strong&gt;。在这本书中，作者提出了渐进归纳法的文本高亮方法，以抓取和提炼出核心内容。具体而言，首先将文本的重点标记出，而后在重点中标记出重点的重点，以此类推。实操角度，例如收藏的一篇文章作为第一层级，而后在文章中以加粗的形式标记认为的重点，其次使用高亮标记将重点的重点标注出。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;用自己的语言重述&lt;/strong&gt;。最后一个层级，也是最重要且被绝大多数人所忽略的：用自己的语言将要点重现表述，并增加自己的理解。这有助于深刻掌握内容。&lt;/p&gt;
&lt;h3 id=&#34;4-表达与实践&#34;&gt;4. 表达与实践&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;If you&amp;rsquo;re thinking without writing, you only think you&amp;rsquo;re thinking.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;知识的价值是为了生产，而不是为了收藏。将所学转化为自己的语言并表达出来，才算真正掌握。可以从简单的记录入手，将零散的想法整理成文章或笔记，逐步积累，最终形成系统的表达。&lt;/p&gt;
&lt;p&gt;一开始，这可能会有些困难，但可以从简单的句子开始，慢慢汇总这些“半熟素材”。可以从记录在备忘录中的一段核心想法，或是社交媒体上几百字的感想出发。当积累到一定程度后，完成一篇长的文章也不再是一件困难的事。&lt;/p&gt;
&lt;p&gt;我非常喜欢18世纪哲学家维柯的一句名言：“Verum ipsum factum”，翻译过来就是“真理不外乎创造”。只有通过自己的语言，将内容重新展示和表达出来，无论形式如何，才是真正的“学会了”。&lt;/p&gt;
&lt;h2 id=&#34;关于创新和创造力和自我表达&#34;&gt;关于创新和创造力和自我表达&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;创新型人才更加善于识别、笼络和联结各种关系。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;创新型人才更加善于识别、笼络和联结各种关系。他们能够从看似无关的事物中找到潜在的联系，并形成解决复杂问题的创造性路径。这种特质源于他们在“发散”和“聚合”思维上的高度敏感和平衡：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;发散思维：&lt;/strong&gt; 开放的心态，能够接纳多种可能性和观点。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Agent 学习笔记：框架 ｜ openAI Swarm</title>
      <link>https://niraya666.github.io/posts/agent-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%A1%86%E6%9E%B6--openai-swarm/</link>
      <pubDate>Mon, 11 Nov 2024 11:10:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/agent-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%A1%86%E6%9E%B6--openai-swarm/</guid>
      <description>&lt;h2 id=&#34;开篇&#34;&gt;开篇&lt;/h2&gt;
&lt;p&gt;“CloseAI” 终于又开源了新的项目，可惜OpenAI明确表示，Swarm是一个实验性框架，主要用于教育目的，不适合生产环境，也没有官方支持。不过从这样一个实验性的框架，至少能够了解到OpenAI对于Agent上的一些理解，对于Agent设计上能够有所帮助和借鉴。&lt;/p&gt;
&lt;h2 id=&#34;routines-and-handoffs&#34;&gt;Routines and Handoffs&lt;/h2&gt;
&lt;p&gt;根据&lt;a href=&#34;https://cookbook.openai.com/examples/orchestrating_agents&#34;&gt;openAI cookbook: &lt;strong&gt;Orchestrating Agents: Routines and Handoffs&lt;/strong&gt;&lt;/a&gt;**，**理解这个框架前首先需要理解的两个概念： &lt;strong&gt;Routines&lt;/strong&gt; 和 &lt;strong&gt;Handoffs&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The notion of a &amp;ldquo;routine&amp;rdquo; is not strictly defined, and instead meant to capture the idea of a set of steps. Concretely, let&amp;rsquo;s define a routine to be a list of instructions in natural language (which we&amp;rsquo;ll represent with a system prompt), along with the tools necessary to complete them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Routines（常规）&lt;/strong&gt;：是由一系列步骤构成的流程，可以理解为给定任务的执行步骤，包括对话系统中指令和所需工具的组合。从代码实现上，基本上就是围绕着openAI 的 &lt;code&gt;openai.chat.completions.create&lt;/code&gt;API的一系列内容， 对话、工具调用等。换句话说，routines只是具有对话+工具调用的chatbot，这也是openAI对于Agent的基础抽象。&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAG工具箱：Query Enhancement</title>
      <link>https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1query-enhancement/</link>
      <pubDate>Thu, 31 Oct 2024 16:04:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1query-enhancement/</guid>
      <description>&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;p&gt;首先，从最简单的RAG（Retrieval-Augmented Generation）谈起。&lt;/p&gt;
&lt;p&gt;RAG结合了信息检索与生成模型，先通过用户的原始问题query 在知识库中检索与相关的文档，再利用生成模型（如ChatGPT）生成回答。最简单的RAG版本通常被称为Naive-RAG，虽然Naive-RAG能够处理一些简单的问题，但在真实场景下，用户提出的问题往往更加复杂多样，远远超出系统最初设计的预期范围。&lt;/p&gt;
&lt;p&gt;在用户与RAG系统交互时，往往会遇到以下几种常见问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;表达模糊不清&lt;/strong&gt;：用户在描述问题时，往往难以精准表达自己的需求。他们可能仅使用几个词组或片段，导致系统难以理解用户的真实意图。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;依赖上下文&lt;/strong&gt;：用户的问题经常依赖之前的对话或背景信息，而系统只接收到当前的孤立问题，缺少关键的上下文支持，无法给出准确的答案。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;复杂多层次问题&lt;/strong&gt;：某些问题本身复杂，包含多个子问题或需要推理、逻辑分析。Naive-RAG依赖简单的关键词匹配或语义匹配，无法很好地处理这类复杂的需求。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9aQuery%20Enhancement-assets/image.png&#34; alt=&#34;image.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;面对这些挑战，Naive-RAG的局限性变得明显：仅仅依靠用户的原始query无法应对多样化的提问场景。那么，如何提升RAG系统的检索能力，增强对复杂问题的处理呢？这时就需要引入&lt;strong&gt;Query-Enhancement&lt;/strong&gt;技术。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Query-Enhancement&lt;/strong&gt;，顾名思义，是对用户的原始query进行增强处理。它的核心思想是：不要直接使用用户的原始query进行相关文档的检索，而是通过某种技术手段对query进行改写、扩展或优化，从而生成一个更适合检索的query。这种技术在不同场景下有不同的命名，如&lt;strong&gt;query rewrite&lt;/strong&gt;或&lt;strong&gt;query reformulation&lt;/strong&gt;，但核心目标都是一致的——根据用户的初始输入，生成一个更符合检索需求、更能提升查询准确性的新query。&lt;/p&gt;
&lt;p&gt;通过Query-Enhancement，可以解决许多Naive-RAG无法处理的问题。例如，针对模糊或简短的提问，增强后的query可以通过添加上下文或关键词来丰富信息内容；对于复杂的多层次问题，增强后的query可以拆解为多个子问题，逐步进行检索与推理。&lt;/p&gt;
&lt;p&gt;本文将深入探讨不同的Query-Enhancement技术方案，并分析这些技术如何根据原始query生成更高效的查询，帮助RAG系统在复杂场景下提供更精确的答案。&lt;/p&gt;
&lt;h2 id=&#34;query-rewrite&#34;&gt;Query Rewrite&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Because the original query can not be always optimal to retrieve for the LLM, especially in the real world&amp;hellip; we first prompt an LLM to rewrite the queries, then conduct retrieval-augmented reading.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Query Rewrite的目的是将用户模糊、不明确或不完整的查询转换为更适合检索的形式，以提升检索效率和准确性。&lt;/p&gt;
&lt;p&gt;仅使用原始query的缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;查询常常模糊、不具体或不完整，导致难以找到有效的检索结果。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;缺乏明确术语，无法有效从大型数据集中提取相关信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对话上下文中的查询含义因对话历史而异，同样的表达在不同的上下文中可能有不同的意图。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;输入文本与真正需要检索的知识之间不可避免地存在差距。这种差距限制了检索性能，增加了对检索能力增强和提示工程的依赖。&lt;/p&gt;
&lt;p&gt;为了解决这些问题，检索器之前增加了一步对输入进行改写的过程，填补给定输入与检索需求之间的差距。这一步利用了LLM本身的能力对原始查询进行有针对性的改写。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9aQuery%20Enhancement-assets/image%201.png&#34; alt=&#34;image 1.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;比如，来自&lt;a href=&#34;https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/query_transformations.py&#34;&gt;RAG_Techniques&lt;/a&gt; 的这段prompt：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;query_rewrite_template&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;You are an AI assistant tasked with reformulating user queries to improve retrieval in a RAG system. 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        Original query: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{original_query}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        Rewritten query:&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使LLM可以更加系统地将用户的原始查询改写为更符合检索需求的形式。&lt;/p&gt;</description>
    </item>
    <item>
      <title>食在大马</title>
      <link>https://niraya666.github.io/travel/%E5%A4%A7%E9%A9%AC%E6%B8%B8%E8%AE%B02024/</link>
      <pubDate>Tue, 22 Oct 2024 20:02:00 +0800</pubDate>
      <guid>https://niraya666.github.io/travel/%E5%A4%A7%E9%A9%AC%E6%B8%B8%E8%AE%B02024/</guid>
      <description>&lt;h2 id=&#34;写在前面&#34;&gt;写在前面&lt;/h2&gt;
&lt;p&gt;2024年的国庆假期，第一次带父母踏出国门，目的地定在了马来西亚。挑选这个地方，并非偶然，既因为语言上的便利，也因对食物多样性的向往。对于第一次尝试出国旅行的新手来说，这样的选择再合适不过了。尤其是对于福建闽南人，马来西亚似乎有着一种熟悉而温暖的亲切感。&lt;/p&gt;
&lt;p&gt;行程从厦门出发，飞往槟城，然后搭乘火车前往怡保，再一路南下至吉隆坡，最终从吉隆坡返回故乡。虽说只是短短数日的旅行，但沿途的风景与美食却像是一条无形的丝线，将我们一家人与这片热带土地紧紧相连。&lt;/p&gt;
&lt;p&gt;此次游记，我尝试以“食物”为线索，串联起整个旅程的记忆。或许有些挑战，但也正是这种不同于以往的记录方式，让整个旅程多了些许味觉上的探险色彩。&lt;/p&gt;
&lt;h2 id=&#34;海南没有海南面包和海南鸡&#34;&gt;海南没有海南面包和海南鸡&lt;/h2&gt;
&lt;p&gt;槟城位于马来西亚西北，分成槟岛和威省两部分，作为东南亚重要的贸易港口之一，槟城自18世纪以来便吸引了无数移民，马来人、华人、印度人和欧洲人的足迹在这里留下了不可磨灭的印记，因其多元文化和历史，槟城的首府乔治市（George Town）也被联合国教科文组织纳入人世界文化遗产地。&lt;/p&gt;
&lt;p&gt;第一站是【多春茶室】。尽管其老店名声在外，但为了避开人群，我们选择了位于旧关仔角钟楼附近的分店。清晨9点到达时，茶室内还未拥挤，扫码点餐的现代化模式也让整个过程更加方便。&lt;/p&gt;
&lt;p&gt;点餐是件有趣的过程。面包、抹酱、饮品，一步步选择下来，经典的烤海南面包加上浓郁的咖椰酱，搭配香浓的Kopi-O，让这平凡的早餐充满满足感。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/6F734170-B982-4F62-934A-22FF8C6CCE86_1_105_c.jpeg&#34; alt=&#34;6F734170-B982-4F62-934A-22FF8C6CCE86_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;烤海南面包加上咖椰酱&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;有趣的是，海南面包源自南洋，并非来自海南本土。早年海南人漂洋过海来到南洋，受雇于英国人家庭和西化的峇峇家庭做帮佣，学习了西方的烘焙技艺，结合本地口味，创造出了适合东南亚人的海南面包。这些经历使他们将西式的咖啡与面包融入本地，逐渐普及成为南洋的经典早餐文化。&lt;/p&gt;
&lt;p&gt;当然，当地人早餐常吃的生熟蛋也是值得一试的， 鸡蛋泡在热水中几分钟，蛋白微凝固但仍带液态，蛋黄保持流动感，吃时只需加入酱油和白胡椒调味，用勺子轻轻搅拌，也可以蘸面包吃。如果不习惯生鸡蛋，店家还贴心地提供了不同熟度的选择。&lt;/p&gt;
&lt;p&gt;在这家店，店主还提供了4RM一个椰浆饭供食客自取，经典的江鱼仔鸡蛋口味，对于第一次尝试椰浆饭的人而言，味道的确很奇特。sambal辣酱并没有想象中那么辣，带有一丝丝的甜味，米饭也是经过调味的。&lt;/p&gt;
&lt;p&gt;茶室不远处便是槟城的地标——旧关仔角钟楼。钟楼由著名华商张弼士捐资修建，以纪念维多利亚女王登基60周年。与钟楼相邻的康华丽斯堡则是另一个标志性景点，虽名为堡垒，实未参与战斗。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/F8C5900A-FE98-4DCF-8B04-E73A9CB9A30C_1_201_a.jpeg&#34; alt=&#34;F8C5900A-FE98-4DCF-8B04-E73A9CB9A30C_1_201_a.jpeg&#34;  /&gt;

&lt;em&gt;旧关仔角钟楼&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;乔治市的街道以交叉十字贯穿各个文化区域。从小印度区入至华人区，再到马来区，都是一幅幅独特的文化画卷。右边为殖民时期的建筑，左侧则是古朴的华人会馆；再往前走，便是色彩斑斓的印度庙宇了。恍惚间，仿佛还能看到那些早年南来的移民，提着皮箱穿过狭窄的街巷，寻找着属于自己的一方天地。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/73FE20C9-AFC7-4F90-BCD9-6980BDE26F13_1_105_c.jpeg&#34; alt=&#34;73FE20C9-AFC7-4F90-BCD9-6980BDE26F13_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;吉宁甲必丹回教堂&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;槟城的美不止于其自然风光，而在于文化的碰撞与融合。早期移民将家乡味道带入南洋，创造出诸如海南鸡饭这样的经典。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/E399B1CB-F4F0-4639-86E7-A6F3F8C91BFC_1_201_a.jpg&#34; alt=&#34;E399B1CB-F4F0-4639-86E7-A6F3F8C91BFC_1_201_a.jpg&#34;  /&gt;

&lt;em&gt;伍秀泽海南鸡饭茶室&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;午后，我们寻觅到【伍秀泽海南鸡饭茶室】。这家茶室外观简单得甚至有些不起眼，但店里却充满着人间烟火气息。菜单也十分简单：白切鸡、烧鸡、鸡杂和鸡油饭。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/48AD27F9-8A94-4558-A87E-334128902AB1_1_105_c.jpeg&#34; alt=&#34;48AD27F9-8A94-4558-A87E-334128902AB1_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;海南鸡饭&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;鸡肉鲜嫩多汁，配上油光闪亮的鸡油饭，再添一勺微辣的辣椒酱，与黄瓜片相伴，让人回味无穷。&lt;/p&gt;
&lt;p&gt;一杯槟城特有的冰豆蔻水，为这丰盛的一餐画上美丽的句号，而在槟城的每一次咀嚼，都是对过去的重温。&lt;/p&gt;
&lt;p&gt;○○○&lt;/p&gt;
&lt;p&gt;【多春茶室】&lt;/p&gt;
&lt;p&gt;位置：37, Bishop St, Georgetown, 10200 George Town, Penang, 马来西亚&lt;/p&gt;
&lt;p&gt;营业时间：08:30-16:30 （周四店休）&lt;/p&gt;
&lt;p&gt;【伍秀泽海南鸡饭茶室】&lt;/p&gt;
&lt;p&gt;位置：340, Lbh Chulia, George Town, 10200 George Town, Pulau Pinang, 马来西亚&lt;/p&gt;
&lt;p&gt;营业时间：10:00-17:00 （周三店休， 周末营业时间延后一小时）&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;粿条和饮料&#34;&gt;粿条和饮料&lt;/h2&gt;
&lt;p&gt;粿条，本是潮汕人乃至闽南人对于米制面条的称呼。粿条的形式多种多样，既可以用来做汤，也可以干拌或者炒制。其中，最为著名的当属炒粿条。&lt;/p&gt;
&lt;p&gt;炒粿条的名字源自福建话“Char Kway Teow”。虽然它发源于潮州，但在潮州并不流行像马来半岛那样使用重酱油、鱼露，或加入血蚶的风味。&lt;/p&gt;
&lt;p&gt;几代人的迁徙流传，使得最初的潮汕炒粿条逐渐演变成如今的槟城炒粿条。在今天的马来半岛，各地的茶餐室、路边摊甚至食阁中，随处可见这一道菜。当地华人适应了赤道气候，也逐渐偏爱浓烈的口味，将黑酱油和鱼露加入其中，使其味道与原先的潮汕风味逐渐拉开了距离。&lt;/p&gt;
&lt;p&gt;槟城的炒粿条以其丰富的本地特色而闻名，以至于“槟城炒粿条”如今已然成为马来西亚外的“炒粿条”代名词。也许正是槟城人所炒的粿条充满了独特风味，让其从冠以“潮州”的乡土印记中脱颖而出，成为一种具有浓厚本地色彩的代表。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/6762BC7A-C04B-4F8A-B9DC-3E5BA158D640_1_105_c.jpeg&#34; alt=&#34;6762BC7A-C04B-4F8A-B9DC-3E5BA158D640_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;Char Kway Teow&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>2024-大马轨道交通攻略</title>
      <link>https://niraya666.github.io/travel/%E5%A4%A7%E9%A9%AC%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A%E6%94%BB%E7%95%A5/</link>
      <pubDate>Mon, 14 Oct 2024 20:02:00 +0800</pubDate>
      <guid>https://niraya666.github.io/travel/%E5%A4%A7%E9%A9%AC%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A%E6%94%BB%E7%95%A5/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;国庆期间，在西马玩了快一个礼拜，期间体验了从北海到怡保的ETS、槟城的升旗山登山缆车，还有吉隆坡复杂多样的轨道交通系统。旅行中，我踩过一些坑，也解锁了一些便利的玩法。经过查阅不少攻略，加上实地探索和切身体会，我决定将这次旅途中的交通攻略整理成这篇文章，分享给大家。&lt;/p&gt;
&lt;p&gt;注：本文所包含的信息有效截止至2024年10月，同时主要讨论西马（马来半岛）的轨道交通；希望能对你的大马之旅有所帮助。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;大马铁路概述&#34;&gt;&lt;strong&gt;大马铁路概述&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;马来西亚的铁路系统起源于19世纪末的英国殖民时期，当时的铁路主要是为了支持锡矿业和橡胶种植园的经济发展。第一条铁路于1885年建成，连接了太平和砵威港口（今称为瓜拉十八丁），而太平是当时霹雳州英国人的行政中枢。这条铁路的建设是为了便于将矿产资源从内陆运输到港口。此后，英国殖民政府开始加快在马来亚各地开辟铁路的步伐，主要目的是为了促进殖民地经济发展，例如吉隆坡至巴生的铁路于1886年建成通车，芙蓉至波德申的铁路于1891年建成通车，吉隆坡至万挠的铁路于1892年建成通车，安顺至打巴路的铁路于1893年建成通车。1895年，受英国保护的雪兰莪、森美兰、霹雳和彭亨四州组成马来联邦。当时马来亚不同州的铁路各自发展，没有一个统一的规划和管理机构，于是殖民政府当局在1901年成立了马来联邦铁路（FMSR），统合管理马来西亚半岛上各地包括马来联邦、马来属邦、海峡殖民地的铁路。这些初期建设的米轨铁路成为连接各主要城镇和经济区的重要交通工具。&lt;/p&gt;
&lt;p&gt;20世纪初，马来西亚的铁路网迅速扩展，最重要的两条干线为东海岸线和西海岸线。二战期间，铁路遭到日军的严重破坏，但战后得到了重建。1948年，马来联邦铁路被改组为马来亚铁路（MR）。1963年，马来亚、新加坡、砂拉越和沙巴组成了新的联邦国家——马来西亚（新加坡于1965年退出），马来亚铁路的官方名称也更改为马来语“Keretapi Tanah Melayu”（KTM）。&lt;/p&gt;
&lt;p&gt;现如今，马来西亚的铁路系统主要由两条干线组成：西海岸线和东海岸线。东海岸线（也称金马士－道北铁路）由马来亚铁道运营，起自金马士，途经吉兰丹、彭亨、森美兰，穿越马来半岛中部，全长528公里，最终到达泰国边境的道北。虽然名为东海岸线，但大部分路段穿行于内陆丛林地带，因此又被称为“丛林铁路”，吸引许多背包客体验。西海岸线则起自泰国边境的巴东勿刹，沿西海岸一直延伸至柔佛的南端，通过新柔长堤连接新加坡，全长950公里，途经包括吉隆坡在内的八个州属，是马来西亚铁路运输的重要交通大动脉。由国有企业马来亚铁道公司（KTMB）运营的铁路系统经过了多次改组和现代化，如今的铁路服务已经涵盖了从通勤列车到高速城际列车的多种交通模式。目前，马来西亚铁路系统不仅联通国内主要城市，还连接着泰国和新加坡，是东南亚地区重要的交通枢纽。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/b90015596a676e51d6df9b98736e90da.jpg&#34; alt=&#34;b90015596a676e51d6df9b98736e90da.jpg&#34;  /&gt;

&lt;em&gt;&lt;a href=&#34;https://www.pinterest.com/pin/ktm-the-620km-east-coast-rail-route-ecrr--834010424715426579/&#34;&gt;来源&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;铁路分类&#34;&gt;&lt;strong&gt;铁路分类&lt;/strong&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;KTM Komuter（城际通勤列车）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;KTM Komuter是由马来亚铁道公司（KTM）运营的通勤铁路服务，最初于1995年在巴生谷地区启用，后于2015年扩展至北部各州（如霹雳、槟城、吉打和玻璃市）。该服务连接了吉隆坡及其周边郊区，还服务于槟城和其他北部州属，总长度约456公里，包含芙蓉线、巴生港线等多条线路。KTM Komuter的列车是空调电力列车，并提供便捷的“停车换乘”设施，适合游客和通勤者方便进入市区，避免交通拥堵。KTM通勤铁路还为乘客提供多种票务选项，包括通过KTMB移动应用程序购买手机票（二维码）、Touch &amp;rsquo;n Go（仅限巴生谷地区）、自动售票机与车站售票柜台购票。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ETS（电动列车服务）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ETS（Electric Train Service）是由马来亚铁道公司运营的快速城际电力动车组服务，于西海岸线运行，连接金马士与巴东勿刹，全长950公里。ETS是马来西亚最快的米轨列车，速度可达每小时140公里，属于准高速铁路。列车分为Gold、Silver、Platinum 以及 Express 4种等级，分别对应不同的服务和票价，是前往怡保、槟城等城市的高效方式。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;KTM Intercity（城际列车）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;KTM Intercity是马来亚铁道运营的柴油牵引城际列车服务，覆盖马来半岛的南部地区、新加坡以及泰国。部分列车主要运行于东海岸线金马士至道北之间，并延伸至新加坡。2021年4月推出了柴油动车组（DMU）列车，取代了原有的传统列车，服务于东海岸的丹绒至吉利地段。DMU列车配备现代化设施，包括集群座椅、LED显示屏、电源插座、祈祷室、厕所、小餐馆及行李存储空间，并有无障碍设施，满足残障人士的需求。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;如何购买火车票&#34;&gt;&lt;strong&gt;如何购买火车票&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;购买火车票的方式有多种，最为方便的是通过KTMB官方网站或手机应用程序进行在线购买。也可以在吉隆坡中环车站（KL Sentral）及其他主要车站直接购票，但热门线路的车票在高峰时期（如假日、周末）可能会售罄，建议提前预订。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/%e6%88%aa%e5%b1%8f2024-10-13%20%e4%b8%8b%e5%8d%887.15.27.png&#34; alt=&#34;截屏2024-10-13 下午7.15.27.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/%e6%88%aa%e5%b1%8f2024-10-13%20%e4%b8%8b%e5%8d%887.16.04.png&#34; alt=&#34;截屏2024-10-13 下午7.16.04.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;以网上购买ETS车票为例，需在KTMB官网注册账号，然后选择出发和到达车站、以及对应的ETS车次类型（如Gold、Platinum、Express等）。不同级别的车次在停靠站数量和服务上有所不同，例如Platinum和Express级别提供商务座，商务座采用1+2的座位排布，包含免费食物和饮料，价格相对更高；普通席则是2+2的座位排布。Gold车次则没有商务座位。选择座位时，需要注意座位方向，有些座位是与行驶方向相反的，如果不喜欢反向乘坐，记得选择“forward”座位。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/%e6%88%aa%e5%b1%8f2024-10-13%20%e4%b8%8b%e5%8d%887.47.05.png&#34; alt=&#34;截屏2024-10-13 下午7.47.05.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;ETS列车的车型也有所区别，Platinum和Express列车多为较新款，由中国中车制造，而Silver级别列车则采用较老款，速度较慢，停靠站较多。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/7F6C6773-CA59-499B-93C2-2825C2DAE157_1_105_c.jpeg&#34; alt=&#34;7F6C6773-CA59-499B-93C2-2825C2DAE157_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;ETS-Express列车（摄于Butterworth车站）&lt;/em&gt;
&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/B03BE15A-8BF1-4709-BC16-4C95696ED6FE_1_105_c.jpeg&#34; alt=&#34;B03BE15A-8BF1-4709-BC16-4C95696ED6FE_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;ETS-Gold列车，采用旧款车型（摄于Ipoh车站）&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;吉隆坡轨道交通&#34;&gt;&lt;strong&gt;吉隆坡轨道交通&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;吉隆坡及其周边地区有完善的轨道交通系统，涵盖了多种轻轨和地铁线路。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/%e6%88%aa%e5%b1%8f2024-10-14%20%e4%b8%8b%e5%8d%887.56.41.png&#34; alt=&#34;截屏2024-10-14 下午7.56.41.png&#34;  /&gt;
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LRT（轻快铁）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LRT是吉隆坡的轻轨系统，包含3号 LRT Ampang Line、4号LRT Sri Petaling Line和5号LRT Kelana Jaya Line。LRT贯穿吉隆坡市中心及重要商业区，是游客前往市区景点如双子塔、茨厂街的首选交通工具。在高峰期，列车会非常拥挤。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/107EF1BC-2124-4F8E-BCEA-7027EA7E3C54_1_105_c.jpeg&#34; alt=&#34;107EF1BC-2124-4F8E-BCEA-7027EA7E3C54_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;5号线LRT，摄于Bangsar车站&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;3号LRTAmpang Line（橙黄色）&lt;/strong&gt;：占美清真寺，独立广场，ICC pudu等景点。&lt;/p&gt;</description>
    </item>
    <item>
      <title>2024 Can-festival：在海边 混杂着雨水和泪水 向后摇</title>
      <link>https://niraya666.github.io/travel/2024-can-festival-%E5%9C%A8%E6%B5%B7%E8%BE%B9-%E6%B7%B7%E6%9D%82%E7%9D%80%E9%9B%A8%E6%B0%B4%E5%92%8C%E6%B3%AA%E6%B0%B4-%E5%90%91%E5%90%8E%E6%91%87/</link>
      <pubDate>Wed, 25 Sep 2024 13:32:00 +0800</pubDate>
      <guid>https://niraya666.github.io/travel/2024-can-festival-%E5%9C%A8%E6%B5%B7%E8%BE%B9-%E6%B7%B7%E6%9D%82%E7%9D%80%E9%9B%A8%E6%B0%B4%E5%92%8C%E6%B3%AA%E6%B0%B4-%E5%90%91%E5%90%8E%E6%91%87/</guid>
      <description>&lt;p&gt;第一次来到舟山，仅仅是因为Can-festival音乐节。&lt;/p&gt;
&lt;p&gt;上次错过了越位音乐节，这次看到Can-festival的阵容，根本不可能再错过。光是Day2的阵容：We Lost the Sea、Lost in Kiev、The Seven Mile Journey、声子虫，几乎全是我播放器里多年循环的乐队。更别提Day3，This Will Destroy You和World’s End Girlfriend等老牌乐队，还有年初遗憾未能见到的四月雨。&lt;/p&gt;
&lt;h2 id=&#34;与普拉桑的极限拉扯&#34;&gt;与“普拉桑”的极限拉扯&lt;/h2&gt;
&lt;p&gt;出发前几天，台风“普拉桑”紧跟着前一个台风的步伐，直扑江浙沪，着实让我焦虑不已。临行的前一天，我每隔二十分钟就要刷新一次台风路径图，心里祈祷它能转向或加速离去。担心音乐节会取消，或是要在狂风暴雨中听音乐。不过，最终台风带来的破坏都留在了上海，而到了舟山，却意外地迎来了晴朗的天气。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/2024-Can-festival/DE10C0BD-A093-45EE-B67F-421C767FE234.jpg&#34; alt=&#34;DE10C0BD-A093-45EE-B67F-421C767FE234.jpg&#34;  /&gt;

&lt;em&gt;暴雨中的南浦大桥&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;后摇和雨更配&#34;&gt;后摇和雨更配&lt;/h2&gt;
&lt;p&gt;其实，我一向讨厌下雨。但谁能想到，在海边，后摇与风雨竟如此契合。或许，这正是音乐的魔力。雨水肆意洒落，浸湿了镜片，视线模糊不清，分不清脸上的水滴究竟是从天而降，还是心底涌出的泪水。音乐与环境的交织，给了我一种难以言喻的感动。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/2024-Can-festival/8E78A7AB-8588-4165-B71F-261E284C1E51_1_105_c.jpeg&#34; alt=&#34;8E78A7AB-8588-4165-B71F-261E284C1E51_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;海边&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当安尼西亚说这首歌是献给孩子，愿这个世界没有伤害时，我的心突然被一种无法抑制的情感击中。或许我们无法阻止每一个悲剧的发生，但在音乐的陪伴下，我希望这个世界能逐渐变得更加温暖。愿这首《离别》不仅仅是一首哀歌。&lt;/p&gt;
&lt;p&gt;Lost in Kiev 在合成器音色和处理上，确实惊艳到我了。不过，他们的贝斯手长的真的好像萨拉赫。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/2024-Can-festival/ABF036E9-FBF3-4B73-9B8F-6804C5FFBEBD_1_105_c.jpeg&#34; alt=&#34;ABF036E9-FBF3-4B73-9B8F-6804C5FFBEBD_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;Lost in Kiev&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;LITE 的音乐在雨中展现出了出乎意料的活力。即使雨水不停，现场的每个人都随着节奏跳动，那种难以言喻的现场氛围，仿佛雨水并不再是困扰，而是与音乐共舞的一部分。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/2024-Can-festival/CEF4C784-5E96-402F-A73B-AD3ED115EF1F_1_105_c.jpeg&#34; alt=&#34;CEF4C784-5E96-402F-A73B-AD3ED115EF1F_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;雨中的LITE&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;声子虫的音墙依旧厚重，像一座无形的高山压迫着我。正如去年看他们演出时的一样， 特别喜欢他们开场时的创意—随着音乐的铺垫进行， 在屏幕上，一笔一画地把“聲子蟲” 三个字缓慢打出。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/2024-Can-festival/46590887-7972-4CEF-A4F7-A40BF24EDAE4_1_105_c.jpeg&#34; alt=&#34;46590887-7972-4CEF-A4F7-A40BF24EDAE4_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;缺了最后一笔的“聲子蟲”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;一直期待We Lost the Sea的现场演出，但就在那时，吉他却出了问题。声音时有时无，让本该震撼人心的演奏显得有些破碎。雨水不停地落在身上，心情也随之变得复杂。一点小小的遗憾，像是雨中一滴未曾融入地面的水珠，总让人感到有些不完整。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/2024-Can-festival/BEA4ACE5-B17A-48FB-9E95-EE2BFA987988_1_105_c.jpeg&#34; alt=&#34;BEA4ACE5-B17A-48FB-9E95-EE2BFA987988_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;We Lost the Sea — by 群里的艺术家&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/2024-Can-festival/1EF13608-9B3E-4159-90C3-034AAD648C5D_1_105_c.jpeg&#34; alt=&#34;1EF13608-9B3E-4159-90C3-034AAD648C5D_1_105_c.jpeg&#34;  /&gt;

&lt;em&gt;The Seven Mile Journey — by 群里的艺术家&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;年纪渐长，似乎每次出门前都有更多的顾虑。年轻时我总能义无反顾地冲向每一个音乐节，不管是风雨还是其他未知的挑战，都觉得无所谓。然而这次，在雨中，我的脑海里浮现出更多的“如果”：如果天气更好一些，如果能再勇敢一些……我无法完全放下这些顾虑，哪怕台上的音乐依旧动人，我却发现自己没有像以前那样尽兴了。也许成长的代价，就是学会在更多的限制和考量中寻找自己的平衡。&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM 输出限制：Structured Outputs、受限编码和提示词工程</title>
      <link>https://niraya666.github.io/posts/llm-%E8%BE%93%E5%87%BA%E9%99%90%E5%88%B6structured-outputs%E5%8F%97%E9%99%90%E7%BC%96%E7%A0%81%E5%92%8C%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/</link>
      <pubDate>Wed, 21 Aug 2024 14:49:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/llm-%E8%BE%93%E5%87%BA%E9%99%90%E5%88%B6structured-outputs%E5%8F%97%E9%99%90%E7%BC%96%E7%A0%81%E5%92%8C%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/</guid>
      <description>&lt;p&gt;在使用大型语言模型（LLM）时，我们常常面临一个挑战：如何从模型输出中准确提取自己所需的信息。例如，当我们希望模型输出 JSON 格式的数据时，由于模型生成的内容并不总是稳定，可能需要额外编写大量的正则表达式来匹配并提取其中的有效信息。然而，由于 LLM 的能力，导致其输出结构并不永远可靠。&lt;/p&gt;
&lt;p&gt;现阶段， 让LLM按要求生成特定格式文本的主要方法有几种种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;微调：使模型的输出遵循特定格式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OpenAI Json-mode/Structured Outputs/function-calling:&lt;/strong&gt; 这些功能允许模型生成更严格、结构化的输出，但受限于openAI平台。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;格式约束&lt;/strong&gt;：在decoding阶段进行约束，限制模型的输出，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Engineering&lt;/strong&gt;： 最简单的办法，但不稳定。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多阶段prompting： 通过多个步骤的提示逐步引导模型生成所需的格式。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文将聚焦在Structured Outputs， 受限编码， 和prompt-engineering的角度，探讨它们在生成特定格式文本中的应用和效果。&lt;/p&gt;
&lt;h2 id=&#34;json-mode&#34;&gt;Json Mode&lt;/h2&gt;
&lt;p&gt;仅特定模型和平台支持&lt;/p&gt;
&lt;p&gt;以openAI 为例， 在&lt;code&gt;openai.chat.completions.create&lt;/code&gt; 参数中增加&lt;code&gt;response_format={&amp;quot;type&amp;quot;:&amp;quot;json_object&amp;quot;}&lt;/code&gt; 即可（具体参见：&lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat/create#chat-create-response_format&#34;&gt;response_format&lt;/a&gt; ）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;需要在prompt中要求输出json格式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不能保证完全按要求的格式结构输出&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但非100%成功率，存在一些需要额外检测和适当处理的edge case。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
  &lt;summary&gt;Handling edge cases&lt;/summary&gt;
  &lt;details&gt;
    &lt;summary&gt;根据OpenAI官方文档提供的处理方案&lt;/summary&gt;
    https://platform.openai.com/docs/guides/structured-outputs/json-mode
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;we_did_not_specify_stop_tokens&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;completions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;gpt-3.5-turbo-0125&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;You are a helpful assistant designed to output JSON.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Who won the world series in 2020? Please respond in the format {winner: ...}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;response_format&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;json_object&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Check if the conversation was too long for the context window, resulting in incomplete JSON &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finish_reason&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;length&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# your code should handle this error case&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Check if the OpenAI safety system refused the request and generated a refusal instead&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;refusal&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# your code should handle this error case&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# In this case, the .content field will contain the explanation (if any) that the model generated for why it is refusing&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;refusal&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Check if the model&amp;#39;s output included restricted content, so the generation of JSON was halted and may be partial&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finish_reason&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content_filter&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# your code should handle this error case&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finish_reason&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;stop&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# In this case the model has either successfully finished generating the JSON object according to your schema, or the model generated one of the tokens you provided as a &amp;#34;stop token&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;we_did_not_specify_stop_tokens&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;c1&#34;&gt;# If you didn&amp;#39;t specify any stop tokens, then the generation is complete and the content key will contain the serialized JSON object&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;c1&#34;&gt;# This is guaranteed to parse successfully and should now contain  &amp;#34;{&amp;#34;winner&amp;#34;: &amp;#34;Los Angeles Dodgers&amp;#34;}&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;c1&#34;&gt;# Check if the response.choices[0].message.content ends with one of your stop tokens and handle appropriately&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Your code should handle errors here, for example a network error calling the API&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;使用pydantic的方案&lt;/summary&gt;
    使用pydantic的方案
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pydantic&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;BaseModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;EmailStr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ValidationError&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# 定义你期望的 JSON 数据模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;UserModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BaseModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;email&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;EmailStr&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# 检查 JSON 是否符合模型的函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;validate_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# 将输入的 JSON 字符串转换为 UserModel 实例&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;UserModel&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parse_raw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# 如果验证通过，返回字典&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ValidationError&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;JSON validation error: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ve&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# 示例用法&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;{&amp;#34;name&amp;#34;: &amp;#34;John Doe&amp;#34;, &amp;#34;email&amp;#34;: &amp;#34;john.doe@example.com&amp;#34;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;validated_json&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;validate_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;validated_json&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;JSON is valid and conforms to the schema:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;validated_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;JSON is invalid.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/details&gt;
&lt;/details&gt;
&lt;p&gt;Json-Mode 更多是对于输出json的格式进行检查(即Json格式的有效性)&lt;/p&gt;</description>
    </item>
    <item>
      <title>翻译｜向下螺旋：《黑暗之魂》系列游戏中的后现代意识与佛教形而上学</title>
      <link>https://niraya666.github.io/essay/%E5%90%91%E4%B8%8B%E8%9E%BA%E6%97%8B%E9%BB%91%E6%9A%97%E4%B9%8B%E9%AD%82%E7%B3%BB%E5%88%97%E6%B8%B8%E6%88%8F%E4%B8%AD%E7%9A%84%E5%90%8E%E7%8E%B0%E4%BB%A3%E6%84%8F%E8%AF%86%E4%B8%8E%E4%BD%9B%E6%95%99%E5%BD%A2%E8%80%8C%E4%B8%8A%E5%AD%A6/</link>
      <pubDate>Thu, 15 Aug 2024 20:53:00 +0800</pubDate>
      <guid>https://niraya666.github.io/essay/%E5%90%91%E4%B8%8B%E8%9E%BA%E6%97%8B%E9%BB%91%E6%9A%97%E4%B9%8B%E9%AD%82%E7%B3%BB%E5%88%97%E6%B8%B8%E6%88%8F%E4%B8%AD%E7%9A%84%E5%90%8E%E7%8E%B0%E4%BB%A3%E6%84%8F%E8%AF%86%E4%B8%8E%E4%BD%9B%E6%95%99%E5%BD%A2%E8%80%8C%E4%B8%8A%E5%AD%A6/</guid>
      <description>&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;p&gt;本文探讨了“黑暗之魂”系列游戏在当代日本社会中的意义定位。我认为，这款游戏可以被看作是当今文化潮流的象征，就像有人可能会把杰克·凯鲁亚克的《达摩流浪者》视为60年代反文化的象征一样。&lt;strong&gt;我主张，“黑暗之魂”系列通过寓言的方式表达了人们在一个日常行为和社会本身的意义都变得极不稳定的时代中生活的焦虑&lt;/strong&gt;。游戏采用碎片化的叙事方式，融合了佛教的形而上学思想，并以描绘一个曾经辉煌的王国在最后时刻挣扎的阴森哥特式美学为背景。这种对当代社会焦虑的表达，与日本的后现代主义话语密切相关。通过将这些游戏视为文本、环境和游戏系统之间的反馈回路，我把这些游戏的主要概念主题与大泽真幸提出的“后虚构时代”概念，以及东浩纪对御宅族的定义联系起来。&lt;/p&gt;
&lt;h1 id=&#34;前言&#34;&gt;前言&lt;/h1&gt;
&lt;p&gt;在人文学科这个领域，我们认为艺术和文学不仅仅是艺术鉴赏。当我们阅读夏目漱石&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;或三岛由纪夫&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;的作品时，教授和学生不仅仅像粉丝那样陶醉于他们优美的文笔，而是作为评论家，从中挑出深刻的思想。通过这种方式阅读足够多的作品，我们会发现一种更宏大的东西：&lt;strong&gt;一个跨越时代和文化的思想洪流，在这个洪流中，生活的神秘、美丽、恐怖和悲剧汇聚成我们人类经验的漩涡和流动&lt;/strong&gt;。文学是指南，就像老话说的那样，是通向美好生活的指南：它是一面镜子，反映我们的位置，也是我们漫步时的地图。简而言之，伟大的作品让我们变得更强大。它们让我们清晰地面对生活的矛盾，并有勇气承受其重压。我们学习文学是为了找到人类经验中的共性，并将其内化。这至少是人文学科的理想和创立原则。&lt;/p&gt;
&lt;p&gt;但如果这是正确的，我们能说这种深刻的体验只是文学独有的吗？书面文字是否有某种独特的力量，能够以其他媒介无法企及的方式激发反思？最终，文学只是一个个故事，但故事并不局限于一种媒介。故事是跨媒介的。它们可以口头讲述，可以印刷，可以通过舞蹈、图像，甚至可能通过尚未构想的方式来讲述。这是因为故事首先存在于人类心灵的深层结构中，不同的媒介让这些结构的不同方面显现出来。&lt;strong&gt;故事是人类生活的核心，它们赋予我们的社会和个人生活以连贯性和意义。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;故事是个人身份的基石，人类将经验转化为故事的能力可能与我们感知时间的能力有关。&lt;strong&gt;毕竟，故事是什么？它是以有意义的方式组织和编辑时间&lt;/strong&gt;。简而言之，通过研究故事，特别是那些在社会想象中占据重要地位的故事，我们可以进入人类心灵的最深处。当我们接近这一神秘领域时，我们更接近自己，也许会找到一些我们遗忘的，对我们至关重要的东西，它像火药桶上的火花一样在我们脚下点燃，在这场大火中我们的世界观重生。&lt;/p&gt;
&lt;p&gt;新的媒介在大学里常常面临艰难，因为每种媒介都必须越过高文化裁决者的障碍&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;。这在二十世纪初的电影和摄影上是如此，在今天的漫画、电视和视频游戏上也是如此。但如果我们仅因为这些作品属于错误的媒介而忽视了沟口健二&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;的作品，人文学科会变得多么贫乏？偏重研究一种媒介而忽视其他媒介有什么好处？这种偏见是最糟糕的，我们都因这种武断的判断而变得贫乏。我们切断了自己探索那些激发我们深层结构的新视角的机会。故事在新的媒介中同样存在，此外，对那些在这些新媒介中成长的人来说，发现其中的故事是引人入胜、动人且深具意义的。视频游戏中的故事体验与其他媒介有着根本的不同，正是这种不同使得研究它们变得如此重要。它反映了一种新的世界观和价值观。我们不再生活在一个技术只是工具的世界里；技术是我们生活的环境。电影和电视是工业时代的本土媒介，而视频游戏是数字时代的本土媒介。视频游戏不是小众的。这个行业在全球产生的收入大大超过了电影和印刷品。这本身就使得研究它们成为紧迫的事情。&lt;/p&gt;
&lt;p&gt;话虽如此，我们必须认识到，视频游戏是一种新兴的媒介。就像早期的电影只是基本现象的再现——火车向屏幕疾驰或马在慢动作中奔跑——视频游戏的媒介中无疑有着尚未开发的巨大潜力。此外，我们还不能像理解文学那样全面理解这一媒介。我们还没有足够的时间去理解视频游戏在文化中可能扮演的角色以及它们对塑造我们的价值观和性格的影响。我不会在这里主张创建一个新的经典目录。现在还为时过早，而且流行经典化的过程早已在进行中。本文研究的游戏《黑暗之魂》系列已经被这样经典化了。它享有一种地位，其他同类游戏以它为标准，而那些共享其设计原则的游戏被称为“魂类游戏（Soul-like）”，这可能类似于许多文学或电影作品被描述为“卡夫卡式的”&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;。然而，我不会试图将这款游戏作为一部伟大作品来评估，以便将研究这一系列游戏制度化。我认为这些游戏被经典化不仅仅是因为它们“有趣”，而是因为它们直接处理了当代日本及其年轻一代面临的问题、焦虑和挑战。这是我们将要问的问题：&lt;strong&gt;这些游戏中反映了什么，使其在跨文化范围内以及在粉丝和评论家中产生如此深刻的共鸣？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我将在这里主要讨论日本，但我相信在研究这款游戏时得出的教训具有全球意义。目前，这些意义将保持原样。本质上，为了故事而玩游戏是一件矛盾的事情。游戏的内部组件，作为一个具象化的代码系统和作为不同类型叙事（文本、视觉、听觉）的载体，对玩家提出了一系列相互竞争的需求。这种矛盾在《黑暗之魂》中和几乎所有其他游戏中一样没有解决，但该系列在这些相互竞争的元素之间达到了罕见的一致性，可能直接反映了日常生活中数字世界的体验。我希望我在这里的分析，即使只是初步和不完整的，也能成为反思社会走向、新的价值结构的出现以及文学解释或在这种情况下的游戏解释可以对这些问题有所启示的机会。&lt;/p&gt;
&lt;h1 id=&#34;第一章引言&#34;&gt;&lt;strong&gt;第一章：引言&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;本文旨在探讨“黑暗之魂”系列游戏与当代日本社会状况之间的关系。我认为，“黑暗之魂”系列通过寓言形式表达了在一个日常行为意义甚至社会本身都变得不稳定的时代生活的焦虑。这一表达通过破碎的叙事方式实现，这种方式结合了佛教形而上学，并以描绘一个昔日伟大王国最后挣扎的阴暗哥特风格为背景。这种寓言中的焦虑与日本后现代性讨论密切相关，特别是现代性项目失败和进步叙事腐败的观点。在我的论文中，我认为这种讨论在“黑暗之魂”中通过模拟经典英雄之旅得以体现，但最终通过剥夺玩家的英雄成就感并用深深的模糊和不确定性取而代之，颠覆了这一旅程。&lt;/p&gt;
&lt;p&gt;“黑暗之魂”系列是一款第三人称动作RPG，其核心机制围绕探索一个破败的世界展开。该系列由著名日本游戏公司FromSoftware在总裁宫崎英高的指导下开发。第一款游戏于2011年9月发布，第三款于2016年4月发布。这是一款难度极高的游戏，设定在一个末世奇幻世界，要求玩家克服许多复杂的运动任务。游戏的一大特点是其缺乏具体的叙事阐述。然而，有一些概念性主题将这些游戏联系在一起。游戏中总是有一个被“不死诅咒”摧毁的王国，并且总是有神秘人物指示玩家杀死旧神并使用他们的灵魂来“连接火焰”。这个过程在第一款游戏中被解读为一个世界复兴过程，但在第二和第三款游戏中被揭示为不可避免的衰败螺旋。&lt;/p&gt;
&lt;p&gt;全球销量数百万，三部作品在国外几乎普遍获得好评，赢得了众多“年度游戏”称号和大量其他行业奖项。它对当代游戏设计产生了深远的影响，许多采用类似设计的游戏经常被称为“魂类”或“魂风格”。这已成为一种陈词滥调，类似于带有超现实或存在主义色彩的文学作品被描述为“卡夫卡式”。我认为其地位的原因并非游戏的“有趣”，而是它有一些关于我们今天所处世界的强有力表达，这些表达与那些对现代性的后现代批评观点一致的人产生共鸣。&lt;/p&gt;
&lt;p&gt;本文的核心论点是，“黑暗之魂”系列体现了具有后现代意识的生活体验。这个术语“后现代意识”是我用来总结后现代思想的一个总称。然而，我特别关注日本分支，引用了社会学家大泽真幸&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;、文化评论家东浩纪&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;、文学学者田中真纪子&lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;和小说家村上春树&lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;的著作。&lt;strong&gt;从弗朗索瓦·利奥塔&lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;（Francois Lyotard）开始——他首次提出“后现代”一词——后现代思想的不同分支的核心主张是，曾经用来指导社会的“大叙事”已经无可救药地破裂并且无法修复&lt;/strong&gt;。大泽和其他思想家拾起了这条思路，并将其应用到具体的日本背景。他们认为，日本战后时期的大叙事的破裂在年轻一代中引发了虚无主义行为，这种行为&lt;u&gt;表现为从政治原因和社区参与转向过度消费主义和一种表现为御宅族形象的媒体崇拜&lt;/u&gt;。在一些极端情况下，这种御宅族主义可能导致病态行为，如奥姆真理教&lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;的恐怖主义，但需要注意的是，这些思想家将这种暴力行为视为御宅族行为连续体的最外端，而不是在类别上有所不同。从大泽和东浩纪等后现代思想家那里，&lt;strong&gt;我将后现代意识提炼为两个基本特征：1. 拒绝或无法接受宏大叙事和意识形态作为意义的来源 2. 对“他者”的日益焦虑和敌意&lt;/strong&gt;。在这种情况下，他者指的是主体与他者之间的经典哲学二元关系；换句话说，就是自我与世界上所有其他自我之间的关系。&lt;u&gt;大叙事的破裂削弱了依赖这些叙事来维系和稳定的社区纽带和同胞感&lt;/u&gt;。这种意识是“黑暗之魂”系列设计和叙事的主要当代文化元素。&lt;/p&gt;
&lt;p&gt;然而，后现代意识在日本确实广泛传播，这并不是显而易见的。出于这个原因，我在第一章中追溯了大叙事在日本历史中逐渐瓦解的确切方式，从战后时期开始一直到现在。这使得我们能够看到后现代意识的发展及其在日本社会和“黑暗之魂”系列中的表达。没有这一步骤，就不可能识别贯穿这个系列的后现代意识。&lt;/p&gt;
&lt;p&gt;为了挖掘日本后现代意识的文化根源，我采用了大泽的文化时代精神理论，&lt;strong&gt;将战后时期分为三个阶段：意识形态时代（1945 - 1972），虚构时代（1972 - 1995）和后虚构时代（1995 - 现在）&lt;/strong&gt;。大泽在其作品中提出的基本观点是，意识形态的死亡——本质上是他对“宏大叙事”的术语——刺激了新的形式，这些形式最终使他们脱离了日本战后社会的意识形态基础。从1972年的联合赤军事件&lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;开始，激进的左翼政治让位于非政治的消费享乐主义。这导致了围绕显著消费形式尤其是时尚的亚文化的繁荣。然而，对一些人来说，对更深层意义的渴望仍然存在，这最终催生了新时代的邪教，即奥姆真理教，它们同样从传统宗教和动漫中汲取力量来满足这种需求。&lt;/p&gt;
&lt;p&gt;奥姆真理教的重要性在于他们既标志着传统信仰和意识形态的弱化，也标志着对任何被他们视为“他者”的事物的日益不容忍。他们还标志着一种对远在天边但又近在咫尺的敌对他者的偏执。例如，他们认为日本政府被全球犹太共济会阴谋控制，而他们自己的莲花团体则充满了双重间谍。他们在1995年对这个被认为是犹太人的他者的恐怖袭击，具有讽刺意味的是，传播了这种对奥姆真理教妖魔的偏执，这些妖魔潜伏在学校、企业甚至政府中。这种怪异他者的概念在“黑暗之魂”中得到了有力的表达，因为它向玩家展示了一个充满敌对个体和群体的世界——这些实体是玩家角色的他者——他们的目标和实践是难以理解的。这也通过一种系统得到了加强，即玩家始终连接到互联网，并且开放给其他玩家入侵。&lt;/p&gt;
&lt;p&gt;东浩纪采纳了大泽的时代精神，并提出了一种“动物化”理论。他指出，由于后现代时代缺乏大叙事，人们失去了理想和抱负。&lt;strong&gt;因此，他们退缩到一个以收集符号为中心的世界，这些符号被添加到一个巨大的符号数据库中并被重新利用&lt;/strong&gt;。 他的主要证据是，当今的御宅族不再对叙事感兴趣。相反，他们只是享受识别、重新混合和扩展数据库的组件。他的预测是，御宅族的活动——他们无休止地收集符号——是大文化的先锋，后续几代人将在自己的领域中变得越来越像御宅族。东浩纪所指出的这一流行文化趋势在“黑暗之魂”中体现为深深的模糊和稀疏的叙事。&lt;/p&gt;
&lt;p&gt;那么“黑暗之魂”究竟如何通过游戏玩法表达后现代意识呢？我认为它通过为我们提供一个任务和一个王国来模拟传统的英雄之旅，但剥夺了我们理解这个任务意义的任何连贯方式。游戏提供了一个视觉细节丰富的世界，但完全缺乏具体的阐述，将玩家置于考古学家和法医科学家的角色中。然而，从未有任何可靠的解释；只有更多的线索和片段，有些是矛盾的。这被称为“环境叙事”，它创造了游戏与后现代思想之间最关键的接触点；即它对主叙事的拒绝。有“拯救王国”的建议，但仅仅是建议，主要是通过类型的惯例传达的，而不是叙事。你所做事情的意义及其服务的目的从未完全清楚。&lt;/p&gt;
&lt;p&gt;重要的是要记住，虽然可以从传统的文学解释视角来解释“黑暗之魂”系列的叙事，但当试图将游戏机制解释为寓意时，会遇到许多实际和理论问题。出于这个原因，我在第二章中对当代游戏研究的批判理论进行了文献综述。利用Espen Aarseth&lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;和其他奠定该领域基础的思想家的论点，我认为需要结合“第一人称”现象学方法和更传统的文学分析方法，才能正确评估视频游戏中潜在的潜在意义。这样做是为了建立一种分析方式，通过与游戏系统的斗争，让玩家体验到我上面概述的后现代意识的两个基本特征。我在第三章中将这种现象学方法付诸实践，探索了一种特别有效的文本叙事、环境叙事和游戏玩法的融合，捕捉到游戏作为一个统一体验的本质。&lt;/p&gt;
&lt;p&gt;除了后现代主义，还有另一股影响游戏的力量，那就是佛教末法概念&lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;。这两种影响力在有趣的方式上重叠，并产生了惊人的相似之处。末法在镰仓时代是一个极具影响力的概念，正如我们的时代一样，那是一个深刻的社会转型时期。末法指的是佛教教义失去其效力，人们无法再依靠自己的努力来获得启示。&lt;strong&gt;随之而来的是僧侣和寺庙变得不可否认的腐败，人们因此无法离开轮回，被困在一系列日益退化的转世中&lt;/strong&gt;。我在第四章中分析了末法的哲学核心，并展示了它如何与大泽和东浩纪的后现代话语一致。此外，我认为，只要“黑暗之魂”系列表达了后现代意识，它主要是通过采用这个佛教末世论概念来表达的。&lt;strong&gt;后现代思想和末法都表达了一种恐惧，即事情只会变得更糟，人类的努力无法改变结果&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在第五章中，我回到现象学和文学分析的混合方法，展示末法概念以及佛教形而上学的混合如何作为构建游戏虚拟世界的核心要素，尽管游戏的美学显然源于中世纪的欧洲奇幻调色板。这些佛教元素共同揭示了游戏世界被困在一个日益退化的轮回中，玩家的任务基本上是一种徒劳的行为，只会推动这个痛苦的循环。我认为佛教形而上学的融合最终表达了东浩纪的结论，即后现代世界及其死去的叙事和怪异他者无可避免地导致社会整体的“动物化”。尽管“黑暗之魂”是一款美学显然源于中世纪欧洲奇幻风格的游戏，但它充满了末法的逻辑，因此游戏深受异教影响，通过采用和改造佛教形而上学，在阴暗的骑士在破败的城堡中冒险的表面下表达了一种后现代情感。&lt;/p&gt;
&lt;h2 id=&#34;衰败叙事&#34;&gt;&lt;strong&gt;衰败叙事&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;过去几十年，日本几乎成了停滞的代名词。这在很大程度上归因于日本在1970年代到1980年代经历的“奇迹”，以及他们令人震惊的衰落，自那以后，国家似乎一直处于无所事事的状态。在美国，当《纽约时报》或《华尔街日报》等出版物提到日本时，往往很少有积极的报道，而是集中在一小部分话题：人口老龄化，年轻人自杀；货币贬值，索尼、丰田和东芝等企业巨头被更精简的竞争对手击败；核燃料仍在福岛渗入地下水，但无人承担责任，等等，每一个预言都比前一个更严峻。在西方，日本作为一个正在衰败的帝国的叙述已经流传已久。这种衰败的印象如此强烈，似乎只有惯性才能维持一切运作，以至于人们忘记了日本仍然是世界上最富有、最富裕和技术最先进的国家之一，仍然领先于许多西欧国家。这种停滞的叙述也存在于日本。正如现任首相安倍晋三在2012年选举中的口号所示：“日本を取り戻す”（取回日本）。从谁那里取回？取回到哪里？凭借他的“安倍经济学”&lt;sup id=&#34;fnref:15&#34;&gt;&lt;a href=&#34;#fn:15&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;15&lt;/a&gt;&lt;/sup&gt;议程中的“三支箭”，他将从日本自己的“萎缩心态”中拯救日本（Sharp）。&lt;strong&gt;如果说1980年代的代表是那些狂热工作、渴望企业晋升的上班族，那么近年来这种原型被更为无力的角色所取代：草食男子&lt;/strong&gt;&lt;sup id=&#34;fnref:16&#34;&gt;&lt;a href=&#34;#fn:16&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;16&lt;/a&gt;&lt;/sup&gt;&lt;strong&gt;（sōshoku danshi）、尼特族&lt;/strong&gt;&lt;sup id=&#34;fnref:17&#34;&gt;&lt;a href=&#34;#fn:17&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;17&lt;/a&gt;&lt;/sup&gt;&lt;strong&gt;（NEET，指不在职或不在学的年轻人）、隐蔽青年&lt;/strong&gt;&lt;sup id=&#34;fnref:18&#34;&gt;&lt;a href=&#34;#fn:18&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;18&lt;/a&gt;&lt;/sup&gt;&lt;strong&gt;（hikikomori，指社会隐士）和其他贬损的称呼&lt;/strong&gt;。诚然，日本的经济和文化问题与其他任何国家一样真实存在，但这种叙述的力量已经超越了现实，成为一种独立的存在。&lt;/p&gt;
&lt;p&gt;这种“萎缩”的心态和随之而来的文化表达，我将称之为后现代意识。这种意识必须与正统的后现代哲学区分开来，因为哲学本身只是对围绕日本的整体衰败叙述的众多情感反应之一。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;后现代意识的核心是一种源于对人类社会已经达到不可否认的衰退点的感知——无论是有意识还是无意识的——的焦虑&lt;/strong&gt;。鉴于上面概述的围绕日本经济和文化衰退的广泛文化讨论，后现代意识在日本文化心理中占据了中心地位。因此，这些源自后现代意识的停滞叙述在日本的流行媒体中也找到了强大而多样的表达。虽然有许多例子可以引用，但游戏《黑暗之魂》及其所有续集，是这种“萎缩”心态的卓越典范。要理解它如何以这种方式运作，我们不仅要看叙述，还要看《黑暗之魂》相对于同类游戏的存在。《黑暗之魂》属于一种被称为角色扮演游戏（RPG）的游戏类型。RPG通常是一个开放式的幻想世界模拟，玩家可以探索领土、收集宝物和击败怪物。通常，玩家创建一个角色——一个在游戏世界中的化身——并以此角色进行任务，其最终目标通常涉及拯救某物（王国、存在平面、公主等）免于毁灭。另一个RPG的基本特征是成长概念。尽管有许多设计模式和隐喻用于模拟成长过程，通常玩家的化身通过击败怪物获得经验值，并通过积累这些点数“升级”。通过升级过程，玩家解锁能力，他们的化身变得更强大。总的来说，RPG往往是许多文化神话中常见的英雄之旅模式的模拟：年轻、未成型的人必须离开家园的安全区域，面对未知的危险，克服它们，培养他们潜在的能力，并以强大和完全实现的人的身份返回，无论是字面上还是象征性地。&lt;/p&gt;
&lt;p&gt;在其基本设计中，《黑暗之魂》作为RPG是相当传统的。然而，它有许多叙述和游戏设计选择，颠覆了这个几十年旧的类型的许多传统。作为一个叙述，它可以被解读为一种政治和文化的寓言，++直接反映了生活在一个意识形态叙述失去吸引力和连贯性的衰败文明中的经验++。它也是一种新兴新类型的前沿：后末日幻想。&lt;strong&gt;在这款游戏中，王国被占领，英雄们都死了或堕落了，没有人可以拯救，而你存在的最大威胁是那些与你在废墟中一起生存的人&lt;/strong&gt;。社区是不可能的。基本的本体状态是无休止的失败，而“英雄”只是注定要忍受它。甚至死亡也不能免除角色的负担，而你被赋予的任务的意义和目标是模糊和不明确的。叙述几乎不存在。当游戏开始时，玩家被简单地放在一个被怪物和不死者占领的废弃王国中，没有明确的理由说明为何事情会如此，或者他们应该怎么做。仅有的叙述存在于零碎的文本中，只提供诱人但最终不完整或矛盾的关于世界的信息。所有这些叙述元素都对已建立的类型惯例提出了严重挑战，因此将其与衰退的讨论联系起来。&lt;/p&gt;
&lt;p&gt;在游戏设计方面，《黑暗之魂》有两个突出的特点。第一个是游戏被有意设计得异常困难。这实际上是其吸引力的主要来源之一。该系列在西方的广告标语是“准备去死”（Prepare To Die），而在日本，该系列被认为是しにがみ（死亡之神）的主要例子，暗示玩家在与远比玩家创建的化身强大的巨大、恐怖的怪物斗争时必然会经历无数次死亡。另一个特点是，尽管游戏主要设计为单人体验——也是RPG类型的一个既定惯例——玩家始终连接到互联网。这被视频游戏评论家广泛赞誉为该类型的重要创新。在实践中，这创造了一种紧张的局势，玩家总是暴露在其他玩家的“入侵”之中，这些玩家会试图杀死该玩家。这种互动中内置了一个复杂的风险/回报系统，入侵者通过杀死其他玩家可以获得很多，但如果失败则会失去很多。&lt;/p&gt;
&lt;p&gt;实际上，始终连接到互联网使得游戏世界充满了偏执和危险。其他玩家是玩家在游戏中可能面对的最危险和不可预测的怪物。入侵玩家经常会潜伏在一个不合适的时机突然袭击，玩家无法自卫，从而逆转他们不幸的受害者辛苦获得的进展。我们将详细探讨叙述和游戏系统，但这一系列游戏的基本概况引出了一个问题：在一个没有希望拯救王国，并且异常困难常常到不公平地步的游戏中，怎么会有如此大的吸引力？但事实上，这款游戏在日本、欧洲和北美都极具吸引力。&lt;strong&gt;这也指出了游戏的设计和叙述如何与在无聊时代生活的年轻一代的经验产生共鸣&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;日本文化领域的停滞叙述需要进一步澄清。我认为《黑暗之魂》可以被解读为对当代日本状况的政治和文化寓言。这是一种后现代的英雄之旅的颠倒：一种被污染的神话碎片的模拟。&lt;strong&gt;它直接反映了许多年轻日本人今天试图在庞大、失修的机构中航行时所经历的无聊和徒劳的感觉，这些机构至多对他们的存在漠不关心，至多直接敌对。然而，这种寓言不仅仅是关于生活在1980年代“奇迹”之后的经济问题。它同样涉及生活在一个国家、政治和文化叙述已经失去了大部分意义和连贯性的社会中的社会和心理成本，这些叙述曾经作为一种心理基石——为个人和社区身份提供稳定&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;催化这一恶化的事件起源于1995年，那一年发生了神户地震和沙林毒气袭击。在西方媒体中，关于这些事件的文化或政治意义的讨论通常不多，但在许多日本知识分子中，这些事件似乎标志着现代性的决定性破裂。在著名小说家村上春树的书《地下：东京毒气袭击和日本心理》中，对沙林毒气袭击幸存者的一系列采访，并得出结论，这一事件的后果不可逆转地揭示了日本社会的所有矛盾、缺陷和内在不稳定性：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“神户地震和1995年1月和3月的东京毒气袭击是日本战后历史上两起最严重的悲剧。毫不夸张地说，这些事件前后的日本意识发生了显著变化。这两次灾难将作为我们生活中的两个里程碑，永远铭刻在我们的心灵中。如此灾难性的事件接连发生是令人震惊的，也是巧合的。然而，当日本的“泡沫经济”破裂，标志着那些泛滥成灾的时代结束时，这些事件带来了对日本国家根本根源的批判性审视。就像这些事件一直在等待伏击我们。两者共有的是压倒性的暴力元素：&lt;strong&gt;一个是不可避免的自然灾难，另一个是可以避免的人为灾难。&lt;/strong&gt;”（村上，237页）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;通过村上等许多知识分子的工作，1995年已成为一个单一且不可改变的地位：&lt;strong&gt;通往破碎和功能失调时代的门户&lt;/strong&gt;。这里分析的主要理论家——东浩纪、大泽真幸和田中基子——都&lt;strong&gt;将1995年视为进入反乌托邦现状的起点&lt;/strong&gt;。这些思想家的语调本身就有一种微妙的后末日色彩，仿佛我们生活在一个无法拯救的被污染时代。这也是衰败讨论的一部分。这些思想家有一种确定的末世论信念，将他们与这一讨论联系起来。&lt;/p&gt;
&lt;p&gt;无论如何，这些灾难比任何经济灾难都更可能是现任首相希望根除的“萎缩”心态的原因。尽管已经过去几十年，1995年的事件作为焦虑和无助感的触发点，在《黑暗之魂》的寓言中找到了源头。经济的持续低迷、老龄化人口、年轻一代的就业前景减少以及福岛等灾难，只是加剧了这些灾难在1995年最初引发的负面情绪。福岛等事件只帮助在日本意识中创造了一种遗产。近年来，右翼极端民族主义政治的重新出现和尼特族及隐蔽青年的社会退缩，形成了对这一相同的文化病态的极端和相反的情感反应。右翼试图通过与其真实和感知的对手（韩国、中国、朝鲜）进行公开的对抗来复兴“大和”帝国的活力，试图通过历史修正主义抹去日本帝国的暴力和道德可憎之处，并试图通过修改宪法（第9条）恢复战争作为国家主权权利。而尼特族和隐蔽青年则将自己沉溺于网络和其他形式的私人数字享乐中。他们没有叙述可供复兴，没有事业可供加入，甚至没有可以参与的兴趣小组。&lt;strong&gt;与他人沟通实在是太困难了，在他们看来，也太危险了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我的观点不是《黑暗之魂》系列是这些问题的根源，甚至不是它们的贡献，而是它是对在公众意识中循环的深层社会焦虑，特别是对视频游戏作为熟悉媒介的年轻一代的一种特别有力的表达。《黑暗之魂》系列的持续流行，作为一种社会腐化的象征，反映了人们在日常生活中的感觉。但这些焦虑到底是什么，它们如何在《黑暗之魂》中表现出来？另一种问这个问题的方法是，后现代意识的基本要素是什么？定义1995年后时代的有两个主要元素。&lt;strong&gt;1. 对构建战后秩序的政治和社会叙述的拒绝；2. 一种对他者的弥漫性焦虑，侵蚀了对社会过程的信任和信心&lt;/strong&gt;。他者的概念是指自我与世界上遇到的所有其他自我之间的二元关系的一半。这一概念的延伸是文化他者，即一种感觉某些人与自己相似，另一些人则是异类。日本社会通常被认为具有非常同质的国家认同感，彼此之间有相同的文化、种族和相似的价值观。这反过来又创造了强烈的信任和社区感，但这种亲近的逆向效应是，外来者被认为比在美国、英国或法国等文化多样性更大的国家中更为陌生。大泽真幸的论点是，奥姆真理教的恐怖活动将潜在威胁引入了公众。这种恐惧是一种诡异的他者的恐惧，这种他者会突然出现，以一种深刻的方式扰乱你的生活，有时甚至是致命的。社会结构中的这种破裂从未真正修复，并继续受到挑战，直到现在。关于诡异他者的偏执是定义《黑暗之魂》的氛围和叙述的主要特征之一，也是其游戏机制，尤其是其在线组件。&lt;/p&gt;
&lt;p&gt;要理解《黑暗之魂》如何作为一种描述后现代意识的寓言运作，我们必须追踪战后日本社会状况的衰退轨迹。&lt;strong&gt;这根本上是一个现代进步叙述——本质上是从西方继承的——首先在1960年代末引发了激烈的意识形态斗争，然后在1980年代变成一种无政治的享乐主义，最后，最终在五个正义的宗教狂热者用雨伞尖端戳破装满沙林毒气的袋子的时刻，被一种微妙的虚无主义彻底摧毁&lt;/strong&gt;。为此，我们将研究社会学家大泽真幸的工作。大泽花费了相当多的职业生涯试图回答奥姆为什么会做他们所做的事情。&lt;strong&gt;在他的书《虚构时代的终结》中，他认为答案涉及意识形态本身的致命缺陷：一种危险而空洞的思维模式，导致在一个自我设计的世界中越来越高的疏离感。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;理性时代&#34;&gt;理性时代&lt;/h2&gt;
&lt;p&gt;借用社会学家見田宗介&lt;sup id=&#34;fnref:19&#34;&gt;&lt;a href=&#34;#fn:19&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;19&lt;/a&gt;&lt;/sup&gt;（Mita Munesuke）的观点，大泽真幸将战后时代分为两个不同的阶段。第一个阶段他称为“理想的时代（理想の時代，risō no jidai）”，第二个阶段他称为“虚构的时代（虚構の時代，kyokō no jidai）”。理想的时代始于20世纪60年代，结束于1972年，虚构的时代从1972年开始，一直持续到1995年。大泽将“理想”和“虚构”描述为“可能世界（可能の世界 kanōsei no sekai）”，因为它们都反映了我们对世界的感知以及我们认为世界应该如何。然而，尽管这两个概念在根本层面上是相关的，但它们在几个重要方面是不同的。&lt;strong&gt;大泽认为，理想与现实世界密切相关，而虚构则完全脱离现实世界&lt;/strong&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;理想是一个在未来有望或期待在现实中实现的可能世界。因此，理想必须存在于现实的因果延伸之上。从这个意义上讲，理想不是一个纯粹的可能世界，而是广义现实世界的一个方面。相反，虚构是一个可以在现实中实现与否无关的可能世界，因此是纯粹的反现实。（大泽，41页）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;理想は、未来において現実に着地することが予期（期待）されているような可能世界である。だから、理想は、現実の因果的な延長上になくてならない。その意味では、理想は、純粋な可能世界ではなく、むしろ広義の現実世界の一局面である。それにたいして、虚構は現実への着地ということについてさしあたって無関連ありうる可能世界であり、それゆえ純粋な反現実である。(Osawa, 41)&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;暂且不讨论虚构如何将我们与现实疏离，日本的理想时代很大程度上受到冷战阴影的笼罩。当亚洲大部分地区处于苏联的保护伞下时，日本则在美国的庇护下，因而在意识形态上致力于民主和经济自由主义。在20世纪60年代，日本在这些条件下几乎在各个方面都得到了繁荣：科学、基础设施、经济、文化等。大泽将20世纪60年代称为理想的黄金时代，并指出家用电器是赋予大众理想的物质形式：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;理想时代在大众层面的黄金期是20世纪60年代。当然，这与日本的高速增长期相吻合。在此期间，例如，受到国民绝大多数人广泛需求的家电产品赋予了大众理想物质的表达……经济增长和科学技术的进步并不是因为理想而被接受的，相反，正因为理想作为可能的现实在广泛（全球范围内）被信奉，经济才能够增长，科学和技术才能进步。（大泽，44页）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;理想の時代の、大衆的な水準で黄金期は、1960年代である。もちろん、これは、高度成長期にあたる。この時期、たとえば、国民の圧倒的な大多数によって広範に欲求された家電製品が、大衆的理想に物質的な表現を与えた&amp;hellip;経済成長や科学・技術の進歩があったから理想が抱かれたのではなく、逆に、理想が可能的現実として広く（世界規模で）信憑されたがゆえに、経済が成長することができ、また科学や技術進歩していると感受されたのである。(Osawa, 44)&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAG工具箱：检索</title>
      <link>https://niraya666.github.io/posts/rag%E6%A3%80%E7%B4%A2/</link>
      <pubDate>Thu, 25 Jul 2024 17:08:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/rag%E6%A3%80%E7%B4%A2/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;If you want to make a good RAG tool that uses your documentation, you should start by making a search engine over those documents that would be good enough for a human to use themselves. This is likely something your organization has considered before, and if it doesn’t exist it’s because building a good search engine has traditionally been a significant undertaking.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;— from &lt;a href=&#34;https://blog.elicit.com/search-vs-vector-db/&#34;&gt;Build a search engine, not a vector DB&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Agent学习笔记： 如何验证模型的tool-using能力</title>
      <link>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/</link>
      <pubDate>Tue, 25 Jun 2024 17:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/</guid>
      <description>&lt;p&gt;本文将简单介绍如何评价LLM的tool-using 能力。&lt;/p&gt;
&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;p&gt;在工具使用评估方面，过去的研究主要有以下几种思路：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对比工具使用和纯LLM在基准测试上的分数&lt;/strong&gt;：例如&lt;a href=&#34;https://arxiv.org/abs/2302.04761&#34;&gt;Toolformer&lt;/a&gt;和&lt;a href=&#34;https://arxiv.org/abs/2305.17126&#34;&gt;LATM&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在Toolformer研究中，通过下游任务如语言模型评估基准测试、数学推理任务和问答任务来验证工具使用的有效性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LATM则采用了来自BigBench的六个数据集进行评估。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;测试工具使用的准确率和响应质量&lt;/strong&gt;：例如&lt;a href=&#34;https://arxiv.org/abs/2304.08244&#34;&gt;API-Bank&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在评估过程中，首先初始化评估系统，确保每个API的数据库包含默认值。然后，将预测的API调用与手动标注的API调用进行比较，以确定它们的一致性。响应评估则使用ROUGE-L指标。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;利用LLM对工具使用的效果进行评价&lt;/strong&gt;：例如Tool-bench。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;two evaluation metrics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pass Rate&lt;/strong&gt;: Calculates the proportion of successfully completing an instruction within limited OpenAI API calls.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Preference&lt;/strong&gt;: Measured by comparing two answers (action sequences) for a given instruction.We pre-define a set of criteria for a better answer, which are organized as prompts for ChatGPT.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;构造虚拟运行环境，测试代理与环境的交互结果&lt;/strong&gt;：例如ToolAlpaca。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用LLM模拟环境（用户代理和助手代理），并使用GPT-4对ToolAlpaca模型进行机器评估，评估其使用各种未见工具的能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于绝大多数企业和垂直场景下， 其中思路1需要构建额外的测试集成本比较高（但还是有必要的）， 而思路4构造虚拟运行环境实际上并不现实； 所以还是选择思路2，外加通过思路3辅助判断；换句话说， 根据场景，构造工具列表和工具调用的ground-truth（包括函数名， 和传入参数）  ，在存在歧义时，采用ROUGE评价响应质量， 或者使用LLM判断响应结果并评价。&lt;/p&gt;
&lt;p&gt;顺带提一下Langchain 项目中有关Agent的tool-using能力测试的内容， 不过由于Langchain项目又臭又长，且有很大的局限性， 这里只讨论其思路。&lt;/p&gt;</description>
    </item>
    <item>
      <title>【钢琴谱分享】坂本龙一《for Johann》</title>
      <link>https://niraya666.github.io/musik/for_johann/</link>
      <pubDate>Sat, 01 Jun 2024 12:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/musik/for_johann/</guid>
      <description>&lt;p&gt;上周看了《坂本龙一：Opus》，特别喜欢其中有一首未收录在之前作品中的曲目《for Johann》&lt;/p&gt;
&lt;p&gt;第一反应是这首曲子可能是献给已故的冰岛作曲家Johann Johannsson，也是我最喜欢的音乐人之一&lt;/p&gt;
&lt;p&gt;不过，我找不到确切的证据&lt;/p&gt;
&lt;p&gt;万一是巴赫（Johann Sebastian Bach） 也有可能&lt;/p&gt;
&lt;p&gt;总觉得这首歌的旋律走向和Johann Johannsson的作品有某种神似，也有可能是我的错觉罢了吧&lt;/p&gt;
&lt;p&gt;试着弹一下这首歌， 顺带用AnthemScore扒了下谱子
可能有些小错误，但我希望能将这份音乐传递下去&lt;/p&gt;
&lt;p&gt;希望大家喜欢&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/music/for_johnann/1.png&#34; alt=&#34;&#34;  /&gt;

&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/music/for_johnann/2.png&#34; alt=&#34;&#34;  /&gt;

&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/music/for_johnann/3.png&#34; alt=&#34;&#34;  /&gt;

&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/music/for_johnann/4.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;He’s gone, but the music remains.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ありがとうございます&lt;/p&gt;
&lt;p&gt;感谢教授的最后礼物， 也感谢同样被迫包场的另两位陌生人&lt;/p&gt;</description>
    </item>
    <item>
      <title>泉州行记：古城漫步与味蕾之旅</title>
      <link>https://niraya666.github.io/travel/%E6%B3%89%E5%B7%9E%E8%A1%8C%E8%AE%B0%E5%8F%A4%E5%9F%8E%E6%BC%AB%E6%AD%A5%E4%B8%8E%E5%91%B3%E8%95%BE%E4%B9%8B%E6%97%85/</link>
      <pubDate>Thu, 23 May 2024 19:42:00 +0800</pubDate>
      <guid>https://niraya666.github.io/travel/%E6%B3%89%E5%B7%9E%E8%A1%8C%E8%AE%B0%E5%8F%A4%E5%9F%8E%E6%BC%AB%E6%AD%A5%E4%B8%8E%E5%91%B3%E8%95%BE%E4%B9%8B%E6%97%85/</guid>
      <description>&lt;p&gt;2024年 夏&lt;/p&gt;
&lt;p&gt;这是我第一次踏上泉州这片土地，虽然我是厦门人，已经快三十岁了，却一直没有机会来这座近在咫尺的城市。&lt;/p&gt;
&lt;p&gt;泉州在我想象中，是一座充满历史韵味的地方，同时也被一些暴发户的繁荣所点缀。几年前，这座城市成功申遗，从此逐渐成为小众旅游的热门选择。泉州的古老街区、传统建筑和浓厚的文化氛围，让人忍不住想一探究竟。&lt;/p&gt;
&lt;p&gt;大学时，我有一位好友家在泉州。我们是班里唯二的福建人，因此自然成了很好的朋友。每次听他讲起泉州的美食、风景，总让我心生向往。&lt;/p&gt;
&lt;p&gt;这次借着回家的机会，我终于决定亲自走一趟泉州。&lt;/p&gt;
&lt;p&gt;泉州，我来了！&lt;/p&gt;
&lt;h2 id=&#34;初印象&#34;&gt;初印象&lt;/h2&gt;
&lt;p&gt;初到泉州，路上穿梭的电动车给我留下了深刻的第一印象。这些电动车在街头巷尾自由穿行，让我一度产生了身处越南的错觉。或许，这正是泉州的独特之处——在传统与现代之间，在历史与现实之中，找到一种和谐的平衡。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/50F93B5D-5373-486C-A785-4BB341FD0679_1_105_c.jpeg&#34; alt=&#34;50F93B5D-5373-486C-A785-4BB341FD0679_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;作为古城，鲤城区似乎尽可能地保留着过去的模样。漫步在古城，却能产生一种记忆中的故乡的错觉，这一切似乎都太像了。&lt;/p&gt;
&lt;p&gt;那些熟悉的景象和气息，让人倍感亲切。有人说过，“离开了，故乡才称之为故乡。”庆幸的是，故乡以另一种形式呈现在我的面前，尽管这不是我的故乡。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/458F4F0B-B35C-4AC9-A447-0A38E69CC35D_1_105_c.jpeg&#34; alt=&#34;458F4F0B-B35C-4AC9-A447-0A38E69CC35D_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;在鲤城区，街头的小贩、古早风格的便利店、上了年纪的理发店，无时无刻不把我拉回到记忆的深处。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/218DC3D6-D630-49FE-9796-64202907D7E3_1_105_c.jpeg&#34; alt=&#34;218DC3D6-D630-49FE-9796-64202907D7E3_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;人&#34;&gt;人 &lt;/h2&gt;
&lt;p&gt;历史离不开人，特别是一个个普通人&lt;/p&gt;
&lt;p&gt;正是这些普通人，构成了这座城市的血脉与灵魂。他们的日常琐事，他们的勤劳与坚韧，使得这座古老的城市充满了生机与活力。在他们的身上，我看到了泉州的过去、现在和未来。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/E5CBBA91-C9A6-4F93-853D-009FD2D568C5_1_105_c.jpeg&#34; alt=&#34;E5CBBA91-C9A6-4F93-853D-009FD2D568C5_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/BC390CC0-02B4-45A6-9266-1C7638C75D76_1_105_c.jpeg&#34; alt=&#34;BC390CC0-02B4-45A6-9266-1C7638C75D76_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/3F165220-A99D-4E4F-92AB-94F572A0B231_1_105_c.jpeg&#34; alt=&#34;3F165220-A99D-4E4F-92AB-94F572A0B231_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/0DA901A1-F620-4B8A-A722-63E95EDAA536_1_105_c.jpeg&#34; alt=&#34;0DA901A1-F620-4B8A-A722-63E95EDAA536_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/46A3B7FB-2306-4661-8B47-7DEDB3FF20AE_1_105_c.jpeg&#34; alt=&#34;46A3B7FB-2306-4661-8B47-7DEDB3FF20AE_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;宗教&#34;&gt;宗教&lt;/h2&gt;
&lt;p&gt;泉州作为海上丝绸之路的起点，在那辉煌的历史长河中，不仅是贸易和文化交流的中心，也吸引了大量的外来文化和宗教。佛教、道教、伊斯兰教、基督教等多种宗教在这里交汇融合，形成了独特的宗教文化景观。经过千年的融合与发展，这些宗教在泉州和谐共存，互相尊重，不分彼此。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/22205648-89A8-41BE-B99C-56850A28D252_1_105_c.jpeg&#34; alt=&#34;22205648-89A8-41BE-B99C-56850A28D252_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/BB0999F1-EDEA-4AA2-BA72-D6954CD12BA8_1_105_c.jpeg&#34; alt=&#34;BB0999F1-EDEA-4AA2-BA72-D6954CD12BA8_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/5A6D2D91-D86E-4BBA-9248-272095117CE9_1_105_c.jpeg&#34; alt=&#34;5A6D2D91-D86E-4BBA-9248-272095117CE9_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;吃&#34;&gt;吃&lt;/h2&gt;
&lt;h3 id=&#34;牛肉店&#34;&gt;牛肉店&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/FEA7D1E0-80AD-45BC-B2F9-E3BF31A1130A_1_201_a.jpg&#34; alt=&#34;FEA7D1E0-80AD-45BC-B2F9-E3BF31A1130A_1_201_a.jpg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;阿秋牛排馆&lt;/p&gt;
&lt;p&gt;牛排并不是传统意义上的steak，而是采用香料和咖喱炖煮而成的牛排骨。招牌牛排非常推荐，炖得非常软烂，入口即化，肉质瞬间脱骨。咖喱的香气与牛肉的原汁原味相得益彰，不会掩盖肉本身的美味。用汤汁拌饭，可谓是一绝。&lt;/p&gt;
&lt;p&gt;不过，对于从小习惯了晋江牛肉店的闽南人来说，阿秋牛排馆的汤味道可能稍显清淡，不够浓郁，因此未必合所有人的口味。此外，这家店的价格也比其他店稍高一些。&lt;/p&gt;
&lt;p&gt;除此之外，我的收藏夹里还有几家值得尝试的牛排店：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;阿波牛肉店&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;天财牛肉店&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;阿泉全牛馆&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;面线糊&#34;&gt;面线糊&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/FC2DD610-927E-4E1E-829A-420ACD1A0418_1_105_c.jpeg&#34; alt=&#34;FC2DD610-927E-4E1E-829A-420ACD1A0418_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;平阿面线糊&lt;/p&gt;
&lt;p&gt;我去的这家平阿面线糊，在周末早上8点左右已经挤满了人，足见其受欢迎程度。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/0615C07D-8BA9-484A-BBFC-FF59E764955B_1_201_a.jpg&#34; alt=&#34;0615C07D-8BA9-484A-BBFC-FF59E764955B_1_201_a.jpg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;与厦门地区加入了猪血、虾米的面线糊相比，泉州的面线糊更多地呈现出字面上的意思——就是很单纯的面线糊。所用的面线更加细碎，完全不用担心吃太慢会坨，因为这甚至可以用面线汤来形容。但喝上一口汤，你会发现这绝不是一碗普通的面线汤，在汤头上，店家一定是下足了功夫的。&lt;/p&gt;
&lt;p&gt;食客可以根据自己的喜好添加额外的食材，这种模式在闽南地区基本相同。在泉州，根据我对本地食客的观察，基本上必加的食材有：醋肉、卤大肠、套肠、豆干等等，当然绝对不能忘了加一根油条。&lt;/p&gt;
&lt;p&gt;除了平阿面线糊，我还收藏了几家值得一试的面线糊店：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;水门国仔老店&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;后城面线糊&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;文啊面线糊&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;烧肉粽&#34;&gt;烧肉粽&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/F2CA54E0-ADE3-42B7-A243-D90C9B559D7B_1_105_c.jpeg&#34; alt=&#34;F2CA54E0-ADE3-42B7-A243-D90C9B559D7B_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;东街肉粽店&lt;/p&gt;
&lt;p&gt;“烧”在闽南语中的含义既包含了特定的烹饪方法，也体现了食物的热度（与“烫”同音）。在“烧肉粽”中，“烧”不仅指将肉粽通过炖、煮、蒸等方式烹饪至入味，还强调了粽子食用时热乎的特质。&lt;/p&gt;
&lt;p&gt;与在厦门吃的肉粽不同，除了甜辣酱外，泉州的肉粽更喜欢加入花生酱，增添了一份独特的香气和口感。&lt;/p&gt;
&lt;p&gt;原本计划去侯阿婆烧肉粽，但可惜饭点人太多，只能临时改变计划，选择了不远处的东街肉粽店。不过这家感觉有些失望，对粽子没有太多感觉，店里的海蛎煎下的油太多，实在无法恭维。&lt;/p&gt;</description>
    </item>
    <item>
      <title>大阪游记：时光交错下的日本探索</title>
      <link>https://niraya666.github.io/travel/%E5%A4%A7%E9%98%AA%E6%B8%B8%E8%AE%B0%E6%97%B6%E5%85%89%E4%BA%A4%E9%94%99%E4%B8%8B%E7%9A%84%E6%97%A5%E6%9C%AC%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Thu, 16 May 2024 16:32:00 +0800</pubDate>
      <guid>https://niraya666.github.io/travel/%E5%A4%A7%E9%98%AA%E6%B8%B8%E8%AE%B0%E6%97%B6%E5%85%89%E4%BA%A4%E9%94%99%E4%B8%8B%E7%9A%84%E6%97%A5%E6%9C%AC%E6%8E%A2%E7%B4%A2/</guid>
      <description>&lt;p&gt;2024-春夏之交 大阪&lt;/p&gt;
&lt;p&gt;旅行时间2天3夜&lt;/p&gt;
&lt;p&gt;在多邻国上学了快一年的散装日语，受到了看大河剧、日本电影和玩日本游戏的影响，我决定利用刚获得的三年多次入境签证，以及51假期的空闲时间，去日本看看。考虑到时间限制，我选择了关西的交通枢纽和经济中心——大阪，作为这次日本之行的第一站。&lt;/p&gt;
&lt;p&gt;对于日本，尤其是大阪，我的第一印象是热门景区和场所人非常多。这主要是因为赶上了日本的10天黄金周，同时由于日元汇率低迷，大量外国人涌入日本消费和旅游。然而，在居民区，特别是我所住的浪速区，情况则大为不同，晚上和清晨几乎见不到几个人，给人一种非常萧条的感觉。中国人会说，这叫做“缺乏人气”。此外，随处可见的大乌鸦加深了这种萧条感。或许这也可能是宫崎英高在《黑魂》系列中乌鸦的灵感来源吧。在日本，乌鸦似乎被视为吉祥的象征。&lt;/p&gt;
&lt;h2 id=&#34;游玩篇&#34;&gt;游玩篇&lt;/h2&gt;
&lt;p&gt;出了民宿，我的第一站是不远处的难波八阪神社。这里以其狮子头形状的大狮子殿闻名，成为了一处热门的打卡地点。据说，这个狮子头具有驱除灾难和带来好运的力量。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/D22F4C9A-23D6-472A-B359-5A9DC656DE03_1_201_a.jpeg&#34; alt=&#34;D22F4C9A-23D6-472A-B359-5A9DC656DE03_1_201_a.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;经过两站地下铁，即可到达动物园前站， 这里是新世界的入口。&lt;/p&gt;
&lt;p&gt;新世界，曾是日本向西方看齐、力图“脱亚入欧”时的产物。在20世纪初，日本大量吸纳西方文化元素，并在大阪建立了这一街区。然而时光流转，21世纪的今天，这里更像是一个保存良好的“旧世界”。街区内充满昭和时代的气息，从游戏厅、炸串店到浮夸的店面招牌，甚至粉红色影院，处处透露出时代的印记。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/6DA5908E-2DB7-48B0-9254-7B189FB7848A_1_201_a.jpeg&#34; alt=&#34;6DA5908E-2DB7-48B0-9254-7B189FB7848A_1_201_a.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/AF7FD137-8145-4DE2-91D7-116908DC6985_1_201_a.jpeg&#34; alt=&#34;AF7FD137-8145-4DE2-91D7-116908DC6985_1_201_a.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;作为泡沫经济时期产物， 粉红影院现在主要吸引了一部分中老年男性和非传统性别的人士。影院的“学生半价”标志显得有些讽刺，同时也透露出一种时代变迁的哀愁。鉴于这类场所的特殊性，不推荐旅行者单独前往。&lt;/p&gt;
&lt;p&gt;新世界的标志性建筑通天阁，则见证了区域的多重历史。这座铁塔最初在1912年仿照巴黎的埃菲尔铁塔建造，但在二战中因为“献纳”政策而被拆除，用其材料支持军工。通天阁的现代版本建于1956年，为了迎接万博会而重建，塔身醒目地印有日立的广告，成为了大阪的新地标。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/6C8F7905-91AC-46AA-BEC9-79AF3A362781_1_105_c.jpeg&#34; alt=&#34;6C8F7905-91AC-46AA-BEC9-79AF3A362781_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/0B1EA1C4-DFF3-4FDA-ACF8-EFDB75E7A3C0_1_201_a.jpeg&#34; alt=&#34;0B1EA1C4-DFF3-4FDA-ACF8-EFDB75E7A3C0_1_201_a.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;西成区，与新世界仅一路之隔，是大阪的旧城区。这个区域以较复杂的治安情况、流浪汉的较高出现率，以及成人娱乐业而知名。其中，著名的酒吧一条街和在中文互联网上广为人知的飞田新地均位于此地。游客在此区域应特别小心，避免随意使用手机或拍照，以尊重当地文化和增加个人安全。&lt;/p&gt;
&lt;p&gt;往新世界东北边走， 则能到达天王寺车站，商圈，以及以此命名此地的四天王寺。这里的天王寺车站作为从关西机场到大阪市区的两条主要电车线路之一JR西日本的终点站，同前面走过的西成区和新世界相比， 自然非常繁华。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/2E815B2C-F25B-4CB4-A8FB-8D993265A540_1_105_c.jpeg&#34; alt=&#34;2E815B2C-F25B-4CB4-A8FB-8D993265A540_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;天王寺站前&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/42E69559-0A2E-4F15-8B70-C4CD15948641_1_201_a.jpeg&#34; alt=&#34;42E69559-0A2E-4F15-8B70-C4CD15948641_1_201_a.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;JR西日本机场线之HARUKA， 以Hello- Kitty涂装著称。&lt;/p&gt;
&lt;p&gt;日本的许多古迹因二战的轰炸和历史上的大地震而稀少，多数是在原址上修复或重建的。四天王寺就是这样的例子，它是日本历史悠久的寺庙之一，最初由飞鸟时期的圣德太子创建。虽然历经多次战火，我们今天所见的四天王寺主要是1957年后的重建。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/C316DC6A-106E-494C-9926-6F5ED52B11E3_1_105_c.jpeg&#34; alt=&#34;C316DC6A-106E-494C-9926-6F5ED52B11E3_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/30F7FC2C-4BFA-494F-A0EC-1C07AEBA1A5E_1_105_c.jpeg&#34; alt=&#34;30F7FC2C-4BFA-494F-A0EC-1C07AEBA1A5E_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/3BFFEA31-F958-4239-99FD-23B5D8F91CFF_1_105_c.jpeg&#34; alt=&#34;3BFFEA31-F958-4239-99FD-23B5D8F91CFF_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;前往天王寺途中，偶遇的一心寺。&lt;/p&gt;
&lt;p&gt;在天王寺附近，我意外地发现了一个旧书集市。在那里，我用400日元买到了一本1994年的旧书。虽然还有很多书我想买想看，但考虑到海关的限制和行李空间的限制，我只能忍痛放弃。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/A0D7A507-9B4F-44D5-AA9C-6B771FA520D2_1_201_a.jpeg&#34; alt=&#34;A0D7A507-9B4F-44D5-AA9C-6B771FA520D2_1_201_a.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/96FA58A9-C223-40F4-9BC8-33B6A50D4BF0_1_105_c.jpeg&#34; alt=&#34;96FA58A9-C223-40F4-9BC8-33B6A50D4BF0_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;不可免俗的道顿堀格利高小人&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/17DC7E7D-8CD2-4FCD-A19E-EC4BCE661FF1_1_105_c.jpeg&#34; alt=&#34;17DC7E7D-8CD2-4FCD-A19E-EC4BCE661FF1_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;蟹道乐&lt;/p&gt;
&lt;p&gt;夜幕降临， 抵达梅田，乘坐hep five摩天轮，体验大阪夜景。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/90FE62D5-F899-43B8-BBB7-D44B242C2CEB_1_201_a.jpeg&#34; alt=&#34;90FE62D5-F899-43B8-BBB7-D44B242C2CEB_1_201_a.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;hep five摩天轮&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/5C716546-81DE-4FE8-BEAF-EA239F27DAB4_1_201_a.jpeg&#34; alt=&#34;5C716546-81DE-4FE8-BEAF-EA239F27DAB4_1_201_a.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;第二天，前往大阪历史博物馆和大阪城， 以及shooping。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/FDCCBE76-D57A-4EC6-8D79-D19D9066390F_1_105_c.jpeg&#34; alt=&#34;FDCCBE76-D57A-4EC6-8D79-D19D9066390F_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;大阪城&lt;/p&gt;
&lt;p&gt;大阪城始建于1583年，由丰臣秀吉下令建造。大阪城的天守阁如今是博物馆，展示了丰臣秀吉的生平、战国时期的武器和铠甲，以及大阪城的历史变迁。&lt;/p&gt;
&lt;p&gt;如果对于历史感兴趣的小伙伴， 大阪城公园边上的大阪历史博物馆也值得逛一逛。 大阪历史博物馆展示了古代大阪作为日本重要商业城市的发展过程，以及现代大阪的城市化进程。参观路线从10楼一路到7楼，6楼为特别展。&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAG工具箱：文本分块</title>
      <link>https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97/</link>
      <pubDate>Wed, 15 May 2024 16:11:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97/</guid>
      <description>&lt;h2 id=&#34;为什么要进行文本分块&#34;&gt;&lt;strong&gt;为什么要进行文本分块？&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。&lt;/p&gt;
&lt;h2 id=&#34;如何进行文本分块&#34;&gt;&lt;strong&gt;如何进行文本分块&lt;/strong&gt;&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;**块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：&lt;/p&gt;
&lt;h3 id=&#34;句子分割sentence-splitting&#34;&gt;&lt;strong&gt;句子分割（Sentence Splitting）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;...&amp;#34;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 你的文本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.text_splitter&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CharacterTextSplitter&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;text_splitter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CharacterTextSplitter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;separator&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;chunk_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;chunk_overlap&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;docs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text_splitter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create_documents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;递归字符文本分割recursive-character-text-splitting&#34;&gt;&lt;strong&gt;递归字符文本分割（Recursive Character Text Splitting）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;...&amp;#34;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 你的文本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;langchain.text_splitter&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RecursiveCharacterTextSplitter&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;text_splitter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RecursiveCharacterTextSplitter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;chunk_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;chunk_overlap&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;docs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text_splitter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create_documents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;根据langchain 的&lt;a href=&#34;https://github.com/langchain-ai/langchain/blob/9ef2feb6747f5a69d186bd623b569ad722829a5e/libs/langchain/langchain/text_splitter.py#L842&#34;&gt;默认分隔条件&lt;/a&gt; &lt;code&gt;[&amp;quot;\n\n&amp;quot;, &amp;quot;\n&amp;quot;, &amp;quot; &amp;quot;, &amp;quot;&amp;quot;]&lt;/code&gt; ,也就是会将text根据该分割条件的顺序（两个换行-&amp;gt;一个换行-&amp;gt;空格）将文本进行递归分割。&lt;/p&gt;
&lt;h3 id=&#34;针对特定文档的分割方法document-specific-splitting&#34;&gt;&lt;strong&gt;针对特定文档的分割方法（Document Specific Splitting）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。&lt;/p&gt;
&lt;p&gt;langchain 提供了一些常见文档的分割方法：&lt;/p&gt;
&lt;p&gt;mardown的分割逻辑&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;c1&#34;&gt;# First, try to split along Markdown headings (starting with level 2)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;#{1,6} &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;c1&#34;&gt;# Note the alternative syntax for headings (below) is not handled here&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;c1&#34;&gt;# Heading level 2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;c1&#34;&gt;# ---------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;c1&#34;&gt;# End of code block&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34;```&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;c1&#34;&gt;# Horizontal lines&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n\\&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\\&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;*+&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;---+&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;___+&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;c1&#34;&gt;# Note that this splitter doesn&amp;#39;t handle horizontal lines defined&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;c1&#34;&gt;# by *three or more* of ***, ---, or ___, but this is not handled&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;python的分割逻辑：&lt;/p&gt;</description>
    </item>
    <item>
      <title>基于大语言模型的 Agent：科普向</title>
      <link>https://niraya666.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84-agent%E7%A7%91%E6%99%AE%E5%90%91/</link>
      <pubDate>Mon, 13 May 2024 16:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84-agent%E7%A7%91%E6%99%AE%E5%90%91/</guid>
      <description>&lt;h2 id=&#34;写在开头&#34;&gt;写在开头&lt;/h2&gt;
&lt;p&gt;本文是基于最近组内技术交流的文字稿整理。&lt;/p&gt;
&lt;h2 id=&#34;what-is-agent&#34;&gt;What is Agent？&lt;/h2&gt;
&lt;p&gt;在探讨复杂的人工智能技术之前，让我们先回顾一下生活中的一个简单例子：扫地机器人。这种智能设备在房间中自主导航，避开障碍物，寻找最有效的清洁路径。它就是一个现实生活中的Agent——一个可以自主决策和行动的实体。&lt;/p&gt;
&lt;p&gt;在人工智能领域，Agent指的是任何可以感知其环境并根据感知结果做出决策的实体。这些决策旨在完成某些任务或达成特定的目标。Agent的行为可以简单如游戏里的机器人，也可以复杂如自动驾驶汽车。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/Pasted%202024-05-10-14-58-28.webp&#34; alt=&#34;Pasted 2024-05-10-14-58-28.webp&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;开始于强化学习&#34;&gt;开始于强化学习&lt;/h3&gt;
&lt;p&gt;在强化学习中， 我们往往能见到agent的概念。强化学习是一种机器学习方法，它教导Agent通过试错法找到最佳行动路径。就像训练小狗一样，我们通过奖励来引导Agent做出正确的决策。Agent的目标是在与环境的交互中寻找最优策略。理想情况下，如果Agent能够获取足够多的真实环境数据，它就能找到最佳解决方案。然而，由于真实环境的复杂性，完全模拟真实世界是不现实的。&lt;/p&gt;
&lt;p&gt;目前，强化学习主要适用于环境简单、问题定义明确的场景，如围棋或视频游戏。这种方法在虚拟环境中通过大量试错来探索解决方案，这种方法虽然有效，但缺乏灵活性和高效性。与人类学习新技能的方式相比，强化学习的效率远低。人们通常通过少量的尝试就能迅速掌握新技能，而强化学习可能需要成千上万次的试错。&lt;/p&gt;
&lt;p&gt;这时候，如果agent具有大脑就好了。&lt;/p&gt;
&lt;h3 id=&#34;将llms作为大脑-赋能智能agent的关键技术&#34;&gt;将LLMs作为大脑: &lt;strong&gt;赋能智能Agent的关键技术&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;相较于基于强化学习的Agent，人类的优势在于我们天生具备的记忆能力和逻辑判断能力，甚至包括反思和从经验中学习的能力。这些能力使得我们能够通过极少的试错迅速适应和掌握新技能。&lt;/p&gt;
&lt;p&gt;语言模型（LLMs）为AI领域带来了革命性的变化。LLMs通过其深度学习的新范式，以及在思维链和自然语言理解方面的强大能力，预示着Agent将拥有更强大的学习和迁移能力。这种能力的提升将使得创建广泛应用且实用的Agent成为可能。&lt;/p&gt;
&lt;p&gt;虽然LLM是否真正具备了推理能力仍然存疑，但LLM的出现无疑改变了很多。以COT（Chain of Thought）为例，这种模型通过打印解题的中间步骤，加强了在数学和逻辑推理方面的能力，减少了幻觉的出现。这一突破性的工作揭示了LLM在不同场景下的强大&amp;quot;in-context learning&amp;quot;能力，以及其在未经微调的情况下的泛化能力。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png&#34; alt=&#34;截屏2024-05-08 15.37.21.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;将LLM视为AI Agent的大脑，为自动化系统提供了一种全新的构思方式。这种基于LLM的agent系统综合了规划、记忆、工具使用和行动的能力，通过API调用与外部世界互动，显示出了前所未有的灵活性和效率。&lt;/p&gt;
&lt;p&gt;根据&lt;a href=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/&#34;&gt;LLM Powered Autonomous Agents&lt;/a&gt;一文对LLM-based agent系统的定义， agent需要具备的基本能力：规划+记忆+工具+行动。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规划能力&lt;/strong&gt;：将复杂的任务分解成小任务， 并管理每一个子任务的目标， 并从过去的失败中反思，以吸取经验。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;记忆&lt;/strong&gt;：LLM的上下文长度有限， 通过额外的记忆系统以提升LLM作为大脑的能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;工具调用&amp;amp;行动&lt;/strong&gt;：LLM通过API调用的方式，执行任务， 与外界交互，而不是只是输出文字。&lt;/p&gt;
&lt;h3 id=&#34;探索ai代理的独特能力人类与单一llm无法比拟&#34;&gt;&lt;strong&gt;探索AI代理的独特能力：人类与单一LLM无法比拟&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;AI系统的主要优势在于它们的规模和效率。这些系统能够执行以下任务，超越人类能力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;大规模数据处理&lt;/strong&gt;：AI能够高效地分析和处理超出人类理解范围的数据量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;无需休息的持续操作&lt;/strong&gt;：AI系统可以不间断地运行，而无需像人类那样休息和恢复。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;超快速计算&lt;/strong&gt;：AI可以迅速执行复杂的计算，处理速度和效率远超人类。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;AI代理与单一LLM的不同:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;根据Andrew Ng在讲座中分享的内容，使用相对“简单”模型的代理工作流程（例如GPT-3.5）在实际应用中往往能够超越使用“智能”模型（如GPT-4）的零次提示。这说明在特定场景下，选择适当的AI模型和策略可能比单一的高级模型更有效。&lt;/p&gt;
&lt;p&gt;AI代理在决策制定中的应用也显示出其独特的优势。它们可以在没有情感偏见的情况下，基于大量数据做出快速且精确的决策。这种能力在需要快速响应和高精确度的领域尤为重要，如金融交易和紧急响应系统。&lt;/p&gt;
&lt;h2 id=&#34;agent的规划和思维过程&#34;&gt;&lt;strong&gt;Agent的规划和思维过程&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI Agent在处理复杂任务时，通过将大任务分解成小任务来提高效率。此外，自我反思能力允许Agent从过去的行动中学习，通过评估过去的决策来改善未来的表现。&lt;/p&gt;
&lt;p&gt;CoT，Chain of Thought， &lt;a href=&#34;https://arxiv.org/abs/2201.11903&#34;&gt;Wei et al. 2022&lt;/a&gt;。 即“思维链”，是一种使Agent逐步思考的方法。它通过要求模型展示解决问题的中间步骤来加强其逻辑推理能力，从而提高决策的质量和准确性。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png&#34; alt=&#34;截屏2024-05-08 15.37.21.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tree of Thoughts， ToT&lt;/strong&gt;  (&lt;a href=&#34;https://arxiv.org/abs/2305.10601&#34;&gt;Yao et al. 2023&lt;/a&gt;)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Agent学习笔记：OpenAI Function Calling完全指南</title>
      <link>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0openai-function-calling%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sun, 28 Apr 2024 15:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0openai-function-calling%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/</guid>
      <description>&lt;h2 id=&#34;写在最开始&#34;&gt;写在最开始&lt;/h2&gt;
&lt;p&gt;当我们在讨论基于大型语言模型（LLM-based）的智能代理（agent）时，我们究竟在谈论什么？根据Lilian W在其文章《LLM Powered Autonomous Agents》中的讨论，一个智能代理需要具备几个核心能力：规划（Planning）、记忆（Memory）、以及工具使用（Tool use）。特别地，工具使用方面的进展，得益于OpenAI在API中提供的function calling功能，为我们开启了新的可能性。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/agent-overview.png&#34; alt=&#34;AGI&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;OpenAI function calling，作为智能代理与外部工具交互的基本方式，对于每位从业者来说都是必备技能。随着技术的发展，我们期望的不只是能与我们对话的LLM，而是能够辅助我们使用各种工具、做出决策的智能伙伴。&lt;/p&gt;
&lt;p&gt;不过需要特别指出的是，最近OpenAI在Chat Completions API中已经废弃了“函数（function）”的使用，转而采用“工具（tool）”。这一变更旨在拓宽LLM集成的功能范围，为更复杂的交互模式铺平道路，如构建能够相互作用的多代理系统。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.16.54.png&#34; alt=&#34;截屏2024-03-28 15.16.54.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.17.38.png&#34; alt=&#34;截屏2024-03-28 15.17.38.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;尽管如此，由于语言习惯的原因，本文中仍然会使用function calling的术语来描述OpenAI的tool using功能，因为“function calling”的说法已经深入人心了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核心内容概览&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Function Calling的定义&lt;/strong&gt;：解释什么是function calling，以及它在智能代理工作中的作用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OpenAI Cookbook示例&lt;/strong&gt;：提供实际的function calling示例，帮助读者理解其在实际应用中的用途。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;开源LLM的Tool Using&lt;/strong&gt;：探索如何在开源大型语言模型中实现工具使用，以及LLM在tool using的时候经历了什么。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;del&gt;评价与训练&lt;/del&gt;&lt;/strong&gt;&lt;del&gt;：讨论如何评价开源模型的工具使用能力，以及如何训练LLM进行有效的工具使用。&lt;/del&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;鉴于整理笔记的速度远赶不上更新的速度， 会将第四部份作为单独的部分整理。&lt;/p&gt;
&lt;h2 id=&#34;何为function-calling&#34;&gt;何为function calling&lt;/h2&gt;
&lt;p&gt;一句话解释：&lt;strong&gt;function calling从本质上并不是严格的工具调用， 而是作为工具调用的前奏，它通过更加结构化的方式指导LLM输出，为在本地执行具体函数提供了参数，铺平了道路。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;具体来说，function calling允许LLM在执行过程中通过指定的参数来调用并执行一个特定的函数。这种方式不仅实现了代码的重用和模块化处理，而且能够从模型中获取更可靠的结构化数据回应。在API调用过程中，开发者可以描述想要执行的功能，并让模型智能地选择输出包含所需参数的JSON对象。&lt;strong&gt;这个过程中，Chat Completions API本身不直接执行任何函数调用，而是生成了可以在开发者代码中实现函数调用的JSON。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;function calling的应用范围广泛，如&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;创建智能助手：通过调用外部API回答问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;转换指令：将自然语言指令转换成API调用指令。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据提取：从文本中提取结构化数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;function calling的过程涵盖了从定义函数集、通过模型生成遵循自定义模式的JSON对象字符串，到在代码中解析这个字符串并调用相应函数的全过程。这一连串操作不仅自动化了交互过程，还确保了执行操作的安全性和准确性。&lt;/p&gt;
&lt;h2 id=&#34;一些常见的问题&#34;&gt;一些常见的问题&lt;/h2&gt;
&lt;h3 id=&#34;json-mode&#34;&gt;JSON mode&lt;/h3&gt;
&lt;p&gt;json mode 和tool-using 有什么关系？有了json mode 还需要用到tool-using吗？&lt;/p&gt;
&lt;p&gt;从json mode 的本质， 更多的是在system prompt 增加一句类似“请以json格式输出”之类的话，然后在LLM输出时增加json结果检查和格式转换。在使用时只需要在&lt;code&gt;client.chat.completions.create &lt;/code&gt;中 增加&lt;code&gt;response_format={ &amp;quot;type&amp;quot;: &amp;quot;json_object&amp;quot; }&lt;/code&gt; 即可。&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>https://niraya666.github.io/about/</link>
      <pubDate>Sun, 21 Apr 2024 12:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/about/</guid>
      <description>&lt;h3 id=&#34;个人介绍&#34;&gt;个人介绍&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;后现代人类&lt;/li&gt;
&lt;li&gt;AI从业者与终身学习者&lt;/li&gt;
&lt;li&gt;工作狂&lt;/li&gt;
&lt;li&gt;世界探索者&lt;/li&gt;
&lt;li&gt;INFJ&lt;/li&gt;
&lt;li&gt;阅读 听歌 创作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;欢迎来到我的个人博客！&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAG工具箱：文档解析与表格处理</title>
      <link>https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E4%B8%8E%E8%A1%A8%E6%A0%BC%E5%A4%84%E7%90%86/</link>
      <pubDate>Sat, 20 Apr 2024 17:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E4%B8%8E%E8%A1%A8%E6%A0%BC%E5%A4%84%E7%90%86/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/post-cover/rag_toolkits_2.JPG&#34; alt=&#34;image&#34;  /&gt;
&lt;/p&gt;
&lt;h2 id=&#34;引言&#34;&gt;&lt;strong&gt;引言&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;在信息化时代，数据和知识的快速提取变得尤为重要。特别是对于学术和技术文档，如何从格式丰富且结构复杂的PDF文件中准确地提取信息，是提高研究效率的关键。本文将探讨几种先进的技术方法，用于优化学术论文的PDF解析及其表格内容的处理。&lt;/p&gt;
&lt;p&gt;对于文档解析，&lt;strong&gt;&lt;code&gt;langchain&lt;/code&gt;&lt;/strong&gt; 和 &lt;strong&gt;&lt;code&gt;llama_index&lt;/code&gt;&lt;/strong&gt; 提供的 &lt;strong&gt;&lt;code&gt;document loader&lt;/code&gt;&lt;/strong&gt; 能够支持多种文件类型，覆盖绝大多数文档格式的需求。但对于pdf解析而言还存在着一些挑战。&lt;/p&gt;
&lt;h3 id=&#34;人类与机器的阅读差异&#34;&gt;&lt;strong&gt;人类与机器的阅读差异&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;尽管PDF格式适合人类阅读，提供了优秀的视觉体验和格式保真，但它并不适合机器阅读。PDF文件通常包含复杂的布局和多样的内容元素，如多列布局、公式和表格，这些都给自动解析带来了挑战。&lt;/p&gt;
&lt;h3 id=&#34;常见的pdf解析问题&#34;&gt;&lt;strong&gt;常见的PDF解析问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;使用传统的PDF解析库可能遇到多种问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;多列布局导致的文本流读取错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;公式和表格的解析效果差，难以正确提取信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;解析过程中结构化信息（如标题和列表）的丢失。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;影印版PDF的文本无法被标准OCR工具识别。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;高级解析技术&#34;&gt;&lt;strong&gt;高级解析技术&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;根据&lt;a href=&#34;https://unstructured.io/&#34;&gt;unstractued&lt;/a&gt;提供的方案，文档解析可以大致分为两种方法：结构化解析和基于图像的解析。结构化解析侧重于从文档中提取文字和其它字符数据。而图像基解析则包括以下两种技术：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OCR技术&lt;/strong&gt;：首先使用目标检测模型对文档布局进行分析，识别出标题、表格等关键元素的位置，然后在这些位置上使用OCR技术提取文字。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;基于Transformer的端到端解析&lt;/strong&gt;：使用深度学习模型直接将图像转换为相应的文字内容。在这方面，&lt;strong&gt;&lt;code&gt;Dount&lt;/code&gt;&lt;/strong&gt; 和 &lt;strong&gt;&lt;code&gt;Nougat&lt;/code&gt;&lt;/strong&gt; 模型表现出色，尤其是 &lt;strong&gt;&lt;code&gt;Nougat&lt;/code&gt;&lt;/strong&gt; 能够将图像中的文章整理成Markdown或Latex格式，非常适合需要保留结构信息（如标题层级、公式和表格）的场景。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;只可惜Nougat只针对英文的学术论文做了训练，但遇到其他语言如中文论文的效果就不是那么的好了。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://unstructured-io.github.io/unstructured/_images/strategy.png&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;必须强调一点的是，Markdown格式因其简洁性和易于解析的特点，被广泛认为是LLM（大型语言模型）友好的文档格式。Markdown通过明确的标记语法，帮助模型更好地理解文档结构和内容，从而提高信息提取的准确性和效率。特别在存在大量公式，表格的学术论文场景下，Markdown可能是更合适的格式选择。&lt;/p&gt;
&lt;h2 id=&#34;快速上手使用nougat将pdf解析成适合llm读取的markdown&#34;&gt;快速上手：使用Nougat将pdf解析成适合LLM读取的markdown&lt;/h2&gt;
&lt;p&gt;依赖按照&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pip&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;q&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pymupdf&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Levenshtein&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nltk&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pip&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;q&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;git&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;https&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;github&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;com&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huggingface&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transformers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;git&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Load model and processor&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;transformers&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AutoProcessor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VisionEncoderDecoderModel&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;processor&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AutoProcessor&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_pretrained&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;facebook/nougat-base&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VisionEncoderDecoderModel&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;from_pretrained&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;facebook/nougat-base&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;cuda&amp;#34;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cuda&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;is_available&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;cpu&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将pdf转成图像&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;typing&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Optional&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;io&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;fitz&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pathlib&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Path&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rasterize_paper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;outpath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Optional&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;dpi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;96&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;return_pil&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Optional&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;io&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BytesIO&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]]:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Rasterize a PDF file to PNG images.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Args:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        pdf (Path): The path to the PDF file.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        outpath (Optional[Path], optional): The output directory. If None, the PIL images will be returned instead. Defaults to None.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        dpi (int, optional): The output DPI. Defaults to 96.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        return_pil (bool, optional): Whether to return the PIL images instead of writing them to disk. Defaults to False.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        pages (Optional[List[int]], optional): The pages to rasterize. If None, all pages will be rasterized. Defaults to None.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    Returns:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        Optional[List[io.BytesIO]]: The PIL images if `return_pil` is True, otherwise None.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pillow_images&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;outpath&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;return_pil&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;isinstance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;pdf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fitz&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pages&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;pages&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;page_bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pdf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_pixmap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dpi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dpi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pil_tobytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;PNG&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;return_pil&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;n&#34;&gt;pillow_images&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;io&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BytesIO&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outpath&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;%02d&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;.png&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;wb&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;page_bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;Exception&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;return_pil&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pillow_images&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;transformers&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;StoppingCriteria&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;StoppingCriteriaList&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;collections&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;defaultdict&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;RunningVarTorch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;L&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;L&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;L&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Tensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;elif&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;L&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;variance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;var&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;var&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;StoppingCriteriaScores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;StoppingCriteria&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.015&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;threshold&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threshold&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vars&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RunningVarTorch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;varvars&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RunningVarTorch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;L&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop_inds&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;defaultdict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stopped&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;defaultdict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;bool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@torch.no_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__call__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LongTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;FloatTensor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;last_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vars&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;last_scores&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cpu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;varvars&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vars&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;variance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;varvar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;varvars&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;variance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;last_scores&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;varvar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;threshold&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop_inds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stopped&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stopped&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop_inds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop_inds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                        &lt;span class=&#34;nb&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.15&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;window_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4095&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stop_inds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stopped&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;all&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stopped&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stopped&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将pdf转成markdown&lt;/p&gt;</description>
    </item>
    <item>
      <title>游记：2024-春 昆明大理</title>
      <link>https://niraya666.github.io/travel/%E6%B8%B8%E8%AE%B02024-%E6%98%A5-%E6%98%86%E6%98%8E%E5%A4%A7%E7%90%86/</link>
      <pubDate>Wed, 10 Apr 2024 00:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/travel/%E6%B8%B8%E8%AE%B02024-%E6%98%A5-%E6%98%86%E6%98%8E%E5%A4%A7%E7%90%86/</guid>
      <description>&lt;h1 id=&#34;游记2024-春-昆明大理&#34;&gt;游记：2024-春 昆明大理&lt;/h1&gt;
&lt;h2 id=&#34;昆明&#34;&gt;昆明&lt;/h2&gt;
&lt;h3 id=&#34;时间似乎停止了&#34;&gt;时间似乎停止了&lt;/h3&gt;
&lt;p&gt;不知为何在昆明有一种回到兰州的感觉，一样的三线省会，似曾相识的破败老城区街道，赫鲁晓夫楼，砖瓦房，和五六十年代的家属大院，似乎时间就停止流动了。我不认为这是种贬义的表达，至少清晨行走在老街区，唤起了我上学时，清晨走出校园到火车站赶火车的尘封记忆。
不过需要提一嘴的是，似乎当前的实体经济，特别是在老城区，不论是这次旅行所看到的，还是之前在故乡和别的城市所看到的，可以说是很糟糕了。目光所及有一半的店面处于关门转让的状态，而开着的那一半，又有近乎三成处于清仓甩卖中。&lt;/p&gt;
&lt;h3 id=&#34;古镇ptsd&#34;&gt;古镇PTSD&lt;/h3&gt;
&lt;p&gt;在全国绝大多数古镇逐渐趋同演化的当下，不知这是否是件悲哀的事。因为去云南省博物馆的途中会路过官渡古镇，遂决定顺便去看看。从古镇的东北边进入至正门而出，这次访问让我有幸同时见证了从破败而真实的古镇到商业化过度开发的古镇的转变。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://live.staticflickr.com/65535/53659997366_7bdf10738b_w.jpg&#34; alt=&#34;官渡古镇&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;在历史长河中被剥夺了名字的人&#34;&gt;在历史长河中被剥夺了名字的人&lt;/h3&gt;
&lt;p&gt;在昆明这个城市名字的由来中，有一段被历史辗转淡忘的故事。昆明这一名称起源于昆明夷——西汉时期活跃在洱海周边的一个游牧民族。而在这片土地上生活的滇人，一个拥有先进青铜技术的农耕文明，不断地抵抗游牧民族的侵扰。尽管如此，在历史的长河中，正是这些滇人创造了辉煌的文明，却在历史的演进中失去了自己的名字。这不禁让人感受到一种悲剧的讽刺——在自己孕育辉煌的土地上，却被剥夺了命名的权力。这反映出历史的无情，以及文化与权力之间复杂的交织。&lt;/p&gt;
&lt;h3 id=&#34;故乡与迁徙&#34;&gt;故乡与迁徙&lt;/h3&gt;
&lt;p&gt;在省博的临时展区，有幸看到了一个关于迁徙和故乡的特别展。 正巧这次来云南的最初目的也是为了探寻人生的下一个迁徙地。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;今天，流动成为常态。我们祖辈所拥有的那种一生居于一地的安稳逐渐被打破。很多人离开熟悉的地方，到另一处，与来自天南地北的人一起，不知不觉将异乡生活成故乡。&lt;/p&gt;
&lt;p&gt;而提到故乡，你会想到什么？是那方伴你长大的土地，是老屋里围炉团聚的家人，是家乡菜的味道和浓浓的乡音，是家门口熟悉的街道、树林和田地，是小时候玩耍的院子，和那群如今已各奔东西的伙伴。无论走多远，想到那一草一木，一人一景，就安宁。&lt;/p&gt;
&lt;p&gt;这也许就是人们一直以来追寻的栖息地。在远方，在心里，它叫“香格里拉”。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;现代的我们因为各种原因，在故乡与异乡之间辗转，继续着“迁徙与流动”。展览策划过程中，我们以“故乡”“现居地”“理想地”为题，以“故事+展品”的方式开启活动征集，鼓励不同身份的人群通过不同角度的讲述，分享他们的感受与思考。在近一个月的时间里，我们得到了大家的积极回响。在大家的分享中，我们与不同的故事和记忆相连，也看到因为不同而更加多元、广阔的世界。&lt;/p&gt;
&lt;p&gt;这里展示的文字和物品，是记忆的承载，也是对“故的未来。&lt;/p&gt;
&lt;p&gt;乡”的“好久不见”，它记录着我们的成长，也指引着我们&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;大理&#34;&gt;大理&lt;/h2&gt;
&lt;p&gt;这次来大理的初始动机是实地考察和调研“数字游民”这个群体，他们是否真正像想象中的自由，他们是如何工作和生活的， 他们背后的故事又是什么？ 以及他们为什么选择大理？&lt;/p&gt;
&lt;p&gt;感谢Dalihub， 让我有幸认识一群有趣的人。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://live.staticflickr.com/65535/53660356884_1676ae103e_z.jpg&#34; alt=&#34;E0322096-D284-4044-BFAD-C6655AA9EAB9_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;来自海边房子&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://live.staticflickr.com/65535/53660223478_846693b3a1_w.jpg&#34; alt=&#34;259DFD62-6C94-4135-9D79-CD1A775DCFF1_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;Dalihub的秘密空间&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://live.staticflickr.com/65535/53660223473_2d7c23b817_w.jpg&#34; alt=&#34;5E8B65D3-9970-41AB-9E2A-133E8CB0952C_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;救火途中的直升机&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://live.staticflickr.com/65535/53660223468_35ffcb583c_w.jpg&#34; alt=&#34;7F7303CF-6B12-4417-B71A-B0826682E0F2_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;自由飞翔&lt;/p&gt;
&lt;h3 id=&#34;猜你喜欢是坏的吗&#34;&gt;猜你喜欢是“坏”的吗&lt;/h3&gt;
&lt;p&gt;在大理的第二天，我便幸运地参与了一场与我的工作密切相关的线下沙龙活动，主题涉及推荐系统。我的工作列表中正好有一项是关于如何防止大型科技公司通过推荐系统作恶的问题。
活动中，主讲人“西雅图大黄蜂”提出了一个观点：所有的算法和技术本质上都是中性的，真正的“恶”是由使用它们的人带来的。作为技术从业者，我们当然不希望看到自己的发明像原子弹一样被用于恶劣的目的。但现实往往很残酷，技术的接受与否很大程度上是由资本决定的，而非我们。&lt;/p&gt;
&lt;p&gt;之前我考虑过一个想法：将推荐系统的召回和排序分开，召回过程保留在服务器端，而排序则转移到用户端，这样一来可以提高用户的隐私保护。技术上并不复杂，真正的挑战来自于资本或大公司缺乏推行此类改变的动力。除非有一天，大多数用户愿意为保护隐私牺牲一定的便利性，否则这种改变还遥遥无期，至少在当前的中国是这样的。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://mmbiz.qpic.cn/mmbiz_png/XVQWiaVrXNFVWAFWZMMYiczNYLvg9dPX3JKlYNQexPiceosvQXz4CHIic0ZN0Naw6BHDxQj7Rd1kZvFoBV9HBxKZ4A/640?wx_fmt=png&amp;amp;from=appmsg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;的多面人生.JPG&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;再次感谢主理人Nian和主讲人魏峰，一次难忘的体验。&lt;/p&gt;
&lt;h3 id=&#34;真的躺平吗不只是喘口气&#34;&gt;真的躺平吗？不，只是喘口气&lt;/h3&gt;
&lt;p&gt;选择大理的理由： 成本，气候， 和有趣的人们&lt;/p&gt;
&lt;p&gt;在大理，你可以遇到形形色色的人物：那些选择在此旅居的设计师，决定在退休后移居大理的上海夫妇，因成本考虑而搬来的独立开发者，还有视大理为家的咨询师小姐姐。这些都是构成大理独特社群氛围的不同面貌。&lt;/p&gt;
&lt;p&gt;当你不确定下一步该做什么时，不妨去洱海边走走，那里的美景足以让你放慢脚步，深呼吸，重新找回自己的节奏。在大理，即便是“躺平”，也是一种享受生活、与自然和谐共处的态度。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://live.staticflickr.com/65535/53659998511_c358f49f0b_c.jpg&#34; alt=&#34;458FFF9D-2F2B-44BA-97C6-61BCE1D4637D_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;洱海边落日&lt;/p&gt;
&lt;h3 id=&#34;取舍及时调整自己的欲望&#34;&gt;取舍，及时调整自己的欲望&lt;/h3&gt;
&lt;p&gt;在网上能看到很多对于大理的劝退文， 无外乎就是过度商业化网红化， 城市规划稀烂，交通不方便，宰客现象严重等等。 以上我都认同， 对于一个习惯了大城市便利的人而言， 初到大理的感受的确是如此。 和在地的小伙伴聊下来，发现及时调整自己的欲望还是挺重要的。&lt;/p&gt;
&lt;p&gt;但是，在早晨拉开窗帘看到洱海的一瞬间， 似乎这一切都是值得的。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://live.staticflickr.com/65535/53659999386_a95d8713d9_w.jpg&#34; alt=&#34;732C07E9-39CD-430A-87F5-2C0D20084DF2_1_105_c.jpeg&#34;  /&gt;

随处可见的丁达尔效应&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;去跳海，去发疯！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://live.staticflickr.com/65535/53660223128_1d2709b4df_w.jpg&#34; alt=&#34;63447450-9DD1-4BE2-8450-25E4E5F54DBA_1_105_c.jpeg&#34;  /&gt;
&lt;/p&gt;</description>
    </item>
    <item>
      <title>RAG工具箱：评估RAG系统的方法论</title>
      <link>https://niraya666.github.io/posts/rag_toolkit_eval/</link>
      <pubDate>Mon, 08 Apr 2024 11:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/rag_toolkit_eval/</guid>
      <description>&lt;h2 id=&#34;写在最前面&#34;&gt;写在最前面&lt;/h2&gt;
&lt;p&gt;在过去的几个月中，我主要致力于与RAG（检索增强生成模型）相关的研究和实验工作。通过深入地分析众多论文和项目代码，我发现虽然在RAG领域取得基本成就相对容易，但要实现出色的成果却异常困难。&lt;/p&gt;
&lt;p&gt;此系列文章旨在分享我在RAG研究中的心得和挑战。正如我们从OpenAI的开发者日活动中看到的，即使是在这个领域的领头羊也在不断试验和努力以寻求突破。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/rag_toolkits/1_1.png&#34; alt=&#34;from openAI devday&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;在我们深入探索RAG系统提升的各种方法之前，有一个基本问题需要解决：我们如何准确地评估一个RAG系统的性能？这就像是在机器学习或深度学习任务中没有给定的测试集和评价标准，我们难以判断实验的成功与否。&lt;/p&gt;
&lt;p&gt;因此，本系列的第一篇文章将聚焦于介绍RAG系统的评价方法、相关指标以及测试框架，为我们接下来的探索设定明确的标准和目标。&lt;/p&gt;
&lt;h2 id=&#34;测试框架&#34;&gt;测试框架&lt;/h2&gt;
&lt;p&gt;以下是一些测试框架，为RAG系统评估提供了强大的支持。&lt;/p&gt;
&lt;h3 id=&#34;trulens&#34;&gt;&lt;strong&gt;TruLens&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;TruLens提供了一个独特的视角来评估和跟踪大型语言模型（LLM）实验，通过一系列创新的功能和方法，帮助开发者和研究人员更深入地了解模型性能和行为。&lt;/p&gt;
&lt;p&gt;TruLens的反馈功能（Feedback Functions）是其核心概念之一，提供了一种程序化的方法来评估应用的运行表现。这些函数从“可扩展性”和“有意义性”两个维度出发，考虑评估的范围，旨在为用户提供有价值的反馈，帮助他们理解和改进他们的LLM应用。&lt;/p&gt;
&lt;p&gt;在RAG应用中，提供准确的上下文信息至关重要，以避免生成不真实的“幻觉”答案。TruLens采用了创新性的RAG三元组评估方法，专门针对RAG架构的每个环节进行幻觉风险评估，确保模型的每个部分都能有效地工作，从而减少误导信息的产生。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://www.trulens.org/assets/images/RAG_Triad.jpg&#34; alt=&#34;TruLens RAG_Triad&#34;  /&gt;
&lt;/p&gt;
&lt;h4 id=&#34;上下文相关性context-relevance&#34;&gt;上下文相关性（Context Relevance）&lt;/h4&gt;
&lt;p&gt;上下文相关性是评估RAG应用的第一步，确保每一段检索到的上下文都与提出的查询紧密相关。TruLens利用序列化记录的结构来评估上下文的相关性，这是一个关键的步骤，确保模型在正确的信息上生成回答。&lt;/p&gt;
&lt;h4 id=&#34;真实性groundedness&#34;&gt;真实性（Groundedness）&lt;/h4&gt;
&lt;p&gt;在检索到的上下文信息的基础上，大型语言模型将生成答案。TruLens强调了独立验证每个回答的重要性，以确保它们基于可靠信息，并且能够在检索到的上下文中找到支持的证据。这一步骤是确保模型回答的真实性和可靠性的关键。&lt;/p&gt;
&lt;h4 id=&#34;答案相关性answer-relevance&#34;&gt;答案相关性（Answer Relevance）&lt;/h4&gt;
&lt;p&gt;最后，评估需要确保最终回答有效地解答了原始问题，这通过评估应用的最终回答与用户输入的相关性来实现。这一过程确保了模型的输出不仅是真实的，而且是对用户查询有用的。&lt;/p&gt;
&lt;p&gt;TruLens还提出了“诚实、无害和有帮助”的评估原则（Honest, Harmless, and Helpful Evaluations），这些原则旨在确保LLM应用在提供帮助的同时，也是安全和可信的。&lt;/p&gt;
&lt;h3 id=&#34;ragas&#34;&gt;Ragas&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://docs.ragas.io/en/stable/_static/imgs/component-wise-metrics.png&#34; alt=&#34;Ragas&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;Ragas框架专为评估检索增强生成（RAG）系统而设计，定义了四个核心评估指标：上下文相关性（context_relevancy）、上下文回溯（context_recall）、忠实度（faithfulness）和答案相关性（answer_relevancy）。这些指标共同构成了Ragas的评分体系，提供了一个全面的方法来评价RAG系统的性能。&lt;/p&gt;
&lt;p&gt;此外，Ragas巧妙地利用大语言模型（LLM）进行无参考评估，有效降低了评估成本。通过这种方法，Ragas能够提供一种既经济又有效的方式来评估RAG系统，尤其是在处理大量数据和复杂查询时。&lt;/p&gt;
&lt;p&gt;其他测试框架&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DeepEval&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/confident-ai/deepeval&#34;&gt;DeepEval&lt;/a&gt; &lt;a href=&#34;https://www.confident-ai.com/blog/how-to-evaluate-rag-applications-in-ci-cd-pipelines-with-deepeval&#34;&gt;How to Evaluate RAG Applications in CI/CD Pipelines with DeepEval&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ARES&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;github: &lt;a href=&#34;https://github.com/stanford-futuredata/ARES&#34;&gt;https://github.com/stanford-futuredata/ARES&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Paper: ARES: &lt;a href=&#34;https://arxiv.org/abs/2311.09476&#34;&gt;An Automated Evaluation Framework for Retrieval-Augmented Generation Systems&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://python.langchain.com/docs/guides/evaluation/&#34;&gt;LangChain Evals&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.llamaindex.ai/en/stable/module_guides/evaluating/root.html&#34;&gt;Llama Index Evals&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/uptrain-ai/uptrain&#34;&gt;UpTrain&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据&#34;&gt;数据&lt;/h2&gt;
&lt;p&gt;在评估数据集时，不必依赖人工标注的标准答案，而是通过底层的大语言模型 (LLM) 来进行评估。&lt;/p&gt;</description>
    </item>
    <item>
      <title>My First Post: Hello-World!</title>
      <link>https://niraya666.github.io/posts/helloworld/</link>
      <pubDate>Sat, 30 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://niraya666.github.io/posts/helloworld/</guid>
      <description>&lt;h1 id=&#34;hello-world&#34;&gt;Hello-World!&lt;/h1&gt;
&lt;p&gt;欢迎来到我的博客&lt;/p&gt;
&lt;p&gt;在这里，我将深入探索生成式人工智能的奥秘，同时也会涉猎音乐、电影等领域，分享一些个人的思考和感悟。&lt;/p&gt;
&lt;h2 id=&#34;为什么我决定写博客&#34;&gt;为什么我决定写博客&lt;/h2&gt;
&lt;p&gt;在生活的纷扰和无尽的日常中，我发现自己一直在与拖延症作斗争。直到今天，我终于下定决心，决定将心中的思绪和感悟记录下来，开启我的博客之旅。&lt;/p&gt;
&lt;p&gt;有几个原因驱使我做出了这个决定。&lt;/p&gt;
&lt;p&gt;首先，岁月不饶人，尤其是经历了新冠疫情之后，我明显感觉到我的记忆力不如以往。过去能够轻松驾驭多重任务的我，如今却常在走入客厅的半路上忘记初衷，或是在浏览器的搜索框前失去了寻找的目的。这种突如其来的迷茫，让我开始思索，我的思绪是否正如秋日里的落叶，悄然飘落。&lt;/p&gt;
&lt;p&gt;其次，在深夜的静思中，我时常回想起坂本龙一那句引人深思的话：“我还能看到几次满月？”这不仅是对时间流逝的感慨，更是一种对生命有限性的深刻体悟。在这有限的时光里，我究竟能留下什么？假如我的时间之沙仅剩下几颗，我的存在又有何意义？我不求答案，但愿通过这些文字，如同在时间的长河中种下一棵树，哪怕是最微小的存在，也能留下自己生命的痕迹。&lt;/p&gt;
&lt;p&gt;最后，我被“数据主义”（Dataism）这一概念深深吸引，它如同一面镜子，映照出在数字时代，我们的数据、思考和情感不仅仅是信息的载体，更是构成我们数字化身份的基石。随着AI的羽翼日渐丰满，我开始憧憬一个可能的未来，其中一个由我的数据、思想和经历塑造出的“我”，在某个未知的时间点复苏。这种思考，如同在深海中发现了一座灯塔，为我的存在指明了一条全新的路径。在这个时代，我选择不再是沉默的旁观者，而是通过我的文字，积极参与到这场未知的探索中。&lt;/p&gt;
&lt;p&gt;因此，这篇博客标志着我的新开始。虽然不确定未来的路会怎样，但至少，在这个过程中，我会找到自己的声音，并希望能够与你共鸣。&lt;/p&gt;
&lt;script src=&#34;https://utteranc.es/client.js&#34;
        repo=&#34;https://github.com/Niraya666/niraya666.github.io&#34;
        issue-term=&#34;pathname&#34;
        theme=&#34;github-dark&#34;
        crossorigin=&#34;anonymous&#34;
        async&gt;
&lt;/script&gt;</description>
    </item>
  </channel>
</rss>
