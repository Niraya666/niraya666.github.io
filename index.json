[{"content":"AI 新闻 OpenAI 发布o1-preview OpenAI于9月12日发布了其最新的大型语言模型o1-preview，该模型在推理能力上实现了重大突破。o1模型通过使用Chain of Thought技术，能够解决复杂的数学和编程问题，其表现超越了之前的GPT-4o模型。\no1模型在多个基准测试中表现出色，包括在美国国际数学邀请赛中取得接近全国前500名的成绩，并在科学问题的准确度上超过了人类博士水平。该模型通过强化学习增强了推理能力，能够逐步分析问题，拆解复杂步骤并自动修正错误。\nOpenAI还推出了o1-mini版本，虽然规模较小，但在推理任务上表现优异，且成本更低。o1-mini特别适合编程任务，预计未来将向所有ChatGPT用户开放。\n相关信息：\nsystem card\n官方介绍\nReverse engineering OpenAI’s o1\n去年 Jim Fan 对于 Q* 的预测\n相关GitHub仓库： Awesome LLM Strawberry (OpenAI o1)\n关于 Open AI o1 的 AMA\nMIT EI seminar, Hyung Won Chung from OpenAI. \u0026ldquo;Don\u0026rsquo;t teach. Incentivize.\u0026rdquo;\nQwen2.5系列模型 阿里云的Qwen团队近日发布了Qwen2.5系列大型语言模型。该系列包括多种尺寸的模型，从0.5B到72B参数不等，并提供基础和指令调优版本。Qwen2.5在多个方面取得了显著进步，包括更强的知识储备、编码和数学能力的提升，以及在指令跟随、长文本生成和结构化数据理解方面的改进。\nQwen2.5支持多达29种语言，能够处理长达128K的上下文，并生成最多8K的文本。该模型在多语言支持、角色扮演和聊天机器人条件设置方面表现出更高的弹性。\n此外，Qwen2.5还推出了专门用于编码和数学的模型，如Qwen2.5-Coder和Qwen2.5-Math，进一步增强了在这些领域的应用能力。Qwen2.5-Coder特别在代码生成、推理和修复方面表现出色，而Qwen2.5-Math则在数学推理能力上有显著提升。\n官方博客：Qwen2.5: 基础模型大派对！\nDeepSeek-V2.5 DeepSeek-AI 推出了其最新模型 DeepSeek-V2.5，成功融合了之前版本 DeepSeek-V2-Chat 和 DeepSeek-Coder-V2-Instruct 的功能。该模型集成了通用语言处理和编程能力。\nDeepSeek-V2.5 经过性能优化，特别在写作、任务执行和高级编程等方面表现出色，在 AlpacaEval 2.0 和 HumanEval Python 等基准测试中超越了前代产品。此外，模型还新增了函数调用功能，使其能够与外部工具交互，拓展了实时天气报告、翻译等应用场景。\n该模型采用了多头潜在注意力（MLA）等技术创新，显著提升了推理速度和资源利用效率。同时，DeepSeek-V2.5 在 Hugging Face 平台上开源，并提供商业化许可，允许企业将其用于自动化客服、内容生成等业务流程中。其性能表现已跻身主流排行榜，与 GPT-4-Turbo 和 LLaMA3-70B 等顶尖模型齐名。\n值得关注的开源项目 g1: Using Llama-3.1 70b on Groq to create o1-like reasoning chains 项目旨在通过使用 Llama-3.1 70b 模型在 Groq 上创建类似 o1 的推理链，以提高大型语言模型（LLM）的推理能力。该项目通过提示策略，帮助 LLM 解决通常难以处理的逻辑问题。g1 通过动态的推理链展示 LLM 的“思考”过程，允许用户看到每个推理步骤的标题和内容。项目的目标是展示仅通过提示就能克服 LLM 逻辑问题的潜力，并为开源社区提供灵感，以开发新的策略来生成类似 o1 的推理。g1 适用于需要改进逻辑推理能力的应用场景，尤其是那些涉及复杂问题解决的领域。\n项目地址: GitHub - bklieger-groq/g1\nLocal File Organizer Local File Organizer 是一个开源项目，旨在通过人工智能技术帮助用户高效地管理本地文件，包括文本、图像和PDF文档。该工具利用 Google Gemma 2-2B 和 Llava v1.6 模型，能够智能扫描、重组和整理文件，确保用户的隐私安全。所有处理均在本地设备上完成，无需互联网连接，确保数据不被外泄。\n其 GitHub 页面：Local File Organizer。\nGOT-OCR2.0 该项目提供了一个强大的OCR模型，能够处理各种类型的光学字符，包括文本、数学公式、表格和图形等。GOT-OCR2.0的设计旨在提高OCR的准确性和效率，支持多种输入格式和输出类型，适用于学术研究和实际应用。\n更多信息请访问项目的GitHub页面：GOT-OCR2.0。\n模型： huggingface.co/ucaslcl/GOT-OCR2_0\nFish Speech Fish Speech 是一个全新的开源文本转语音（TTS）解决方案，专为有基础的开发者设计。该项目基于 700,000 小时的多语言音频数据进行训练，支持多种语言，包括英语、中文、德语、日语等。其特点在于高质量的语音合成和丰富的表达能力，能够接近人类的语言处理水平。Fish Speech 的优点在于其开放性和可扩展性，开发者可以根据自己的需求进行定制和优化。更多信息请访问项目的 GitHub 页面：Fish Speech GitHub。\n出海网站经验总结 这个开源项目是一个针对海外网站的笔记管理工具，旨在帮助开发者更高效地记录和管理与海外网站相关的信息。项目的特点包括简洁的界面、易于使用的笔记功能以及支持多种格式的内容输入。优点在于它能够帮助有基础的开发者快速整理和查找信息，提高工作效率。该项目适合希望提升信息管理能力的开发者。更多信息可以访问项目的GitHub地址：GitHub - PrinceSinghhub。\nAwesome-Dify-Workflow Awesome-Dify-Workflow 是一个开源项目，旨在分享一些实用的 Dify DSL 工作流程，适合开发者自用和学习。该项目的特点包括支持多任务并行和会话变量，所有工作流程均可免费使用，且易于导入和修改。它为有基础的开发者提供了一个直观的界面，方便他们快速构建和发布自己的工作流。通过使用 Dify，开发者可以专注于创新，而无需从头开始构建复杂的系统。更多信息和代码可以在 GitHub 上找到。\nitext2kg itext2kg 是一个开源项目，旨在利用大型语言模型构建增量知识图谱。该项目的特点包括灵活性和可扩展性，允许开发者在不断变化的数据环境中动态更新知识图谱。它支持多种数据源，并提供了友好的接口，方便开发者进行集成和扩展。该项目特别适合具备一定基础的开发者，能够帮助他们在知识图谱构建和管理方面提升效率和效果。更多信息请访问项目的 GitHub 页面。\nKotaemon Kotaemon是一个开源的基于RAG（Retrieval-Augmented Generation）技术的工具，旨在帮助开发者与文档进行交互和对话。该项目的特点包括易于使用的界面、灵活的文档处理能力以及支持多种本地和云端模型的集成。Kotaemon特别适合有一定基础的开发者，能够通过自定义和扩展功能来满足特定需求。其优点在于能够提升文档检索和问答的效率，适用于各种应用场景。更多信息请访问其GitHub页面：Kotaemon GitHub。\n影音记录 精选歌单 Live演出 09.17 Milflife Vas 09.21 can festival 舟山 电影 是枝裕和影展《比海更深》\n最近在追的一部韩综《思想验证区域》，非常推荐。\n官方提供的政治倾向测试：https://thecommunity.co.kr/home\n书\u0026amp;阅读摘录 读完了JD-万斯《乡下人的悲歌》\nThe Intelligence Age The story of progress will continue, and our children will be able to do things we can’t.\nHow did we get to the doorstep of the next leap in prosperity?\nIn three words: deep learning worked.\nIn 15 words: deep learning worked, got predictably better with scale, and we dedicated increasing resources to it.\n再见了，盛夏 大部分中产阶级的打工人在工作困顿之际难免反思到工作的目的究竟是什么，而得到的结论普遍为以下几种： 第一种，为钱工作。 第二种，为未来工作。 第三种，为了不工作。\n在我身边的绝大多数人目前也都遵循这一成功模板来构建属于自己的幸福生活，而它的终局只能是幻觉。\n在《规训与惩罚》中，福柯指出这种规训在社会中具有着普遍性，称之为微权力。这种规训微权力通过规范来控制个体的行为，让社会形成了一种全景敞视的监狱，个体在这种权力结构中被迫自我规训，成为合格的社会成员。\n因此，工作和生活保持平衡是一个狡猾说法，它的隐藏含义是将工作与生活置于平等的定位。而生活是一切，工作只是工作，后者是为前者服务的手段而已。\n老猴子：因为空有天赋，不思进取，小富即安，沉迷享乐。想安逸，又想名利；想快意江湖，又想成佛作祖，哪有这样的好事？身本多忧，怎可全求？\nCreativity Fundamentally Comes From Memorization a flash of inspiration connecting internalized concepts. …\nBy definition, you can\u0026rsquo;t even be certain of novelty without familiarity of existing works. Creativity comes to those who have internalized the patterns of their art \u0026ndash; they can see the connection or novelty because it\u0026rsquo;s all in their head.\nTherefore autonomy enables creativity, and a system helps achieve autonomy quicker.\nIt involved two steps:\nMemorizing the different classifications/patterns in a concept [1] Exposing myself to a breadth of cases so I could match the real-world example to one of the previously learned patterns But I maintain that such pattern recognition is just another form of memorization, though often a more subconscious one. This is learned from repeated exposure, and what I\u0026rsquo;m attempting to do when I try to see a \u0026ldquo;breadth\u0026rdquo; of cases after learning the framework and available patterns to use.\nOnce this heuristic is internalized, it becomes a new primitive and we focus our attention to higher-level problems.\nOnce you learn music theory, you\u0026rsquo;re able to violate it in ways that resonate. Avant-garde art requires knowing what the establishment is to push the boundaries as orthogonally as possible.\nIf creativity is born from autonomy in multiple areas, then one way to become more creative is to become autonomous in many areas!\nSo if you want to be creative, learn lots of things in-depth, and learn how to learn them fast. Embrace systems to achieve this, and use them to free you up from the basics \u0026ndash; so you can focus on the novel.\n","permalink":"https://niraya666.github.io/monthly/2024-09/","summary":"\u003ch2 id=\"ai-新闻\"\u003eAI 新闻\u003c/h2\u003e\n\u003ch3 id=\"openai-发布o1-preview\"\u003eOpenAI 发布o1-preview\u003c/h3\u003e\n\u003cp\u003eOpenAI于9月12日发布了其最新的大型语言模型o1-preview，该模型在推理能力上实现了重大突破。o1模型通过使用Chain of Thought技术，能够解决复杂的数学和编程问题，其表现超越了之前的GPT-4o模型。\u003c/p\u003e\n\u003cp\u003eo1模型在多个基准测试中表现出色，包括在美国国际数学邀请赛中取得接近全国前500名的成绩，并在科学问题的准确度上超过了人类博士水平。该模型通过强化学习增强了推理能力，能够逐步分析问题，拆解复杂步骤并自动修正错误。\u003c/p\u003e\n\u003cp\u003eOpenAI还推出了o1-mini版本，虽然规模较小，但在推理任务上表现优异，且成本更低。o1-mini特别适合编程任务，预计未来将向所有ChatGPT用户开放。\u003c/p\u003e\n\u003cp\u003e相关信息：\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://cdn.openai.com/o1-system-card.pdf\"\u003esystem card\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/introducing-openai-o1-preview/\"\u003e官方介绍\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.interconnects.ai/p/reverse-engineering-openai-o1\"\u003eReverse engineering OpenAI’s o1\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://x.com/dotey/status/1835395891483554105\"\u003e去年 Jim Fan 对于 Q* 的预测\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e相关GitHub仓库： \u003ca href=\"https://github.com/hijkzzz/Awesome-LLM-Strawberry\"\u003e\u003cstrong\u003eAwesome LLM Strawberry (OpenAI o1)\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://x.com/op7418/status/1835153295855567356\"\u003e关于 Open AI o1 的 AMA\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.youtube.com/watch?v=kYWUEV_e2ss\"\u003eMIT EI seminar, Hyung Won Chung from OpenAI. \u0026ldquo;Don\u0026rsquo;t teach. Incentivize.\u0026rdquo;\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"qwen25系列模型\"\u003eQwen2.5系列模型\u003c/h3\u003e\n\u003cp\u003e阿里云的Qwen团队近日发布了Qwen2.5系列大型语言模型。该系列包括多种尺寸的模型，从0.5B到72B参数不等，并提供基础和指令调优版本。Qwen2.5在多个方面取得了显著进步，包括更强的知识储备、编码和数学能力的提升，以及在指令跟随、长文本生成和结构化数据理解方面的改进。\u003c/p\u003e\n\u003cp\u003eQwen2.5支持多达29种语言，能够处理长达128K的上下文，并生成最多8K的文本。该模型在多语言支持、角色扮演和聊天机器人条件设置方面表现出更高的弹性。\u003c/p\u003e\n\u003cp\u003e此外，Qwen2.5还推出了专门用于编码和数学的模型，如Qwen2.5-Coder和Qwen2.5-Math，进一步增强了在这些领域的应用能力。Qwen2.5-Coder特别在代码生成、推理和修复方面表现出色，而Qwen2.5-Math则在数学推理能力上有显著提升。\u003c/p\u003e\n\u003cp\u003e官方博客：\u003ca href=\"https://qwenlm.github.io/zh/blog/qwen2.5/\"\u003eQwen2.5: 基础模型大派对！\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"deepseek-v25\"\u003eDeepSeek-V2.5\u003c/h3\u003e\n\u003cp\u003eDeepSeek-AI 推出了其最新模型 DeepSeek-V2.5，成功融合了之前版本 DeepSeek-V2-Chat 和 DeepSeek-Coder-V2-Instruct 的功能。该模型集成了通用语言处理和编程能力。\u003c/p\u003e\n\u003cp\u003eDeepSeek-V2.5 经过性能优化，特别在写作、任务执行和高级编程等方面表现出色，在 AlpacaEval 2.0 和 HumanEval Python 等基准测试中超越了前代产品。此外，模型还新增了函数调用功能，使其能够与外部工具交互，拓展了实时天气报告、翻译等应用场景。\u003c/p\u003e\n\u003cp\u003e该模型采用了多头潜在注意力（MLA）等技术创新，显著提升了推理速度和资源利用效率。同时，DeepSeek-V2.5 在 Hugging Face 平台上开源，并提供商业化许可，允许企业将其用于自动化客服、内容生成等业务流程中。其性能表现已跻身主流排行榜，与 GPT-4-Turbo 和 LLaMA3-70B 等顶尖模型齐名。\u003c/p\u003e","title":"2024-09 月刊"},{"content":"第一次来到舟山，仅仅是因为Can-festival音乐节。\n上次错过了越位音乐节，这次看到Can-festival的阵容，根本不可能再错过。光是Day2的阵容：We Lost the Sea、Lost in Kiev、The Seven Mile Journey、声子虫，几乎全是我播放器里多年循环的乐队。更别提Day3，This Will Destroy You和World’s End Girlfriend等老牌乐队，还有年初遗憾未能见到的四月雨。\n与“普拉桑”的极限拉扯 出发前几天，台风“普拉桑”紧跟着前一个台风的步伐，直扑江浙沪，着实让我焦虑不已。临行的前一天，我每隔二十分钟就要刷新一次台风路径图，心里祈祷它能转向或加速离去。担心音乐节会取消，或是要在狂风暴雨中听音乐。不过，最终台风带来的破坏都留在了上海，而到了舟山，却意外地迎来了晴朗的天气。\n暴雨中的南浦大桥\n后摇和雨更配 其实，我一向讨厌下雨。但谁能想到，在海边，后摇与风雨竟如此契合。或许，这正是音乐的魔力。雨水肆意洒落，浸湿了镜片，视线模糊不清，分不清脸上的水滴究竟是从天而降，还是心底涌出的泪水。音乐与环境的交织，给了我一种难以言喻的感动。\n海边\n当安尼西亚说这首歌是献给孩子，愿这个世界没有伤害时，我的心突然被一种无法抑制的情感击中。或许我们无法阻止每一个悲剧的发生，但在音乐的陪伴下，我希望这个世界能逐渐变得更加温暖。愿这首《离别》不仅仅是一首哀歌。\nLost in Kiev 在合成器音色和处理上，确实惊艳到我了。不过，他们的贝斯手长的真的好像萨拉赫。\nLost in Kiev\nLITE 的音乐在雨中展现出了出乎意料的活力。即使雨水不停，现场的每个人都随着节奏跳动，那种难以言喻的现场氛围，仿佛雨水并不再是困扰，而是与音乐共舞的一部分。\n雨中的LITE\n声子虫的音墙依旧厚重，像一座无形的高山压迫着我。正如去年看他们演出时的一样， 特别喜欢他们开场时的创意—随着音乐的铺垫进行， 在屏幕上，一笔一画地把“聲子蟲” 三个字缓慢打出。\n缺了最后一笔的“聲子蟲”\n一直期待We Lost the Sea的现场演出，但就在那时，吉他却出了问题。声音时有时无，让本该震撼人心的演奏显得有些破碎。雨水不停地落在身上，心情也随之变得复杂。一点小小的遗憾，像是雨中一滴未曾融入地面的水珠，总让人感到有些不完整。\nWe Lost the Sea — by 群里的艺术家\nThe Seven Mile Journey — by 群里的艺术家\n年纪渐长，似乎每次出门前都有更多的顾虑。年轻时我总能义无反顾地冲向每一个音乐节，不管是风雨还是其他未知的挑战，都觉得无所谓。然而这次，在雨中，我的脑海里浮现出更多的“如果”：如果天气更好一些，如果能再勇敢一些……我无法完全放下这些顾虑，哪怕台上的音乐依旧动人，我却发现自己没有像以前那样尽兴了。也许成长的代价，就是学会在更多的限制和考量中寻找自己的平衡。\n遗憾，化作前行的力量 只看了Day2的演出后，考虑到气温骤降和大雨，再加上风大到船次取消，去普陀山的计划也被迫放弃，我决定提前撤离。没想到，海边的天气竟如此难以捉摸，Day3下午居然又转晴了。错过了傍晚的晚霞，也错过了在L-ISA环绕音响下的World’s End Girlfriend演出，实在是遗憾至极。然而，这些遗憾，正是让我期待下一次音乐节的动力。或许，正因为未尽的体验，才会让我对未来的演出更加期待。\n也感谢群里的小伙伴传来的照片和视频， 能让我第一时间见证这些美丽的瞬间。\n我错过的晚霞 — by 群里的艺术家\n四月雨和夕阳 — by 群里的艺术家\nThis Will Destroy You — by 群里的艺术家\nWEG — by 群里的艺术家\n当然，更要感谢罐总Can给大家带来的这次演出，愿大家都能圆梦。\n","permalink":"https://niraya666.github.io/travel/2024-can-festival-%E5%9C%A8%E6%B5%B7%E8%BE%B9-%E6%B7%B7%E6%9D%82%E7%9D%80%E9%9B%A8%E6%B0%B4%E5%92%8C%E6%B3%AA%E6%B0%B4-%E5%90%91%E5%90%8E%E6%91%87/","summary":"\u003cp\u003e第一次来到舟山，仅仅是因为Can-festival音乐节。\u003c/p\u003e\n\u003cp\u003e上次错过了越位音乐节，这次看到Can-festival的阵容，根本不可能再错过。光是Day2的阵容：We Lost the Sea、Lost in Kiev、The Seven Mile Journey、声子虫，几乎全是我播放器里多年循环的乐队。更别提Day3，This Will Destroy You和World’s End Girlfriend等老牌乐队，还有年初遗憾未能见到的四月雨。\u003c/p\u003e\n\u003ch2 id=\"与普拉桑的极限拉扯\"\u003e与“普拉桑”的极限拉扯\u003c/h2\u003e\n\u003cp\u003e出发前几天，台风“普拉桑”紧跟着前一个台风的步伐，直扑江浙沪，着实让我焦虑不已。临行的前一天，我每隔二十分钟就要刷新一次台风路径图，心里祈祷它能转向或加速离去。担心音乐节会取消，或是要在狂风暴雨中听音乐。不过，最终台风带来的破坏都留在了上海，而到了舟山，却意外地迎来了晴朗的天气。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/DE10C0BD-A093-45EE-B67F-421C767FE234.jpg\" alt=\"DE10C0BD-A093-45EE-B67F-421C767FE234.jpg\"  /\u003e\n\n\u003cem\u003e暴雨中的南浦大桥\u003c/em\u003e\u003c/p\u003e\n\u003ch2 id=\"后摇和雨更配\"\u003e后摇和雨更配\u003c/h2\u003e\n\u003cp\u003e其实，我一向讨厌下雨。但谁能想到，在海边，后摇与风雨竟如此契合。或许，这正是音乐的魔力。雨水肆意洒落，浸湿了镜片，视线模糊不清，分不清脸上的水滴究竟是从天而降，还是心底涌出的泪水。音乐与环境的交织，给了我一种难以言喻的感动。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/8E78A7AB-8588-4165-B71F-261E284C1E51_1_105_c.jpeg\" alt=\"8E78A7AB-8588-4165-B71F-261E284C1E51_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003e海边\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e当安尼西亚说这首歌是献给孩子，愿这个世界没有伤害时，我的心突然被一种无法抑制的情感击中。或许我们无法阻止每一个悲剧的发生，但在音乐的陪伴下，我希望这个世界能逐渐变得更加温暖。愿这首《离别》不仅仅是一首哀歌。\u003c/p\u003e\n\u003cp\u003eLost in Kiev 在合成器音色和处理上，确实惊艳到我了。不过，他们的贝斯手长的真的好像萨拉赫。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/ABF036E9-FBF3-4B73-9B8F-6804C5FFBEBD_1_105_c.jpeg\" alt=\"ABF036E9-FBF3-4B73-9B8F-6804C5FFBEBD_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003eLost in Kiev\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eLITE 的音乐在雨中展现出了出乎意料的活力。即使雨水不停，现场的每个人都随着节奏跳动，那种难以言喻的现场氛围，仿佛雨水并不再是困扰，而是与音乐共舞的一部分。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/CEF4C784-5E96-402F-A73B-AD3ED115EF1F_1_105_c.jpeg\" alt=\"CEF4C784-5E96-402F-A73B-AD3ED115EF1F_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003e雨中的LITE\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e声子虫的音墙依旧厚重，像一座无形的高山压迫着我。正如去年看他们演出时的一样， 特别喜欢他们开场时的创意—随着音乐的铺垫进行， 在屏幕上，一笔一画地把“聲子蟲” 三个字缓慢打出。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/46590887-7972-4CEF-A4F7-A40BF24EDAE4_1_105_c.jpeg\" alt=\"46590887-7972-4CEF-A4F7-A40BF24EDAE4_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003e缺了最后一笔的“聲子蟲”\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e一直期待We Lost the Sea的现场演出，但就在那时，吉他却出了问题。声音时有时无，让本该震撼人心的演奏显得有些破碎。雨水不停地落在身上，心情也随之变得复杂。一点小小的遗憾，像是雨中一滴未曾融入地面的水珠，总让人感到有些不完整。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/BEA4ACE5-B17A-48FB-9E95-EE2BFA987988_1_105_c.jpeg\" alt=\"BEA4ACE5-B17A-48FB-9E95-EE2BFA987988_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003eWe Lost the Sea — by 群里的艺术家\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/1EF13608-9B3E-4159-90C3-034AAD648C5D_1_105_c.jpeg\" alt=\"1EF13608-9B3E-4159-90C3-034AAD648C5D_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003eThe Seven Mile Journey — by 群里的艺术家\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e年纪渐长，似乎每次出门前都有更多的顾虑。年轻时我总能义无反顾地冲向每一个音乐节，不管是风雨还是其他未知的挑战，都觉得无所谓。然而这次，在雨中，我的脑海里浮现出更多的“如果”：如果天气更好一些，如果能再勇敢一些……我无法完全放下这些顾虑，哪怕台上的音乐依旧动人，我却发现自己没有像以前那样尽兴了。也许成长的代价，就是学会在更多的限制和考量中寻找自己的平衡。\u003c/p\u003e","title":"2024 Can-festival：在海边 混杂着雨水和泪水 向后摇"},{"content":"AI 新闻 Grok-2 Beta 版本 xAI公司发布了Grok-2和Grok-2 mini的测试版，现已向𝕏平台上的Premium和Premium+用户开放。Grok-2是一个先进的语言模型，在聊天、编码和推理方面表现出色，超过了Claude 3.5 Sonnet和GPT-4-Turbo等竞争对手。Grok-2 mini则在速度和答案质量之间取得平衡。此外，关于图像生成功能可能被滥用的问题也引起了关注。\n微软发布Phi-3.5系列模型 https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/discover-the-new-multi-lingual-high-quality-phi-3-5-slms/ba-p/4225280\n涵盖了Phi-3.5-mini、Phi-3.5-MoE和Phi-3.5-vision三种模型。\nPhi-3.5-mini：拥有3.8亿参数，支持128K上下文长度，专注于多语言支持和推理能力。\nPhi-3.5-MoE：混合专家模型，总参数量为42亿，但每次激活仅使用6.6亿参数。\nPhi-3.5-vision：具备4.2亿参数，能够处理多帧图像理解和推理任务，在单图像基准测试中表现显著提升。\nCursor AI 最近大热的一款AI编程辅助工具。\n不仅支持多行代码的自动完成，还能够根据代码上下文进行智能生成和重写， 代码解释和调试帮助。\n2024年8月，Cursor AI 完成了一轮6000万美元的融资，使得公司的估值达到了4亿美元。\nGoogle发布Gemma 2 2B模型及其相关工具 Google发布了新一代轻量级开源大语言模型Gemma 2 2B，并推出了一系列相关工具，包括ShieldGemma和Gemma Scope。这些新工具旨在提升AI的安全性、透明度和性能。\nQwen2-VL https://qwenlm.github.io/zh/blog/qwen2-vl/\n通义千文团队开源了 Qwen2-VL-2B 和 Qwen2-VL-7B，并发布了 Qwen2-VL-72B 的 API。\n72B在大部分指标上甚至超过了 GPT-4o 和 Claude3.5-Sonnet 等。\nQwen2-VL 可理解20分钟以上长视频，并将其用于基于视频的问答等应用。\n值得关注的开源项目 Deep Live Cam real time face swap and one-click video deepfake with only a single image\nGithub: https://github.com/hacksider/Deep-Live-Cam\nmoffee moffee 是一个开源的幻灯片制作工具，可以将 Markdown 文档转换为简洁、专业的幻灯片。\n（等效于自动实现LLM生成markdown+vscode中Marp渲染）\nGitHub：github.com/BMPixel/moffee\n【三年面试五年模拟】算法工程师的求职面试秘籍 【三年面试五年模拟】算法工程师秘籍。涵盖AIGC、传统深度学习、自动驾驶、机器学习、计算机视觉、自然语言处理、具身智能、元宇宙、AGI、SLAM等AI行业面试笔试经验与干货知识。\nGitHub：https://github.com/WeThinkIn/Interview-for-Algorithm-Engineer\nAI-Scientist The AI Scientist项目旨在开发一个能够进行科学研究和发现新知识的全自动系统。该系统利用大型语言模型（LLMs）等基础模型，独立执行研究任务。与现有的需要大量人工监督或限制在特定任务上的模型不同，AI Scientist能够自动生成科学论文、进行实验设计和数据分析。\nGitHub - SakanaAI/AI-Scientist\nClapper Clapper 是一个开源的AI故事可视化工具，旨在通过交互式、迭代和直观的过程，让任何人都能使用AI创建视频，而无需外部工具、电影制作或AI工程技能。与传统的视频编辑器或使用3D场景作为输入的现代AI编辑器不同，Clapper通过高层次的抽象（如角色、地点、天气、时间段、风格等）来迭代故事。项目还在开发一个导演模式，用户可以通过全屏模式和AI助手互动来制作电影。\nGitHub - jbilcke-hf/clapper\nmindSearch MindSearch 是一个基于大型语言模型（LLM）的多代理框架，用于构建类似于 Perplexity.ai Pro 和 SearchGPT 的网络搜索引擎。该项目旨在通过模拟人类思维的方式，提供深度的 AI 搜索功能。其核心功能动态图构建， 可以将查询分解成多个子问题查询，并调用工具动态扩展图。\nGithub: https://github.com/InternLM/MindSearch\nSD变现宝：一键把comfyui工作流转换成小程序 旨在将ComfyUI工作流一键转换为小程序，包括“微信小程序”、“抖音小程序”、“微信内H5”和“微信外H5”，并支持支付变现功能。\nGitHub - zhulu111/ComfyUI_Bxb\n影音记录 精选歌单 Live演出 08.03 Sat. yinyin vas\n电影 《异形：夺命舰》\n书\u0026amp;阅读摘录 读完《数字化孤独：社交媒体时代的亲密关系》。\n写书真是个不挣钱的事情 但是写书，仍旧是跟写文章不同的事情。既然我们谈到深度阅读，我们就也需要考虑深度写作。我可以每天写切中当前新闻热点的文章，这也是一种写作。但是如果这些文章是日抛型的，一年后，甚至一个月后，大家看到就索然无味的话，那么这些写作就是应景的，浅表的。但是深度的写作，可以有更长时间的价值。别的不提，我前面提到的三篇爆款文，至少是有跨越一定时间的力量的。\n我想我应该给自己一点点压力，去写一些真正的书，真正有野心成为一个有体系，有结构的作品。也许写作方法还是边写边在公众号上发布，但是写的时候，就开始思考结构是什么，主题是什么，要解决什么样的问题。 这样才成为深度写作。虽然不太挣钱。\n李沐重返母校上海交大，从LLM聊到个人生涯，这里是演讲全文 短期来看，算力翻倍，价格可能会有 1.4 倍的提升。但是长期来看，当竞争变得越来越激烈，摩尔定律会发挥作用，就是说算力翻倍，价格不一定变。所以长期来看算力会变得越来越便宜。 … 很多时候，大家不要去想我现在能搞多大的模型，一年之后，这个模型会贬值。我想说，大模型不是特别有性价比的东西。你要想清楚，从长期来看，你的模型能带来什么价值，让你能够保值。\n所以，很有可能在未来一阵子，因为受限于内存大小和数据的尺寸，我觉得 100B 到 500B 会是未来主流的一个大势。\n音乐是一种表达，是一个人的交互，任何一个什么感觉你都可以通过音乐表达 … 现在你掌握了这个表达工具之后，我们未来很多人会用音乐这个形式来表达想法和情感。我觉得这个可能是影响力会特别大的，那它不是个技术问题，它可能还是一个商业问题。\n因为设计好的东西不一定满足我们的所有需求，可能满足了 80%，但没有满足对细节的需求，这时可以通过长文本，即输入很长的文字来解决\n在应用层面，AI 本质上是去辅助人类完成任务，给人类提供无限的人力资源。我将应用分成三类: 第一类就是文科白领。白领是用自然语言去跟人、跟世界打交道，包括写文章或者其他。 第二个是工科白领，目前 AI 想取代程序员还早得很。 最后一个是蓝领阶级，这反而是最难的，这里面唯一做的好的是自动驾驶。 对于文科白领的工作，AI 已经能完成简单任务，复杂任务需要继续努力。对于工科白领的工作，简单任务还需要努力，复杂任务存在困难。对于蓝领的工作，除了无人驾驶和特定场景（比如工厂，场景变化不大，也能采集大量数据），AI 连简单任务都做不了，完成复杂任务更难。\n现在在我看起来预训练是一个工程问题，后训练才是一个技术问题。 … 8B 和 70B 的情况也不一样，8B 上调的很多东西在 70B 上不一定成立。\n就是说没有真正的垂直模型，就算是一个很垂直领域的模型，它的通用能力也是不能差的。\n所以很多时候，评估是你最重要的事情，先把评估做好，再去做别的事情。\n从最基本的目标来说，去大公司，是为了升职加薪；读 PhD ，你要保证自己能毕业；而创业的目标是要能推出产品，要么上市，要么卖掉，这是每天都需要思考的。\n打工人的好处是，可以在一个相对简单的环境里学习各种从业知识，比如一个技术如何落地、产品怎么做出来、怎么设计、怎么运营、怎么管理。\n其次是干完被安排的任务后，晚上睡觉不用太担心其他，不会做噩梦。 …\n那么打工人的坏处是什么？坏处就是停留在打工人或者职业经理人的思维。\n创业：有「生死一瞬间」的刺激，也有「三小时醒一次」痛苦\n你要有一个强烈的动机，而强烈的动机要么来自很深沉、很底层的欲望，要么来自很深的恐惧。\n如果这个问题有学术价值，你可以考虑去读 PhD；如果这个问题有商业价值，你可以考虑去创业；如果以上两种属性都不够强烈，但至少有成长价值，那先做做打工人也未尝不可。\n你用导师或者上级的角度去总结自己：你每周干了哪些事情？为什么这些目标没达成？\n这是一个最好的时代，新的技术带来了很多新的机会，就算没有新一代技术出现，现有的技术对世界未来几年的影响都会非常大。 … 同时，这也是一个最坏的时代，在座的各位付出的努力要比上一代更多。上一代吃到了时代红利，而到了你们这一代，时代红利还是有的，只是需要付出更多努力。\n李沐：创业一年，人间三年！ 回过头想，如果AGI是达到普通人类水平，客户要的是专业人士的水平。 … 虽然当时我们内心对AGI充满敬畏，但感觉是避不开的。\n第四阶段的认知是，好的垂直模型通用能力也不能弱，例如reasoning，instruction following这些能力垂直上也是需要的。长远来看，通用和垂直模型都得朝着AGI去。只是垂直模型可以稍微偏科一点，专业课高分，通用课还行，所以研发成本稍微低一点，研发方式也会不一样点。\n我希望工作上有个非常厉害的虚拟助手能跟我一起发明新的东西。等我老了也想有很有意思的机器人陪着。我对于未来的预测是，生产工具越来越发达，一个人完成之前一个团队才能完成的事情，导致人类更加个体独立，大家都忙着追求自己的事情，从而更加孤独。\n创业之后才真正觉得团队的重要性。在大厂的时候，觉得自己是个螺丝钉，团队成员是螺丝，甚至团队也是个螺丝钉。但创业团队就是一辆车。车小点，但能跑，能载重，转弯灵活，各个角落都能去。\n36氪出海·日本｜Sparticle金峰：生成式AI创业，日本能够提供什么机会？ 在大语言模型时代，语言的隔阂正在被消减，跨语种的信息平权成为可能。\n“日本市场是有一定延时性的，在美国、国内激烈竞争的时候，我们做日韩台、做小语种，竞争更小。\n金峰观察到，“日本企业更讲究‘匠人精神’，不追求爆发式增长或者颠覆式创新。做垂直行业、聚焦核心场景，能找到客户、服务好客户，也能过得很好。对他们来说，风险企业反而比较奇怪。”\n在日本面临的语言文化差异也是巨大的。“中国公司的商业逻辑反而可能和美国很像，追求效率，但日本更复杂，人脉、商脉的建立更漫长。\n德鲁克最经典长文：你必须成为自己的CEO 我们生活的这个时代充满着前所未有的机会：如果你有雄心，又不乏智慧，那么不管你从何处起步，你都可以沿着自己所选择的道路登上事业的顶峰。\n但前提是，你必须成为自己的首席执行官，知道何时改变发展道路，并在可能长达50年的职业生涯中不断努力、干出实绩。\n我的优势是什么？ …\n要发现你的优势，唯一的方法就是回馈分析法。 每当你做重要决定或采取重要行动时，写下你期望发生的事情。9或12个月以后，将实际结果与你的期望做对比。\n…\n我是如何做事的？\n首先要清楚，你是阅读型还是倾听型。\n其次，要了解一个人的做事方式，还需要弄清一点，即要知道这个人的学习方式。\n有些人在实干中学习，而另外一些人则通过听自己说话来学习。\n不过，此时他们应该弄清楚以下三个问题的答案：\n我的优势是什么？\n我的做事方式是怎样的？\n还有，我的价值观是什么？\n电商的美国游戏，靠卷赢不了 Temu 的加速崛起更加凸显了行业老大 Amazon 的问题：它便宜不下来。\n在美国的电商游戏里，想要参与就一定要解决物流的问题。但美国需要解决的物流问题和中国完全不是一个。 … 但在美国情况却相反：从中国到美国的物流成本甚至低于美国境内的物流成本。\n这么做显然是不可行的。「郊区大 House」的生活图景在几十年后最终把美国割裂成了两个地理空间：一半是中产阶级和富人，另一半是中下层中产和贫民。而这个几十年城市规划错误的持续积累，把它的苦果也喂给了 Temu 在内的所有需要配送的服务者。\n因为为期几十年的「去工业化」不只是让一批工厂消失，也带走了工厂的上下游、不再培养熟练工人，它失去了大规模生产的能力。而苦果被这个国家的所有人一同咽下。在 Temu 之前，沃尔玛、亚马逊的大半商品已经来自中国。\n失去工业的美国，却有 96% 的工业空间都被仓库租走了。这是个仓库的国家，密密麻麻的大型仓库、个人仓库出现在乡村、郊区、港口、城市之间。美国有全球最大规模的仓库，而且还在不断增加。从 2007 年的 14,600 个仓库增长到了 2023 年大约 22,000 个。即便如此，美国依然面临仓库短缺的问题。\n原本生产一切的美国产业先被转移到欧洲、日本；然后是韩国、四小龙；现在是中国，我们成为了新的世界工厂。未来还有一部分可能会去到越南、印度、印尼\u0026hellip;\u0026hellip;而美国的工厂变成仓库、中产社区衰退成 Hood、工人变成朝不保夕的穷人。 接住了工业的地方会源源不断的生产，商品漂洋过海和再次回到一切的起点与曾经的生产者汇合。经济对人的抛弃结了痂，成了电商企业报表中一条别别扭扭的、需要解释的成本细项。\nThe LLM Triangle Principles to Architect “LLM-Native apps are 10% sophisticated model, and 90% experimenting data-driven engineering work.”\nBuilding production-ready LLM applications requires careful engineering practices. When users cannot interact directly with the LLM, the prompt must be meticulously composed to cover all nuances, as iterative user feedback may be unavailable.\nCurrently, agents (without implicit guidance) are not very good at planning complex processes and usually skip essential steps.\nThe truth is that we don’t always need the largest model; it depends on the task.\n智变时代 / 全面理解机器智能与生成式 AI 加速的新工业革命 “最重要的不是它解决的具体问题，而是广泛意义的通用性在增加”\n大语言模型不是数据库，而是推理引擎！\n接下来，AI 要做的事情就是降低企业在知识工作者上的支出，让大家购买或者是租用能自己工作的 SaaS，从而提高在软件市场的支出。\n新形态的 AI 公司将会是 AI 自动化管理的供应商，只需要少量的人类，可以支持更大规模的客户 AI 劳动力概念的新型态软件，将吃掉传统 SaaS 的市场空间，让他们的利润减少，当然也会同时减少人类的工作机会，但给了 AI 初创企业新的市场机会，来挑战传统软件公司\n现代经济学中有一个简单的定义：当商品、服务或资源的供应或容量增加导致其消费增加时，就会发生诱导需求（Induced demand）。 我们现在使用搜索引擎的成本几乎为零，代价是需要看广告 随着能源、智能和灵活性的成本趋近于零，整个经济将变得更大，结构上更加盈利。科技公司将有巨大的机会销售他们即插即用的劳动力和智能，本质上是将现在分散且不一致的人类劳动力产品化、集中化、按需化和作为服务给软件化，即 SaaS 化。\n在智能时代，将劳动力支出转化为研发支出将改变公司的成本结构，虽然这需要更多的前期投资，但能降低生产和服务的边际成本。\n但是从长远看，人类构建的知识有个明显的天花板，它们的发展会被限制 … 我们无法用符号的逻辑来穷尽这种复杂；相反，我们应该只内建能够找到并捕获这些复杂性的元方法 … 哲学家维特根斯坦（Johann Wittgenstein）很早就表达了对这种近似性的思考：按学科分类做“知识图谱”的方法根本不可能穷尽所有的知识，事物之间总有些相似性是模糊的、不明确的、难以用语言来形容的。 … “理解”就是知道如何将这些符号转换成向量，以及这些向量的元素应该如何相互作用来预测下一个符号的向量。知识体现在你使用的向量及其元素之间的相互作用上，而不是符号规则。 概念作用的权重构成了模型的知识！\n在许多事情都被自动化的情况下，什么是值得学习的呢？\n首先，学会提问，未来的教育应侧重于如何提出有价值的问题，而不仅仅是回答问题。好的思考才能带来好的问题，批判性思维和好奇心是思考的前提，也是人类文明能够向前的动力。\n其次，学会广泛而深入地思考 —— 尽可能多地吸收各种知识和思维模式，重点培养结构化思维。调将复杂的问题分解成更小、更易管理的部分，并通过逻辑和有条理的步骤来解决这些部分，从而达到解决整体问题的目的。\n要成为能指挥 AI 帮我们干活的超级个体，就像 Sam Altman 在 WTF 上比喻的那样：“如果每个人都有一家由一万个能力极强的虚拟 AI 员工组成的公司，世界将会怎样？” 要成为能调动 AI 干活的人，而不是被 AI 替代的人。 … 除了前面提到的三个内在能力提升之外，更好的情绪管理和沟通能力，会强化建立社会连接的效率，人类的服务会变得更加昂贵；\n","permalink":"https://niraya666.github.io/monthly/2024-08/","summary":"\u003ch1 id=\"ai-新闻\"\u003eAI 新闻\u003c/h1\u003e\n\u003ch3 id=\"grok-2-beta-版本\"\u003eGrok-2 Beta 版本\u003c/h3\u003e\n\u003cp\u003exAI公司发布了Grok-2和Grok-2 mini的测试版，现已向𝕏平台上的Premium和Premium+用户开放。Grok-2是一个先进的语言模型，在聊天、编码和推理方面表现出色，超过了Claude 3.5 Sonnet和GPT-4-Turbo等竞争对手。Grok-2 mini则在速度和答案质量之间取得平衡。此外，关于图像生成功能可能被滥用的问题也引起了关注。\u003c/p\u003e\n\u003ch3 id=\"微软发布phi-35系列模型\"\u003e微软发布Phi-3.5系列模型\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/discover-the-new-multi-lingual-high-quality-phi-3-5-slms/ba-p/4225280\"\u003ehttps://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/discover-the-new-multi-lingual-high-quality-phi-3-5-slms/ba-p/4225280\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e涵盖了Phi-3.5-mini、Phi-3.5-MoE和Phi-3.5-vision三种模型。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePhi-3.5-mini\u003c/strong\u003e：拥有3.8亿参数，支持128K上下文长度，专注于多语言支持和推理能力。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePhi-3.5-MoE\u003c/strong\u003e：混合专家模型，总参数量为42亿，但每次激活仅使用6.6亿参数。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePhi-3.5-vision\u003c/strong\u003e：具备4.2亿参数，能够处理多帧图像理解和推理任务，在单图像基准测试中表现显著提升。\u003c/p\u003e\n\u003ch3 id=\"cursor-ai\"\u003eCursor AI\u003c/h3\u003e\n\u003cp\u003e最近大热的一款AI编程辅助工具。\u003c/p\u003e\n\u003cp\u003e不仅支持多行代码的自动完成，还能够根据代码上下文进行智能生成和重写， 代码解释和调试帮助。\u003c/p\u003e\n\u003cp\u003e2024年8月，Cursor AI 完成了一轮6000万美元的融资，使得公司的估值达到了4亿美元。\u003c/p\u003e\n\u003ch3 id=\"google发布gemma-2-2b模型及其相关工具\"\u003e\u003cstrong\u003eGoogle发布Gemma 2 2B模型及其相关工具\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eGoogle发布了新一代轻量级开源大语言模型Gemma 2 2B，并推出了一系列相关工具，包括ShieldGemma和Gemma Scope。这些新工具旨在提升AI的安全性、透明度和性能。\u003c/p\u003e\n\u003ch3 id=\"qwen2-vl\"\u003e\u003cstrong\u003eQwen2-VL\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://qwenlm.github.io/zh/blog/qwen2-vl/\"\u003ehttps://qwenlm.github.io/zh/blog/qwen2-vl/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e通义千文团队开源了 Qwen2-VL-2B 和 Qwen2-VL-7B，并发布了 Qwen2-VL-72B 的 API。\u003c/p\u003e\n\u003cp\u003e72B在大部分指标上甚至超过了 GPT-4o 和 Claude3.5-Sonnet 等。\u003c/p\u003e\n\u003cp\u003eQwen2-VL 可理解20分钟以上长视频，并将其用于基于视频的问答等应用。\u003c/p\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003ch3 id=\"deep-live-cam\"\u003eDeep Live Cam\u003c/h3\u003e\n\u003cp\u003ereal time face swap and one-click video deepfake with only a single image\u003c/p\u003e\n\u003cp\u003eGithub: \u003ca href=\"https://github.com/hacksider/Deep-Live-Cam\"\u003ehttps://github.com/hacksider/Deep-Live-Cam\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"moffee\"\u003emoffee\u003c/h3\u003e\n\u003cp\u003emoffee 是一个开源的幻灯片制作工具，可以将 Markdown 文档转换为简洁、专业的幻灯片。\u003c/p\u003e","title":"2024-08 月刊"},{"content":"在使用大型语言模型（LLM）时，我们常常面临一个挑战：如何从模型输出中准确提取自己所需的信息。例如，当我们希望模型输出 JSON 格式的数据时，由于模型生成的内容并不总是稳定，可能需要额外编写大量的正则表达式来匹配并提取其中的有效信息。然而，由于 LLM 的能力，导致其输出结构并不永远可靠。\n现阶段， 让LLM按要求生成特定格式文本的主要方法有几种种：\n微调：使模型的输出遵循特定格式\nOpenAI Json-mode/Structured Outputs/function-calling: 这些功能允许模型生成更严格、结构化的输出，但受限于openAI平台。\n格式约束：在decoding阶段进行约束，限制模型的输出，\nPrompt Engineering： 最简单的办法，但不稳定。\n多阶段prompting： 通过多个步骤的提示逐步引导模型生成所需的格式。\n本文将聚焦在Structured Outputs， 受限编码， 和prompt-engineering的角度，探讨它们在生成特定格式文本中的应用和效果。\nJson Mode 仅特定模型和平台支持\n以openAI 为例， 在openai.chat.completions.create 参数中增加response_format={\u0026quot;type\u0026quot;:\u0026quot;json_object\u0026quot;} 即可（具体参见：response_format ）。\n需要在prompt中要求输出json格式\n不能保证完全按要求的格式结构输出\n但非100%成功率，存在一些需要额外检测和适当处理的edge case。\nHandling edge cases 根据OpenAI官方文档提供的处理方案 https://platform.openai.com/docs/guides/structured-outputs/json-mode we_did_not_specify_stop_tokens = True try: response = client.chat.completions.create( model=\u0026#34;gpt-3.5-turbo-0125\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant designed to output JSON.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Who won the world series in 2020? Please respond in the format {winner: ...}\u0026#34;} ], response_format={\u0026#34;type\u0026#34;: \u0026#34;json_object\u0026#34;} ) # Check if the conversation was too long for the context window, resulting in incomplete JSON if response.choices[0].message.finish_reason == \u0026#34;length\u0026#34;: # your code should handle this error case pass # Check if the OpenAI safety system refused the request and generated a refusal instead if response.choices[0].message[0].get(\u0026#34;refusal\u0026#34;): # your code should handle this error case # In this case, the .content field will contain the explanation (if any) that the model generated for why it is refusing print(response.choices[0].message[0][\u0026#34;refusal\u0026#34;]) # Check if the model\u0026#39;s output included restricted content, so the generation of JSON was halted and may be partial if response.choices[0].message.finish_reason == \u0026#34;content_filter\u0026#34;: # your code should handle this error case pass if response.choices[0].message.finish_reason == \u0026#34;stop\u0026#34;: # In this case the model has either successfully finished generating the JSON object according to your schema, or the model generated one of the tokens you provided as a \u0026#34;stop token\u0026#34; if we_did_not_specify_stop_tokens: # If you didn\u0026#39;t specify any stop tokens, then the generation is complete and the content key will contain the serialized JSON object # This is guaranteed to parse successfully and should now contain \u0026#34;{\u0026#34;winner\u0026#34;: \u0026#34;Los Angeles Dodgers\u0026#34;}\u0026#34; print(response.choices[0].message.content) else: # Check if the response.choices[0].message.content ends with one of your stop tokens and handle appropriately pass except Exception as e: # Your code should handle errors here, for example a network error calling the API print(e) 使用pydantic的方案 使用pydantic的方案 from pydantic import BaseModel, EmailStr, ValidationError # 定义你期望的 JSON 数据模型 class UserModel(BaseModel): name: str age: int email: EmailStr # 检查 JSON 是否符合模型的函数 def validate_json(json_str): try: # 将输入的 JSON 字符串转换为 UserModel 实例 user = UserModel.parse_raw(json_str) # 如果验证通过，返回字典 return user.dict() except ValidationError as ve: print(f\u0026#34;JSON validation error: {ve.json()}\u0026#34;) return None # 示例用法 json_str = \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john.doe@example.com\u0026#34;}\u0026#39; validated_json = validate_json(json_str) if validated_json is not None: print(\u0026#34;JSON is valid and conforms to the schema:\u0026#34;) print(validated_json) else: print(\u0026#34;JSON is invalid.\u0026#34;) Json-Mode 更多是对于输出json的格式进行检查(即Json格式的有效性)\nStructured Outputs 在模型升级到2024-08-06版本后， OpenAI增加了Structured Outputs功能。\n其旨在保证模型始终生成符合所提供的JSON Schema的响应，而无需处理edge case，以及json内容错误。\n其优势在于：\n无需验证或重试格式不正确的响应\n可通过编程检测模型是否安全生成（在API返回结果中增加了\u0026quot;refusal”字段）\n无需复杂的prompt用于限制输出结构\n相较于Json-Mode， 虽然两者都确保生成有效的JSON，但只有Structured Outputs能确保输出json-schema的一致性。因此理论上无需额外的json-schema检查的代码步骤。\n如何使用 以官方文档所提供的`Structured data extraction`为例：\nfrom pydantic import BaseModel from openai import OpenAI client = OpenAI() class ResearchPaperExtraction(BaseModel): title: str authors: list[str] abstract: str keywords: list[str] completion = client.beta.chat.completions.parse( model=\u0026#34;gpt-4o-2024-08-06\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are an expert at structured data extraction. You will be given unstructured text from a research paper and should convert it into the given structure.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;...\u0026#34;} ], response_format=ResearchPaperExtraction, ) research_paper = completion.choices[0].message.parsed output { \u0026#34;title\u0026#34;: \u0026#34;Application of Quantum Algorithms in Interstellar Navigation: A New Frontier\u0026#34;, \u0026#34;authors\u0026#34;: [ \u0026#34;Dr. Stella Voyager\u0026#34;, \u0026#34;Dr. Nova Star\u0026#34;, \u0026#34;Dr. Lyra Hunter\u0026#34; ], \u0026#34;abstract\u0026#34;: \u0026#34;This paper investigates the utilization of quantum algorithms to improve interstellar navigation systems. By leveraging quantum superposition and entanglement, our proposed navigation system can calculate optimal travel paths through space-time anomalies more efficiently than classical methods. Experimental simulations suggest a significant reduction in travel time and fuel consumption for interstellar missions.\u0026#34;, \u0026#34;keywords\u0026#34;: [ \u0026#34;Quantum algorithms\u0026#34;, \u0026#34;interstellar navigation\u0026#34;, \u0026#34;space-time anomalies\u0026#34;, \u0026#34;quantum superposition\u0026#34;, \u0026#34;quantum entanglement\u0026#34;, \u0026#34;space travel\u0026#34; ] } 和在LLM输出的结果中通过`pydantic`进行格式检查类似，只是直接将格式要求传给了模型，减少了额外工作。 等价于\n... \u0026#34;response_format\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;json_schema\u0026#34;, \u0026#34;json_schema\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;research_paper_extraction\u0026#34;, \u0026#34;schema\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;authors\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } }, \u0026#34;abstract\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;keywords\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } } }, \u0026#34;required\u0026#34;: [\u0026#34;title\u0026#34;, \u0026#34;authors\u0026#34;, \u0026#34;abstract\u0026#34;, \u0026#34;keywords\u0026#34;], \u0026#34;additionalProperties\u0026#34;: false }, \u0026#34;strict\u0026#34;: true } } 此外， 文档中还提供了COT的Structured Outputs例子\nChain of thought\nfrom pydantic import BaseModel from openai import OpenAI client = OpenAI() class Step(BaseModel): explanation: str output: str class MathReasoning(BaseModel): steps: list[Step] final_answer: str completion = client.beta.chat.completions.parse( model=\u0026#34;gpt-4o-2024-08-06\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful math tutor. Guide the user through the solution step by step.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;how can I solve 8x + 7 = -23\u0026#34;} ], response_format=MathReasoning, ) math_reasoning = completion.choices[0].message.parsed output:\n{ \u0026#34;steps\u0026#34;: [ { \u0026#34;explanation\u0026#34;: \u0026#34;Start with the equation 8x + 7 = -23.\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;8x + 7 = -23\u0026#34; }, { \u0026#34;explanation\u0026#34;: \u0026#34;Subtract 7 from both sides to isolate the term with the variable.\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;8x = -23 - 7\u0026#34; }, { \u0026#34;explanation\u0026#34;: \u0026#34;Simplify the right side of the equation.\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;8x = -30\u0026#34; }, { \u0026#34;explanation\u0026#34;: \u0026#34;Divide both sides by 8 to solve for x.\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;x = -30 / 8\u0026#34; }, { \u0026#34;explanation\u0026#34;: \u0026#34;Simplify the fraction.\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;x = -15 / 4\u0026#34; } ], \u0026#34;final_answer\u0026#34;: \u0026#34;x = -15 / 4\u0026#34; } 相比于之前普通版本的COT：\n在测试阶段，程序化检查中间Chain的中间过程变得更加简单\n更优美的提取最终结果\n限制分析过程中的每一步格式，以提高正确率？\nOpenAI API中提供了两种形式的Structured Outputs\nFunction Calling\n使用 json_schema 响应格式\n在function calling （tool-using）时， 在定义tools时需增加\u0026quot;strict\u0026quot;: true 字段，如：\ntools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_delivery_date\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the delivery date for a customer\u0026#39;s order. Call this whenever you need to know the delivery date, for example when a customer asks \u0026#39;Where is my package\u0026#39;\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;order_id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The customer\u0026#39;s order ID.\u0026#34;, }, }, \u0026#34;required\u0026#34;: [\u0026#34;order_id\u0026#34;], \u0026#34;additionalProperties\u0026#34;: False, }, }, \u0026#34;strict\u0026#34;: True, } ] 注意：\u0026quot;strict\u0026quot;: true,会产生一定的延迟（10s以下）\nStructured Outputs功能引入了一个新的字段refusal，用于在模型拒绝执行请求时提供反馈。当用户生成的输入时，模型可能会因为安全原因拒绝履行请求，此时API响应会包含一个名为“refusal”的新字段来指示模型拒绝了请求。当API响应中出现refusal字段时，开发者可以程序化地检测到模型生成了拒绝而不是符合模式的输出。\nConstrained Decoding What Is Constrained Decoding constrained decoding is a technique that manipulates a generative model\u0026rsquo;s token generation process to constrain its next-token predictions to only tokens that do not violate the required output structure.\n仅对严格需要生成的输出部分，从模型的下一个Token概率分布中的兼容Token集进行采样。\n简单来说，对于LLM的输出过程，模型会根据之前的词语序列，计算出下一个词可能出现的概率，并根据这个概率生成下一个词。这一过程会不断重复，直到生成完整的句子或段落（或遇到[EOS]标记）。在普通的生成过程中，模型的概率空间是所有可能的Token。\n相对而言，在引导生成（Guided Generation）过程中，模型的输出会受到额外的引导或约束，以确保生成的内容更加符合某些特定的要求或目标。这种引导可以通过调整概率分布、加入上下文信息、或施加额外规则来实现。\n具体来说， 对于给定的输入序列 $\\tilde{S}_t$ 和模型参数 $\\theta$，\n模型首先计算出一个未加约束的概率分布 $\\alpha$，表示下一个Token $\\tilde{s}_{t+1}$ 的可能性 ，\n$$ \\alpha = \\text{LM}(\\tilde{S}_t, \\theta) $$\n为了引入约束或限制，构造一个布尔掩码 $m$，这个掩码将限制下一个Token的选择范围。掩码函数 $m(\\tilde{S}_t)$将原始分布中的部分不符合约束条件的Token概率置为0，形成一个新的受限分布 $\\tilde{\\alpha}$：\n$$ \\tilde{\\alpha} = m(\\tilde{S}_t) \\odot \\alpha $$\n即在原始分布$\\alpha$ 上应用掩码 $m$，只保留那些满足约束条件的Token的概率，其他Token的概率被置为0。\n接下来，模型根据受限分布 $\\tilde{\\alpha}$ 进行采样，选择下一个Token $\\tilde{s}_{t+1}$\n$$ \\tilde{s}_{t+1} \\sim \\text{Categorical}(\\tilde{\\alpha}) $$\n这个步骤意味着模型只会从符合约束条件的Token集合中选择下一个Token，确保生成的输出遵循预定的规则或格式。\n以上内容出自 outlines的paper：Efficient Guided Generation for Large Language Model 具体内容可自行查看。\n以常见的Json格式约束为例（Fast JSON Decoding for Local LLMs with Compressed Finite State Machine），\n有多种框架可以利用本地模型实现约束解码， 如： outlines，SGLang等。\nvllm+outlines 实现结构化输出 依赖环境：\n! pip install vllm ! pip install openai ! pip install instructor 注意：需要使用到GPU，建议使用colab\n启动vllm模型服务，选择适合GPU显存大小的模型：\n#! vllm serve Qwen/Qwen1.5-4B-Chat --max_model_len=10000 ! vllm serve Qwen/Qwen1.5-1.8B --max_model_len=10000 引导生成json结构：\nfrom openai import OpenAI # Set OpenAI\u0026#39;s API key and API base to use vLLM\u0026#39;s API server. openai_api_key = \u0026#34;EMPTY\u0026#34; openai_api_base = \u0026#34;http://localhost:8000/v1\u0026#34; api_client = OpenAI(api_key=\u0026#39;YOUR_API_KEY\u0026#39;, base_url=\u0026#39;http://localhost:8000/v1\u0026#39;) model_name = api_client.models.list().data[0].id json_schema = { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;thought\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, \u0026#34;answer\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;thought\u0026#34;, \u0026#34;answer\u0026#34;] } query = \u0026#34;What is the capital of China?\u0026#34; # Feed the random question into the existing query system_prompt = \u0026#34;Respond only with a json object containing the following fields and nothing else: thought, answer.\u0026#34; completion = api_client.chat.completions.create( model=model_name, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: system_prompt}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: query} ], extra_body={ \u0026#34;stop_token_ids\u0026#34;: [128009], \u0026#34;response_format\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;json_object\u0026#34;}, \u0026#34;guided_json\u0026#34;: json_schema } ) 输出：\nprint(completion.choices[0].message.content.strip()) # {\u0026#34;thought\u0026#34;: \u0026#34;What is the capital of China?\u0026#34;, \u0026#34;answer\u0026#34;: \u0026#34;Beijing\u0026#34;} 另一个例子， 引导生成符合结构的《Harry Potter》角色属性：\n定义角色属性结构\nfrom openai import OpenAI from pydantic import BaseModel, Field import base64 import instructor import time from enum import Enum from typing import List from glob import glob class Property(BaseModel): key: str = Field(description=\u0026#34;Must be snake case\u0026#34;) value: str class House(Enum): Griffindor = \u0026#34;gryffindor\u0026#34; Hufflepuff = \u0026#34;hufflepuff\u0026#34; Ravenclaw = \u0026#34;ravenclaw\u0026#34; Slytherin = \u0026#34;slytherin\u0026#34; Targaryen = \u0026#34;targaryen\u0026#34; # This schema is what guides generation class Character(BaseModel): name: str age: int house: House properties: List[Property] api_client = OpenAI(api_key=\u0026#39;YOUR_API_KEY\u0026#39;, base_url=\u0026#39;http://localhost:8000/v1\u0026#39;) client = instructor.from_openai(api_client, mode=instructor.Mode.MD_JSON) model_name = api_client.models.list().data[0].id system_prompt = \u0026#34;\u0026#34;\u0026#34;\\ You are a highly creative assistant tasked with generating fictional characters for a fantasy novel. Each character belongs to a specific house, and their properties should reflect their house\u0026#39;s traits. However, ensure that the characters are entirely original and do not directly reference or resemble any characters, events, or settings from the Harry Potter series. Avoid using names, events, or any elements that would make the character too similar to existing Harry Potter content. The goal is to create unique and novel characters that can stand on their own in a fantasy world. \u0026#34;\u0026#34;\u0026#34; def run(name): try: response = client.chat.completions.create( model=model_name, response_model=Character, messages=[ { \u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: system_prompt }, { \u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: name } ], temperature=0.1, # Adjust temperature for creativity ) return response except Exception as e: print(f\u0026#34;An error occurred: {e}\u0026#34;) return None # Example usage character_name = \u0026#34;Voldemort\u0026#34; character = run(character_name) if character: print(character) else: print(\u0026#34;Failed to generate character.\u0026#34;) # name=\u0026#39;Voldemort\u0026#39; age=50 house=\u0026lt;House.Slytherin: \u0026#39;slytherin\u0026#39;\u0026gt; properties=[Property(key=\u0026#39;power\u0026#39;, value=\u0026#39;dark magic\u0026#39;), Property(key=\u0026#39;reputation\u0026#39;, value=\u0026#39;evil\u0026#39;), Property(key=\u0026#39;history\u0026#39;, value=\u0026#39;murdered his parents and became the Dark Lord\u0026#39;)] Prompt-based Methods 根据奥卡姆剃刀法制，“如无必要，勿增实体”， 或许使用prompt也可以实现， 避免引入不必要的复杂性。\n使用Prompt Engineering 要求LLM输出符合格式要求的json（或者其他）时， 可能可以用的一些小Tips：\n明确的指令和提示，并提供具体的例子: 往往LLM的few-shot learning 的能力还行， 模仿个简单的json格式基本不在话下。\n使用占位符： 为具体的json元素标注数据类型和格式，便于LLM理解。这一步骤类似于给json定义一个schema。如\n{ \u0026#34;user\u0026#34;: \u0026#34;示例用户\u0026#34;, \u0026#34;id\u0026#34;: 12345, \u0026#34;items\u0026#34;: [ {\u0026#34;item_name\u0026#34;: \u0026#34;示例物品1\u0026#34;, \u0026#34;quantity\u0026#34;: 2}, {\u0026#34;item_name\u0026#34;: \u0026#34;示例物品2\u0026#34;, \u0026#34;quantity\u0026#34;: 1} ] } 而不是一句“将结果输出成json格式”\n调整温度： 采用较低的温度设置\n分步骤生成： 对于复杂的JSON结构，可以要求模型逐步生成每个部分，然后将它们组合起来； 或先生成JSON的高层结构，然后再深入生成每个子部分。\n让LLM自己检查：类似“三段式翻译” 之类的prompt， LLM首先生成第一版json，而后LLM对LLM进行检查，并提出修改建议， 最后基于建议和初版输出生成最终版结果。\n格式有效性检查： 使用如Pydantic等工具进行验证和解析，如果模型生成了不正确的JSON，可以通过循环过程直到输出有效的JSON为止；或使用一些第三方库修复json, 如json_repair。\n这里推荐一个开源项目， TypeChat， 一个由微软开发，用于让LLM输出类型定义的结果。TypeChat 自动处理生成提示、验证 LLM 输出是否符合定义的类型，并在必要时修复不符合的输出。\n其核心是通过prompt的方式，要求LLM按特定要求输出。\n以官方提供的Calendar例子为例：\n其实现功能即，将自然语言转换成json格式， 用于后续的代办事项的工具使用。\n如输入：\n📅\u0026gt; I need to get my tires changed from 12:00 to 2:00 pm on Friday March 15, 2024 则会输出：\n{ \u0026#34;actions\u0026#34;: [ { \u0026#34;actionType\u0026#34;: \u0026#34;add event\u0026#34;, \u0026#34;event\u0026#34;: { \u0026#34;day\u0026#34;: \u0026#34;Friday March 15, 2024\u0026#34;, \u0026#34;timeRange\u0026#34;: { \u0026#34;startTime\u0026#34;: \u0026#34;12:00 pm\u0026#34;, \u0026#34;endTime\u0026#34;: \u0026#34;2:00 pm\u0026#34; }, \u0026#34;description\u0026#34;: \u0026#34;get my tires changed\u0026#34; } } ] } 首先需要事先定义具体且复杂的schema，如 schema.py\nfrom typing_extensions import Literal, NotRequired, TypedDict, Annotated, Doc class UnknownAction(TypedDict): \u0026#34;\u0026#34;\u0026#34; if the user types text that can not easily be understood as a calendar action, this action is used \u0026#34;\u0026#34;\u0026#34; actionType: Literal[\u0026#34;Unknown\u0026#34;] text: Annotated[str, Doc(\u0026#34;text typed by the user that the system did not understand\u0026#34;)] class EventTimeRange(TypedDict, total=False): startTime: str endTime: str duration: str class Event(TypedDict): day: Annotated[str, Doc(\u0026#34;date (example: March 22, 2024) or relative date (example: after EventReference)\u0026#34;)] timeRange: EventTimeRange description: str location: NotRequired[str] participants: NotRequired[Annotated[list[str], Doc(\u0026#34;a list of people or named groups like \u0026#39;team\u0026#39;\u0026#34;)]] class EventReference(TypedDict, total=False): \u0026#34;\u0026#34;\u0026#34; properties used by the requester in referring to an event these properties are only specified if given directly by the requester \u0026#34;\u0026#34;\u0026#34; day: Annotated[str, Doc(\u0026#34;date (example: March 22, 2024) or relative date (example: after EventReference)\u0026#34;)] dayRange: Annotated[str, Doc(\u0026#34;(examples: this month, this week, in the next two days)\u0026#34;)] timeRange: EventTimeRange description: str location: str participants: list[str] class FindEventsAction(TypedDict): actionType: Literal[\u0026#34;find events\u0026#34;] eventReference: Annotated[EventReference, Doc(\u0026#34;one or more event properties to use to search for matching events\u0026#34;)] class ChangeDescriptionAction(TypedDict): actionType: Literal[\u0026#34;change description\u0026#34;] eventReference: NotRequired[Annotated[EventReference, Doc(\u0026#34;event to be changed\u0026#34;)]] description: Annotated[str, Doc(\u0026#34;new description for the event\u0026#34;)] class ChangeTimeRangeAction(TypedDict): actionType: Literal[\u0026#34;change time range\u0026#34;] eventReference: NotRequired[Annotated[EventReference, Doc(\u0026#34;event to be changed\u0026#34;)]] timeRange: Annotated[EventTimeRange, Doc(\u0026#34;new time range for the event\u0026#34;)] class AddParticipantsAction(TypedDict): actionType: Literal[\u0026#34;add participants\u0026#34;] eventReference: NotRequired[ Annotated[EventReference, Doc(\u0026#34;event to be augmented; if not specified assume last event discussed\u0026#34;)] ] participants: NotRequired[Annotated[list[str], \u0026#34;new participants (one or more)\u0026#34;]] class RemoveEventAction(TypedDict): actionType: Literal[\u0026#34;remove event\u0026#34;] eventReference: EventReference class AddEventAction(TypedDict): actionType: Literal[\u0026#34;add event\u0026#34;] event: Event Actions = ( AddEventAction | RemoveEventAction | AddParticipantsAction | ChangeTimeRangeAction | ChangeDescriptionAction | FindEventsAction | UnknownAction ) class CalendarActions(TypedDict): actions: list[Actions] 这些类表示各种日历操作，每个操作类都有一个actionType字段，确定操作类型：\n• FindEventsAction：查找事件，包含一个eventReference字段，用于指定要查找的事件属性。\n• ChangeDescriptionAction：更改事件描述，包含eventReference（可选）和新的description字段。\n• ChangeTimeRangeAction：更改事件的时间范围，包含eventReference（可选）和新的timeRange字段。\n• AddParticipantsAction：为事件添加参与者，包含eventReference（可选）和参与者列表participants（可选）。\n• RemoveEventAction：删除事件，包含一个eventReference字段。\n• AddEventAction：添加新事件，包含一个event字段。\n在TypeChat的核心 prompt如下：\nprompt = f\u0026#34;\u0026#34;\u0026#34; You are a service that translates user requests into JSON objects of type \u0026#34;{self._type_name}\u0026#34; according to the following TypeScript definitions: ``` {self._schema_str} ``` The following is a user request: \u0026#39;\u0026#39;\u0026#39; {intent} \u0026#39;\u0026#39;\u0026#39; The following is the user request translated into a JSON object with 2 spaces of indentation and no properties with the value undefined: \u0026#34;\u0026#34;\u0026#34; 以上面的例子，最终生成的prompt：\n\u0026#34;\u0026#34;\u0026#34; You are a service that translates user requests into JSON objects of type \u0026#34;CalendarActions\u0026#34; according to the following TypeScript definitions: ``` interface CalendarActions { actions: Array\u0026lt; | AddEventAction | RemoveEventAction | AddParticipantsAction | ChangeTimeRangeAction | ChangeDescriptionAction | FindEventsAction | UnknownAction \u0026gt;; } // if the user types text that can not easily be understood as a calendar action, this action is used interface UnknownAction { actionType: \u0026#34;Unknown\u0026#34;; // text typed by the user that the system did not understand text: string; } interface FindEventsAction { actionType: \u0026#34;find events\u0026#34;; // one or more event properties to use to search for matching events eventReference: EventReference; } // properties used by the requester in referring to an event // these properties are only specified if given directly by the requester interface EventReference { // date (example: March 22, 2024) or relative date (example: after EventReference) day?: string; // (examples: this month, this week, in the next two days) dayRange?: string; timeRange?: EventTimeRange; description?: string; location?: string; participants?: string[]; } interface EventTimeRange { startTime?: string; endTime?: string; duration?: string; } interface ChangeDescriptionAction { actionType: \u0026#34;change description\u0026#34;; // event to be changed eventReference?: EventReference; // new description for the event description: string; } interface ChangeTimeRangeAction { actionType: \u0026#34;change time range\u0026#34;; // event to be changed eventReference?: EventReference; // new time range for the event timeRange: EventTimeRange; } interface AddParticipantsAction { actionType: \u0026#34;add participants\u0026#34;; // event to be augmented; if not specified assume last event discussed eventReference?: EventReference; // new participants (one or more) participants?: string[]; } interface RemoveEventAction { actionType: \u0026#34;remove event\u0026#34;; eventReference: EventReference; } interface AddEventAction { actionType: \u0026#34;add event\u0026#34;; event: Event; } interface Event { // date (example: March 22, 2024) or relative date (example: after EventReference) day: string; timeRange: EventTimeRange; description: string; location?: string; // a list of people or named groups like \u0026#39;team\u0026#39; participants?: string[]; } ``` The following is a user request: I need to get my tires changed from 12:00 to 2:00 pm on Friday March 15, 2024 The following is the user request translated into a JSON object with 2 spaces of indentation and no properties with the value undefined: \u0026#34;\u0026#34;\u0026#34; 参考 A Guide to Structured Generation Using Constrained Decoding\n在 🤗 Transformers 中使用约束波束搜索引导文本生成\nStructured Outputs\nIntroduction to Structured Outputs\nFunction calling\nStructured Outputs for Multi-Agent Systems\nAdd guided decoding for OpenAI API server\noutlines: Serve with vLLM\n如何正确约束输出格式，Deepmind最新：让LLM精准生成任何格式的文本，COLM2024\nCoalescence: making LLM inference 5x faster\nEfficient Guided Generation for Large Language Models\nFast JSON Decoding for Local LLMs with Compressed Finite State Machine\n通过Typechat控制LLM的输出\n大模型 JSON 格式化输出小技巧\nFormatron\nOutlines 〰️\nSGLang\nTypeChat\n","permalink":"https://niraya666.github.io/posts/llm-%E8%BE%93%E5%87%BA%E9%99%90%E5%88%B6structured-outputs%E5%8F%97%E9%99%90%E7%BC%96%E7%A0%81%E5%92%8C%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/","summary":"\u003cp\u003e在使用大型语言模型（LLM）时，我们常常面临一个挑战：如何从模型输出中准确提取自己所需的信息。例如，当我们希望模型输出 JSON 格式的数据时，由于模型生成的内容并不总是稳定，可能需要额外编写大量的正则表达式来匹配并提取其中的有效信息。然而，由于 LLM 的能力，导致其输出结构并不永远可靠。\u003c/p\u003e\n\u003cp\u003e现阶段， 让LLM按要求生成特定格式文本的主要方法有几种种：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e微调：使模型的输出遵循特定格式\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eOpenAI Json-mode/Structured Outputs/function-calling:\u003c/strong\u003e 这些功能允许模型生成更严格、结构化的输出，但受限于openAI平台。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e格式约束\u003c/strong\u003e：在decoding阶段进行约束，限制模型的输出，\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePrompt Engineering\u003c/strong\u003e： 最简单的办法，但不稳定。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e多阶段prompting： 通过多个步骤的提示逐步引导模型生成所需的格式。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e本文将聚焦在Structured Outputs， 受限编码， 和prompt-engineering的角度，探讨它们在生成特定格式文本中的应用和效果。\u003c/p\u003e\n\u003ch2 id=\"json-mode\"\u003eJson Mode\u003c/h2\u003e\n\u003cp\u003e仅特定模型和平台支持\u003c/p\u003e\n\u003cp\u003e以openAI 为例， 在\u003ccode\u003eopenai.chat.completions.create\u003c/code\u003e 参数中增加\u003ccode\u003eresponse_format={\u0026quot;type\u0026quot;:\u0026quot;json_object\u0026quot;}\u003c/code\u003e 即可（具体参见：\u003ca href=\"https://platform.openai.com/docs/api-reference/chat/create#chat-create-response_format\"\u003eresponse_format\u003c/a\u003e ）。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e需要在prompt中要求输出json格式\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e不能保证完全按要求的格式结构输出\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e但非100%成功率，存在一些需要额外检测和适当处理的edge case。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdetails\u003e\n  \u003csummary\u003eHandling edge cases\u003c/summary\u003e\n  \u003cdetails\u003e\n    \u003csummary\u003e根据OpenAI官方文档提供的处理方案\u003c/summary\u003e\n    https://platform.openai.com/docs/guides/structured-outputs/json-mode\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"n\"\u003ewe_did_not_specify_stop_tokens\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003etry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eclient\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echat\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecompletions\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;gpt-3.5-turbo-0125\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"n\"\u003emessages\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;role\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;system\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;content\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;You are a helpful assistant designed to output JSON.\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;role\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;user\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;content\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Who won the world series in 2020? Please respond in the format {winner: ...}\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"p\"\u003e],\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"n\"\u003eresponse_format\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;type\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;json_object\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"c1\"\u003e# Check if the conversation was too long for the context window, resulting in incomplete JSON \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efinish_reason\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;length\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# your code should handle this error case\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003epass\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"c1\"\u003e# Check if the OpenAI safety system refused the request and generated a refusal instead\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;refusal\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# your code should handle this error case\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# In this case, the .content field will contain the explanation (if any) that the model generated for why it is refusing\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;refusal\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"c1\"\u003e# Check if the model\u0026#39;s output included restricted content, so the generation of JSON was halted and may be partial\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efinish_reason\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;content_filter\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# your code should handle this error case\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003epass\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efinish_reason\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;stop\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# In this case the model has either successfully finished generating the JSON object according to your schema, or the model generated one of the tokens you provided as a \u0026#34;stop token\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ewe_did_not_specify_stop_tokens\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"c1\"\u003e# If you didn\u0026#39;t specify any stop tokens, then the generation is complete and the content key will contain the serialized JSON object\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"c1\"\u003e# This is guaranteed to parse successfully and should now contain  \u0026#34;{\u0026#34;winner\u0026#34;: \u0026#34;Los Angeles Dodgers\u0026#34;}\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econtent\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"c1\"\u003e# Check if the response.choices[0].message.content ends with one of your stop tokens and handle appropriately\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"k\"\u003epass\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003eexcept\u003c/span\u003e \u003cspan class=\"ne\"\u003eException\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"c1\"\u003e# Your code should handle errors here, for example a network error calling the API\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e  \u003c/details\u003e\n  \u003cdetails\u003e\n    \u003csummary\u003e使用pydantic的方案\u003c/summary\u003e\n    使用pydantic的方案\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epydantic\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBaseModel\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eEmailStr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eValidationError\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"c1\"\u003e# 定义你期望的 JSON 数据模型\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eBaseModel\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003estr\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"n\"\u003eemail\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eEmailStr\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"c1\"\u003e# 检查 JSON 是否符合模型的函数\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003evalidate_json\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ejson_str\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003etry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# 将输入的 JSON 字符串转换为 UserModel 实例\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"n\"\u003euser\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eUserModel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eparse_raw\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ejson_str\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# 如果验证通过，返回字典\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edict\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003eexcept\u003c/span\u003e \u003cspan class=\"n\"\u003eValidationError\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eve\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;JSON validation error: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eve\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"c1\"\u003e# 示例用法\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"n\"\u003ejson_str\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john.doe@example.com\u0026#34;}\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"n\"\u003evalidated_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003evalidate_json\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ejson_str\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003evalidated_json\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"ow\"\u003enot\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;JSON is valid and conforms to the schema:\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003evalidated_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;JSON is invalid.\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e  \u003c/details\u003e\n\u003c/details\u003e\n\u003cp\u003eJson-Mode 更多是对于输出json的格式进行检查(即Json格式的有效性)\u003c/p\u003e","title":"LLM 输出限制：Structured Outputs、受限编码和提示词工程"},{"content":"摘要 本文探讨了“黑暗之魂”系列游戏在当代日本社会中的意义定位。我认为，这款游戏可以被看作是当今文化潮流的象征，就像有人可能会把杰克·凯鲁亚克的《达摩流浪者》视为60年代反文化的象征一样。我主张，“黑暗之魂”系列通过寓言的方式表达了人们在一个日常行为和社会本身的意义都变得极不稳定的时代中生活的焦虑。游戏采用碎片化的叙事方式，融合了佛教的形而上学思想，并以描绘一个曾经辉煌的王国在最后时刻挣扎的阴森哥特式美学为背景。这种对当代社会焦虑的表达，与日本的后现代主义话语密切相关。通过将这些游戏视为文本、环境和游戏系统之间的反馈回路，我把这些游戏的主要概念主题与大泽真幸提出的“后虚构时代”概念，以及东浩纪对御宅族的定义联系起来。\n前言 在人文学科这个领域，我们认为艺术和文学不仅仅是艺术鉴赏。当我们阅读夏目漱石1或三岛由纪夫2的作品时，教授和学生不仅仅像粉丝那样陶醉于他们优美的文笔，而是作为评论家，从中挑出深刻的思想。通过这种方式阅读足够多的作品，我们会发现一种更宏大的东西：一个跨越时代和文化的思想洪流，在这个洪流中，生活的神秘、美丽、恐怖和悲剧汇聚成我们人类经验的漩涡和流动。文学是指南，就像老话说的那样，是通向美好生活的指南：它是一面镜子，反映我们的位置，也是我们漫步时的地图。简而言之，伟大的作品让我们变得更强大。它们让我们清晰地面对生活的矛盾，并有勇气承受其重压。我们学习文学是为了找到人类经验中的共性，并将其内化。这至少是人文学科的理想和创立原则。\n但如果这是正确的，我们能说这种深刻的体验只是文学独有的吗？书面文字是否有某种独特的力量，能够以其他媒介无法企及的方式激发反思？最终，文学只是一个个故事，但故事并不局限于一种媒介。故事是跨媒介的。它们可以口头讲述，可以印刷，可以通过舞蹈、图像，甚至可能通过尚未构想的方式来讲述。这是因为故事首先存在于人类心灵的深层结构中，不同的媒介让这些结构的不同方面显现出来。故事是人类生活的核心，它们赋予我们的社会和个人生活以连贯性和意义。\n故事是个人身份的基石，人类将经验转化为故事的能力可能与我们感知时间的能力有关。毕竟，故事是什么？它是以有意义的方式组织和编辑时间。简而言之，通过研究故事，特别是那些在社会想象中占据重要地位的故事，我们可以进入人类心灵的最深处。当我们接近这一神秘领域时，我们更接近自己，也许会找到一些我们遗忘的，对我们至关重要的东西，它像火药桶上的火花一样在我们脚下点燃，在这场大火中我们的世界观重生。\n新的媒介在大学里常常面临艰难，因为每种媒介都必须越过高文化裁决者的障碍3。这在二十世纪初的电影和摄影上是如此，在今天的漫画、电视和视频游戏上也是如此。但如果我们仅因为这些作品属于错误的媒介而忽视了沟口健二4的作品，人文学科会变得多么贫乏？偏重研究一种媒介而忽视其他媒介有什么好处？这种偏见是最糟糕的，我们都因这种武断的判断而变得贫乏。我们切断了自己探索那些激发我们深层结构的新视角的机会。故事在新的媒介中同样存在，此外，对那些在这些新媒介中成长的人来说，发现其中的故事是引人入胜、动人且深具意义的。视频游戏中的故事体验与其他媒介有着根本的不同，正是这种不同使得研究它们变得如此重要。它反映了一种新的世界观和价值观。我们不再生活在一个技术只是工具的世界里；技术是我们生活的环境。电影和电视是工业时代的本土媒介，而视频游戏是数字时代的本土媒介。视频游戏不是小众的。这个行业在全球产生的收入大大超过了电影和印刷品。这本身就使得研究它们成为紧迫的事情。\n话虽如此，我们必须认识到，视频游戏是一种新兴的媒介。就像早期的电影只是基本现象的再现——火车向屏幕疾驰或马在慢动作中奔跑——视频游戏的媒介中无疑有着尚未开发的巨大潜力。此外，我们还不能像理解文学那样全面理解这一媒介。我们还没有足够的时间去理解视频游戏在文化中可能扮演的角色以及它们对塑造我们的价值观和性格的影响。我不会在这里主张创建一个新的经典目录。现在还为时过早，而且流行经典化的过程早已在进行中。本文研究的游戏《黑暗之魂》系列已经被这样经典化了。它享有一种地位，其他同类游戏以它为标准，而那些共享其设计原则的游戏被称为“魂类游戏（Soul-like）”，这可能类似于许多文学或电影作品被描述为“卡夫卡式的”5。然而，我不会试图将这款游戏作为一部伟大作品来评估，以便将研究这一系列游戏制度化。我认为这些游戏被经典化不仅仅是因为它们“有趣”，而是因为它们直接处理了当代日本及其年轻一代面临的问题、焦虑和挑战。这是我们将要问的问题：这些游戏中反映了什么，使其在跨文化范围内以及在粉丝和评论家中产生如此深刻的共鸣？\n我将在这里主要讨论日本，但我相信在研究这款游戏时得出的教训具有全球意义。目前，这些意义将保持原样。本质上，为了故事而玩游戏是一件矛盾的事情。游戏的内部组件，作为一个具象化的代码系统和作为不同类型叙事（文本、视觉、听觉）的载体，对玩家提出了一系列相互竞争的需求。这种矛盾在《黑暗之魂》中和几乎所有其他游戏中一样没有解决，但该系列在这些相互竞争的元素之间达到了罕见的一致性，可能直接反映了日常生活中数字世界的体验。我希望我在这里的分析，即使只是初步和不完整的，也能成为反思社会走向、新的价值结构的出现以及文学解释或在这种情况下的游戏解释可以对这些问题有所启示的机会。\n第一章：引言 本文旨在探讨“黑暗之魂”系列游戏与当代日本社会状况之间的关系。我认为，“黑暗之魂”系列通过寓言形式表达了在一个日常行为意义甚至社会本身都变得不稳定的时代生活的焦虑。这一表达通过破碎的叙事方式实现，这种方式结合了佛教形而上学，并以描绘一个昔日伟大王国最后挣扎的阴暗哥特风格为背景。这种寓言中的焦虑与日本后现代性讨论密切相关，特别是现代性项目失败和进步叙事腐败的观点。在我的论文中，我认为这种讨论在“黑暗之魂”中通过模拟经典英雄之旅得以体现，但最终通过剥夺玩家的英雄成就感并用深深的模糊和不确定性取而代之，颠覆了这一旅程。\n“黑暗之魂”系列是一款第三人称动作RPG，其核心机制围绕探索一个破败的世界展开。该系列由著名日本游戏公司FromSoftware在总裁宫崎英高的指导下开发。第一款游戏于2011年9月发布，第三款于2016年4月发布。这是一款难度极高的游戏，设定在一个末世奇幻世界，要求玩家克服许多复杂的运动任务。游戏的一大特点是其缺乏具体的叙事阐述。然而，有一些概念性主题将这些游戏联系在一起。游戏中总是有一个被“不死诅咒”摧毁的王国，并且总是有神秘人物指示玩家杀死旧神并使用他们的灵魂来“连接火焰”。这个过程在第一款游戏中被解读为一个世界复兴过程，但在第二和第三款游戏中被揭示为不可避免的衰败螺旋。\n全球销量数百万，三部作品在国外几乎普遍获得好评，赢得了众多“年度游戏”称号和大量其他行业奖项。它对当代游戏设计产生了深远的影响，许多采用类似设计的游戏经常被称为“魂类”或“魂风格”。这已成为一种陈词滥调，类似于带有超现实或存在主义色彩的文学作品被描述为“卡夫卡式”。我认为其地位的原因并非游戏的“有趣”，而是它有一些关于我们今天所处世界的强有力表达，这些表达与那些对现代性的后现代批评观点一致的人产生共鸣。\n本文的核心论点是，“黑暗之魂”系列体现了具有后现代意识的生活体验。这个术语“后现代意识”是我用来总结后现代思想的一个总称。然而，我特别关注日本分支，引用了社会学家大泽真幸6、文化评论家东浩纪7、文学学者田中真纪子8和小说家村上春树9的著作。从弗朗索瓦·利奥塔10（Francois Lyotard）开始——他首次提出“后现代”一词——后现代思想的不同分支的核心主张是，曾经用来指导社会的“大叙事”已经无可救药地破裂并且无法修复。大泽和其他思想家拾起了这条思路，并将其应用到具体的日本背景。他们认为，日本战后时期的大叙事的破裂在年轻一代中引发了虚无主义行为，这种行为表现为从政治原因和社区参与转向过度消费主义和一种表现为御宅族形象的媒体崇拜。在一些极端情况下，这种御宅族主义可能导致病态行为，如奥姆真理教11的恐怖主义，但需要注意的是，这些思想家将这种暴力行为视为御宅族行为连续体的最外端，而不是在类别上有所不同。从大泽和东浩纪等后现代思想家那里，我将后现代意识提炼为两个基本特征：1. 拒绝或无法接受宏大叙事和意识形态作为意义的来源 2. 对“他者”的日益焦虑和敌意。在这种情况下，他者指的是主体与他者之间的经典哲学二元关系；换句话说，就是自我与世界上所有其他自我之间的关系。大叙事的破裂削弱了依赖这些叙事来维系和稳定的社区纽带和同胞感。这种意识是“黑暗之魂”系列设计和叙事的主要当代文化元素。\n然而，后现代意识在日本确实广泛传播，这并不是显而易见的。出于这个原因，我在第一章中追溯了大叙事在日本历史中逐渐瓦解的确切方式，从战后时期开始一直到现在。这使得我们能够看到后现代意识的发展及其在日本社会和“黑暗之魂”系列中的表达。没有这一步骤，就不可能识别贯穿这个系列的后现代意识。\n为了挖掘日本后现代意识的文化根源，我采用了大泽的文化时代精神理论，将战后时期分为三个阶段：意识形态时代（1945 - 1972），虚构时代（1972 - 1995）和后虚构时代（1995 - 现在）。大泽在其作品中提出的基本观点是，意识形态的死亡——本质上是他对“宏大叙事”的术语——刺激了新的形式，这些形式最终使他们脱离了日本战后社会的意识形态基础。从1972年的联合赤军事件12开始，激进的左翼政治让位于非政治的消费享乐主义。这导致了围绕显著消费形式尤其是时尚的亚文化的繁荣。然而，对一些人来说，对更深层意义的渴望仍然存在，这最终催生了新时代的邪教，即奥姆真理教，它们同样从传统宗教和动漫中汲取力量来满足这种需求。\n奥姆真理教的重要性在于他们既标志着传统信仰和意识形态的弱化，也标志着对任何被他们视为“他者”的事物的日益不容忍。他们还标志着一种对远在天边但又近在咫尺的敌对他者的偏执。例如，他们认为日本政府被全球犹太共济会阴谋控制，而他们自己的莲花团体则充满了双重间谍。他们在1995年对这个被认为是犹太人的他者的恐怖袭击，具有讽刺意味的是，传播了这种对奥姆真理教妖魔的偏执，这些妖魔潜伏在学校、企业甚至政府中。这种怪异他者的概念在“黑暗之魂”中得到了有力的表达，因为它向玩家展示了一个充满敌对个体和群体的世界——这些实体是玩家角色的他者——他们的目标和实践是难以理解的。这也通过一种系统得到了加强，即玩家始终连接到互联网，并且开放给其他玩家入侵。\n东浩纪采纳了大泽的时代精神，并提出了一种“动物化”理论。他指出，由于后现代时代缺乏大叙事，人们失去了理想和抱负。因此，他们退缩到一个以收集符号为中心的世界，这些符号被添加到一个巨大的符号数据库中并被重新利用。 他的主要证据是，当今的御宅族不再对叙事感兴趣。相反，他们只是享受识别、重新混合和扩展数据库的组件。他的预测是，御宅族的活动——他们无休止地收集符号——是大文化的先锋，后续几代人将在自己的领域中变得越来越像御宅族。东浩纪所指出的这一流行文化趋势在“黑暗之魂”中体现为深深的模糊和稀疏的叙事。\n那么“黑暗之魂”究竟如何通过游戏玩法表达后现代意识呢？我认为它通过为我们提供一个任务和一个王国来模拟传统的英雄之旅，但剥夺了我们理解这个任务意义的任何连贯方式。游戏提供了一个视觉细节丰富的世界，但完全缺乏具体的阐述，将玩家置于考古学家和法医科学家的角色中。然而，从未有任何可靠的解释；只有更多的线索和片段，有些是矛盾的。这被称为“环境叙事”，它创造了游戏与后现代思想之间最关键的接触点；即它对主叙事的拒绝。有“拯救王国”的建议，但仅仅是建议，主要是通过类型的惯例传达的，而不是叙事。你所做事情的意义及其服务的目的从未完全清楚。\n重要的是要记住，虽然可以从传统的文学解释视角来解释“黑暗之魂”系列的叙事，但当试图将游戏机制解释为寓意时，会遇到许多实际和理论问题。出于这个原因，我在第二章中对当代游戏研究的批判理论进行了文献综述。利用Espen Aarseth13和其他奠定该领域基础的思想家的论点，我认为需要结合“第一人称”现象学方法和更传统的文学分析方法，才能正确评估视频游戏中潜在的潜在意义。这样做是为了建立一种分析方式，通过与游戏系统的斗争，让玩家体验到我上面概述的后现代意识的两个基本特征。我在第三章中将这种现象学方法付诸实践，探索了一种特别有效的文本叙事、环境叙事和游戏玩法的融合，捕捉到游戏作为一个统一体验的本质。\n除了后现代主义，还有另一股影响游戏的力量，那就是佛教末法概念14。这两种影响力在有趣的方式上重叠，并产生了惊人的相似之处。末法在镰仓时代是一个极具影响力的概念，正如我们的时代一样，那是一个深刻的社会转型时期。末法指的是佛教教义失去其效力，人们无法再依靠自己的努力来获得启示。随之而来的是僧侣和寺庙变得不可否认的腐败，人们因此无法离开轮回，被困在一系列日益退化的转世中。我在第四章中分析了末法的哲学核心，并展示了它如何与大泽和东浩纪的后现代话语一致。此外，我认为，只要“黑暗之魂”系列表达了后现代意识，它主要是通过采用这个佛教末世论概念来表达的。后现代思想和末法都表达了一种恐惧，即事情只会变得更糟，人类的努力无法改变结果。\n在第五章中，我回到现象学和文学分析的混合方法，展示末法概念以及佛教形而上学的混合如何作为构建游戏虚拟世界的核心要素，尽管游戏的美学显然源于中世纪的欧洲奇幻调色板。这些佛教元素共同揭示了游戏世界被困在一个日益退化的轮回中，玩家的任务基本上是一种徒劳的行为，只会推动这个痛苦的循环。我认为佛教形而上学的融合最终表达了东浩纪的结论，即后现代世界及其死去的叙事和怪异他者无可避免地导致社会整体的“动物化”。尽管“黑暗之魂”是一款美学显然源于中世纪欧洲奇幻风格的游戏，但它充满了末法的逻辑，因此游戏深受异教影响，通过采用和改造佛教形而上学，在阴暗的骑士在破败的城堡中冒险的表面下表达了一种后现代情感。\n衰败叙事 过去几十年，日本几乎成了停滞的代名词。这在很大程度上归因于日本在1970年代到1980年代经历的“奇迹”，以及他们令人震惊的衰落，自那以后，国家似乎一直处于无所事事的状态。在美国，当《纽约时报》或《华尔街日报》等出版物提到日本时，往往很少有积极的报道，而是集中在一小部分话题：人口老龄化，年轻人自杀；货币贬值，索尼、丰田和东芝等企业巨头被更精简的竞争对手击败；核燃料仍在福岛渗入地下水，但无人承担责任，等等，每一个预言都比前一个更严峻。在西方，日本作为一个正在衰败的帝国的叙述已经流传已久。这种衰败的印象如此强烈，似乎只有惯性才能维持一切运作，以至于人们忘记了日本仍然是世界上最富有、最富裕和技术最先进的国家之一，仍然领先于许多西欧国家。这种停滞的叙述也存在于日本。正如现任首相安倍晋三在2012年选举中的口号所示：“日本を取り戻す”（取回日本）。从谁那里取回？取回到哪里？凭借他的“安倍经济学”15议程中的“三支箭”，他将从日本自己的“萎缩心态”中拯救日本（Sharp）。如果说1980年代的代表是那些狂热工作、渴望企业晋升的上班族，那么近年来这种原型被更为无力的角色所取代：草食男子16（sōshoku danshi）、尼特族17（NEET，指不在职或不在学的年轻人）、隐蔽青年18（hikikomori，指社会隐士）和其他贬损的称呼。诚然，日本的经济和文化问题与其他任何国家一样真实存在，但这种叙述的力量已经超越了现实，成为一种独立的存在。\n这种“萎缩”的心态和随之而来的文化表达，我将称之为后现代意识。这种意识必须与正统的后现代哲学区分开来，因为哲学本身只是对围绕日本的整体衰败叙述的众多情感反应之一。\n后现代意识的核心是一种源于对人类社会已经达到不可否认的衰退点的感知——无论是有意识还是无意识的——的焦虑。鉴于上面概述的围绕日本经济和文化衰退的广泛文化讨论，后现代意识在日本文化心理中占据了中心地位。因此，这些源自后现代意识的停滞叙述在日本的流行媒体中也找到了强大而多样的表达。虽然有许多例子可以引用，但游戏《黑暗之魂》及其所有续集，是这种“萎缩”心态的卓越典范。要理解它如何以这种方式运作，我们不仅要看叙述，还要看《黑暗之魂》相对于同类游戏的存在。《黑暗之魂》属于一种被称为角色扮演游戏（RPG）的游戏类型。RPG通常是一个开放式的幻想世界模拟，玩家可以探索领土、收集宝物和击败怪物。通常，玩家创建一个角色——一个在游戏世界中的化身——并以此角色进行任务，其最终目标通常涉及拯救某物（王国、存在平面、公主等）免于毁灭。另一个RPG的基本特征是成长概念。尽管有许多设计模式和隐喻用于模拟成长过程，通常玩家的化身通过击败怪物获得经验值，并通过积累这些点数“升级”。通过升级过程，玩家解锁能力，他们的化身变得更强大。总的来说，RPG往往是许多文化神话中常见的英雄之旅模式的模拟：年轻、未成型的人必须离开家园的安全区域，面对未知的危险，克服它们，培养他们潜在的能力，并以强大和完全实现的人的身份返回，无论是字面上还是象征性地。\n在其基本设计中，《黑暗之魂》作为RPG是相当传统的。然而，它有许多叙述和游戏设计选择，颠覆了这个几十年旧的类型的许多传统。作为一个叙述，它可以被解读为一种政治和文化的寓言，++直接反映了生活在一个意识形态叙述失去吸引力和连贯性的衰败文明中的经验++。它也是一种新兴新类型的前沿：后末日幻想。在这款游戏中，王国被占领，英雄们都死了或堕落了，没有人可以拯救，而你存在的最大威胁是那些与你在废墟中一起生存的人。社区是不可能的。基本的本体状态是无休止的失败，而“英雄”只是注定要忍受它。甚至死亡也不能免除角色的负担，而你被赋予的任务的意义和目标是模糊和不明确的。叙述几乎不存在。当游戏开始时，玩家被简单地放在一个被怪物和不死者占领的废弃王国中，没有明确的理由说明为何事情会如此，或者他们应该怎么做。仅有的叙述存在于零碎的文本中，只提供诱人但最终不完整或矛盾的关于世界的信息。所有这些叙述元素都对已建立的类型惯例提出了严重挑战，因此将其与衰退的讨论联系起来。\n在游戏设计方面，《黑暗之魂》有两个突出的特点。第一个是游戏被有意设计得异常困难。这实际上是其吸引力的主要来源之一。该系列在西方的广告标语是“准备去死”（Prepare To Die），而在日本，该系列被认为是しにがみ（死亡之神）的主要例子，暗示玩家在与远比玩家创建的化身强大的巨大、恐怖的怪物斗争时必然会经历无数次死亡。另一个特点是，尽管游戏主要设计为单人体验——也是RPG类型的一个既定惯例——玩家始终连接到互联网。这被视频游戏评论家广泛赞誉为该类型的重要创新。在实践中，这创造了一种紧张的局势，玩家总是暴露在其他玩家的“入侵”之中，这些玩家会试图杀死该玩家。这种互动中内置了一个复杂的风险/回报系统，入侵者通过杀死其他玩家可以获得很多，但如果失败则会失去很多。\n实际上，始终连接到互联网使得游戏世界充满了偏执和危险。其他玩家是玩家在游戏中可能面对的最危险和不可预测的怪物。入侵玩家经常会潜伏在一个不合适的时机突然袭击，玩家无法自卫，从而逆转他们不幸的受害者辛苦获得的进展。我们将详细探讨叙述和游戏系统，但这一系列游戏的基本概况引出了一个问题：在一个没有希望拯救王国，并且异常困难常常到不公平地步的游戏中，怎么会有如此大的吸引力？但事实上，这款游戏在日本、欧洲和北美都极具吸引力。这也指出了游戏的设计和叙述如何与在无聊时代生活的年轻一代的经验产生共鸣。\n日本文化领域的停滞叙述需要进一步澄清。我认为《黑暗之魂》可以被解读为对当代日本状况的政治和文化寓言。这是一种后现代的英雄之旅的颠倒：一种被污染的神话碎片的模拟。它直接反映了许多年轻日本人今天试图在庞大、失修的机构中航行时所经历的无聊和徒劳的感觉，这些机构至多对他们的存在漠不关心，至多直接敌对。然而，这种寓言不仅仅是关于生活在1980年代“奇迹”之后的经济问题。它同样涉及生活在一个国家、政治和文化叙述已经失去了大部分意义和连贯性的社会中的社会和心理成本，这些叙述曾经作为一种心理基石——为个人和社区身份提供稳定。\n催化这一恶化的事件起源于1995年，那一年发生了神户地震和沙林毒气袭击。在西方媒体中，关于这些事件的文化或政治意义的讨论通常不多，但在许多日本知识分子中，这些事件似乎标志着现代性的决定性破裂。在著名小说家村上春树的书《地下：东京毒气袭击和日本心理》中，对沙林毒气袭击幸存者的一系列采访，并得出结论，这一事件的后果不可逆转地揭示了日本社会的所有矛盾、缺陷和内在不稳定性：\n“神户地震和1995年1月和3月的东京毒气袭击是日本战后历史上两起最严重的悲剧。毫不夸张地说，这些事件前后的日本意识发生了显著变化。这两次灾难将作为我们生活中的两个里程碑，永远铭刻在我们的心灵中。如此灾难性的事件接连发生是令人震惊的，也是巧合的。然而，当日本的“泡沫经济”破裂，标志着那些泛滥成灾的时代结束时，这些事件带来了对日本国家根本根源的批判性审视。就像这些事件一直在等待伏击我们。两者共有的是压倒性的暴力元素：一个是不可避免的自然灾难，另一个是可以避免的人为灾难。”（村上，237页）\n通过村上等许多知识分子的工作，1995年已成为一个单一且不可改变的地位：通往破碎和功能失调时代的门户。这里分析的主要理论家——东浩纪、大泽真幸和田中基子——都将1995年视为进入反乌托邦现状的起点。这些思想家的语调本身就有一种微妙的后末日色彩，仿佛我们生活在一个无法拯救的被污染时代。这也是衰败讨论的一部分。这些思想家有一种确定的末世论信念，将他们与这一讨论联系起来。\n无论如何，这些灾难比任何经济灾难都更可能是现任首相希望根除的“萎缩”心态的原因。尽管已经过去几十年，1995年的事件作为焦虑和无助感的触发点，在《黑暗之魂》的寓言中找到了源头。经济的持续低迷、老龄化人口、年轻一代的就业前景减少以及福岛等灾难，只是加剧了这些灾难在1995年最初引发的负面情绪。福岛等事件只帮助在日本意识中创造了一种遗产。近年来，右翼极端民族主义政治的重新出现和尼特族及隐蔽青年的社会退缩，形成了对这一相同的文化病态的极端和相反的情感反应。右翼试图通过与其真实和感知的对手（韩国、中国、朝鲜）进行公开的对抗来复兴“大和”帝国的活力，试图通过历史修正主义抹去日本帝国的暴力和道德可憎之处，并试图通过修改宪法（第9条）恢复战争作为国家主权权利。而尼特族和隐蔽青年则将自己沉溺于网络和其他形式的私人数字享乐中。他们没有叙述可供复兴，没有事业可供加入，甚至没有可以参与的兴趣小组。与他人沟通实在是太困难了，在他们看来，也太危险了。\n我的观点不是《黑暗之魂》系列是这些问题的根源，甚至不是它们的贡献，而是它是对在公众意识中循环的深层社会焦虑，特别是对视频游戏作为熟悉媒介的年轻一代的一种特别有力的表达。《黑暗之魂》系列的持续流行，作为一种社会腐化的象征，反映了人们在日常生活中的感觉。但这些焦虑到底是什么，它们如何在《黑暗之魂》中表现出来？另一种问这个问题的方法是，后现代意识的基本要素是什么？定义1995年后时代的有两个主要元素。1. 对构建战后秩序的政治和社会叙述的拒绝；2. 一种对他者的弥漫性焦虑，侵蚀了对社会过程的信任和信心。他者的概念是指自我与世界上遇到的所有其他自我之间的二元关系的一半。这一概念的延伸是文化他者，即一种感觉某些人与自己相似，另一些人则是异类。日本社会通常被认为具有非常同质的国家认同感，彼此之间有相同的文化、种族和相似的价值观。这反过来又创造了强烈的信任和社区感，但这种亲近的逆向效应是，外来者被认为比在美国、英国或法国等文化多样性更大的国家中更为陌生。大泽真幸的论点是，奥姆真理教的恐怖活动将潜在威胁引入了公众。这种恐惧是一种诡异的他者的恐惧，这种他者会突然出现，以一种深刻的方式扰乱你的生活，有时甚至是致命的。社会结构中的这种破裂从未真正修复，并继续受到挑战，直到现在。关于诡异他者的偏执是定义《黑暗之魂》的氛围和叙述的主要特征之一，也是其游戏机制，尤其是其在线组件。\n要理解《黑暗之魂》如何作为一种描述后现代意识的寓言运作，我们必须追踪战后日本社会状况的衰退轨迹。这根本上是一个现代进步叙述——本质上是从西方继承的——首先在1960年代末引发了激烈的意识形态斗争，然后在1980年代变成一种无政治的享乐主义，最后，最终在五个正义的宗教狂热者用雨伞尖端戳破装满沙林毒气的袋子的时刻，被一种微妙的虚无主义彻底摧毁。为此，我们将研究社会学家大泽真幸的工作。大泽花费了相当多的职业生涯试图回答奥姆为什么会做他们所做的事情。在他的书《虚构时代的终结》中，他认为答案涉及意识形态本身的致命缺陷：一种危险而空洞的思维模式，导致在一个自我设计的世界中越来越高的疏离感。\n理性时代 借用社会学家見田宗介19（Mita Munesuke）的观点，大泽真幸将战后时代分为两个不同的阶段。第一个阶段他称为“理想的时代（理想の時代，risō no jidai）”，第二个阶段他称为“虚构的时代（虚構の時代，kyokō no jidai）”。理想的时代始于20世纪60年代，结束于1972年，虚构的时代从1972年开始，一直持续到1995年。大泽将“理想”和“虚构”描述为“可能世界（可能の世界 kanōsei no sekai）”，因为它们都反映了我们对世界的感知以及我们认为世界应该如何。然而，尽管这两个概念在根本层面上是相关的，但它们在几个重要方面是不同的。大泽认为，理想与现实世界密切相关，而虚构则完全脱离现实世界：\n理想是一个在未来有望或期待在现实中实现的可能世界。因此，理想必须存在于现实的因果延伸之上。从这个意义上讲，理想不是一个纯粹的可能世界，而是广义现实世界的一个方面。相反，虚构是一个可以在现实中实现与否无关的可能世界，因此是纯粹的反现实。（大泽，41页）\n理想は、未来において現実に着地することが予期（期待）されているような可能世界である。だから、理想は、現実の因果的な延長上になくてならない。その意味では、理想は、純粋な可能世界ではなく、むしろ広義の現実世界の一局面である。それにたいして、虚構は現実への着地ということについてさしあたって無関連ありうる可能世界であり、それゆえ純粋な反現実である。(Osawa, 41)\n暂且不讨论虚构如何将我们与现实疏离，日本的理想时代很大程度上受到冷战阴影的笼罩。当亚洲大部分地区处于苏联的保护伞下时，日本则在美国的庇护下，因而在意识形态上致力于民主和经济自由主义。在20世纪60年代，日本在这些条件下几乎在各个方面都得到了繁荣：科学、基础设施、经济、文化等。大泽将20世纪60年代称为理想的黄金时代，并指出家用电器是赋予大众理想的物质形式：\n理想时代在大众层面的黄金期是20世纪60年代。当然，这与日本的高速增长期相吻合。在此期间，例如，受到国民绝大多数人广泛需求的家电产品赋予了大众理想物质的表达……经济增长和科学技术的进步并不是因为理想而被接受的，相反，正因为理想作为可能的现实在广泛（全球范围内）被信奉，经济才能够增长，科学和技术才能进步。（大泽，44页）\n理想の時代の、大衆的な水準で黄金期は、1960年代である。もちろん、これは、高度成長期にあたる。この時期、たとえば、国民の圧倒的な大多数によって広範に欲求された家電製品が、大衆的理想に物質的な表現を与えた\u0026hellip;経済成長や科学・技術の進歩があったから理想が抱かれたのではなく、逆に、理想が可能的現実として広く（世界規模で）信憑されたがゆえに、経済が成長することができ、また科学や技術進歩していると感受されたのである。(Osawa, 44)\n乐观和对更美好（物质富足）未来的渴望是这一时代的指路明灯，这种乐观本身就反映了对美国模式的意识形态拥抱，推动了日本从一个被毁灭的国家向一个繁荣的国家的转变。大泽将这种发展归因于对可能世界的执着。在他的著作《拥抱失败》中，约翰·多尔20（John Dower）通过分析战后立即涌现的泛泛女孩21现象，生动地展示了这一拥抱的一个具体表现——这些年轻女性在占领期间主动接近并与美军士兵交往：\n在那段饥饿和匮乏的岁月里，美国人的物质舒适简直令人瞠目结舌。使美国“伟大”的是它如此富有；而对许多人来说，使“民主”具有吸引力的是它显然是通往繁荣之路。在普通人中，没有哪个群体像泛泛女孩那样公然利用征服者的物质财富。她们从美国军用商店获得物品，而在那些贫困的日子里，这些商店真的就像是魔法之地的宝库：不仅装满了基本食品，还有酒和香烟、糖果和美味佳肴，以及性感而颓废的女性物品如口红和尼龙袜。（多尔，136页）\nIn those years of acute hunger and scarcity, the material comforts of the Americans was simply staggering to behold. What made America “great” was that it was so rich; and, for many, what made “democracy” appealing was that it apparently was the way to become prosperous. Among ordinary people, no group tapped the material treasures of conquerors as blatantly as the panpan. They were the recipients of goods from the U.S. military exchange posts that in those impoverished days truly seemed like treasure houses from a magic land: crammed not only with basic foodstuffs, but with liquor and cigarettes, sweets and delicacies, voluptuously decadent feminine things such as lipstick and nylon stockings. (Dower, 136)\n到20世纪60年代后期，美国占领军所展示的意识形态愿景在很大程度上以非常具体的方式兑现了其承诺，普通日本人开始以便利设施、消费电子产品、便利和所有现代化工业国家的装饰形式享受经济发展的成果。大泽认为，这是意识形态在社会中最顺畅地运作的时候。尽管存在意识形态冲突，人们完全接受了作为他们理想“可能世界”的意识形态，并为之努力，无论他们是马克思主义者还是资本主义者。然而，需要注意的是，尽管20世纪60年代有所增长，仍然有许多日本人处于贫困之中。使20世纪60年代成为理想时代的不是相对的繁荣本身，而是对这种繁荣的承诺，以及对战后秩序确实朝着这个方向发展的普遍信念。普通日本人顽强地坚持这种愿景。这是当时的流行意识形态：汽车、收音机、流行音乐、方便获取的食品以及所有在战后立即投降的绝望、痛苦和毁灭中缺失的舒适和物质享受的承诺。\n然而，大泽认为，这种对意识形态的拥抱最终导致了意识形态向他称之为“虚构”的转变。这与意识形态结构本身的内在不稳定性有关，而不一定与日本的意识形态建制的具体情况有关。大泽以最广泛的术语谈论意识形态，但他将驱动意识形态的动机归结为他从佛教借来的一个原则：“貧病争（ひんびょうそう）”22。这个术语可以粗略翻译为“世间的烦恼”，它们被识别为贫穷、疾病和争斗。他主要基于意识形态与虚构的区别，意识形态是面向与貧病争斗争的。换句话说，大多数意识形态都承诺从世间的烦恼中解救出来。这种救赎总是必然在未来，但对其实现的信念保持稳定，并促使在现实世界中采取具体行动。这在大多数世界宗教，特别是忏悔宗教中是如此，但在像资本主义（自由市场=繁荣和自由）和马克思主义（废除财产/阶级=救赎不平等）等世俗概念中也是如此。然而，在理想和貧病争之间的关系中存在一个悖论：\n理想时代是一个社会整体上被疏离到理想中的时代。在这样的时代，最大的痛苦是从理想中被永久疏离。换句话说，在意识形态关系中，人们经历了双重疏离。貧病争代表了一种不可逃避的条件，在这种条件下，实现和接触我们的理想变得极其困难，我们不可避免地永远与之疏离。这种疏离引起的痛苦只能通过对我们理想的重新信仰来解决，只要我们认为其实现的可能性足够高。这只有在我们已经被疏离到意识形态中的情况下才有可能。（大泽，45页）\n理想の時代とは、社会が全体として理想へと疎外されている時代である。このような時代において、最大の不幸とは、理想から永続的に疎外されること、つまり理想との関係において二重に疎外されることである。「貧病争」は、理想への到達・接近が著しく困難になりうるような－理想からの永続的な疎外を余儀なくするような－宿命的な環境条件を代表している。不幸は、－すでに理想への疎外によって条件づけられている以上は－、到達の蓋然性が十分に高い現実性として理想を回復することによってしか、解消されない。(Osawa, 45)\n大泽指出，在苦难和救赎承诺之间存在一个相互强化的解释循环。貧病争，按定义，使人们与各自意识形态的救赎承诺疏离，但这种痛苦只能通过复兴理想来消除。++苦难往往不会导致信仰者失去信仰，而是激励他们按照自己已经信奉的叙事来解释自己的苦难。++使苦难有意义是一种常用于应对我们生活中悲剧性事件的应对机制。矛盾的是，这意味着即使我们离意识形态所承诺的可能世界极其遥远，貧病争也能加强意识形态信仰。当我们对可能世界的信仰非常强烈时，我们会在这种意识形态中“疏离”，只通过其中提供的狭隘解释视角来看待世界。这反映了走向教条主义和正统的驱动力，在这种状态下，貧病争仅作为意识形态引擎的燃料。然而，这个循环的关键部分在某种程度上超出了它；我们必须继续相信可能世界是可能的。大泽的虚构时代描绘了一种信念崩溃的普遍现象，但这种崩溃不应与某种信仰的丧失混淆，例如虔诚的天主教徒变成无神论者或坚定的资本家转变成马克思主义革命者。这只是将一种意识形态换成另一种意识形态。基本结构和取向保持不变。从意识形态到虚构的转变代表了一种新的疏离，一步远离了貧病争和意识形态之间的循环。这是一步远离世界本身。\n大泽举了许多例子，说明在20世纪80年代，日本的意识形态地图如何逐渐脱离大规模叙事（资本主义对抗共产主义），并催生了新人类（新人類 しんじんるい）23、御宅族（オタク）24以及最终的奥姆真理教（Aum Shinrikyō）和1994-1995年的沙林毒气袭击。然而，需要注意的是，在所有这些案例中，无论是伊斯兰教还是马克思主义，意识形态都与当前世界的实际问题密切交织。投射的可能世界正是通过这种对比才可以理解的。正是在与貧病争的这种重要关系中，意识形态与虚构分道扬镳。**对于大泽来说，从意识形态到虚构的转变是由20世纪60年代政治活动后的深刻失望所催化的。**虽然大泽认为20世纪60年代是意识形态运作最顺畅的时期，但这并不意味着那个时代没有意识形态冲突。相反，就政治而言，20世纪60年代末的日本充满了社会动荡。20世纪60年代意识形态运作顺畅的概念并不意味着政治和谐，而是指个人能够完全地、彻底地投身于构成其特定意识形态立场的叙事。\n20世纪60年代标志着许多学生运动，反映了当时日本普遍的政治激活。这些运动大多针对日本政府支持越南战争等问题提出抗议，但间接上也形成了对美国影响日本外交政策的一种抵制。反帝国主义和反美情绪主要由日本共产党刺激。它们创建了全学联合（Zengakuren）25，这是一个在大学生中创造了广泛的左翼文化的组织（羽根，465页）。最终，这些运动演变成了与警察的暴力冲突，抗议者和警察都受到了伤害，有时甚至死亡：\n20世纪60年代中期，东京的一些大学开始出现反对学费上涨的学生示威。总的来说，1968年有115所大学面临学生抗议、示威和骚乱。大规模罢工，设置路障，占领重要建筑。教授们经常被激进学生审讯，被逼供认罪行。（羽根，465页）\n暴力的出现也加剧了最初和平政治议程的混乱。这些抗议由许多不同议程的左翼团体拼凑而成，其中一些比其他更加激进。没有具体或连贯政治需求的暴力最终导致这些学生运动消亡，留下了持久的政治失望感。田中元子（Motoko Tanaka）26在大泽的时代背景基础上，认为安保和全共斗运动的失败是结束理想时代的一个主要因素。全共斗运动27是一个特别持久的事件，形成了一种由其他学生起义效仿的围攻战模式。这场斗争始于东京大学，当时医学生要求废除实习制度。管理层的压迫态度引发了一场全校范围的争议。1968年7月，学生们成立了全共斗，即全学共斗会议的简称。随着斗争的持续，全共斗逐渐激进，开始质疑日本社会的基础。他们占领了整个大学六个月，最终被警察驱逐。田中写道：\n安保和全共斗等政治运动的失败突显了即使在占领结束后，美国对日本政治的持续影响。经历了这些政治运动失败的年轻男性，有意或无意地吸收了应对美国力量的困难和失败的创伤。（田中，46页）\n大泽本人指出，1972年的联合赤军事件（連合赤軍事件）28是从理想时代转向虚构时代的主要转折点。联合赤军是几个激进马克思主义团体合并，意图暴力推翻日本政府。赤军是其中一个宣战日本政府并开始一系列恐怖袭击的团体，包括劫持飞机和袭击特拉维夫的罗德机场，导致26人死亡，80人受伤。政府对该团体进行镇压，逮捕了大多数成员，迫使其余成员与其他团体合并，最终隐藏起来。这个新合并的激进左翼在长野山区建立了一个秘密基地，进行军事训练。在那里发生了对自己队伍的清洗：14名成员因被认为缺乏革命热情而被残忍杀害，有的被绞死，有的被刀割。警察发现了他们的藏身之处并进行逮捕，剩余成员劫持人质， 将自己封锁在一座山间小屋中。这场持续一整天的围攻是日本第一次现场直播的马拉松式电视广播，持续了10小时40分钟。此事件导致了左翼激进政治的急剧衰退。\n当然，意识形态热情的衰退不仅限于左派，也存在于右派。在另一部相关的作品《不可能性的时代》中，大泽将三岛由纪夫未遂的政变视为另一个普遍意识形态崩溃的象征（大泽，13页）。在所有这些案例中，这些意识形态失败的高可见度都表明意识形态本身的某种无力感，其最激进的支持者的过激行为被转化为电视观众眼中的电视节目，令大多数人觉得这些不是高尚革命者的反抗行为，而是堕落的社会病态者的过激行为。取代这种意识形态热情的是大多数人只是享受经济繁荣的成果。\n虚构时代 大泽的虚构时代从1972年延续到1995年，但或许最能捕捉大泽对虚构与意识形态定义的隐喻无疑是“泡沫”这一概念。日本的1980年代通常被称为“泡沫时代”，意指经济的快速崛起及其随后的崩溃。这也传达了一种隔离感。1980年代对日本来说是一个极其繁荣和平的时期，“泡沫”这个比喻传达了普通日本人被困在一种虚假的安全感中的感觉，他们在从战争创伤中完全复苏的社会中享受着温暖、超现代的光芒。然而，这一时期本应被视为对现状充满乐观和信心的时代，却存在一种根本的模糊性。繁荣带来了物质上的丰富，但不一定带来个人或精神上的丰富。大泽认为，如前所述，虚构试图在世界之外重构意识形态，反映出对这种潜在世界在现实中实现的前景的极大失望。简言之，政治和革命活动被放弃了，但对理想的追求并没有消失。\n我们需要认识到，这两者之间没有明确的界限。相反，这种区分反映了控制现实感知和社会活动的态度连续体。我们越接近虚构标记的光谱，就越疏远现实，并且通常会完全拒绝当前的现实状态。此外，越接近虚构光谱，我们就越倾向于完全拒绝既定秩序，并放弃调整或改变它的计划。大泽认为，取而代之的是一种末世论修辞，即世界变得无法拯救，理想在不清除一切的情况下完全无法实现。他将虚构定义为在虚构中保存和扩展的意识形态冲动（大泽, 56）。\n这可以从字面上理解为流行媒体如漫画和动漫作为探索和满足意识形态冲动的空间，但也可以比喻为在这一时期开始繁荣的新兴消费主义和新兴宗教的神秘宇宙论。\n大泽用来体现虚构的三个象征是迪斯尼乐园的建设、涩谷作为东京主要娱乐区取代新宿的发展以及新人类的出现，这些新人类是这个新的“虚构”时代的本地居民（大泽, 46-49）。“新人类”一词可以翻译为“新人”或“新种族”。这个词首次出现在1985年，当时《朝日新闻》刊登了一系列对日本年轻人的采访，标题为《新人类的旗手们》（Herbig）。它通常指的是在1970年代及以后的成长的人群。1970年代和1980年代成长的一代人没有经历过战后重建的艰辛。相反，他们在一个富裕、有影响力、技术先进的国家中成长，这个国家鼓励他们把自己打造成富裕社会的一员。与1950年代和1960年代的年轻人截然不同的是，新人类对左翼政治毫无兴趣，事实上，几乎没有任何政治倾向，因此他们被称为“反应无代”（Herbig）。这种差异不仅仅是文化上的，更是身体上的。之前的几代人经历过粮食短缺，而新一代人从小就能定期过度享受。1965年至1985年间，日本男性的平均身高增加了7厘米，平均体重增加了5公斤，而女性的平均身高增加了6厘米，平均体重增加了1.4公斤。代替意识形态或政治抱负的是，这一代人更感兴趣的是在公司超级结构中的个人进步，或者是个人议程，关注如何设计新的生活方式。如果这些生活方式提出了挑战上一代权威的新价值观，那么可供新人类使用的财富和富裕让他们可以摆脱这些旧的社会结构的重压。例如，许多年轻人在这段时间里有能力搬出家庭独立生活，导致了另一个绰号的出现：“独身贵族”（Herbig）。\n这里讨论的每一项——迪斯尼乐园、涩谷和新人类——都反映了某种与定义过去的意识形态斗争的疏离、隔离或冷漠。迪斯尼乐园在这里是一个很好的隐喻，因为它不仅象征着日本泡沫经济的巨大成功，也象征了一种从世界中物理上的隔离感。迪斯尼乐园被精心设计，一旦顾客进入，他们就看不到其边界以外的东西。这是为了让顾客（尤其是儿童）能够完全沉浸在一个自主的幻想世界中，而不受世俗的干扰。从这个意义上说，迪斯尼乐园作为一种消费体验，完全是以购买从日常生活中暂时逃脱的机会为基础的。将政治或明确的意识形态活动引入迪斯尼乐园将是对其作为幻想空间的自主性的侵犯。但这种政治与休闲之间的绝对分离，在一个脱离普通生活的空间中具体呈现出来，本身就是一种意识形态。这是意识形态与虚构之间的界限开始变得清晰的地方。\n然而，东京的城市中心本身正在经历一种由房地产开发商主导的“迪士尼化”，这些开发商在政府的基本不加监管的情况下进行开发。最终使涩谷成为东京首要娱乐区的新代表，是该地区完全转变为一个主要的消费空间：\n“涩谷的成功在很大程度上归功于西武集团的投资。通过这些投资，整个区域被开发成一个时尚的‘超现实’空间——换句话说，一个充满符号差异的前沿空间——适应了消费社会。”\n“渋谷が成功したのは、とりわけ西武系資本の投入によって、街の全体が、消費会社に適合した、「ハイパーリアル」でオシャレな－つまり先進的な記号的差異に満ちた－空間へと仕立てあげられたからである。要するに、渋谷は虚构の时代に适合した盛り场だったのだ。”（大泽, 47）\n我们可以通过当代对日本的描绘来佐证大泽的论点。涩谷著名的十字路口——经常在延时摄影中显示，其日常通勤者像迅速变化的人群一样脉动——不仅是东京的一个有力象征，也是日本作为一个超现代国家的象征。此外，涩谷因此转变为一个象征日本未来的标志，不仅对日本人而言，也是对整个世界而言，作为未来本身的象征。\n大泽使用“超现实”（ハイパーリアル，hyper-real）一词指的是一种新的城市沉浸感。这是一种建立在对消费主义无疑庆祝基础上的超高清未来愿景。他没有详细解释这个词的确切含义，但他的用法无疑是借鉴了让·鲍德里亚在其著作《模拟与拟像》中的概念。在他的书中，鲍德里亚将当代社会描绘为一个不再包含任何现实参照的巨大符号狂欢。一个符号的意义只能是其他符号在不断变化的符号系列中的另一个符号。在这种框架下，符号获得了自己的自主权，并对我们的现实感知产生了强大的影响。通过博尔赫斯的《科学的准确性》作为寓言，他断言地图作为表征取代了领土，最终成为需要创建新地图的领土本身（Baudrillard, 1）29。没有参照闭合系统之外的任何事物的符号，他称之为拟像。在鲍德里亚的观点中，现代社会与后现代社会的区别在于，现代社会专注于通过更高水平的工业化进行生产，而后现代社会则围绕着生产“模拟”来组织，他指的是电视、互联网、电影、广告、虚拟现实等。\n这种新的媒体生态本质上是一个创造拟像的引擎。例如，真人秀的核心是其主体的非脚本化互动，但实际上是高度编排、制作和编辑的，使这些互动符合我们对戏剧的期望。这种新的“现实”视野因此被消费者接受为解释自己和自己经历的新模式。在鲍德里亚的模拟社会中，身份是通过这种图像的挪用来构建的，从模拟中派生的模型决定了个体如何看待自己以及如何与他人关系。通过延伸，一个超现实空间是一个设计用于交叉并反映这种模拟世界的空间。它利用生活在“模拟”中的各种交织的拟像系统来构建其美学。\n迪斯尼乐园是超现实空间的最佳例子，因为它代表了将地图（构成迪斯尼的符号矩阵）变为实际领土的真诚尝试，在这种情况下，地图无疑是优先的。这在涩谷并不明显，但当我们开始思考将这一地区转变为一个旨在促进各种消费的空间的基本动机时——情趣酒店、夜总会、购物中心、百货商店、娱乐中心——显然，这个世界离不开几十年来在现代广告和品牌建设中构建的符号语言。广告本身就是一个完全致力于通过符号的精心融合来改变产品认知的领域。这些符号被融合到产品的形象中，以便以特定方式阅读产品。通过这种方式，全新的设备或服务被转化为绝对必要品，奢侈品不仅仅授予地位，而是不可逆地与特定的“生活方式”身份混淆。与美国的大型购物中心相似，涩谷是广告、营销和品牌的物理化表现。它试图将城市空间密封在这个不断变化的新符号领土中。在这个空间内，他断言： “真实是从微型化单元、矩阵、存储器和指令模型中生产出来的——通过这些，它可以无限次地复制。它不再需要理性，因为它不再需要与某种理想或负面的事物进行比较。它只不过是操作性的。事实上，因为它不再被想象所包围，它根本不再是真实的。它是一个超现实的产品，一个没有大气层的超空间中的辐射综合体。”（Baudrillard, 2）\n在这种新密封的图像领土中进化并被其服务的新一代就是新人类： “虚构时代的年轻文化最密切相关的是1980年代前半期的新人类，然后是后半期的御宅族。新人类没有被任何意识形态或概念吸引，而是在他们的消费、时尚和兴趣层面上通过‘符号的戏耍’来表现自己的身份。这是一种态度，表达了他们从支配意识形态时代的理想重压下解放出来。”（Osawa, 48）\n在1972年至1995年虚构时代中出现的各种年轻文化中，“符号的戏耍”本身成为了理想的来源。这几十年间有无数的亚文化和时尚趋势——大多源自涩谷和原宿的街头文化——完美地展示了这种“戏耍”。这些众多亚文化的共同点是对生活方式的热爱，这种生活方式主要由美学定义。不同类型的コギャル（kogyaru）亚文化提供了一个生动且特别字面的例子，展示了新人类一代人所拥抱的狂热符号混搭。\nコギャル（高中女生）时尚大约始于1990年代，但其实践和美学可以追溯到早期的亚文化现象。“ギャル”（Gyaru，女孩，源自英语的“gal”）这个称号自1970年代末以来一直用于指代年轻女性的前卫、冒险风格，并在当代用作后缀，表示ギャル连续体内的细分。最初，コギャル风格是一种对校服风格的改编——西装外套、裙子和长袜——被改造得更性感，并混合了大胆的元素，如染发、夸张的化妆，偶尔还有整形手术。随着时间的推移，コギャル风格变得更加多样化和极端，产生了无数不同的变种。“コギャル”这个词与少年犯罪甚至卖淫联系在一起，并且成为老一代人批评的目标。批评者认为这些年轻女性是寄生在父母身上的自恋者，破坏了传统价值观和女性身份。文化人类学家劳拉·米勒在一篇讨论1990年代年轻人时尚的文章中使用“无国籍”（むこくせき，mukokuseki）一词来解释コギャル美学背后的文化逻辑。她使用这个词来说明日本时尚潮流不是由模仿国外特定趋势驱动的，而是希望将尽可能多的吸引符号混合到一个单一的整体中：\n“无国籍的审美刻意唤起某个地方或某个历史时期的图像——越南农民裤子、美洲原住民的流苏和珠子、1960年代的佩斯利图案——但将这些与匡威跑鞋或日本木屐、棒球帽或拉斯塔法里编织贝雷帽结合或并置\u0026hellip;\u0026hellip;日本年轻人的时尚中发现的超历史和文化融合并不仅仅是美国文化帝国主义的证据。仔细观察会发现，在许多情况下，被挪用的物品是有意“误用”或扭曲的。例如，一些コギャル玩弄廉价的夏威夷意象，使用假塑料花环、兰花、koa种子项链和波利尼西亚印花纱笼，但并不是为了看起来像真正的夏威夷人。那些采用这些装饰的人有时被称为“地方女孩”或“纱笼女儿”\u0026hellip;\u0026hellip;コギャル和其他人夸大了他们外表的人工性。结果在真诚、嘲讽和媚俗之间徘徊，使人难以分辨他们是否或在多大程度上是在开玩笑。”（Miller, 83-84）\n这种审美的共同特点是将常见或熟悉的物品与不寻常的物品搭配，创造出高度异国情调，有时甚至是故意怪异的新背景：一件鲜红色的格子纹和服，8英寸高的厚底鞋和一大片亮粉色的头发。这些符号不指向西方，甚至不指向江户时代，它们只属于コギャル时尚文化中的符号网络。像涩谷和原宿这样的超现实城市空间不仅是购买服装的地方，也是展示它们的空间。\n这种通过时尚和个人品味定义自己找到意义的新人类一代，通过拥抱这种新的超现代性的果实来表达自己。他们不是通过政治观点表达自己，而是通过显著的消费形式来创造身份。从这个意义上说，他们完全生活在日本的泡沫中。然而，新人类仍然是一个广泛的类别，反映了广泛的信仰和社会活动。对于大泽来说，完全体现虚构时代主要方面的亚文化是御宅族（Otaku）。御宅族起源于新人类一代，但发展成了一个独特的群体：\n“御宅族指的是一种从新人类中发展出来的青年文化。如果新人类的行为特征在于他们从过去时代的执着中解放出来，那么相反，御宅族的行为特征在于新的执着。**御宅族是这样一群人：他们对一个特定领域——动画、电子游戏、电脑、偶像歌手等——表现出过度的、几乎不合理的热情。**我将这种不合理的热情定义为‘意义’（这里我们可以认为是该领域的社会必要性，或像艺术一样，它本身具有的价值）和御宅族对该兴趣领域收集的信息密度之间的明显失衡。信息的密度压倒了意义。例如，在大多数情况下，如动画的典型例子中，故事[物语]只是虚构[虚构]的积累。因此，对于御宅族来说，他们钟爱的虚构世界似乎比普通现实更重要。”\n“オタクは、この新人類から分化・発展してきた若者の類型である。新人類が、過去の時代を支配していた執着からの解放の身振りによって特徴付けられるのだとすれば、逆にオタクは、新たな拘泥の身振りによって特徴付けられる。オタクとは、かつてだったら興味として片付けられるような一見瑣末なさまざまな領域—アニメーション、テレビゲーム、コンピュータ、アイドル歌手等々—に、不合理なまでに過剰に熱狂的に耽溺する人々である。「不合理なまで過剰」というのは、その領域の社会的な必要とか（芸术のような）それ自身として有すると考えられている価値といったような「意味」の大きさと、その領域に関してオタクが集积する「信息」の浓度との间に、バランスが失われているように见えるということ、「意义」の大きさを「信息」の浓度が压倒しているように见えるということ、である。たとえばアニメーションの場合が典型であるように、多くの场、物语＝虚构の集合である。それゆえ、オタクにとっては、まるで、通常の现実よりも、彼らが爱する虚构の世界の方がより重要なものになっているように见えるのである。”（Osawa, 48）\n大泽在这里提出的御宅族概念非常熟悉，但他从他们对流行媒体的热情中提取了更大的意义，而这常常被忽视。如果说红军联盟成员完全投身于马克思主义革命理想的热情，那么御宅族的特征在于对他们的细分兴趣的痴迷。这些信仰在结构和总体方向上的区别在于，马克思主义革命旨在改变周围的条件以服务于其愿景，而御宅族对周围条件基本无动于衷。他们只是希望更加深入地沉浸在自己喜欢的电视系列中，或者换句话说，更深入地进入特定的符号宇宙。大泽在上面提出的意义（いみ）与信息（じょうほう）之间的平衡，意味着对符号本身的奢华享受逐渐超过了它们的内容。虚构中所代表的理想逐渐在虚构本身中得到保留，达到理想无法在虚构之外生存的地步。这本质上构成了大泽所说的意识形态与虚构之间的关键区别。然而，单独指出御宅族是日本社会结构中的某种异常是错误的。大泽试图指出的是，御宅族对虚构的倾向在整个文化中普遍存在，或许只是通过程度上有所区分。\n御宅族与超现实 大泽在这里讲述的故事可以看作是宏大叙事逐渐消亡及人们为应对这种变化所作的努力。这些叙事曾是赋予私人和公共行动意义并为某些社区活动提供稳定的社会结构。超现实和“新人类”代表了一种意识形态的畸变，将激进分子的能量重新导向个人主义的新意识形态。\n自20世纪70年代以来，宏大叙事的死亡，或者说意义的死亡，一直是许多有影响力的哲学家和学者作品中的共同主题。这个概念最早由法国文学批评家Francois Lyotard30提出，后来成为后现代哲学的主要标志之一。“宏大叙事”一词通常指的是18世纪欧洲出现的各种社会建构，这些建构是为了将欧洲各王国的封建拼凑整合为统一的实体，形成具有单一身份的大型民族国家。知识上，宏大叙事体现在人性和理性的观念中，革命叙事如马克思主义中，经济上则表现为生产至上的国家存在理由。大泽的论点基本上是宏大叙事在日本如何消亡的具体案例。他的论点坚定地位于后现代哲学的传统中，讨论的是时代精神中的意识形态和虚构的死亡过程。\n从这个角度看，“新人类”亚文化和御宅族的出现只是对这些叙事死亡的情感反应。文化批评家东浩纪在他的《御宅族：日本的数据库动物》中，描述了御宅族作为后现代世界中努力保持理智的不安幸存者的形象：\n“御宅族无论走到哪里，都随身携带大量的书籍、杂志、同人志和塞满大纸袋的碎片，像寄居蟹一样，”因为如果他们不随身携带“自我的壳”——即他们的群体归属幻想——他们就无法在精神上保持稳定……现代性受宏大叙事的支配。相反，在后现代性中，宏大叙事崩溃，社会整体的凝聚力迅速减弱。在日本，这种减弱在1970年代加速了，当时高速经济增长和“政治季节”结束，日本经历了石油危机和联合赤军事件。从这个角度看，我们可以将御宅族用垃圾亚文化材料构建“自我壳”的行为模式视为填补宏大叙事消失所造成空虚的行为模式。（东浩纪, 27）\n这种“寄居蟹”形象，与穿戴各种奇异饰品和配件的コギャル（日本街头少女）并无二致，有时她们甚至被这些饰品贴满。消费主义达到极致是一种虚构：一种对世界不感兴趣的意识形态，仅关注符号。这是一种沉浸于超现实的狂喜。御宅族只是消费主义的一个极端代表。这种消费主义类似于意识形态热情，但应用于某些小众兴趣。大泽和东浩纪告诉我们，无论我们是否消费漫画，我们都是在宏大叙事的遗骸中为寻求我们的身份的寄居蟹。从这个角度看，像涩谷这样充满光辉和魅力的超现实空间实际上是一个精神的深渊。\n虚构时代的时代精神仅仅指出晚期资本主义社会中滋生一种几乎宗教态度的消费者的趋势，他们对自己的爱好、喜爱的电视节目、音乐类型等充满热情。西方的民主、工业化国家（暂且包括日本）正是由于其巨大的财富和高度发达的基础设施，使我们能够过上与貧病争大多隔绝的生活；饥饿不存在，现代医学可以治愈许多疾病，洪水和地震的影响通过技术进步大大减弱等。这反过来使我们与现实疏远，同时将我们进一步沉浸在一个与自然世界完全不同的日益技术化的环境中。\n城市一直提供某种程度的与贫病死的疏离。然而，基础设施中表现出的先进技术越来越使我们能够从未曾可能的方式中消除死亡、疾病和暴力。超现实就像虚拟现实的类比原型；一种存在的层面，甚至隔绝了城市本身的更严酷环境，专注于消费和机械化的满足。这就是涩谷与迪斯尼乐园的联系所在，使这些超现实空间与东京臭名昭著的山谷（さんや）31地区或大阪的釜崎（釜ヶ崎，かまがさき）32区不同，在那里贫困的体验是痛苦可见的。城市提供的疏离使自然世界的侵入或突发死亡的可能性变得更加创伤。这就是为什么沙林毒气攻击和1995年神户地震对国家心理产生如此深远影响的原因。这两个事件对大泽有特别重要的意义，因为它们扰乱了城市的超现实环境，结束了虚构时代。\n进入超现实本质上是现代化西方的特权，可以说，创造超现实空间的欲望在大泽定义的意识形态最纯粹形式中反映出来：消除贫病死的斗争。讽刺的是，这削弱了我们与意识形态的关系，将贫病死推向模糊的边缘。然而，超现实从未完全隔离我们；我们始终容易遭受灾难、受伤或突如其来的死亡，破坏我们对世界安全或稳定的看法。超现实只是掩盖了我们对这种灾难可能性的意识，直到它以灾难性的事件出现在我们的生活中。\n70年代日本右翼和左翼意识形态活动的明显失败——红军的暴力、三岛由纪夫的自杀、学生运动的混乱和政治无能，甚至远处苏联的解体——导致了结构日本战后社会的宏大叙事的普遍崩溃。**从这个角度看，大泽的虚构时代是由意识形态时代向虚构时代过渡的双重运动推动的：超现实中的疏离和政治幻灭。**在这种背景下，新人类对经典意识形态斗争不感兴趣或不信服。他们转向内心的虚构和超现实的享乐空间，作为新理想的空间。对于1980年代的御宅族，他们实际上献身于虚构，作为新理想可以蓬勃发展的空间。超现实是鼓励和增强向虚构冲动的空间。像涩谷这样的空间由开发商建造，作为对消费符号的激情献身的自然基质。正如田中元子（Motoko Tanaka）敏锐指出：\n“……现代日本[已经]标准化和媒体化，有着精心维护的分销管理系统。在日本，消费者需求可以立即和机械地满足，无需他者的介入。以前只能通过社会交流获得的欲望对象，如食物和性释放，现在可以很容易地获得，或几乎不需要交流。”（田中, 57）\n当然，这不仅适用于日本，还适用于整个后工业化西方。现代性的成果导致了许多基本需求自动、即时，甚至在我们意识之外得到满足的系统。根本上，超现实代表了一种对虚拟现实的渴望。新宿和迪斯尼乐园就像原型；模拟形式的虚拟空间。但是，虚拟的渴望究竟是什么？斯洛文尼亚哲学家斯拉沃热·齐泽克（Slavoj Zizek）对这个术语提供了一个有趣的解释：\n“[虚拟现实]提供了被剥夺其实质的现实……就像脱咖啡因咖啡闻起来和尝起来像真正的咖啡但不是实物……一切都被允许，你可以享受一切——只要它被剥夺了使其危险的实质。”（齐泽克, 38）\n这种对虚拟的概念，即享受无后果的乐趣或去除物体本质的欲望，是我们迄今为止探讨的超现实和虚构概念的核心。向虚构的运动反映了一种沉浸在符号的吸引世界中的愿望，在那里理想可以不受阻碍地生存，超现实的城市空间同样反映了一种欲望，即将城市中任何不愉快或危险的因素剥离。然而，超现实倾向于那些不仅使我们与超现实之外的现实疏离，而且间接地与他者疏离的系统。这导致了对现实的共同感知的削弱。那些在70年代末和80年代开发的超现实空间充当了当代虚拟空间扩散的原型。虚拟现实和超现实仍然保持各自的领域，但技术的整体趋势指向政府和私营部门积极努力将数字实用性与物理空间整合（智能手机与城市的互动是一个很好的例子；例如Uber，甚至约会服务如Tinder）。超现实中反映的虚拟渴望与从70年代末到现在的视频游戏的加速增长和流行密切相关。然而，如果这些空间使某种行为或某种消费关系得以实现，大泽会将其定义为转向虚构的行为，但它们并不一定决定这种行为。大泽关于御宅族的论点揭示了沉浸在超现实中的欲望如何反映出一种快乐的享乐主义，但也可以反映出对世界的深层次怨恨，迅速转变为病态的虚无主义。\n虚构的负面逆转 超现实世界的主要问题在于，虽然它充满了符号和物质上的享受，但却缺乏意义。对当代整体情况常见的情感反应是讽刺、玩世不恭和刻意的冷漠。另一种常见反应是制定复杂且高度综合的新世纪信仰体系。这些信仰体系鼓励信徒完全服从一种彻底另类的世界观，通常看起来像科幻小说或幻想作品一样刻意。在这个意义上，它是虚构时代最有力的象征。这些信仰体系通常强调世界的虚假和无意义。因此，围绕新世纪信仰体系组织的邪教往往核心是一个末世论叙事，要么寻求逃避当前形式的世界，要么寻求其毁灭。在社会学家岛园嗣的研究中，指出新世纪邪教成员的两个关键特点：一是成员主要来自相对富裕或中产阶级背景；二是加入邪教的主要原因是世界的虚假、虚幻或无意义 (田中, 48)。这两个特点似乎概括了问题的核心。尽管这些人生活舒适，物质上得到满足，但这种满足并不能填补当代生活中某种根本性的意义空虚。\n对于大泽来说，虚构时代（1972-1995）的主要象征是奥姆真理教。他认为这个组织是御宅族的极端表现。这在字面上是部分正确的。众所周知，麻原彰晃和他的追随者是漫画和动漫的狂热爱好者，这些虚构的内容直接融入了他们的综合信仰体系中，包括诺斯替基督教、吠陀神秘主义、阴谋论和超自然伪科学。一个小例子是“宇宙清洁器”，这是一个大型空调单元，麻原声称可以净化外界毒素的空气（大泽, 50）。这个名字直接取自流行动漫《宇宙战舰大和号》，其叙事围绕人类试图修复被敌对外星人辐射污染的地球。此外，该邪教还通过身体和精神上远离外界，建立了一个名为莲花村的公社，作为他们的新乌托邦时代的诺亚方舟，并称之为香巴拉，这是从藏传佛教中借用的天堂概念。通过隐退，他们得以完全封闭在自己设计的世界中。莲花村是他们尝试创建的超真实空间，在这里他们可以用新的虚构符号包裹自己。全面探讨他们所有的宗教实践在这里是不可能的，但简而言之，像“宇宙清洁器”这样的遗物、麻原的秘传布道、能量转移仪式如夏克提巴特，以及电击疗法和在黑暗房间里度过数天的极端宗教训练，都是他们沉浸在自己的超真实中的一部分。\n麻原彰晃将许多阴谋论作为他们神话的一部分。他们认为日本政府是一个由恶意的全球犹太阴谋（共济会）操纵的傀儡，实际上控制了世界。他们认为美国政府在共济会的影响下开发了一种地震机器，导致了1995年的神户地震。在他们看来，世界是不可救药的，受恶意力量的控制。他们甚至认为自己的公社莲花村里充满了共济会间谍，这导致了一个秘密内圈的形成，最终负责毒气袭击。在奥姆未能在1990年获得政治职位后，大泽指出，麻原在该团体内部刊物中的言辞变得越来越末日论和对日本政府的敌意。甚至有证据表明，在1995年之前有几次失败的毒气袭击（奥尔森, 413 - 416）。未能当选相当于外界对其虚构的拒绝，这对他们来说是不可容忍的侮辱，促使进一步的神秘启示和更多的阴谋论，以巩固他们的信仰。\n奥姆还标志着日本社会状况与《黑暗之魂》系列之间的第一个接触点。在每个游戏中，总是存在着在已坍塌王国废墟中仍在运作的敌对、神秘的亡灵邪教。这在第三部作品中特别明显，几乎整个游戏过程中都可以看到亡灵邪教的证据。这些无法理解的信仰实践者代表了有组织社会的最后残余，他们一见到玩家就完全致力于消灭你。正如奥姆的一些成员甚至对其实践和目标也感到模糊一样，《黑暗之魂》中的亡灵邪教的实践和目标也是如此。只有他们作为玩家威胁的存在是明确的。这重现了许多人对奥姆的恐惧和焦虑，他们只是一个威胁和神秘的实体。\n大泽认为，像奥姆真理教这样的新宗教与基督教等旧的千禧年传统不同之处在于，他们通过退缩故意脱离与“贫病争”的斗争。佐证岛园的论点，他指出这种退缩的主要动机是“生活的空虚”（生活の空虚）（大泽, 35）。他将新信仰与旧信仰进行对比。例如，基督教在《圣经》中包含一个末世论叙事，涉及物质与神圣最终完美结合（《启示录》实际上是麻原的主要灵感来源之一）。然而，大多数形式的基督教在通过慈善等努力积极参与与“贫病争”的斗争。换句话说，他们不通过退缩来拒绝现实的严酷，而是积极努力通过各种可能的途径消除它。这使得它们在经典意义上是意识形态的。令人惊讶的是，许多在日常生活中与贫困和疾病作斗争的人往往是宗教信徒。如果我们看一下像天主教会这样的机构，大多数教区居民来自第三世界，如南美洲、非洲甚至贫困水平较高的亚洲。相比之下，属于虚构时代的宗教如奥姆真理教明确拒绝世界，通常渴望世界的终结或其他形式的毁灭。在我们的文化中，人民圣殿教（乔恩斯顿大屠杀）33和天堂之门34是两个虚构取向而非意识形态取向的宗教的好例子。\n岛园对加入像奥姆真理教这样的团体的动机的研究似乎表明，现代经验中出现的某种缺失需要被填补。这是从意识形态转向虚构的根源，在面对当代的模糊、混乱和意识形态的空虚时对意义的真诚渴望。虚构就像是在这混乱中的生命线，但一个人越深入这领域，病态行为的潜力就越高。如果沉迷于自己最喜欢的系列神话的御宅族是对虚构和超真实的“积极”异化，那么实行恐怖主义的末日邪教则是无法容忍其虚构界限之外世界的“消极”异化。奥姆对其自创虚构的痴迷，以及他们完全退隐至莲花村——他们自己设计的超真实空间的尝试——使他们无法接受任何与其虚构相矛盾的存在。这是对虚构的依恋导致对世界虚无主义拒绝的关键点。在后现代性的背景下——即宏大叙事不再起作用的世界——现实无法维持这种虚构中潜在的理想，往往会导致认为现实本身某种程度上是被污染的结论。\n第二章：受苦之魔力圈 未实现的道路 文学解释充满了模棱两可，因为一个文本可以有无数种解读。这一点在电子游戏中更为显著，因为其“游戏性”（或游戏特质）和叙事结构之间存在根本性的张力。传统的文学解释依赖于文本的某种稳定性，以便提取出一种“解读”。在《了不起的盖茨比》中，读者只能通过一个“路径”来进行叙事。威尔逊总是射杀盖茨比，而这一叙事事件的描述对所有读者来说都是相同的。虽然可能有许多解释方式——例如，我们可以将其解读为对资本主义意识形态如何使无产阶级自相残杀的马克思主义批判——但这种解释只有在基于菲茨杰拉德的原始作品《了不起的盖茨比》的基础上才有效。\n如果我们将电子游戏，特别是RPG（角色扮演游戏）类型，视为一种文本，它们更像是一个选择你自己的冒险小说，其中玩家的自主性决定了事件的进程。从叙事角度来看，这种思维方式有助于分析《黑暗之魂》，因为它的叙事结构大致是线性的。它有一个开始，并有几个决定结局的叙事选择，而这些点之间有限的叙事内容是由“作者”（设计师）设定的。然而，即便在这里也存在问题，因为游戏作为美学艺术品并不主要在于通过叙事来前进，推动玩家想知道接下来会发生什么。游戏的体验在于游戏本身，这种游戏形式可能与叙事或其中所出现的虚构世界有松散甚至完全没有实质性的联系。例如，想象一下，你只能在完成一场5公里跑步比赛且时间在六分钟以内的情况下从第九章继续到第十章。在文学中，这些活动之间没有联系，但在电子游戏中，“跑步比赛”的体验非常重要，并直接影响我们对叙事的解读。在像《黑暗之魂》这样的游戏中，完成游戏大约需要40个小时，而阅读、观看过场动画或听对话的时间可能只有30分钟。\n大多数电子游戏是困难且繁琐的，即使对那些熟悉这一媒介的人来说也是如此。对于那些没有所需数字素养和基本操作游戏设备技能的人来说，它们简直是不可能的。正是这种繁琐和挑战性，导致电子游戏学者Espen Aarseth称电子游戏为“需耗费精力的文学”（ergodic literature），即“需要付出巨大努力才能让玩家穿越游戏文本”（Aarseth，第2页）。“ergodic”这个词来源于希腊词语ergon和hodos，分别意为“工作”和“路径”。这个概念出现在Aarseth的开创性作品《Cybertext: Perspectives on Ergodic Literature》中，成为这一新领域的核心理论工具。这个概念的核心是玩家在游戏中拥有的自主性，这种自主性是书籍读者或电影观众所不具备的：\n读者，即使强烈地参与到叙事的展开中，也无能为力。就像足球比赛的观众，他可以推测、推断、外推，甚至大声咒骂，但他不是比赛的参与者。就像火车上的乘客，他可以研究和解释不断变化的风景，可以随意休息眼睛，甚至拉下紧急刹车并下车，但他不能自由地改变轨道方向。他无法拥有玩家的影响乐趣：“让我们看看我这样做会发生什么。”读者的乐趣是偷窥的乐趣。安全但无能为力。（Aarseth，第2页）\n然而，除了“影响的乐趣”——即通过游戏系统选择自己的“路径”的乐趣之外，还存在其负面反转的未探索可能性。在另一篇题为“定义现实”（Define Real）的文章中，他写道：\n\u0026hellip;玩家意识到他们体验的部分性质，众多策略和未走的路径，以及游戏中可能存在他们永远不会遇到的谜团，超出他们技能水平的解决方案\u0026hellip;你可能永远不会知道你的选择的确切结果；也就是说，你到底错过了什么（Aarseth，第3页）。\n在文学中，没有只有在特定条件下才会显现的秘密章节。当我们从头到尾阅读《了不起的盖茨比》时，我们确信已经读完了整部作品。当然，多次阅读会揭示多种解释，但我们从不会为是否仍有大量未发现内容而感到焦虑。从形式上、游戏设计角度以及文本/电影的角度来看，《黑暗之魂》是一款推动这种感觉的游戏，有时这种感觉令人不安、疲惫和疏远。应对这种感觉是游戏作为一个偶然性系统运作的关键方面。在对第一款《黑暗之魂》游戏的分析中，Daniel Vella将这种焦虑称为“需耗费精力的讽刺”（ergodic irony）（Vella，第16页），以表示我们的自主性如何可以削弱我们对游戏“完成”或“掌握”的驱动力。\n除了“需耗费精力的讽刺”中潜在的焦虑之外，还有由游戏行为产生的不稳定心理模式的问题。尽管被称为“游戏”，但在这个领域仍有相当大的争论，即电子游戏是否应该被视为游戏。这并不难理解，因为电子游戏通常同时既是一个故事又是一个具有规则和程序的游戏。当我们踏上篮球场时，我们进入了一个特定的心理框架；所有的行动都是通过一个基本的目标来理解的，即在一个内化的任意限制（例如，不携带球、不击打其他球员等）下将球投入篮筐。\n实际上，正是这种框架使人成为篮球运动员。这正是荷兰社会学家Johan Huizinga所说的“游戏的魔法圈”（magic circle of play）（Huizinga，第32页）。它是指游戏划定了一个空间，在这个空间内只能采用某种心理框架。篮球场是一个“魔法圈”；它允许篮球运动的发生，但只有在篮球游戏本身的心理框架下才能使用。如果做其他事情，就会排除游戏的可能性。篮球场也可以用作高中舞会的场地，此时“圈”的魔法处于休眠状态。小说也是一种魔法圈，因为它是以某种心理框架为前提而创作的。当我们阅读小说时，通常会暂停许多其他阅读方式，以便欣赏故事。文学评论家、历史学家和文学爱好者不会以相同的方式阅读小说，尽管他们可能是同一个人。然而，所有这些框架都是允许的，并且不会削弱作品的基本存在。\n此外，阅读小说的行为通常并不是围绕着完成一个任意目标进行的，而阅读的“规则”并不是基于封闭的一套理性公理。电子游戏会在你无法理解或处理游戏作为一个规则和程序系统时让叙事停滞不前。电子游戏，特别是RPG类型，要求玩家在最基本的层面上通过多种心理模式进行转换。玩家必须随时准备成为电影观众、读者、统计数据的解释者以及复杂运动任务的执行者，所有这些都在几分钟之内完成。\n从这个意义上讲，魔法圈的概念开始崩溃，因为很明显，电子游戏是一个可以同时存在多个圈并要求不同心理框架的空间，而不会削弱电子游戏作为互动艺术品的功能。更好的理解电子游戏的方式是将其视为模拟，其中传统意义上的游戏要么被直接纳入，要么可以在设计师意图之外自发地出现。此外，尽管电子游戏通常将虚构作为体验的核心方面，但严格来说，它们与虚构并不完全相同。引用游戏学者Jesper Juul的话，电子游戏是“半真实的”：\n电子游戏是现实的，因为它们由玩家实际互动的真实规则组成，赢得或输掉游戏是一个真实事件。然而，通过杀死一条龙赢得游戏时，龙并不是真实的龙，而是虚构的。玩电子游戏因此是与真实规则互动，同时想象一个虚构世界，电子游戏是规则和虚构世界的结合。（Juul，第1页）\n然而，在“真实”与“虚构”龙的问题上，还有另一个重要的观点。Espen Aarseth认为，像《魔戒》这样的幻想作品中的龙和像《无尽的任务》（Sony Online Entertainment，1999）这样的幻想RPG游戏中的龙具有截然不同的本体论性质。即使是同一条龙，如《霍比特人》小说中的Smaug和《霍比特人》电子游戏改编中的Smaug，也是如此。区别在于虚构与模拟之间的差异。在题为“门与感知：游戏中的虚构与模拟”（Doors and Perceptions: Fiction vs Simulation in Games）的文章中，Aarseth写道：\n一条龙显然是虚构的，但另一条是模拟的。一条龙是供阅读或在电视或电影屏幕上观看的，另一条龙是供玩耍的。一条龙完全由符号构成，另一条由符号和动态模型构成，这个动态模型将指定其行为并响应我们的输入。正是这种模型行为使其与虚构不同，因为我们可以比了解虚构更亲密地了解模拟。虚构很少甚至从来都不是个人化的，而模拟通过体验可以成为个人化的。模拟允许我们测试其极限、理解因果关系、制定策略并产生变化，这些在虚构中被明确拒绝，但在现实中却非常相似。（Aarseth，第35页）\n然而，如果我们将游戏视为模拟，它们到底在模拟什么呢？如果模拟的是一些现实世界的活动，如驾驶飞机或汽车，这个问题的答案就很简单。在电子游戏行业本身，“模拟器”一词指的是一种试图在世界中再现实际、有时是非常平凡的体验的游戏。模拟可以是低保真或高保真的，但它们的参照物是显而易见的。\n以虚构为导向的游戏，本质上是将那种虚构作为一个数字世界的模拟。当我们考虑电子游戏与传统虚构中的既定类型的关系时，这一点最为明显。科幻电子游戏《光晕：战斗进化》（Bungie，2001）似乎直接借鉴了几部科幻作品，并将它们拼凑在一起。游戏发生的巨大的环形太空栖息地（即标题中提到的“光晕”）让人联想到Larry Niven的《环形世界》系列，而主角Master Chief穿着的“Mjolnir Powered Assault Armor”似乎暗示了John Steakley的《装甲》一书，该书的情节也围绕着穿着动力外骨骼与外星威胁作战的士兵展开。可以几乎无限地以这种方式继续下去，将光晕神话中的某些方面孤立出来，并试图从科幻经典作品中挖掘出影响。这种拼凑是类型小说的基本特征。不同的是，当这些元素被重新构建为一个虚拟的“现实”时。\n设计师不像作家那样，必须回答一些困难的问题，例如，等离子步枪的感觉和声音如何？它的射速有多快？它能穿透坦克的外壳吗？作家可以简单地依靠读者自己想象这些体验细节。以这种方式，《光晕》就像是对构成该类型的符号集合的模拟：模拟模拟物。然而，电子游戏并不是由影响其美学的虚构类型定义的，而是由游戏玩法的惯例定义的。《光晕》的虚构可能源自科幻，但它首先是一款第一人称射击游戏。因此，作为一种体验，它与《孤岛惊魂：原始杀戮》（Ubisoft Montreal，2016）——一款发生在人类原始的穴居人过去的“射击”游戏（标枪、弓箭等）——相比，具有更多的共同点，而不是与《幽浮》这款科幻游戏进行比较，尽管《幽浮》也涉及人类与外星人之间的冲突，但它是一款策略游戏，其原则更类似于国际象棋或Risk这样的棋盘游戏。\n然而，电子游戏不仅仅模拟作为美学集合的类型，或甚至是作为与外星人战斗的太空陆战队员的幻想，尽管它们在这些方面做得相当令人信服。它们还模拟人类存在的模式，或者换句话说，它们模拟文化原型。它们几乎是作为这些原型在古今虚构作品中表现的逻辑延伸来模拟的。\n在其作品《千面英雄》中，美国神话学家Joseph Campbell首次提出了“英雄之旅”的概念，这是一种在不同文化和时代中可见的叙事模式。他描述了基本模式如下：\n一个英雄从日常世界出发，进入一个充满超自然奇迹的区域：在那里遇到令人惊叹的力量，并赢得决定性的胜利：英雄从这个神秘的冒险中回来，拥有了为同伴带来恩惠的力量。（Campbell，第23页）\n正是这种模式的认知使我们能够看到《星球大战》中的卢克·天行者几乎与《伊利亚特》中的奥德修斯扮演了完全相同的文化功能。RPG类型作为一个整体几乎完全围绕这种模式在叙事和游戏设计中进行结构化。在这些游戏中，几乎总是有一个任务，一次跨越许多土地的旅程，一个成长的过程（例如，升级，解锁能力和获得强大的物品），以及一个英雄式的结局，一个王国，或者宇宙本身得救。《黑暗之魂》与其RPG前辈不同之处在于一个关键的类别：英雄式的结局。英雄的方面不仅被模糊和故意含糊不清，而且甚至没有提供一个真正的结局，像卢克自我实现为绝地武士并推翻邪恶帝国的那种方式。这是使《黑暗之魂》作为作品独特的关键方面，因为它模拟了英雄之旅，同时又颠覆了构成其核心价值观的基本结构。\n电子游戏之现象学 如果电子游戏是一种对虚构类型和文学/文化原型的模拟，而不是简单的虚构再现，那么我们该如何解释它们的意义呢？游戏的高度开放性和“能动性”特质（ergodic）在试图对某一作品进行严谨理解时带来了挑战。这一问题在游戏学者中广泛讨论，但一种广泛应用的解决方案是采用现象学方法，即Edmund Husserl和Martin Heidegger等思想家所提倡的在研究游戏体验的基本特征时所用的方法。简而言之，现象学是指通过经验调查现实，而不是单纯依赖外部的、理性的（主要是隐含的）公理体系来证明我们的知识。\n从根本上说，游戏的现象学是一种“第一人称”的分析方法，它不会忽视学者在与游戏这种物质系统互动时所产生的变化和解释框架。这种方法并不排除其他传统的文学解释方法，也不排除社会学、人类学或历史等其他研究模式，而是将这些模式纳入研究者的心理整体中。这样，评论家可以关注游戏过程中相对于具体文本和电影元素所出现的多种心理模式。毕竟，电子游戏不仅仅是叙事，也不仅仅是一组抽象的程序和规则。它们是两者的结合。玩家通常将这些元素作为一个整体来体验，仅仅关注叙事或游戏玩法中的任何一个都会忽略一些至关重要的方面。只有通过严格的自我反思过程，游戏评论家才能提出关于这种全新媒介中出现的意义类型的连贯论点。\n之前，我提到过Johan Huizinga对游戏的定义，即“魔力圈”，其中划定了一个需要特定心理框架的空间，才能使游戏存在。由于游戏在每一刻都引发多种心理模式，电子游戏理论家Dominic Arsenault和Bernard Perron借用了Huizinga的概念，并将魔力圈重新定义为“魔法循环”（magic cycle）（Arsenault，Perron 109）。这一术语指的是玩家与游戏系统之间的反馈循环，玩家通过探测系统来推进游戏，系统则产生新的游戏状态，激发玩家对游戏世界的不同理解，促使玩家采取进一步行动。在《黑暗之魂》系列中，玩家探索世界以获取材料，这些材料可以用来升级武器，使他们能够打败更强大的敌人，从而探索更多的世界，获得更多的武器和材料，依此类推。在这个过程中，他们将看到、阅读和体验到改变他们对自己活动看法并激发新行动的事物。\nArsenault和Perron的魔法循环概念在游戏研究中广泛传播，但游戏设计师早已意识到反馈循环对其媒介的重要性。作为《光环》的首席设计师，Jaime Griesmer曾在一次采访中说：\n在《光环1》中，大概有30秒的乐趣反复出现。如果你能找到30秒的乐趣，你基本上就能把它延伸成整个游戏。（Kietzmann，web）\n由于《光环》在游戏历史中的重要地位，这句话已成为商业领域的设计信条。然而，Griesmer在几年后的另一次采访中对此进行了重要补充：\n在Vidoc（视频纪录片）中被删掉的那句后半部分我谈到了如何在不同的环境中，以不同的武器、不同的载具、对抗不同的敌人、不同组合的敌人，有时对抗彼此战斗的敌人来进行那30秒的乐趣。《光环》的每30秒都不会重复；任务不断改变你所处的环境。（Kietzmann）\n这揭示了Arsenault和Perron意识到但其术语未能充分表达的魔法循环的重要方面。游戏玩法不是一个循环，而是一个不断扩展的螺旋，叙事和游戏元素交织在一起，创造出对游戏世界作为虚构空间和系统的不断演变的理解。\n在下一章中，我将对我在《黑暗之魂III》中遇到的一个隐藏区域进行现象学描述，该区域是在玩了大约30小时后发现的。角色和地点的名字将同时给出英文本地化和日文原版。这些本地化版本相对忠实但可能与原版有显著偏差。这是因为本地化过程优先考虑的是游戏的市场性和销售，而不是文本的忠实度。在原版日文和本地化版本之间有显著差异的地方，我将提供自己的翻译。这将在文本引用中注明。我将采用现象学方法来传达在魔法循环中发现的变化心理模式，这些模式不仅是整个系列的特征，而且可以在游戏的任何特定部分中浓缩。尽管从叙事角度来看，描述中会有许多看似晦涩的部分，但这种晦涩是故意构建在体验中的。只有当我们检查魔法循环的轮廓时，才能正确地将这些散落在这段短暂但强有力的体验中的叙事片段置于上下文中。这里提供的《黑暗之魂》系列的解释将展示叙事框架如何与游戏元素交织在一起，创造出必须整体分析的连贯体验。\n夏目漱石。日本近代文学巨匠，被誉为“日本现代文学之父”，其作品探讨了人与社会、个人内心世界等深刻主题，代表作有《我是猫》、《心》、《明暗》等。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n三岛由纪夫。日本著名作家、剧作家和政治活动家，以其充满美学与哲学思考的作品著称，代表作有《金阁寺》、《春雪》、《海与毒药》等。他的作品往往探讨人性、荣誉、死亡等主题。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n或翻译成“新的媒介在大学里常常遇到困难，因为每一种媒介都必须通过那些把关“高雅文化”的权威人士的审查。”\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n沟口健二（1898-1956）是日本著名电影导演，以精湛的拍摄技巧和深刻的社会洞察力闻名。其代表作包括《雨月物语》和《山椒大夫》，他擅长于通过细腻的叙事手法展现人性的复杂。沟口被视为日本电影史上的大师之一，对后世电影影响深远。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n指代一种源自捷克作家弗朗茨·卡夫卡（Franz Kafka）作品风格的情境，通常描述一种充满荒诞、绝望和无助感的氛围。在这种情境中，个体往往陷入与无情且不可理解的官僚体系或命运的斗争中，感受到无力改变自身处境的痛苦和迷茫感。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n大泽真幸 Masachi Ōsawa（1958-）是日本当代著名的社会学家、哲学家和评论家，专注于社会理论、文化批评和历史哲学。研究焦点包括现代日本社会的结构性问题及后现代思想在日本的应用。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n东浩纪 Hiroki Azuma（1971-），日本文化评论家和哲学家，专注于后现代主义、信息社会理论及日本流行文化的研究。他的代表作《动物化的后现代》探讨了当代日本动漫、游戏等亚文化现象，并提出了“数据库消费”等独特概念。东浩纪在日本思想界和文化评论领域具有重要影响力，尤其在分析现代社会和文化变化方面贡献卓著。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n田中真纪子（Makiko Tanaka），日本文学学者，研究方向包括现代日本文学及文化，她的研究涉及后现代思想对日本文学的影响。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n村上春树（Murakami Haruki）是日本著名小说家，以其独特的风格和对梦幻与现实交织的描绘而闻名。他的代表作包括《挪威的森林》、《海边的卡夫卡》和《1Q84》，这些作品探讨了孤独、爱情、以及人类存在的意义。村上春树的作品广受国际读者喜爱，并对全球文学产生了深远影响。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n弗朗索瓦·利奥塔 Francois Lyotard（1924-1998），法国哲学家，以其对后现代主义的研究著称。他在1979年出版的《后现代状况》一书中首次提出了“后现代”一词，主张大叙事（如宗教、政治意识形态）的破裂和小叙事的兴起。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n奥姆真理教 日本的极端宗教团体，创立于1984年，因其在1995年东京地铁沙林毒气袭击事件中的恐怖行为而广为人知。该教派结合了多种宗教和神秘主义信仰，曾声称能够提供终极真理。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n联合赤军事件（日本语：連合赤軍事件）是指1971年至1972年间，由日本极左激进组织联合赤军（連合赤軍）发动的一系列暴力事件。联合赤军由“赤军派”和“京滨安保共斗”两派极端左翼组织合并而成，其成员信奉极端左翼思想，试图通过暴力推翻政府。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEspen Aarseth 挪威学者，游戏研究领域的开创者之一，以其对电子游戏叙事和游戏性分析的贡献著称。著有《Cybertext: Perspectives on Ergodic Literature》（《赛博文本：互动文学视角》），提出了“互动文学”的概念，强调玩家在游戏中的互动和参与对于理解游戏文本的重要性。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n佛教末法概念 佛教教义中的一个概念，指佛法逐渐衰微的时代，教义的力量减弱，人们无法通过修行获得解脱。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n“安倍经济学”是指日本首相安倍晋三（Shinzō Abe）自2012年开始推行的一系列经济政策。这些政策包括所谓的“三支箭”策略：大胆的货币政策、灵活的财政政策和促进投资的增长战略。安倍经济学的目标是通过刺激经济增长、提高通货膨胀率来摆脱长期的通货紧缩和经济停滞状态。这些政策在日本和国际上都引起了广泛关注和讨论，但也引发了对其效果和可持续性的质疑。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n草食男子（日语：草食(そうしょく)系男子(けいだんし)，sōshoku danshi）是日本的一种社会现象，指那些对事业、恋爱和结婚不感兴趣，生活态度温和、不争、不抢的男性。这个词最早由日本作家深泽真纪在2006年提出，反映了日本社会中一些年轻男性的生活态度和行为模式的变化。这些男性通常不追求传统意义上的男性气概和社会成就，反而更注重个人兴趣和生活质量。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n尼特族 （NEET，Not in Education, Employment, or Training）是指那些既不在学、也不在职、也不接受职业培训的年轻人。这个词源自英国，但在日本也广泛使用。尼特族的出现反映了现代社会中青年失业率高、就业压力大以及社会结构变化等问题。这一群体在日本引起了社会关注，因为他们的经济依赖性和社会疏离感对家庭和社会结构带来了挑战。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n隐蔽青年 （日语：引(ひ)き籠(こも)り，hikikomori）是指那些因社会压力、精神疾病或其他原因而长期闭门不出、与社会隔绝的年轻人。这种现象在日本尤为突出，被认为是社会压力、竞争激烈以及家庭结构变化等多重因素共同作用的结果。隐蔽青年通常在家中长时间不出门，不上学、不工作，依赖父母或家庭成员的支持。这个现象不仅影响到个人的心理健康和生活质量，也对家庭和社会产生了深远的影响。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n見田宗介 是日本著名社会学家，曾任东京大学名誉教授，是日本社会学界的重要人物之一。他的研究领域广泛，涵盖现代社会理论、文化社会学以及日本社会的独特发展轨迹。峰崎的代表作《现代社会的理论》（『現代社会の理論』）对日本社会现代性的转型和结构做了深刻分析，被认为是社会学研究的重要文献。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n约翰·多尔 是一位美国历史学家和作家，以研究日本历史和美日关系闻名。他的著作《拥抱失败：日本在美国的阴影下》（Embracing Defeat: Japan in the Wake of World War II）通过详细的历史分析和丰富的文献资料，探讨了二战后日本社会的变化和重建过程。多尔的研究不仅涉及政治和经济层面，还深入探讨了社会文化的转变，特别是日本人对美国模式的接受和适应。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n泛泛女孩（panpan girls）是指二战后日本被美国占领时期，一些日本女性与驻日美军士兵交往的现象。这些女性通常通过与美军士兵建立关系，获得他们带来的物资和经济利益。泛泛女孩现象反映了战后日本社会的贫困与物质匮乏，以及人们对物质富裕和更好生活的渴望。二战后，日本遭受了巨大的物质和经济损失，许多人生活在极度贫困之中。占领日本的美军士兵带来了大量的物资和财富，使得美军的生活条件远优于普通日本人的生活水平。泛泛女孩们通过与美军士兵的交往，获得了食品、酒类、香烟、糖果、化妆品等在当时极为稀缺的物品。泛泛女孩现象不仅仅是一个物质交换的过程，它还反映了当时日本社会对美国文化和生活方式的向往。对许多日本人来说，美国的富裕和舒适的生活条件成为他们追求的目标，这种对美国模式的向往也在一定程度上推动了战后日本的现代化和经济复苏。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n貧病争 ひんびょうそう是一个源自佛教的概念，指的是“世间的烦恼”，具体包括贫穷、疾病和争斗。这三个方面代表了人类在世俗生活中不可避免的痛苦和困扰。以下是对每个方面的解释: 贫穷（ひん），指物质上的匮乏和经济上的贫困，贫穷会导致人们为了生计而不断奋斗，成为生活中的一大烦恼；疾病（びょう），指身体上的疾病和健康问题，疾病的存在使得人们不断追求健康和医治；争斗（そう），指人际之间的冲突和社会中的斗争，这包括个人之间的争执、家庭内部的冲突、社会中的暴力和战争等，争斗使得人们生活在不安和紧张的环境中。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n新人类（しんじんるい）是20世纪80年代日本的一代年轻人，他们在思想、行为和文化上与之前的世代有显著的不同。这一群体的出现标志着日本社会的深刻转型，影响了当时的社会文化和经济发展。通过对新人类的研究，可以更好地理解日本意识形态在20世纪80年代的变化和发展。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n御宅族 通常用于描述对某一特定兴趣（如动漫、漫画、电子游戏等）有着极端热情和深入了解的人群。这个词汇最早出现在20世纪80年代，最初带有一定的负面意味，指那些沉迷于兴趣爱好、常常在家里闭门不出、不太参与社会活动的年轻人。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n全学联合（日语：全学連，Zengakuren）是“全日本学生自治会总联合”（全日本学生自治会総連合）的简称，成立于1948年，是日本历史上重要的学生运动组织。全学联合主要由日本各大学的学生自治会组成，代表学生在政治、社会问题上发声。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n田中元子 是一位研究日本战后政治运动的学者，特别关注20世纪60年代的学生运动，如安保运动（Anpo）和全共斗运动（Zenkyoto）。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n全共斗运动 （全学共闘会議，Zenkyōtō）是20世纪60年代末至70年代初，日本大学生和左翼组织发起的激进学生运动，旨在反对政府的教育政策、经济措施以及与美国的安保条约。这个运动的特点是学生自发组织、没有固定的领导层，通过激烈的抗议和占领校园来表达政治诉求。全共斗的行动在日本社会引起了广泛关注，成为那个时代反抗精神的象征。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n联合赤军事件（Rengō Akagun jiken）是指1972年日本联合赤军组织进行的一系列激进和暴力事件。联合赤军是由极左翼的日本学生运动组织合并而成的激进组织，他们在长野县浅间山庄劫持了人质，导致与警方的对峙长达10天。最终，日本警方采取了强攻行动，事件导致人质获救、部分赤军成员被捕或死亡，引发了日本社会对极端左翼运动的广泛批判。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n通过博尔赫斯的《科学的准确性》作为寓言，他断言地图作为表征取代了领土，最终成为需要创建新地图的领土本身： 来自于阿根廷作家豪尔赫·路易斯·博尔赫斯（Jorge Luis Borges）的一篇短篇小说《精确的地图》（也译作《科学的准确性》）。在这个故事中，博尔赫斯描绘了一个极端的情况：地图变得如此精确，以至于它与现实世界（领土）完全重叠，最后，地图的细节变得如此复杂，以至于它不再是现实世界的象征，而是成为了一个替代现实的东西。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n弗朗索瓦·李奥塔（François Lyotard，1924-1998）是法国著名的哲学家和文学批评家，以其在后现代主义领域的开创性研究而闻名。他的代表性著作《后现代状况》（La Condition Postmoderne，1979年）对20世纪末的思想产生了深远影响。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n山谷是东京台东区和荒川区附近的一个地区，以前被认为是日工、无家可归者和社会底层人员聚集的地方。在这个地区，贫困和社会问题较为突出。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n釜崎是大阪市西成区的一个地区，类似于东京的山谷，这里也有大量的日工和无家可归者。如今，这个区域的正式地名为”爱邻地区”（あいりんちく，Airin Chiku），但釜崎的称呼仍然流行。这一地区长期以来是社会底层人员的聚集地，经济落后，社会问题严重。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n人民圣殿教是美国的一个新宗教团体，由吉姆·琼斯（Jim Jones）于1950年代创立。该教团以其强烈的社会平等和共产主义色彩著称，特别强调种族平等与社会正义。然而，这一组织在1978年因乔恩斯镇大屠杀（Jonestown Massacre）而闻名。当时，吉姆·琼斯带领900多名信徒在南美圭亚那的乔恩斯镇集体自杀，成为现代宗教历史上最惨烈的悲剧之一。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n天堂之门是一个美国的新宗教团体，由马歇尔·阿普尔怀特（Marshall Applewhite）和邦妮·内托尔斯（Bonnie Nettles）于1970年代创立。这个教团以其独特的末世论思想和对外星生命的信仰而著称。教义核心是认为地球将被净化，信徒的灵魂需要通过离开身体（即自杀）以进入一艘外星飞船，从而到达更高的存在层次。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://niraya666.github.io/essay/%E5%90%91%E4%B8%8B%E8%9E%BA%E6%97%8B%E9%BB%91%E6%9A%97%E4%B9%8B%E9%AD%82%E7%B3%BB%E5%88%97%E6%B8%B8%E6%88%8F%E4%B8%AD%E7%9A%84%E5%90%8E%E7%8E%B0%E4%BB%A3%E6%84%8F%E8%AF%86%E4%B8%8E%E4%BD%9B%E6%95%99%E5%BD%A2%E8%80%8C%E4%B8%8A%E5%AD%A6/","summary":"\u003ch1 id=\"摘要\"\u003e摘要\u003c/h1\u003e\n\u003cp\u003e本文探讨了“黑暗之魂”系列游戏在当代日本社会中的意义定位。我认为，这款游戏可以被看作是当今文化潮流的象征，就像有人可能会把杰克·凯鲁亚克的《达摩流浪者》视为60年代反文化的象征一样。\u003cstrong\u003e我主张，“黑暗之魂”系列通过寓言的方式表达了人们在一个日常行为和社会本身的意义都变得极不稳定的时代中生活的焦虑\u003c/strong\u003e。游戏采用碎片化的叙事方式，融合了佛教的形而上学思想，并以描绘一个曾经辉煌的王国在最后时刻挣扎的阴森哥特式美学为背景。这种对当代社会焦虑的表达，与日本的后现代主义话语密切相关。通过将这些游戏视为文本、环境和游戏系统之间的反馈回路，我把这些游戏的主要概念主题与大泽真幸提出的“后虚构时代”概念，以及东浩纪对御宅族的定义联系起来。\u003c/p\u003e\n\u003ch1 id=\"前言\"\u003e前言\u003c/h1\u003e\n\u003cp\u003e在人文学科这个领域，我们认为艺术和文学不仅仅是艺术鉴赏。当我们阅读夏目漱石\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e或三岛由纪夫\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e的作品时，教授和学生不仅仅像粉丝那样陶醉于他们优美的文笔，而是作为评论家，从中挑出深刻的思想。通过这种方式阅读足够多的作品，我们会发现一种更宏大的东西：\u003cstrong\u003e一个跨越时代和文化的思想洪流，在这个洪流中，生活的神秘、美丽、恐怖和悲剧汇聚成我们人类经验的漩涡和流动\u003c/strong\u003e。文学是指南，就像老话说的那样，是通向美好生活的指南：它是一面镜子，反映我们的位置，也是我们漫步时的地图。简而言之，伟大的作品让我们变得更强大。它们让我们清晰地面对生活的矛盾，并有勇气承受其重压。我们学习文学是为了找到人类经验中的共性，并将其内化。这至少是人文学科的理想和创立原则。\u003c/p\u003e\n\u003cp\u003e但如果这是正确的，我们能说这种深刻的体验只是文学独有的吗？书面文字是否有某种独特的力量，能够以其他媒介无法企及的方式激发反思？最终，文学只是一个个故事，但故事并不局限于一种媒介。故事是跨媒介的。它们可以口头讲述，可以印刷，可以通过舞蹈、图像，甚至可能通过尚未构想的方式来讲述。这是因为故事首先存在于人类心灵的深层结构中，不同的媒介让这些结构的不同方面显现出来。\u003cstrong\u003e故事是人类生活的核心，它们赋予我们的社会和个人生活以连贯性和意义。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e故事是个人身份的基石，人类将经验转化为故事的能力可能与我们感知时间的能力有关。\u003cstrong\u003e毕竟，故事是什么？它是以有意义的方式组织和编辑时间\u003c/strong\u003e。简而言之，通过研究故事，特别是那些在社会想象中占据重要地位的故事，我们可以进入人类心灵的最深处。当我们接近这一神秘领域时，我们更接近自己，也许会找到一些我们遗忘的，对我们至关重要的东西，它像火药桶上的火花一样在我们脚下点燃，在这场大火中我们的世界观重生。\u003c/p\u003e\n\u003cp\u003e新的媒介在大学里常常面临艰难，因为每种媒介都必须越过高文化裁决者的障碍\u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e。这在二十世纪初的电影和摄影上是如此，在今天的漫画、电视和视频游戏上也是如此。但如果我们仅因为这些作品属于错误的媒介而忽视了沟口健二\u003csup id=\"fnref:4\"\u003e\u003ca href=\"#fn:4\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e4\u003c/a\u003e\u003c/sup\u003e的作品，人文学科会变得多么贫乏？偏重研究一种媒介而忽视其他媒介有什么好处？这种偏见是最糟糕的，我们都因这种武断的判断而变得贫乏。我们切断了自己探索那些激发我们深层结构的新视角的机会。故事在新的媒介中同样存在，此外，对那些在这些新媒介中成长的人来说，发现其中的故事是引人入胜、动人且深具意义的。视频游戏中的故事体验与其他媒介有着根本的不同，正是这种不同使得研究它们变得如此重要。它反映了一种新的世界观和价值观。我们不再生活在一个技术只是工具的世界里；技术是我们生活的环境。电影和电视是工业时代的本土媒介，而视频游戏是数字时代的本土媒介。视频游戏不是小众的。这个行业在全球产生的收入大大超过了电影和印刷品。这本身就使得研究它们成为紧迫的事情。\u003c/p\u003e\n\u003cp\u003e话虽如此，我们必须认识到，视频游戏是一种新兴的媒介。就像早期的电影只是基本现象的再现——火车向屏幕疾驰或马在慢动作中奔跑——视频游戏的媒介中无疑有着尚未开发的巨大潜力。此外，我们还不能像理解文学那样全面理解这一媒介。我们还没有足够的时间去理解视频游戏在文化中可能扮演的角色以及它们对塑造我们的价值观和性格的影响。我不会在这里主张创建一个新的经典目录。现在还为时过早，而且流行经典化的过程早已在进行中。本文研究的游戏《黑暗之魂》系列已经被这样经典化了。它享有一种地位，其他同类游戏以它为标准，而那些共享其设计原则的游戏被称为“魂类游戏（Soul-like）”，这可能类似于许多文学或电影作品被描述为“卡夫卡式的”\u003csup id=\"fnref:5\"\u003e\u003ca href=\"#fn:5\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e5\u003c/a\u003e\u003c/sup\u003e。然而，我不会试图将这款游戏作为一部伟大作品来评估，以便将研究这一系列游戏制度化。我认为这些游戏被经典化不仅仅是因为它们“有趣”，而是因为它们直接处理了当代日本及其年轻一代面临的问题、焦虑和挑战。这是我们将要问的问题：\u003cstrong\u003e这些游戏中反映了什么，使其在跨文化范围内以及在粉丝和评论家中产生如此深刻的共鸣？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我将在这里主要讨论日本，但我相信在研究这款游戏时得出的教训具有全球意义。目前，这些意义将保持原样。本质上，为了故事而玩游戏是一件矛盾的事情。游戏的内部组件，作为一个具象化的代码系统和作为不同类型叙事（文本、视觉、听觉）的载体，对玩家提出了一系列相互竞争的需求。这种矛盾在《黑暗之魂》中和几乎所有其他游戏中一样没有解决，但该系列在这些相互竞争的元素之间达到了罕见的一致性，可能直接反映了日常生活中数字世界的体验。我希望我在这里的分析，即使只是初步和不完整的，也能成为反思社会走向、新的价值结构的出现以及文学解释或在这种情况下的游戏解释可以对这些问题有所启示的机会。\u003c/p\u003e\n\u003ch1 id=\"第一章引言\"\u003e\u003cstrong\u003e第一章：引言\u003c/strong\u003e\u003c/h1\u003e\n\u003cp\u003e本文旨在探讨“黑暗之魂”系列游戏与当代日本社会状况之间的关系。我认为，“黑暗之魂”系列通过寓言形式表达了在一个日常行为意义甚至社会本身都变得不稳定的时代生活的焦虑。这一表达通过破碎的叙事方式实现，这种方式结合了佛教形而上学，并以描绘一个昔日伟大王国最后挣扎的阴暗哥特风格为背景。这种寓言中的焦虑与日本后现代性讨论密切相关，特别是现代性项目失败和进步叙事腐败的观点。在我的论文中，我认为这种讨论在“黑暗之魂”中通过模拟经典英雄之旅得以体现，但最终通过剥夺玩家的英雄成就感并用深深的模糊和不确定性取而代之，颠覆了这一旅程。\u003c/p\u003e\n\u003cp\u003e“黑暗之魂”系列是一款第三人称动作RPG，其核心机制围绕探索一个破败的世界展开。该系列由著名日本游戏公司FromSoftware在总裁宫崎英高的指导下开发。第一款游戏于2011年9月发布，第三款于2016年4月发布。这是一款难度极高的游戏，设定在一个末世奇幻世界，要求玩家克服许多复杂的运动任务。游戏的一大特点是其缺乏具体的叙事阐述。然而，有一些概念性主题将这些游戏联系在一起。游戏中总是有一个被“不死诅咒”摧毁的王国，并且总是有神秘人物指示玩家杀死旧神并使用他们的灵魂来“连接火焰”。这个过程在第一款游戏中被解读为一个世界复兴过程，但在第二和第三款游戏中被揭示为不可避免的衰败螺旋。\u003c/p\u003e\n\u003cp\u003e全球销量数百万，三部作品在国外几乎普遍获得好评，赢得了众多“年度游戏”称号和大量其他行业奖项。它对当代游戏设计产生了深远的影响，许多采用类似设计的游戏经常被称为“魂类”或“魂风格”。这已成为一种陈词滥调，类似于带有超现实或存在主义色彩的文学作品被描述为“卡夫卡式”。我认为其地位的原因并非游戏的“有趣”，而是它有一些关于我们今天所处世界的强有力表达，这些表达与那些对现代性的后现代批评观点一致的人产生共鸣。\u003c/p\u003e\n\u003cp\u003e本文的核心论点是，“黑暗之魂”系列体现了具有后现代意识的生活体验。这个术语“后现代意识”是我用来总结后现代思想的一个总称。然而，我特别关注日本分支，引用了社会学家大泽真幸\u003csup id=\"fnref:6\"\u003e\u003ca href=\"#fn:6\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e6\u003c/a\u003e\u003c/sup\u003e、文化评论家东浩纪\u003csup id=\"fnref:7\"\u003e\u003ca href=\"#fn:7\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e7\u003c/a\u003e\u003c/sup\u003e、文学学者田中真纪子\u003csup id=\"fnref:8\"\u003e\u003ca href=\"#fn:8\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e8\u003c/a\u003e\u003c/sup\u003e和小说家村上春树\u003csup id=\"fnref:9\"\u003e\u003ca href=\"#fn:9\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e9\u003c/a\u003e\u003c/sup\u003e的著作。\u003cstrong\u003e从弗朗索瓦·利奥塔\u003csup id=\"fnref:10\"\u003e\u003ca href=\"#fn:10\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e10\u003c/a\u003e\u003c/sup\u003e（Francois Lyotard）开始——他首次提出“后现代”一词——后现代思想的不同分支的核心主张是，曾经用来指导社会的“大叙事”已经无可救药地破裂并且无法修复\u003c/strong\u003e。大泽和其他思想家拾起了这条思路，并将其应用到具体的日本背景。他们认为，日本战后时期的大叙事的破裂在年轻一代中引发了虚无主义行为，这种行为\u003cu\u003e表现为从政治原因和社区参与转向过度消费主义和一种表现为御宅族形象的媒体崇拜\u003c/u\u003e。在一些极端情况下，这种御宅族主义可能导致病态行为，如奥姆真理教\u003csup id=\"fnref:11\"\u003e\u003ca href=\"#fn:11\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e11\u003c/a\u003e\u003c/sup\u003e的恐怖主义，但需要注意的是，这些思想家将这种暴力行为视为御宅族行为连续体的最外端，而不是在类别上有所不同。从大泽和东浩纪等后现代思想家那里，\u003cstrong\u003e我将后现代意识提炼为两个基本特征：1. 拒绝或无法接受宏大叙事和意识形态作为意义的来源 2. 对“他者”的日益焦虑和敌意\u003c/strong\u003e。在这种情况下，他者指的是主体与他者之间的经典哲学二元关系；换句话说，就是自我与世界上所有其他自我之间的关系。\u003cu\u003e大叙事的破裂削弱了依赖这些叙事来维系和稳定的社区纽带和同胞感\u003c/u\u003e。这种意识是“黑暗之魂”系列设计和叙事的主要当代文化元素。\u003c/p\u003e\n\u003cp\u003e然而，后现代意识在日本确实广泛传播，这并不是显而易见的。出于这个原因，我在第一章中追溯了大叙事在日本历史中逐渐瓦解的确切方式，从战后时期开始一直到现在。这使得我们能够看到后现代意识的发展及其在日本社会和“黑暗之魂”系列中的表达。没有这一步骤，就不可能识别贯穿这个系列的后现代意识。\u003c/p\u003e\n\u003cp\u003e为了挖掘日本后现代意识的文化根源，我采用了大泽的文化时代精神理论，\u003cstrong\u003e将战后时期分为三个阶段：意识形态时代（1945 - 1972），虚构时代（1972 - 1995）和后虚构时代（1995 - 现在）\u003c/strong\u003e。大泽在其作品中提出的基本观点是，意识形态的死亡——本质上是他对“宏大叙事”的术语——刺激了新的形式，这些形式最终使他们脱离了日本战后社会的意识形态基础。从1972年的联合赤军事件\u003csup id=\"fnref:12\"\u003e\u003ca href=\"#fn:12\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e12\u003c/a\u003e\u003c/sup\u003e开始，激进的左翼政治让位于非政治的消费享乐主义。这导致了围绕显著消费形式尤其是时尚的亚文化的繁荣。然而，对一些人来说，对更深层意义的渴望仍然存在，这最终催生了新时代的邪教，即奥姆真理教，它们同样从传统宗教和动漫中汲取力量来满足这种需求。\u003c/p\u003e\n\u003cp\u003e奥姆真理教的重要性在于他们既标志着传统信仰和意识形态的弱化，也标志着对任何被他们视为“他者”的事物的日益不容忍。他们还标志着一种对远在天边但又近在咫尺的敌对他者的偏执。例如，他们认为日本政府被全球犹太共济会阴谋控制，而他们自己的莲花团体则充满了双重间谍。他们在1995年对这个被认为是犹太人的他者的恐怖袭击，具有讽刺意味的是，传播了这种对奥姆真理教妖魔的偏执，这些妖魔潜伏在学校、企业甚至政府中。这种怪异他者的概念在“黑暗之魂”中得到了有力的表达，因为它向玩家展示了一个充满敌对个体和群体的世界——这些实体是玩家角色的他者——他们的目标和实践是难以理解的。这也通过一种系统得到了加强，即玩家始终连接到互联网，并且开放给其他玩家入侵。\u003c/p\u003e\n\u003cp\u003e东浩纪采纳了大泽的时代精神，并提出了一种“动物化”理论。他指出，由于后现代时代缺乏大叙事，人们失去了理想和抱负。\u003cstrong\u003e因此，他们退缩到一个以收集符号为中心的世界，这些符号被添加到一个巨大的符号数据库中并被重新利用\u003c/strong\u003e。 他的主要证据是，当今的御宅族不再对叙事感兴趣。相反，他们只是享受识别、重新混合和扩展数据库的组件。他的预测是，御宅族的活动——他们无休止地收集符号——是大文化的先锋，后续几代人将在自己的领域中变得越来越像御宅族。东浩纪所指出的这一流行文化趋势在“黑暗之魂”中体现为深深的模糊和稀疏的叙事。\u003c/p\u003e\n\u003cp\u003e那么“黑暗之魂”究竟如何通过游戏玩法表达后现代意识呢？我认为它通过为我们提供一个任务和一个王国来模拟传统的英雄之旅，但剥夺了我们理解这个任务意义的任何连贯方式。游戏提供了一个视觉细节丰富的世界，但完全缺乏具体的阐述，将玩家置于考古学家和法医科学家的角色中。然而，从未有任何可靠的解释；只有更多的线索和片段，有些是矛盾的。这被称为“环境叙事”，它创造了游戏与后现代思想之间最关键的接触点；即它对主叙事的拒绝。有“拯救王国”的建议，但仅仅是建议，主要是通过类型的惯例传达的，而不是叙事。你所做事情的意义及其服务的目的从未完全清楚。\u003c/p\u003e\n\u003cp\u003e重要的是要记住，虽然可以从传统的文学解释视角来解释“黑暗之魂”系列的叙事，但当试图将游戏机制解释为寓意时，会遇到许多实际和理论问题。出于这个原因，我在第二章中对当代游戏研究的批判理论进行了文献综述。利用Espen Aarseth\u003csup id=\"fnref:13\"\u003e\u003ca href=\"#fn:13\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e13\u003c/a\u003e\u003c/sup\u003e和其他奠定该领域基础的思想家的论点，我认为需要结合“第一人称”现象学方法和更传统的文学分析方法，才能正确评估视频游戏中潜在的潜在意义。这样做是为了建立一种分析方式，通过与游戏系统的斗争，让玩家体验到我上面概述的后现代意识的两个基本特征。我在第三章中将这种现象学方法付诸实践，探索了一种特别有效的文本叙事、环境叙事和游戏玩法的融合，捕捉到游戏作为一个统一体验的本质。\u003c/p\u003e\n\u003cp\u003e除了后现代主义，还有另一股影响游戏的力量，那就是佛教末法概念\u003csup id=\"fnref:14\"\u003e\u003ca href=\"#fn:14\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e14\u003c/a\u003e\u003c/sup\u003e。这两种影响力在有趣的方式上重叠，并产生了惊人的相似之处。末法在镰仓时代是一个极具影响力的概念，正如我们的时代一样，那是一个深刻的社会转型时期。末法指的是佛教教义失去其效力，人们无法再依靠自己的努力来获得启示。\u003cstrong\u003e随之而来的是僧侣和寺庙变得不可否认的腐败，人们因此无法离开轮回，被困在一系列日益退化的转世中\u003c/strong\u003e。我在第四章中分析了末法的哲学核心，并展示了它如何与大泽和东浩纪的后现代话语一致。此外，我认为，只要“黑暗之魂”系列表达了后现代意识，它主要是通过采用这个佛教末世论概念来表达的。\u003cstrong\u003e后现代思想和末法都表达了一种恐惧，即事情只会变得更糟，人类的努力无法改变结果\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e在第五章中，我回到现象学和文学分析的混合方法，展示末法概念以及佛教形而上学的混合如何作为构建游戏虚拟世界的核心要素，尽管游戏的美学显然源于中世纪的欧洲奇幻调色板。这些佛教元素共同揭示了游戏世界被困在一个日益退化的轮回中，玩家的任务基本上是一种徒劳的行为，只会推动这个痛苦的循环。我认为佛教形而上学的融合最终表达了东浩纪的结论，即后现代世界及其死去的叙事和怪异他者无可避免地导致社会整体的“动物化”。尽管“黑暗之魂”是一款美学显然源于中世纪欧洲奇幻风格的游戏，但它充满了末法的逻辑，因此游戏深受异教影响，通过采用和改造佛教形而上学，在阴暗的骑士在破败的城堡中冒险的表面下表达了一种后现代情感。\u003c/p\u003e\n\u003ch2 id=\"衰败叙事\"\u003e\u003cstrong\u003e衰败叙事\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e过去几十年，日本几乎成了停滞的代名词。这在很大程度上归因于日本在1970年代到1980年代经历的“奇迹”，以及他们令人震惊的衰落，自那以后，国家似乎一直处于无所事事的状态。在美国，当《纽约时报》或《华尔街日报》等出版物提到日本时，往往很少有积极的报道，而是集中在一小部分话题：人口老龄化，年轻人自杀；货币贬值，索尼、丰田和东芝等企业巨头被更精简的竞争对手击败；核燃料仍在福岛渗入地下水，但无人承担责任，等等，每一个预言都比前一个更严峻。在西方，日本作为一个正在衰败的帝国的叙述已经流传已久。这种衰败的印象如此强烈，似乎只有惯性才能维持一切运作，以至于人们忘记了日本仍然是世界上最富有、最富裕和技术最先进的国家之一，仍然领先于许多西欧国家。这种停滞的叙述也存在于日本。正如现任首相安倍晋三在2012年选举中的口号所示：“日本を取り戻す”（取回日本）。从谁那里取回？取回到哪里？凭借他的“安倍经济学”\u003csup id=\"fnref:15\"\u003e\u003ca href=\"#fn:15\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e15\u003c/a\u003e\u003c/sup\u003e议程中的“三支箭”，他将从日本自己的“萎缩心态”中拯救日本（Sharp）。\u003cstrong\u003e如果说1980年代的代表是那些狂热工作、渴望企业晋升的上班族，那么近年来这种原型被更为无力的角色所取代：草食男子\u003c/strong\u003e\u003csup id=\"fnref:16\"\u003e\u003ca href=\"#fn:16\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e16\u003c/a\u003e\u003c/sup\u003e\u003cstrong\u003e（sōshoku danshi）、尼特族\u003c/strong\u003e\u003csup id=\"fnref:17\"\u003e\u003ca href=\"#fn:17\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e17\u003c/a\u003e\u003c/sup\u003e\u003cstrong\u003e（NEET，指不在职或不在学的年轻人）、隐蔽青年\u003c/strong\u003e\u003csup id=\"fnref:18\"\u003e\u003ca href=\"#fn:18\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e18\u003c/a\u003e\u003c/sup\u003e\u003cstrong\u003e（hikikomori，指社会隐士）和其他贬损的称呼\u003c/strong\u003e。诚然，日本的经济和文化问题与其他任何国家一样真实存在，但这种叙述的力量已经超越了现实，成为一种独立的存在。\u003c/p\u003e\n\u003cp\u003e这种“萎缩”的心态和随之而来的文化表达，我将称之为后现代意识。这种意识必须与正统的后现代哲学区分开来，因为哲学本身只是对围绕日本的整体衰败叙述的众多情感反应之一。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e后现代意识的核心是一种源于对人类社会已经达到不可否认的衰退点的感知——无论是有意识还是无意识的——的焦虑\u003c/strong\u003e。鉴于上面概述的围绕日本经济和文化衰退的广泛文化讨论，后现代意识在日本文化心理中占据了中心地位。因此，这些源自后现代意识的停滞叙述在日本的流行媒体中也找到了强大而多样的表达。虽然有许多例子可以引用，但游戏《黑暗之魂》及其所有续集，是这种“萎缩”心态的卓越典范。要理解它如何以这种方式运作，我们不仅要看叙述，还要看《黑暗之魂》相对于同类游戏的存在。《黑暗之魂》属于一种被称为角色扮演游戏（RPG）的游戏类型。RPG通常是一个开放式的幻想世界模拟，玩家可以探索领土、收集宝物和击败怪物。通常，玩家创建一个角色——一个在游戏世界中的化身——并以此角色进行任务，其最终目标通常涉及拯救某物（王国、存在平面、公主等）免于毁灭。另一个RPG的基本特征是成长概念。尽管有许多设计模式和隐喻用于模拟成长过程，通常玩家的化身通过击败怪物获得经验值，并通过积累这些点数“升级”。通过升级过程，玩家解锁能力，他们的化身变得更强大。总的来说，RPG往往是许多文化神话中常见的英雄之旅模式的模拟：年轻、未成型的人必须离开家园的安全区域，面对未知的危险，克服它们，培养他们潜在的能力，并以强大和完全实现的人的身份返回，无论是字面上还是象征性地。\u003c/p\u003e\n\u003cp\u003e在其基本设计中，《黑暗之魂》作为RPG是相当传统的。然而，它有许多叙述和游戏设计选择，颠覆了这个几十年旧的类型的许多传统。作为一个叙述，它可以被解读为一种政治和文化的寓言，++直接反映了生活在一个意识形态叙述失去吸引力和连贯性的衰败文明中的经验++。它也是一种新兴新类型的前沿：后末日幻想。\u003cstrong\u003e在这款游戏中，王国被占领，英雄们都死了或堕落了，没有人可以拯救，而你存在的最大威胁是那些与你在废墟中一起生存的人\u003c/strong\u003e。社区是不可能的。基本的本体状态是无休止的失败，而“英雄”只是注定要忍受它。甚至死亡也不能免除角色的负担，而你被赋予的任务的意义和目标是模糊和不明确的。叙述几乎不存在。当游戏开始时，玩家被简单地放在一个被怪物和不死者占领的废弃王国中，没有明确的理由说明为何事情会如此，或者他们应该怎么做。仅有的叙述存在于零碎的文本中，只提供诱人但最终不完整或矛盾的关于世界的信息。所有这些叙述元素都对已建立的类型惯例提出了严重挑战，因此将其与衰退的讨论联系起来。\u003c/p\u003e\n\u003cp\u003e在游戏设计方面，《黑暗之魂》有两个突出的特点。第一个是游戏被有意设计得异常困难。这实际上是其吸引力的主要来源之一。该系列在西方的广告标语是“准备去死”（Prepare To Die），而在日本，该系列被认为是しにがみ（死亡之神）的主要例子，暗示玩家在与远比玩家创建的化身强大的巨大、恐怖的怪物斗争时必然会经历无数次死亡。另一个特点是，尽管游戏主要设计为单人体验——也是RPG类型的一个既定惯例——玩家始终连接到互联网。这被视频游戏评论家广泛赞誉为该类型的重要创新。在实践中，这创造了一种紧张的局势，玩家总是暴露在其他玩家的“入侵”之中，这些玩家会试图杀死该玩家。这种互动中内置了一个复杂的风险/回报系统，入侵者通过杀死其他玩家可以获得很多，但如果失败则会失去很多。\u003c/p\u003e\n\u003cp\u003e实际上，始终连接到互联网使得游戏世界充满了偏执和危险。其他玩家是玩家在游戏中可能面对的最危险和不可预测的怪物。入侵玩家经常会潜伏在一个不合适的时机突然袭击，玩家无法自卫，从而逆转他们不幸的受害者辛苦获得的进展。我们将详细探讨叙述和游戏系统，但这一系列游戏的基本概况引出了一个问题：在一个没有希望拯救王国，并且异常困难常常到不公平地步的游戏中，怎么会有如此大的吸引力？但事实上，这款游戏在日本、欧洲和北美都极具吸引力。\u003cstrong\u003e这也指出了游戏的设计和叙述如何与在无聊时代生活的年轻一代的经验产生共鸣\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e日本文化领域的停滞叙述需要进一步澄清。我认为《黑暗之魂》可以被解读为对当代日本状况的政治和文化寓言。这是一种后现代的英雄之旅的颠倒：一种被污染的神话碎片的模拟。\u003cstrong\u003e它直接反映了许多年轻日本人今天试图在庞大、失修的机构中航行时所经历的无聊和徒劳的感觉，这些机构至多对他们的存在漠不关心，至多直接敌对。然而，这种寓言不仅仅是关于生活在1980年代“奇迹”之后的经济问题。它同样涉及生活在一个国家、政治和文化叙述已经失去了大部分意义和连贯性的社会中的社会和心理成本，这些叙述曾经作为一种心理基石——为个人和社区身份提供稳定\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e催化这一恶化的事件起源于1995年，那一年发生了神户地震和沙林毒气袭击。在西方媒体中，关于这些事件的文化或政治意义的讨论通常不多，但在许多日本知识分子中，这些事件似乎标志着现代性的决定性破裂。在著名小说家村上春树的书《地下：东京毒气袭击和日本心理》中，对沙林毒气袭击幸存者的一系列采访，并得出结论，这一事件的后果不可逆转地揭示了日本社会的所有矛盾、缺陷和内在不稳定性：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“神户地震和1995年1月和3月的东京毒气袭击是日本战后历史上两起最严重的悲剧。毫不夸张地说，这些事件前后的日本意识发生了显著变化。这两次灾难将作为我们生活中的两个里程碑，永远铭刻在我们的心灵中。如此灾难性的事件接连发生是令人震惊的，也是巧合的。然而，当日本的“泡沫经济”破裂，标志着那些泛滥成灾的时代结束时，这些事件带来了对日本国家根本根源的批判性审视。就像这些事件一直在等待伏击我们。两者共有的是压倒性的暴力元素：\u003cstrong\u003e一个是不可避免的自然灾难，另一个是可以避免的人为灾难。\u003c/strong\u003e”（村上，237页）\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e通过村上等许多知识分子的工作，1995年已成为一个单一且不可改变的地位：\u003cstrong\u003e通往破碎和功能失调时代的门户\u003c/strong\u003e。这里分析的主要理论家——东浩纪、大泽真幸和田中基子——都\u003cstrong\u003e将1995年视为进入反乌托邦现状的起点\u003c/strong\u003e。这些思想家的语调本身就有一种微妙的后末日色彩，仿佛我们生活在一个无法拯救的被污染时代。这也是衰败讨论的一部分。这些思想家有一种确定的末世论信念，将他们与这一讨论联系起来。\u003c/p\u003e\n\u003cp\u003e无论如何，这些灾难比任何经济灾难都更可能是现任首相希望根除的“萎缩”心态的原因。尽管已经过去几十年，1995年的事件作为焦虑和无助感的触发点，在《黑暗之魂》的寓言中找到了源头。经济的持续低迷、老龄化人口、年轻一代的就业前景减少以及福岛等灾难，只是加剧了这些灾难在1995年最初引发的负面情绪。福岛等事件只帮助在日本意识中创造了一种遗产。近年来，右翼极端民族主义政治的重新出现和尼特族及隐蔽青年的社会退缩，形成了对这一相同的文化病态的极端和相反的情感反应。右翼试图通过与其真实和感知的对手（韩国、中国、朝鲜）进行公开的对抗来复兴“大和”帝国的活力，试图通过历史修正主义抹去日本帝国的暴力和道德可憎之处，并试图通过修改宪法（第9条）恢复战争作为国家主权权利。而尼特族和隐蔽青年则将自己沉溺于网络和其他形式的私人数字享乐中。他们没有叙述可供复兴，没有事业可供加入，甚至没有可以参与的兴趣小组。\u003cstrong\u003e与他人沟通实在是太困难了，在他们看来，也太危险了。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我的观点不是《黑暗之魂》系列是这些问题的根源，甚至不是它们的贡献，而是它是对在公众意识中循环的深层社会焦虑，特别是对视频游戏作为熟悉媒介的年轻一代的一种特别有力的表达。《黑暗之魂》系列的持续流行，作为一种社会腐化的象征，反映了人们在日常生活中的感觉。但这些焦虑到底是什么，它们如何在《黑暗之魂》中表现出来？另一种问这个问题的方法是，后现代意识的基本要素是什么？定义1995年后时代的有两个主要元素。\u003cstrong\u003e1. 对构建战后秩序的政治和社会叙述的拒绝；2. 一种对他者的弥漫性焦虑，侵蚀了对社会过程的信任和信心\u003c/strong\u003e。他者的概念是指自我与世界上遇到的所有其他自我之间的二元关系的一半。这一概念的延伸是文化他者，即一种感觉某些人与自己相似，另一些人则是异类。日本社会通常被认为具有非常同质的国家认同感，彼此之间有相同的文化、种族和相似的价值观。这反过来又创造了强烈的信任和社区感，但这种亲近的逆向效应是，外来者被认为比在美国、英国或法国等文化多样性更大的国家中更为陌生。大泽真幸的论点是，奥姆真理教的恐怖活动将潜在威胁引入了公众。这种恐惧是一种诡异的他者的恐惧，这种他者会突然出现，以一种深刻的方式扰乱你的生活，有时甚至是致命的。社会结构中的这种破裂从未真正修复，并继续受到挑战，直到现在。关于诡异他者的偏执是定义《黑暗之魂》的氛围和叙述的主要特征之一，也是其游戏机制，尤其是其在线组件。\u003c/p\u003e\n\u003cp\u003e要理解《黑暗之魂》如何作为一种描述后现代意识的寓言运作，我们必须追踪战后日本社会状况的衰退轨迹。\u003cstrong\u003e这根本上是一个现代进步叙述——本质上是从西方继承的——首先在1960年代末引发了激烈的意识形态斗争，然后在1980年代变成一种无政治的享乐主义，最后，最终在五个正义的宗教狂热者用雨伞尖端戳破装满沙林毒气的袋子的时刻，被一种微妙的虚无主义彻底摧毁\u003c/strong\u003e。为此，我们将研究社会学家大泽真幸的工作。大泽花费了相当多的职业生涯试图回答奥姆为什么会做他们所做的事情。\u003cstrong\u003e在他的书《虚构时代的终结》中，他认为答案涉及意识形态本身的致命缺陷：一种危险而空洞的思维模式，导致在一个自我设计的世界中越来越高的疏离感。\u003c/strong\u003e\u003c/p\u003e\n\u003ch2 id=\"理性时代\"\u003e理性时代\u003c/h2\u003e\n\u003cp\u003e借用社会学家見田宗介\u003csup id=\"fnref:19\"\u003e\u003ca href=\"#fn:19\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e19\u003c/a\u003e\u003c/sup\u003e（Mita Munesuke）的观点，大泽真幸将战后时代分为两个不同的阶段。第一个阶段他称为“理想的时代（理想の時代，risō no jidai）”，第二个阶段他称为“虚构的时代（虚構の時代，kyokō no jidai）”。理想的时代始于20世纪60年代，结束于1972年，虚构的时代从1972年开始，一直持续到1995年。大泽将“理想”和“虚构”描述为“可能世界（可能の世界 kanōsei no sekai）”，因为它们都反映了我们对世界的感知以及我们认为世界应该如何。然而，尽管这两个概念在根本层面上是相关的，但它们在几个重要方面是不同的。\u003cstrong\u003e大泽认为，理想与现实世界密切相关，而虚构则完全脱离现实世界\u003c/strong\u003e：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e理想是一个在未来有望或期待在现实中实现的可能世界。因此，理想必须存在于现实的因果延伸之上。从这个意义上讲，理想不是一个纯粹的可能世界，而是广义现实世界的一个方面。相反，虚构是一个可以在现实中实现与否无关的可能世界，因此是纯粹的反现实。（大泽，41页）\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e理想は、未来において現実に着地することが予期（期待）されているような可能世界である。だから、理想は、現実の因果的な延長上になくてならない。その意味では、理想は、純粋な可能世界ではなく、むしろ広義の現実世界の一局面である。それにたいして、虚構は現実への着地ということについてさしあたって無関連ありうる可能世界であり、それゆえ純粋な反現実である。(Osawa, 41)\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e暂且不讨论虚构如何将我们与现实疏离，日本的理想时代很大程度上受到冷战阴影的笼罩。当亚洲大部分地区处于苏联的保护伞下时，日本则在美国的庇护下，因而在意识形态上致力于民主和经济自由主义。在20世纪60年代，日本在这些条件下几乎在各个方面都得到了繁荣：科学、基础设施、经济、文化等。大泽将20世纪60年代称为理想的黄金时代，并指出家用电器是赋予大众理想的物质形式：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e理想时代在大众层面的黄金期是20世纪60年代。当然，这与日本的高速增长期相吻合。在此期间，例如，受到国民绝大多数人广泛需求的家电产品赋予了大众理想物质的表达……经济增长和科学技术的进步并不是因为理想而被接受的，相反，正因为理想作为可能的现实在广泛（全球范围内）被信奉，经济才能够增长，科学和技术才能进步。（大泽，44页）\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e理想の時代の、大衆的な水準で黄金期は、1960年代である。もちろん、これは、高度成長期にあたる。この時期、たとえば、国民の圧倒的な大多数によって広範に欲求された家電製品が、大衆的理想に物質的な表現を与えた\u0026hellip;経済成長や科学・技術の進歩があったから理想が抱かれたのではなく、逆に、理想が可能的現実として広く（世界規模で）信憑されたがゆえに、経済が成長することができ、また科学や技術進歩していると感受されたのである。(Osawa, 44)\u003c/strong\u003e\u003c/p\u003e","title":"翻译｜向下螺旋：《黑暗之魂》系列游戏中的后现代意识与佛教形而上学"},{"content":"AI 新闻 Llama3.1 发布 博客文章： https://ai.meta.com/blog/meta-llama-3-1/\n技术报告：https://ai.meta.com/research/publications/the-llama-3-herd-of-models/\n405B，70B，和8B3个版本 在个别指标上，405B超过了GPT-4o Mistral Large 2 https://mistral.ai/news/mistral-large-2407/\n卷起来了\nOpenAI 发布 GPT-4o mini 更低的API价格，并取代chatGPT中的GPT-3.5 Turbo，成为免费使用的模型\nSAM-2 发布 https://ai.meta.com/blog/segment-anything-2/\nGitHub：https://github.com/facebookresearch/segment-anything-2?tab=readme-ov-file\n与SAM相比， 同时支持视频和图像的分割，更强大的能力\n快手可灵更新 https://klingai.kuaishou.com/\n值得关注的开源项目 knowledge_graph_maker 采用LLM生成knowledge graph\nGitHub： https://github.com/rahulnyk/knowledge_graph_maker\nQwen2-Audio 接受各种音频信号输入，并根据语音指令执行音频分析或直接响应文本\nGitHub: github.com/QwenLM/Qwen2-Audio\nLLM Twin Course An End-to-End Framework for Production-Ready LLM \u0026amp; RAG Systems by Building Your LLM Twin\nGithub：github.com/decodingml/llm-twin-course\nDocker-Proxy 自建Docker镜像加速服务，基于官方Docker Registry 一键部署Docker、K8s、Quay、Ghcr、Mcr等镜像加速\\管理服务。支持部署到Render\\Koyeb\nGitHub: github.com/dqzboy/Docker-Proxy\nMediaGo 支持流媒体下载、视频下载、m3u8 文件下载以及 B 站视频下载\nGitHub：github.com/caorushizi/mediago\nPPTX2MD a pptx to markdown converter\nGitHub: https://github.com/ssine/pptx2md\ngptpdf Using VLLM (like GPT-4o) to parse PDF into markdown.\nGitHub: https://sgithub.com/CosmosShadow/gptpdf\n我的足迹 去了趟WAIC-2024\n全场唯一能够看得上的Agent应用（可实际上手体验的），给亚马逊点个赞；亮点：通过RAG作为agent工作记忆，以实现正向迭代优化。\n明年不想去了；\n一些思考点：\n行业似乎处于一种降温的态势，大家和去年相比， 更加理性也务实了，但同质化也很严重； RAG以及所谓垂域“大模型”应用的难点仍然在数据源头上：如何避免garbage in garbage out 的窘境，这目前仍没有太好的方案； 各行各业都需要一些效率提升工具， AI是值得做的，但远没有到取代人这一步，用论坛上的句话说叫：“外行觉得（AI）内行，内行觉得（AI）外行”； AI时代对于下一代，或者是新人的培养是个问题， 答案对他们来说来的太快太轻松，以至于对他们的思维方式的培养和判断能力的提升是有害的； 整理了一些感兴趣的论坛， 用wishper + LLM三段式润色后， 把代码和文稿开源在了：WAIC-Media-Intelligence\n影音记录 精选歌单 Live演出 07.23 Tues. The Yusssef Dayes 万代南梦宫\n书\u0026amp;阅读摘录 本月完成： 《如何避免孤独终老》\nThe GraphRAG Manifesto: Adding Knowledge to GenAI https://neo4j.com/blog/graphrag-manifesto/\n使用 GraphRAG 的一种常见模式如下：\n进行向量或关键字搜索以找到初始节点集。 遍历图谱以获取相关节点的信息。 可选地，使用基于图的排序算法（如 PageRank）对文档进行重新排序。 与仅使用向量的 RAG 相比，GraphRAG 主要有三个方面的优势：\n更高的准确性和更完整的答案（运行时/生产 受益） 创建知识图后，构建和维护 RAG 应用程序更加容易（开发时间 受益） 提供更好的可解释性、可追溯性和访问控制（治理 受益） 你需要的不是智能体，而是一个适合 AI 的工作流 https://baoyu.io/blog/ai/you-dont-need-agent-but-ai-suitable-workflow\n不要将 AI 的解决方案局限在人类现有的解决方案上 不必完全依赖 AI 做决策，而是让 AI 辅助做决策或者做简单的决策 回归问题本质，AI 只是解决问题的工具\nYC 创业者的必读袖珍指南（中英文对照） https://x.com/HiTw93/status/1814985639240307141\nLaunch now - 立即启动 Build something people want - 打造人们需要的东西 Do things that don\u0026rsquo;t scale - 做一些无法扩展的事情 Find the 90 / 10 solution - 找到90%问题与10%解决方案的平衡 Find 10-100 customers who love your product - 找到10到100个热爱你产品的客户 All startups are badly broken at some point - 所有初创公司在某个时刻都会遇到严重问题 Write code - talk to users - 编写代码 - 与用户交流 \u0026ldquo;It’s not your money\u0026rdquo; - “这不是你的钱” Growth is the result of a great product not the precursor - 成长是优秀产品的自然结果，而非先决条件 Don’t scale your team/product until you have built something people want - 在你打造出人们需要的东西之前，不要扩展你的团队或产品 Valuation is not equal to success or even probability of success - 估值不等于成功，甚至不等于成功的可能性 Avoid long negotiated deals with big customers if you can - 如果可以的话，避免与大客户进行长时间的谈判 Avoid big company corporate development queries - they will only waste time - 避免与大公司进行企业开发咨询 - 他们只会浪费时间 Avoid conferences unless they are the best way to get customers - 除非参加展会是获取客户的最佳方式，否则避免参加 Pre-product market fit - do things that don’t scale: remain small/nimble - 在产品市场契合之前 - 做一些无法扩展的事情：保持小规模和灵活性 Startups can only solve one problem well at any given time - 初创公司在任何时候只能很好地解决一个问题 Founder relationships matter more than you think - 创始人之间的关系比你想象的更重要 Sometimes you need to fire your customers (they might be killing you) - 有时你需要“开除”你的客户（他们可能会毁了你） Ignore your competitors, you will more likely die of suicide than murder - 忽略你的竞争对手，你更可能死于自杀而非他杀 Most companies don\u0026rsquo;t die because they run out of money - 大多数公司并非因为资金耗尽而倒闭 Be nice! Or at least don’t be a jerk - 要友好！或者至少不要成为一个混蛋 Get sleep and exercise - take care of yourself - 睡觉和锻炼 - 照顾好自己 揭秘DeepSeek:一个更极致的中国技术理想主义故事 https://mp.weixin.qq.com/s/r9zZaEgqAa_lml_fOEZmjg\n而另一方面，国产大模型之前很少涉足架构层面的创新，也是因为很少有人主动去击破那样一种成见：美国更擅长从0-1的技术创新，而中国更擅长从1-10的应用创新。\n我们已经习惯摩尔定律从天而降，躺在家里18个月就会出来更好的硬件和软件。Scaling Law也在被如此对待。\n「暗涌」：听说DeepSeek对于卡和人的调集非常灵活。\n梁文锋：我们每个人对于卡和人的调动是不设上限的。如果有想法，每个人随时可以调用训练集群的卡无需审批。同时因为不存在层级和跨部门，也可以灵活调用所有人，只要对方也有兴趣。\n「暗涌」：一种松散的管理方式也取决于你们筛选到了一批强热爱驱动的人。听说你们很擅长从细节招人， 可以让一些非传统评价指标里优秀的人被选出来。\n梁文锋：我们选人的标准一直都是热爱和好奇心，所以很多人会有一些奇特的经历，很有意思。很多人对做研究的渴望，远超对钱的在意。\n翻译|工作自动化对政治行为的影响 https://mp.weixin.qq.com/s/Il3GrwbdVczK-ACwbyE4LA\n常规工人（routine workers）是最近技术变革的主要输家，并且倾向于支持民粹主义政党\n这些研究有一个共同发现——那些因技术变革而在经济上失利的人，通常会对政治现状产生反感，特别是向着民粹主义激进右翼倾斜。 技术变革还创造了一个不那么引人注目、但数量更多且在政治上高度相关的技术受益者群体。\n","permalink":"https://niraya666.github.io/monthly/2024-07/","summary":"\u003ch1 id=\"ai-新闻\"\u003eAI 新闻\u003c/h1\u003e\n\u003ch3 id=\"llama31-发布\"\u003eLlama3.1 发布\u003c/h3\u003e\n\u003cp\u003e博客文章： \u003ca href=\"https://ai.meta.com/blog/meta-llama-3-1/\"\u003ehttps://ai.meta.com/blog/meta-llama-3-1/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e技术报告：\u003ca href=\"https://ai.meta.com/research/publications/the-llama-3-herd-of-models/\"\u003ehttps://ai.meta.com/research/publications/the-llama-3-herd-of-models/\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e405B，70B，和8B3个版本\u003c/li\u003e\n\u003cli\u003e在个别指标上，405B超过了GPT-4o\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://scontent-msp1-1.xx.fbcdn.net/v/t39.2365-6/451735590_1030734788570365_1093008500142144333_n.png?_nc_cat=100\u0026amp;ccb=1-7\u0026amp;_nc_sid=e280be\u0026amp;_nc_ohc=CJNPYAljD8MQ7kNvgE9-8ZQ\u0026amp;_nc_ht=scontent-msp1-1.xx\u0026amp;oh=00_AYAOhN3NhE0dscHn8iazBrc3JmSU5XM9gJ6gjmkqOuUZ3w\u0026amp;oe=66C00DBE\" alt=\"https://scontent-msp1-1.xx.fbcdn.net/v/t39.2365-6/451735590_1030734788570365_1093008500142144333_n.png?_nc_cat=100\u0026amp;ccb=1-7\u0026amp;_nc_sid=e280be\u0026amp;_nc_ohc=CJNPYAljD8MQ7kNvgE9-8ZQ\u0026amp;_nc_ht=scontent-msp1-1.xx\u0026amp;oh=00_AYAOhN3NhE0dscHn8iazBrc3JmSU5XM9gJ6gjmkqOuUZ3w\u0026amp;oe=66C00DBE\"  /\u003e\n\u003c/p\u003e\n\u003ch3 id=\"mistral-large-2\"\u003eMistral Large 2\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://mistral.ai/news/mistral-large-2407/\"\u003ehttps://mistral.ai/news/mistral-large-2407/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-multiple.png\" alt=\"https://mistral.ai/images/news/mistral-large-2407/mistral-large-2407-multiple.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e卷起来了\u003c/p\u003e\n\u003ch3 id=\"openai-发布-gpt-4o-mini\"\u003eOpenAI 发布 GPT-4o mini\u003c/h3\u003e\n\u003cp\u003e更低的API价格，并取代chatGPT中的GPT-3.5 Turbo，成为免费使用的模型\u003c/p\u003e\n\u003ch3 id=\"sam-2-发布\"\u003eSAM-2 发布\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://ai.meta.com/blog/segment-anything-2/\"\u003ehttps://ai.meta.com/blog/segment-anything-2/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eGitHub：\u003ca href=\"https://github.com/facebookresearch/segment-anything-2?tab=readme-ov-file\"\u003ehttps://github.com/facebookresearch/segment-anything-2?tab=readme-ov-file\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e与SAM相比， 同时支持视频和图像的分割，更强大的能力\u003c/p\u003e\n\u003ch3 id=\"快手可灵更新\"\u003e快手可灵更新\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://klingai.kuaishou.com/\"\u003ehttps://klingai.kuaishou.com/\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003ch3 id=\"knowledge_graph_maker\"\u003eknowledge_graph_maker\u003c/h3\u003e\n\u003cp\u003e采用LLM生成knowledge graph\u003c/p\u003e\n\u003cp\u003eGitHub： \u003ca href=\"https://github.com/rahulnyk/knowledge_graph_maker\"\u003ehttps://github.com/rahulnyk/knowledge_graph_maker\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"qwen2-audio\"\u003eQwen2-Audio\u003c/h3\u003e\n\u003cp\u003e接受各种音频信号输入，并根据语音指令执行音频分析或直接响应文本\u003c/p\u003e\n\u003cp\u003eGitHub: \u003ca href=\"http://github.com/QwenLM/Qwen2-Audio\"\u003egithub.com/QwenLM/Qwen2-Audio\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"llm-twin-course\"\u003e\u003cstrong\u003eLLM Twin Course\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eAn End-to-End Framework for Production-Ready LLM \u0026amp; RAG Systems by Building Your LLM Twin\u003c/p\u003e\n\u003cp\u003eGithub：\u003ca href=\"http://github.com/decodingml/llm-twin-course\"\u003egithub.com/decodingml/llm-twin-course\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"docker-proxy\"\u003eDocker-Proxy\u003c/h3\u003e\n\u003cp\u003e自建Docker镜像加速服务，基于官方Docker Registry 一键部署Docker、K8s、Quay、Ghcr、Mcr等镜像加速\\管理服务。支持部署到Render\\Koyeb\u003c/p\u003e\n\u003cp\u003eGitHub: \u003ca href=\"http://github.com/dqzboy/Docker-Proxy\"\u003egithub.com/dqzboy/Docker-Proxy\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"mediago\"\u003eMediaGo\u003c/h3\u003e\n\u003cp\u003e支持流媒体下载、视频下载、m3u8 文件下载以及 B 站视频下载\u003c/p\u003e\n\u003cp\u003eGitHub：\u003ca href=\"https://github.com/caorushizi/mediago\"\u003egithub.com/caorushizi/mediago\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"pptx2md\"\u003e\u003cstrong\u003ePPTX2MD\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003ea pptx to markdown converter\u003c/p\u003e","title":"2024-07 月刊"},{"content":" If you want to make a good RAG tool that uses your documentation, you should start by making a search engine over those documents that would be good enough for a human to use themselves. This is likely something your organization has considered before, and if it doesn’t exist it’s because building a good search engine has traditionally been a significant undertaking.\n— from Build a search engine, not a vector DB\n一个优秀的RAG背后， 一定有一个优秀的搜索引擎；\n很多时候，在针对通用场景下， 如果能够调用常见的搜索引擎，如google 或者bing， RAG的效果一般不会太差；\n但，当考虑到一些垂直场景， 我们需要构造属于自己的“搜索引擎”，而往往根据特定的场景，在索引构建上会有特殊处理；可以参考devv，在针对代码场景下， 对RAG的检索部份也做了不少的工作和设计；\n很显然， 检索不是仅仅使用向量匹配和向量库就能搞定的事情；\n考虑到前LLM时代的NLP检索（甚至是图像检索），或者是推荐系统， 其实会发现， 这些东西并没有什么太大的变化，思路和技术依旧是可以复用的。\nvector-search is not all you need 纯粹基于向量匹配实现起来很简单，但不是万能的\n其问题来源有：\nembedding模型一般在通用预料上做训练， 在特定领域下， 其效果并不会太好，很多时候需要在特定领域语料上再做微调；\n语义匹配不见得是万能的，对于一些特定场景，其局限性尤为明显。例如，当用户询问一个具体的名词时，就会发现单纯使用向量匹配只能匹配到大致的相似度，对于具体的关键词是无能为力的。 这种情况下，语义匹配往往难以捕捉到用户提问中的精确细节。例如，用户可能询问特定型号的苹果电脑（如“MacBook Pro 2021”），但语义匹配算法可能会返回类似类型或年份的苹果电脑，而不是确切的型号。此时语义匹配的效果并不会太好。\nembedding模型计算的是输入的两个文本（A和B）的相似度。然而，在实际应用中，输入的是一个问句（query），需要匹配的是一段文字。在这种情况下，我们关注的重点是文本之间的相关性而非简单的相似性。因此，通常在使用embedding模型后，还需要一个reranking模型，根据相关性对结果进行排序，以确保返回最相关的答案。\n对于组合的问题无效；如果query是一些复杂的需要一些推理的问题（如多跳），使用vector- search显然不是好办法；这类问题通常涉及多个子问题，每个子问题的答案都是解答下一个问题的基础， 举例来说，回答“谁是发明电话的人的孙子在2020年的职业是什么？”需要知道发明电话的人是谁，接着找出他的孙子，然后查询这个孙子的职业。面对需要多步推理的复杂问题时，向量搜索的能力有限，原因在于它不可能进行复杂的逻辑推理和多步信息整合。在这样的场景下，需要的是Agent将query进行分解，然后分别调用工具（搜索引擎）；\n其实我们可能过于迷信向量搜索。事实上，对于一些简单的场景，基于倒排索引的关键词匹配效果更好、更加简单且成本更低。倒排索引是一种高效的文本检索方法，通过建立关键词到文档的映射，可以快速找到包含特定关键词的文档。对于不需要复杂推理的简单查询，倒排索引可以提供快速且准确的搜索结果。\n不止只有向量检索 稀疏向量（Sparse）和稠密向量（Dense）是通过不同的算法计算的。稀疏向量主要由零值组成，只有少数几个非零值，而稠密向量则主要包含非零值。稀疏嵌入由算法如BM25和SPLADE生成，而稠密嵌入则由机器学习模型如GloVe和Transformers生成。\nTF-IDF(Term-Frequency Inverse-Document Frequency)是一种用于评估文本中一个词对一个文档的重要程度的统计方法。其原理基于两个指标：词频（TF）和逆文档频率（IDF）。\n词频（TF）：表示某个词在文档中出现的频率，计算公式为：\n$$ \\text{TF}(t,d) = \\frac{\\text{词t在文档d中出现的次数}}{\\text{文档d中的总词数}} $$\n逆文档频率（IDF）：衡量某词在整个文档集合中重要性的指标。公式为：\n$$ \\text{IDF}(t) = \\log\\left(\\frac{\\text{总文档数}}{\\text{包含词t的文档数} + 1}\\right) $$\nTF-IDF值通过将词频和逆文档频率相乘计算得到：\n$$ \\text{TF-IDF}(t,d) = \\text{TF}(t,d) \\times \\text{IDF}(t) $$\nBM25（Best Matching 25）是一种基于概率模型的文本检索算法，它在TF-IDF（词频-逆文档频率）的基础上进行改进。BM25通过引入二元独立模型，并添加归一化惩罚来计算文档长度相对于数据库中所有文档平均长度的权重。\nBM25的核心公式如下：\n$$ \\text{BM25}(q, D) = \\sum_{i=1}^{n} \\text{IDF}(q_i) \\cdot \\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}})} $$\n其中：\nq 代表查询\nD 代表文档\n$q_i$ 是查询中的第i个词\n$f(q_i, D)$ 是词 ($q_i$) 在文档 (D) 中的词频\n|D| 是文档 (D) 的长度（以词计）\n$\\text{avgdl}$ 是集合中所有文档的平均长度\n$k_1$ 和 b 是调节参数，通常 $k_1$ 在1.2到2之间，b 取0.75\n$\\text{IDF}(q_i)$是词 $q_i$ 的逆文档频率\nDense vector 使用稠密向量表示存储在数据库中的信息，包括文本、图像和其他类型的数据，。这些嵌入由机器学习模型生成，将数据转换为向量。也就是最近两年大家常说的向量检索。\n如何提升检索效果：\n自然而然的想法，不再使用单一的向量检索， 而是采用多种检索方式混合的方式，不论是混合不同的embedding模型的检索还是Sparse-vector和Dense-vector混合使用以获得二者的优势。通常来说，稠密向量擅长理解查询的上下文，而稀疏向量则擅长关键词匹配。\n那么需要将二者合并，but how？\nReciprocal Rank Fusion (RRF) 其核心思想是通过计算每个文档在不同排名列表中的倒数排名之和来确定最终排名。这样，排名较高的文档会得到更高的分数，而排名较低的文档会受到惩罚。\nRRF的计算公式如下：\n$$ \\text{RRF}(d) = \\sum{i=1}^{N} \\frac{1}{k + r_{i}(d)} $$\n其中：\n(d) 代表文档\n(N) 是排名列表的数量\n(k) 是一个常数，用于平滑处理，通常取值为60\n($r_{i}(d)$) 是文档 (d) 在第 (i) 个排名列表中的排名\n通过这个公式，每个文档的最终RRF分数是其在所有排名列表中的倒数排名之和，分数越高，排名越靠前。\n在langchain **ensemble-retriever**的源码中可以看到其具体的思想逻辑：\ndef weighted_reciprocal_rank( self, doc_lists: List[List[Document]] ) -\u0026gt; List[Document]: \u0026#34;\u0026#34;\u0026#34; Perform weighted Reciprocal Rank Fusion on multiple rank lists. You can find more details about RRF here: https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf Args: doc_lists: A list of rank lists, where each rank list contains unique items. Returns: list: The final aggregated list of items sorted by their weighted RRF scores in descending order. \u0026#34;\u0026#34;\u0026#34; if len(doc_lists) != len(self.weights): raise ValueError( \u0026#34;Number of rank lists must be equal to the number of weights.\u0026#34; ) # Associate each doc\u0026#39;s content with its RRF score for later sorting by it # Duplicated contents across retrievers are collapsed \u0026amp; scored cumulatively rrf_score: Dict[str, float] = defaultdict(float) for doc_list, weight in zip(doc_lists, self.weights): for rank, doc in enumerate(doc_list, start=1): rrf_score[ doc.page_content if self.id_key is None else doc.metadata[self.id_key] ] += weight / (rank + self.c) # Docs are deduplicated by their contents then sorted by their scores all_docs = chain.from_iterable(doc_lists) sorted_docs = sorted( unique_by_key( all_docs, lambda doc: doc.page_content if self.id_key is None else doc.metadata[self.id_key], ), reverse=True, key=lambda doc: rrf_score[ doc.page_content if self.id_key is None else doc.metadata[self.id_key] ], ) return sorted_docs 排序模型 在信息检索和问答系统中，处理用户查询通常分为两个步骤：召回（retrieval）和重排序（reranking）。\n召回的目标是用非常短的时间在海量数据中找到一定范围的备选项。这一过程的精度可能不会特别高，但可以将候选项从千万量级压缩到百量级。（这一过程涉及ANN也就是Approximate Nearest Neighbor， 在本文的后段会提及）\n重排序阶段，需要从召回阶段的备选项中选择符合需要的选项。由于候选项数量已经大幅减少，可以采用精度较高但相对计算时间较长的算法对这些备选项进行重新排序，以提高最终结果的准确性。\n重排序阶段场景的模型如`BAAI/bge 系列，从其huggingface仓库中的config.json可以发现：\n\u0026#34;_name_or_path\u0026#34;: \u0026#34;BAAI/bge-m3\u0026#34;, \u0026#34;architectures\u0026#34;: [ \u0026#34;XLMRobertaForSequenceClassification\u0026#34; ], 其本质是基于**XLM-RoBERTa**的序列分类模型。在下游任务中，对于序列分类任务，XLMRobertaForSequenceClassification 在 XLM-RoBERTa 的基础上添加了一个分类层（一个全连接层）来进行分类；简单来说，对于信息检索或问答系统中，输入用户问题（query），和匹配到的doc，通过合并query和doc形成一个sequence（[CLS]query[SEP]doc[SEP]），通过XLMRobertaForSequenceClassification 可以计算出二者的相关性分数，遍历候选集中的doc（一般在百数量级左右），即可得到query同候选集相关性分数。\n一些新的工作 Matryoshka Representation Learning（MRL） 来源于OpenAI 的embedding 技术：New embedding models and API updates\n和NeurIPS 2022发表的论文：Matryoshka Representation Learning\nMotivation：现有的深度学习模型通常学习固定维度的表示，无法灵活适应任务需求；表示维度的难以确定；表示维度缺乏粗到细（coarse-to-fine）的粒度；\nMRL旨在学习具有不同粒度的表示，允许单个embedding适应下游任务的计算约束。其设计思想是为了在不同的embedding维度上使用损失函数，从而训练一个模型，使其在不同的embedding维度上都能保持良好的性能\n训练过程：MRL 在多个嵌套的维度上训练模型，使得每个低维度的表示都能作为数据点的有用表示。这样，模型在不同的任务和计算约束下都能表现良好。\n推理过程：在推理过程中，MRL 可以根据需要使用不同维度的嵌入。对于分类任务，可以从低维度开始，逐步使用更高维度的表示。对于检索任务，可以先使用低维度表示进行初步筛选，然后使用高维度表示进行精细排序。\n（具体可以参考论文和sentence_transformers中所实现的MatryoshkaLoss）\nbge-m3 paper\ngithub\nm3—即Multi-Linguality 支持多语言， Multi-Functionality 支持多种检索方式（Dense-retrieval，Sparse-Retrieval， Multi-Vec Retrieval），以及Multi-Granularity 支持多粒度的检索（sentence-level，Passage-level，和Doc-level）\npip install -U FlagEmbedding Dense Embedding from FlagEmbedding import BGEM3FlagModel model = BGEM3FlagModel(\u0026#39;BAAI/bge-m3\u0026#39;, use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation sentences_1 = [\u0026#34;What is BGE M3?\u0026#34;, \u0026#34;Defination of BM25\u0026#34;] model.encode(sentences_1) print(model.encode(sentences_1)[\u0026#39;dense_vecs\u0026#39;].shape) # (2, 1024) Sparse Embedding (Lexical Weight) output_1 = model.encode(sentences_1, return_dense=True, return_sparse=True, return_colbert_vecs=False) output_1 \u0026#34;\u0026#34;\u0026#34; {\u0026#39;dense_vecs\u0026#39;: array([[-0.03412 , -0.04706 , -0.0009317, ..., 0.0483 , 0.007576 , -0.02959 ], [-0.01026 , -0.0449 , -0.02432 , ..., -0.00828 , 0.01502 , 0.011086 ]], dtype=float16), \u0026#39;lexical_weights\u0026#39;: [defaultdict(int, {\u0026#39;4865\u0026#39;: 0.0836, \u0026#39;83\u0026#39;: 0.0814, \u0026#39;335\u0026#39;: 0.1295, \u0026#39;11679\u0026#39;: 0.252, \u0026#39;276\u0026#39;: 0.17, \u0026#39;363\u0026#39;: 0.2695, \u0026#39;32\u0026#39;: 0.04083}), defaultdict(int, {\u0026#39;262\u0026#39;: 0.04996, \u0026#39;5983\u0026#39;: 0.1367, \u0026#39;2320\u0026#39;: 0.04483, \u0026#39;111\u0026#39;: 0.06335, \u0026#39;90017\u0026#39;: 0.2517, \u0026#39;2588\u0026#39;: 0.3335})], \u0026#39;colbert_vecs\u0026#39;: None} \u0026#34;\u0026#34;\u0026#34; # you can see the weight for each token: print(model.convert_id_to_token(output_1[\u0026#39;lexical_weights\u0026#39;])) # [{\u0026#39;What\u0026#39;: 0.08356, \u0026#39;is\u0026#39;: 0.0814, \u0026#39;B\u0026#39;: 0.1296, \u0026#39;GE\u0026#39;: 0.252, \u0026#39;M\u0026#39;: 0.1702, \u0026#39;3\u0026#39;: 0.2695, \u0026#39;?\u0026#39;: 0.04092}, # {\u0026#39;De\u0026#39;: 0.05005, \u0026#39;fin\u0026#39;: 0.1368, \u0026#39;ation\u0026#39;: 0.04498, \u0026#39;of\u0026#39;: 0.0633, \u0026#39;BM\u0026#39;: 0.2515, \u0026#39;25\u0026#39;: 0.3335}] # compute the scores via lexical mathcing print(model.compute_lexical_matching_score(output_1[\u0026#39;lexical_weights\u0026#39;][0], output_1[\u0026#39;lexical_weights\u0026#39;][1])) # 0 Multi-Vector (ColBERT) sentences_1 = [\u0026#34;What is BGE M3?\u0026#34;, \u0026#34;Defination of BM25\u0026#34;] output_1 = model.encode(sentences_1, return_dense=True, return_sparse=True, return_colbert_vecs=False) print(output_1[\u0026#39;colbert_vecs\u0026#39;][0].shape) # (8, 1024) print(model.colbert_score(output_1[\u0026#39;colbert_vecs\u0026#39;][0], output_1[\u0026#39;colbert_vecs\u0026#39;][1])) # tensor(0.4768) ColBERT score： 在计算完查询和文档之间的相似度矩阵后，对每个查询token选择与文档中token的最大相似度，将所有最大相似度累加，得到最终的colbert_score。\n基于LLM实现embedding 几个代表模型：\nAlibaba-NLP/gte-Qwen2-7B-instruct\nintfloat/e5-mistral-7b-instruct\ne5-mistral-7b-instruct论文：Improving Text Embeddings with Large Language Models\nconfig.json:\n{ \u0026#34;_name_or_path\u0026#34;: \u0026#34;mistralai/Mistral-7B-v0.1\u0026#34;, \u0026#34;architectures\u0026#34;: [ \u0026#34;MistralModel\u0026#34; ], \u0026#34;bos_token_id\u0026#34;: 1, \u0026#34;eos_token_id\u0026#34;: 2, \u0026#34;hidden_act\u0026#34;: \u0026#34;silu\u0026#34;, \u0026#34;hidden_size\u0026#34;: 4096, \u0026#34;initializer_range\u0026#34;: 0.02, \u0026#34;intermediate_size\u0026#34;: 14336, \u0026#34;max_position_embeddings\u0026#34;: 32768, ... 通过LLM生成数据（合成数据）， 采用对比学习微调Mistral-7B；\nGiven a pretrained LLM, we append an [EOS] token to the end of the query and document, and then feed them into the LLM to obtain the query and document embeddings $(h_{q_{inst}^+}, h_d^+)$, by taking the last layer [EOS] vector.\n附录 如何找到合适的embedding模型和reranker模型 首先推荐从 huggingface MTEB Leaderboard上选择排名靠前的模型\n其次，实验！根据自己的场景构造测试集验证，才能选择出适合自己场景的embedding模型和reranker模型；\nembedding模型和reranker模型的注意事项 上下文长度限制。 这些模型大多本质是Bert-based 模型， 而Bert的上下文长度限制一般是512，具体可以在huggingface中的config.json中查看；以BAAI/bge-base-en-v1.5 为例\n{ \u0026#34;_name_or_path\u0026#34;: \u0026#34;/root/.cache/torch/sentence_transformers/BAAI_bge-base-en/\u0026#34;, \u0026#34;architectures\u0026#34;: [ \u0026#34;BertModel\u0026#34; ], \u0026#34;attention_probs_dropout_prob\u0026#34;: 0.1, \u0026#34;classifier_dropout\u0026#34;: null, \u0026#34;gradient_checkpointing\u0026#34;: false, \u0026#34;hidden_act\u0026#34;: \u0026#34;gelu\u0026#34;, \u0026#34;hidden_dropout_prob\u0026#34;: 0.1, \u0026#34;hidden_size\u0026#34;: 768, \u0026#34;id2label\u0026#34;: { \u0026#34;0\u0026#34;: \u0026#34;LABEL_0\u0026#34; }, \u0026#34;initializer_range\u0026#34;: 0.02, \u0026#34;intermediate_size\u0026#34;: 3072, \u0026#34;label2id\u0026#34;: { \u0026#34;LABEL_0\u0026#34;: 0 }, \u0026#34;layer_norm_eps\u0026#34;: 1e-12, \u0026#34;max_position_embeddings\u0026#34;: 512, \u0026#34;model_type\u0026#34;: \u0026#34;bert\u0026#34;, \u0026#34;num_attention_heads\u0026#34;: 12, \u0026#34;num_hidden_layers\u0026#34;: 12, \u0026#34;pad_token_id\u0026#34;: 0, \u0026#34;position_embedding_type\u0026#34;: \u0026#34;absolute\u0026#34;, \u0026#34;torch_dtype\u0026#34;: \u0026#34;float32\u0026#34;, \u0026#34;transformers_version\u0026#34;: \u0026#34;4.30.0\u0026#34;, \u0026#34;type_vocab_size\u0026#34;: 2, \u0026#34;use_cache\u0026#34;: true, \u0026#34;vocab_size\u0026#34;: 30522 } 其中`\u0026quot;max_position_embeddings\u0026quot;: 512, 也就是它的上下文长度，但输入sequence长度超过512个token，则模型只看到了最前面的512个token；\n向量维度\n微调\n如何微调embedding 模型 采用FlagEmbedding，参考：How to fine-tune bge embedding model?\n微调Sentence Transformer，参考：Training Overview\n还有哪些类型的reranker模型 根据ColBert文章\n作者将query-document matching 任务（reranking）分类成：\nRepresentation-based Similarity, 双塔，独立对查询和文档进行编码，然后通过计算它们的向量相似度进行匹配， 但query和doc间无更精细的交互。\nQuery-Document interaction： 在查询和文档之间直接进行交互，通常使用CNN来捕捉查询和文档之间的交互特征， 但交互计算复杂度较高，尤其是当查询和文档长度较长时。\nAll-to-All Interaction，基于Bert 的Cross-encoder结构， 查询和文档的每个词与对方的每个词进行全连接交互。这种方式可以捕捉细粒度的交互信息，通常需要较高的计算资源。\nLate Interaction， 迟交互型，在对查询和文档的每个词进行独立编码后，再进行交互计算。通常使用最大池化（MaxSim）来选择最相关的词进行匹配，从而结合了高效性和细粒度交互的优点。\n此外， 当然也有基于LLMs的reranker，参考：llm_reranker\n以 BAAI/bge-reranker-v2-gemma 为例， 只是做这样一件事\nprompt = \u0026#34;Given a query A and a passage B, determine whether the passage contains an answer to the query by providing a prediction of either \u0026#39;Yes\u0026#39; or \u0026#39;No\u0026#39;.\u0026#34; 以输出“Yes” 的logit 作为相关分数\n对比学习 在之前不断提到了embedding，当然， 和transformer中的embedding层不是一个东西；\n这里所指的embedding是通过对比学习的方式，将语义相近的文本映射到高维参数空间中的相近位置，使它们的距离尽可能短。相反，语义差别大的文本则被映射到参数空间中远离的位置。类似地，这种方法也可以应用于图像（相似图像检索）以及文本和图像的多模态语义匹配（如CLIP）。那么，对比学习有三个核心：loss function，网络架构和采样。\n对比学习有三个核心要素：网络架构、损失函数（loss function）和采样策略。\n常见的损失函数有contrastive loss、triplet loss，以及N-pair loss。\n网络架构方面,对比学习通常采用双塔(siamese network)或者三塔(triplet)结构。双塔结构包含两个相同或相似的编码器,分别用于处理正样本对;三塔结构则增加了一个用于处理负样本的编码器。这些编码器可以是各种深度学习模型,如CNN、RNN或Transformer等,具体选择取决于任务域和数据类型。这一步将原始较为复杂的数据类型，通过深度学习的方法降到相对较低的维度便于之后的计算。\n对于双塔结构， 一般采用Contrastive Loss， 其用于度量两个样本之间的相似度。其公式为：\n$$ L = \\frac{1}{2N} \\sum_{i=1}^N (y_i d_i^2 + (1 - y_i) \\max(0, m - d_i)^2) $$\n其中：\n$d_i$是样本对$(x_i, x_j)$ 的欧几里得距离。\n$y_i$ 是样本对的标签，1 表示正样本对，0 表示负样本对。\nm 是一个超参数，表示负样本对之间的最小距离，也称margin。\nTriplet Loss则使用于triplet-network结构, 其通过构造三元组 ( anchor, positive, negative) 来训练模型，使得正样本（positive）与锚点（anchor）的距离小于负样本（negative）与锚点的距离。其公式为：\n$$ L = \\sum_{i=1}^N \\left[ |f(x_i^a) - f(x_i^p)|_2^2 - |f(x_i^a) - f(x_i^n)|_2^2 + \\alpha \\right] $$\n其中：\n$f(x)$ 表示样本 x 的特征向量。\n$\\alpha$是一个超参数，表示正负样本对之间的最小距离差。\nN-pair Loss 是 Triplet Loss 的推广，通过引入多个负样本来提升训练效果。\n$$ L = \\sum_{i=1}^N \\log \\left( 1 + \\sum_{j \\neq i} \\exp \\left( f(x_i)^\\top f(x_j^n) - f(x_i)^\\top f(x_i^p) \\right) \\right) $$\n在训练过程中， 采样策略则很关键；但运气不好， 选择的样本都是Easy Negative mining，也就是$d(a,p)+margin\u0026lt;d(a,n)$，则模型能够很快收敛，但什么也没有学会，相反在另一个极端中， 采用的多是hard negative mining，也就是$d(a,n)\u0026lt;d(a,p)$的情况，此时模型训练将很难收敛；实际情况中， 往往采用semi-hard 或者是distance-weighted sampling 来寻找难度适中的负样本,以避免模型过于关注极端情况。而由于在高维空间下， 因为高维空间中大部分体积都集中在高维球壳上，所以随机采样得到的点之间的距离往往非常接近，这也是不采用随机采样的策略的原因（Sampling Matters in Deep Embedding Learning）。\n向量库是个什么东西 向量库不是“库”，但也是“库”；\n考虑到传统关系型数据库， 数据以表格形式存储， 但在AI时代， 大量非结构化数据的存储和查询，以表格形式存在这不太合理了；因为数据维度高， 需要一些特殊的查询方式；\n不同于传统数据库的精确匹配查询,向量库主要用于相似性搜索。这种搜索基于向量间的距离,通常使用欧几里得距离或余弦相似度。以暴力遍历的最近邻查询为例(Nearest neighbor search),假设我们有n个d维向量,查询复杂度为$O(nd)$。当n和d都很大时,这种方法变得非常耗时。\n而近似最近邻搜索(Approximate Nearest Neighbor search, ANN)则能将时间复杂度降低到亚线性,通常为$O(log n)$或更优。\n常见的ANN算法：\n基于树的：k-D树(k-D tree):将空间递归地划分为子空间,适用于低维数据。\n基于哈希的：局部敏感哈希(LSH, Locality-Sensitive Hashing):将相似的向量映射到相同的\u0026quot;桶\u0026quot;中。\n乘积量化(Product Quantization):将高维向量分解为低维子向量,并对每个子向量进行量化。\n基于Graph的：分层可导航小世界图(HNSW, Hierarchical Navigable Small World):构建多层图结构,在图上进行快速导航搜索。\n而以上算法的思路都可以归介于—将相似的样本放在一起（减少搜索空间）， 和构建高效的搜索结构。\n参考 Build a search engine, not a vector DB\nHybrid Search Explained\n再谈大模型RAG问答中的三个现实问题：兼看RAG-Fusion多query融合策略、回答引文生成策略及相关数据集概述\nLLM - RAG文档应用处理与召回经验之谈\n[RAG] BGE M3-Embedding | 什么？我的RAG底座模型又要换了？\nColBERT: A complete guide\n搜索引擎技术\nUtilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges\nColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\nLLM4IR-Survey\nFine-Tuning LLaMA for Multi-Stage Text Retrieval\n","permalink":"https://niraya666.github.io/posts/rag%E6%A3%80%E7%B4%A2/","summary":"\u003cblockquote\u003e\n\u003cp\u003eIf you want to make a good RAG tool that uses your documentation, you should start by making a search engine over those documents that would be good enough for a human to use themselves. This is likely something your organization has considered before, and if it doesn’t exist it’s because building a good search engine has traditionally been a significant undertaking.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e— from \u003ca href=\"https://blog.elicit.com/search-vs-vector-db/\"\u003eBuild a search engine, not a vector DB\u003c/a\u003e\u003c/p\u003e","title":"RAG工具箱：检索"},{"content":"AI 新闻 Claude 3.5 Sonnet https://www.anthropic.com/news/claude-3-5-sonnet\n相比其前身 Claude 3 Opus，Claude 3.5 Sonnet 的运行速度提升了两倍，同时在多项基准测试中表现优异。此外，Claude 3.5 Sonnet 还引入了名为“Artifacts”的新功能，使用户可以在与 AI 对话的过程中实时查看和编辑生成的内容。\n开源模型 Qwen 2 https://qwenlm.github.io/zh/blog/qwen2/\n一共开源了Qwen2-0.5B、Qwen2-1.5B、Qwen2-7B、Qwen2-57B-A14B以及Qwen2-72B 5个模型**。增大了上下文长度支持，最高达到128K** tokens（Qwen2-72B-Instruct）。 代码和数学能力显著提升。多个评测基准上的领先表现。 同时还开源了一个智能体解决方案，用于高效处理100万tokens级别的上下文： **使用Qwen-Agent将上下文记忆扩展到百万量级。**\nGemma2 https://developers.googleblog.com/en/gemma-family-and-toolkit-expansion-io-2024/\n包括两个主要版本，分别是 9 B参数和 27 B参数的模型。27B 的 Gemma 2 模型在多个基准测试中表现优异，超过了 Llama 3 70B 模型的性能。\nGemma 2 采用了新的架构设计，使其在推理时更加高效\nNemotron-4 340B https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/\n包含基础模型、指示模型和奖励模型的综合性数据生成流水线，用于训练大型语言模型。\n提供了一种生成合成训练数据的新方法，旨在提升定制语言模型的性能和鲁棒性。\nDeepSeek-Coder-V2 代码模型 https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct\n开源的专家混合模型，性能媲美GPT4-Turbo，专为代码特定任务优化，支持多源高质量语料库预训练，显著提升编程和数学推理能力，支持338种编程语言，扩展上下文长度至128K。\n值得关注的开源项目 Perplexica： 开源版本Perplexity+支持本地LLM。 GitHub：github.com/ItzCrazyKns/Perplexica\ntranslation-agent：吴恩达老师开源了一套 AI Agent 翻译工作流。通过LLM初步翻译， 而后对翻译结果进行反思，并提出改进建议，最后再根据意见进行最终版本的翻译。GitHub： github.com/andrewyng/translation-agent\nStreamer-Sales 销冠 —— 卖货主播 LLM 大模型： 一个能够根据给定的商品特点从激发用户购买意愿角度出发进行商品解说的卖货主播大模型。 另外还集成了 LMDeploy 加速推理🚀、RAG检索增强生成 📚、TTS文字转语音🔊、数字人生成 🦸、 Agent 使用网络查询实时信息🌐、ASR 语音转文字🎙️。 GitHub：github.com/PeterH0323/Streamer-Sales\nsocial-auto-upload： 自动化上传视频到社交媒体：抖音、小红书、视频号、tiktok、youtube、bilibili。 GitHub：github.com/dreammis/social-auto-upload\ngptpdf： 将 PDF 解析为 Markdown 的开源工具，使用了多模态大模型GPT4-o。\n实现几乎完美地解析排版、数学公式、表格、图片、图表。\ngithub.com/CosmosShadow/gptpdf\nEidos—Offline alternative to Notion： Eidos is an extensible framework for managing your personal data throughout your lifetime in one place. github.com/mayneyao/eidos\nComposio： AI Agent集成工具集，支持100+工具和多种框架。 GitHub: github.com/ComposioHQ/composio\nWiseFlow首席情报官： ****一个敏捷的信息挖掘工具，可以从网站、微信公众号、社交平台等各种信息源中按设定的关注点提炼讯息，自动做标签归类并上传数据库。“我们缺的其实不是信息，我们需要的是从海量信息中过滤噪音，从而让有价值的信息显露出来！” GitHub: github.com/TeamWiseFlow/wiseflow\ncomfyui-sound-lab： 声音生成版本的comfyui。GitHub: github.com/shadowcz007/comfyui-sound-lab\nAmphi-ETL： Low-code ETL for structured and unstructured data. Generates Python code you can deploy anywhere. GitHub: github.com/amphi-ai/amphi-etl\n我的足迹 育音堂凯旋路店在7月份将被拆除， 在6月底去看了最后一眼。\n无数年轻乐队从这里开始，从这里走向更大的舞台，只可惜“小白楼”不在了， 年轻乐队能够“演的起”的场地也不多了。\n影音记录 精选歌单 Live演出 06.09 Sun. Alfa Mist 摩登天空\n06.26 Wed. 惘闻 万代南梦宫\n电影 正值第26届上海国际电影节（SIFF）\n二刷 《完美的日子》，也亲眼见到了役所广司；\n《万物理论》，抢票时没仔细看， 以为是同名的霍金自传电影，结果是一部23年的一部打着多重宇宙幌子，对于黑白惊悚电影的拙劣模仿之作，属实是不推荐；\n《她》，在十年之后的AI元年再重新看这部电影，发现电影中的场景已然发生。\n《蒸发》，自90年代日本经济泡沫破裂后，大量人口由于经济等原因，选择人间蒸发。 与其说是“消失”，不如说是对于其设定角色的“逃离”。\n书\u0026amp;阅读摘录 本月完成： 《日本之镜：日本文化中的英雄与恶人》，《深度关系》。\n越来越喜欢肤浅的快乐，是我们的错吗？ https://mp.weixin.qq.com/s/t55b2swIFc9WcwIRLAMxgg\n网络上的东西，越来越快，越来越肤浅，“劲儿”越来越大。即使难得有深度、优质的创作，也难得静下心来，沉浸地去阅读、去感知。\n互联网和手机应用强调第一时间的快感反馈，通过直观的刺激，抢先进行引导，再使用各种各样的手段延长加强的刺激，让人停不下来。这个过程，相当于是绕过了大脑里负责思考的“系统2”，迫使人去做出直接的、即时的反应。 … 但从注意力的角度来讲，用脑来判断的时候也越来越少了，人们会不知不觉地跟着技术设计的脚步走，顺从“系统1”（也就是直觉）带来的简单判断。 … 这种设计，相当于占用了人们更长的空闲时间。 …\n技术设计原本是要侵占碎片时间，结果所有的时间，连同我们的注意力，都被切得粉碎。\n县城体制内女孩婚恋困局：不想将就，又怕结不了婚 https://news.ifeng.com/c/8YxP14GIPYq\n“比如说以前有几十个人天天来催你，到了29、30岁，可能只有几个人。30岁以上，几乎没有什么人来给你说亲了。因为你的机会、资源越来越少，周围人的信心也越来越弱。” … 如果没法在社会“约定俗成”的年纪顺利结婚，取而代之的，就是对个人价值的全方位否定。 晓媛参加一个亲戚的婚礼，看见台上像是强行凑成一对的新人，新娘年轻漂亮，至于新郎，“长得很不行。”\n县域体制内女青年普遍想选择比自己更优秀的体制内男性青年为婚配对象，但县域体制内男青年无论是数量还是质量上均无法满足这一择偶需求。\n她常说，自己年过40岁，才回归到传统中国文化中，理解中国人的行为。为什么红白喜事总是特别隆重，因为它代表着一种社群的仪式，承载着情感，以及人与人之间的链接。 …县城、乡镇就像一个中国传统家庭，讲人情，有温度，但也有越过边界的关心。\n为什么对于有的人来说 ChatGPT 并没有什么卵用？ https://baoyu.io/blog/ai/why-do-someone-think-chatgpt-doesnot-really-work-for-them\nLLM 擅长处理和生成文本，但是受限于上下文窗口长度，并且对于复杂的数据格式，需要用格式化的数据格式表达，并且要借助提示工程将复杂的任务进行拆解。\n如果要用好 LLM，最好是充分利用 LLM 的长处，把一些高频的使用场景，但是原本不适合或者无法自动化的工作流的，借助 LLM 的文本处理能力，变成自动化的工作流。\nAI 应用爆发前夜的三个信号｜鹅库2402 https://mp.weixin.qq.com/s/Fj3WfSP5-tUBT_-OfusYpw\n三个信号\n下一代大模型效果的提升和成本的大幅下降 已有玩家+AI 后的营收大幅增长 共识的应用层创业者浮出水面 我们在使用大语言模型 (LLMs) 构建产品一年中的经验总结 https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/\n战术\nn-shot 提示:\n如果 n 过低，模型可能会过度依赖这些特定示例，影响其泛化能力。一般来说，n 应该不小于 5，甚至可以达到几十个。 如果您使用支持工具的大语言模型，您的 n-shot 示例也应包括您希望智能体使用的工具。\n输入输出结构化:\nClaude 偏好 xml，而 GPT 则偏好 Markdown 和 JSON。\n编写小而精的提示词，专注做好一件事:\n将单一提示词拆分成了多个简单、专注且易于理解的提示词。这样，我们可以分别迭代和评估每个提示词的效果。\nRAG:\n别忘了关键词搜索：把它作为基线并在混合搜索中使用\n我们需要超越单一提示，拥抱工作流:\n将智能体行为设计成线性链、DAG 和状态机的形式；不同的依赖关系和逻辑关系适用于不同的任务规模。能否通过不同的任务架构来优化性能？\n一个有效的方法是让智能体系统生成确定性的计划，并以结构化、可重复的方式执行。\n缓存:\n缓存可以节省成本并消除响应延迟，因为它避免了对相同输入重新计算响应的需要。此外，如果一个响应之前已经经过安全审核，我们可以提供这些审核过的响应，从而减少提供有害或不适当内容的风险。\nLLM-as-Judge 可以工作，但它不是万能的:\n使用成对比较: 呈现两个选项并让它选择较好的一个 控制位置偏差: 选项的呈现顺序会影响大语言模型的决策。为了减少这种偏差，每次成对比较时都交换选项的顺序进行两次 允许平局 使用 Chain-of-Thought 方法 控制回复长度 我们发现传统分类器和奖励模型比 LLM-as-Judge 更准确，且成本更低、延迟更短。在代码生成方面，LLM-as-Judge 的表现可能不如直接执行代码的评估策略。\n对吴恩达 workflow 概念产品化的思考！ https://mp.weixin.qq.com/s/aO1NhCFCy3JFoN80cQjyVA\n吴恩达、Itamar Friedman、Harrison Chase等人一直在提倡 workflow、flow engineering 之类的概念，意在通过多次、分阶段的 LLM 调用、迭代来实现更好的应用效果。\n用自然语言描述清楚一项复杂工作是非常困难的，没有人能够光用嘴巴教你怎么样造火箭或者量子物理。\n要想进一步拓宽上限，就必须采用形式化的表达\n以下两种产品设计思路的方向是截然相反的，我们认为应该采取第一种：\n现有任务的集合，再决定设计出哪些节点（node）。 先设计出节点（node），再思考我设计出的节点能够完成哪些现实世界的任务。 当我们能够对任务进行形式化表达的时候，就能够思考对各种任务的中间过程状态的拆解以及合并归类的方法和策略，进而设计出合理的流程节点。\n经过思考，我们得出了两点结论，这两点结论指引我们对于 workflow 产品的设计：\nworkflow 的系统设计可以形式化地表达为 DFA 的构造。 workflow 的流程节点设计是给定约束条件下的 DFA 状态数量最小化问题。 workflow 系统是一个确定有限自动机:\n整个工作流产品可以用五元组来表示：\n有限状态集合 ：给定任务集合 （包括初始状态、中间状态、结束状态）所包含状态的有限集合。 有限流程节点集合 ：workflow 产品所提供的流程节点的集合。 状态迁移函数δ ： ，状态迁移函数的值是状态集合 的子集。迁移函数定义了在经过流程节点的处理后，workflow 如何从一个状态迁移到另一个状态。 初始状态 ：workflow 的初始状态， 结束状态集合 ：任务的结束状态集合， 夕小瑶：资本寒冬下的AI创业一年 https://zhuanlan.zhihu.com/p/701574775\n至此，我才终于有了比较清晰的融资思路——\n你要找到手里有钱，受资本寒冬影响尽可能小的投资机构 你要找到多次在你所处的赛道和阶段有较多投资记录的机构 你要找到跟你的团队优势、价值观匹配的投资机构 创业的核心是让你的产品跟市场匹配，简称PMF。而加速PMF的方法只有一个——尽可能的缩短你的试错成本。 更快的投向市场拿反馈，更快的迭代，迭代，再迭代，就是技术型创业的核心方法论。\n最后，我们发现我们高估了agent技术成熟的速度和市场接纳的速度。一方面agent的概念没有像ChatGPT一样深入到用户和客户的心智，如果你去年要做这个方向，首先要面临教育市场的问题。而一个天使轮的小公司，是不具备教育市场的能力的，营销成本很高；\n另一方面，agent的概念虽然好，但真实的业务场景细节很多，非标问题很多，还要去挑战甲方公司旧的利益分配体系，这意味着在agent技术变得充分通用、鲁棒之前，你很难用比较低的成本来满足客户需求。尽管我们通过一系列的手段，将大部分agent的定制交付周期从几周缩短到几天，但发现想再往下降成本的时候几乎就是技术不可解的问题了。因此交付成本很高；\nMilestone 忙着打老头环DLC\n","permalink":"https://niraya666.github.io/monthly/2024-06/","summary":"\u003ch1 id=\"ai-新闻\"\u003eAI 新闻\u003c/h1\u003e\n\u003ch2 id=\"claude-35-sonnet\"\u003e\u003cstrong\u003eClaude 3.5 Sonnet\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://www.anthropic.com/news/claude-3-5-sonnet\"\u003ehttps://www.anthropic.com/news/claude-3-5-sonnet\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e相比其前身 Claude 3 Opus，Claude 3.5 Sonnet 的运行速度提升了两倍，同时在多项基准测试中表现优异。此外，Claude 3.5 Sonnet 还引入了名为“Artifacts”的新功能，使用户可以在与 AI 对话的过程中实时查看和编辑生成的内容。\u003c/p\u003e\n\u003ch2 id=\"开源模型\"\u003e开源模型\u003c/h2\u003e\n\u003ch3 id=\"qwen-2\"\u003eQwen 2\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://qwenlm.github.io/zh/blog/qwen2/\"\u003ehttps://qwenlm.github.io/zh/blog/qwen2/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e一共开源了Qwen2-0.5B、Qwen2-1.5B、Qwen2-7B、Qwen2-57B-A14B以及\u003cstrong\u003eQwen2-72B\u003c/strong\u003e 5个模型**。\u003cstrong\u003e增大了上下文长度支持，最高达到\u003c/strong\u003e128K** tokens（Qwen2-72B-Instruct）。 代码和数学能力显著提升。多个评测基准上的领先表现。 同时还开源了一个智能体解决方案，用于高效处理100万tokens级别的上下文： \u003ca href=\"https://qwenlm.github.io/zh/blog/qwen-agent-2405/\"\u003e**使用Qwen-Agent将上下文记忆扩展到百万量级\u003c/a\u003e。**\u003c/p\u003e\n\u003ch3 id=\"gemma2\"\u003eGemma2\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://developers.googleblog.com/en/gemma-family-and-toolkit-expansion-io-2024/\"\u003ehttps://developers.googleblog.com/en/gemma-family-and-toolkit-expansion-io-2024/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e包括两个主要版本，分别是 9 B参数和 27 B参数的模型。27B 的 Gemma 2 模型在多个基准测试中表现优异，超过了 Llama 3 70B 模型的性能。\u003c/p\u003e\n\u003cp\u003eGemma 2 采用了新的架构设计，使其在推理时更加高效\u003c/p\u003e\n\u003ch3 id=\"nemotron-4-340b\"\u003eNemotron-4 340B\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/\"\u003ehttps://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e包含基础模型、指示模型和奖励模型的综合性数据生成流水线，用于训练大型语言模型。\u003c/p\u003e\n\u003cp\u003e提供了一种生成合成训练数据的新方法，旨在提升定制语言模型的性能和鲁棒性。\u003c/p\u003e\n\u003ch3 id=\"deepseek-coder-v2-代码模型\"\u003eDeepSeek-Coder-V2 代码模型\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct\"\u003ehttps://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e开源的专家混合模型，性能媲美GPT4-Turbo，专为代码特定任务优化，支持多源高质量语料库预训练，显著提升编程和数学推理能力，支持338种编程语言，扩展上下文长度至128K。\u003c/p\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003ePerplexica\u003c/strong\u003e： 开源版本Perplexity+支持本地LLM。 GitHub：\u003ca href=\"http://github.com/ItzCrazyKns/Perplexica\"\u003egithub.com/ItzCrazyKns/Perplexica\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003etranslation-agent\u003c/strong\u003e：吴恩达老师开源了一套 AI Agent 翻译工作流。通过LLM初步翻译， 而后对翻译结果进行反思，并提出改进建议，最后再根据意见进行最终版本的翻译。GitHub： \u003ca href=\"http://github.com/andrewyng/translation-agent\"\u003egithub.com/andrewyng/translation-agent\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStreamer-Sales 销冠 —— 卖货主播 LLM 大模型\u003c/strong\u003e： 一个能够根据给定的商品特点从激发用户购买意愿角度出发进行商品解说的卖货主播大模型。 另外还集成了 LMDeploy 加速推理🚀、RAG检索增强生成 📚、TTS文字转语音🔊、数字人生成 🦸、 Agent 使用网络查询实时信息🌐、ASR 语音转文字🎙️。 GitHub：\u003ca href=\"http://github.com/PeterH0323/Streamer-Sales\"\u003egithub.com/PeterH0323/Streamer-Sales\u003c/a\u003e\u003c/p\u003e","title":"2024-06 月刊"},{"content":"本文将简单介绍如何评价LLM的tool-using 能力。\n引言 在工具使用评估方面，过去的研究主要有以下几种思路：\n对比工具使用和纯LLM在基准测试上的分数：例如Toolformer和LATM。\n在Toolformer研究中，通过下游任务如语言模型评估基准测试、数学推理任务和问答任务来验证工具使用的有效性。\nLATM则采用了来自BigBench的六个数据集进行评估。\n测试工具使用的准确率和响应质量：例如API-Bank。\n在评估过程中，首先初始化评估系统，确保每个API的数据库包含默认值。然后，将预测的API调用与手动标注的API调用进行比较，以确定它们的一致性。响应评估则使用ROUGE-L指标。 利用LLM对工具使用的效果进行评价：例如Tool-bench。\ntwo evaluation metrics:\nPass Rate: Calculates the proportion of successfully completing an instruction within limited OpenAI API calls.\nPreference: Measured by comparing two answers (action sequences) for a given instruction.We pre-define a set of criteria for a better answer, which are organized as prompts for ChatGPT.\n构造虚拟运行环境，测试代理与环境的交互结果：例如ToolAlpaca。\n利用LLM模拟环境（用户代理和助手代理），并使用GPT-4对ToolAlpaca模型进行机器评估，评估其使用各种未见工具的能力。 对于绝大多数企业和垂直场景下， 其中思路1需要构建额外的测试集成本比较高（但还是有必要的）， 而思路4构造虚拟运行环境实际上并不现实； 所以还是选择思路2，外加通过思路3辅助判断；换句话说， 根据场景，构造工具列表和工具调用的ground-truth（包括函数名， 和传入参数） ，在存在歧义时，采用ROUGE评价响应质量， 或者使用LLM判断响应结果并评价。\n顺带提一下Langchain 项目中有关Agent的tool-using能力测试的内容， 不过由于Langchain项目又臭又长，且有很大的局限性， 这里只讨论其思路。\n在 Benchmarking Agent Tool Use 一文中，提出了4种指标用于评价Agent 的tool-using 能力：\nCorrectness 即通过LLM判断工具调用结果是否同ground truth 相同；\nCorrect final state 即检查agent 所交互环境的最终状态是否同预期相同；\nIntermediate step correctness 除了最终状态， 也可以检查中间状态；\nRatio of steps taken to the expected steps 即实际步骤与预期步骤的比例。\n在LangChain Benchmarks 项目提供了4个（3个）任务用于测试tool-using， 本质上也是一种构造虚拟环境并与之交互。\nMultiverse Math 任务 ： 要求模型使用提供的工具来解决数学问题。为了确保模型不依赖于内在知识，数学运算被修改以产生不同于预期的结果。例如，乘法和加法的结果会有所不同，但仍保留某些数学性质。 任务示例包括基本的加减乘除运算、幂运算、对数运算等。\ncode \u0026#34;\u0026#34;\u0026#34;Solve basic math question using the provided tools. Must use the provided tools to solve the math question. To make sure that innate knowledge is not used, the math operations have been altered to yield different results than expected. The modified operations should yield different results, but still retain appropriate properties. For example, the modified multiplication operation should still be commutative. Please note that the modified operations are not guaranteed to even make sense in the real world since not all properties will be retained (e.g., distributive property). For example, I ate 1 apple and 2 oranges every day for 7 days. How many fruits did I eat? One would expect the answer to be 21, but in this universe, the answer is 32.34. In addition, it depends on how the operations are grouped: (1 + 2) * 7 = 32.34 But: 1 * 7 + 2 * 7 = 24.3 Due to these changes certain questions are not allowed as inputs as they would yield different results if evaluated in different ways. For example, \u0026#34;convert 15 degrees to radians\u0026#34; is not allowed as an input as it could be interpreted as either: divide(multiply(15, pi()), 180) or multiply(divide(15, 180), pi()) \u0026#34;\u0026#34;\u0026#34; Relational Data任务 ：要求模型使用提供的工具来回答关于关系数据的问题。环境中包含关于用户及其位置和喜好食物的虚假数据，模型需要使用工具查询这些数据以回答问题。 任务示例包括查询用户的位置信息、喜好食物等\ncode \u0026#34;\u0026#34;\u0026#34;Answer questions about relational data using the provided tools. The environment contains fake data about users and their locations and favorite foods. The environment provides a set of tools that can be used to query the data. All questions can be answered by using the provided tools. The answers include the expected result as well as the most efficient way to answer the question using the tools. \u0026#34;\u0026#34;\u0026#34; Typewriter(single-tool, 26-tools): 要求模型使用工具逐字打印给定的字符串。模型需要调用工具来模拟打字机的行为，每次打印一个字符，直到完成整个字符串。 任务示例包括打印特定的句子或段落。\ncode ```python \u0026quot;\u0026quot;\u0026quot;A task where the agent must type a given string one letter at a time. In this variation of the task, the agent is given a single function, that takes a letter as an argument. \u0026quot;\u0026quot;\u0026quot; ``` 根据综述文章《What Are Tools Anyway? A Survey from the Language Model Perspective》，在验证代理或模型的工具使用能力时，可以关注以下指标：\nTask completion：任务完成度，或pass-ratio 这是一个相对宏观的指标， 工具调用的最核心目的就是为了完成任务， 任务的成功与否表征了工具调用的最终结果。\nTool selection： 如何在众多工具中挑选到最合适的工具，这考验了模型在特定场景下对任务的理解和最优化的工具选择；\nTool reusability： 指的是一个工具在不同情境下或解决不同问题时能够被多次使用的能力， 不过往往和工具生成（tool-marking）相关， 不在这次的讨论范围中。\n方法论 综合以上讨论， tool-using 的测试可以简单分为：\n单轮简单测试 在这种测试中，主要测试function_name 和传入参数。关注的指标是pass-rate 和 Preference。具体方法是不需要使用LLM进行判断，只需将返回的function_name 和 function_arguments 与ground-truth进行比对，确认是否一致。最终使用pass-ratio 评价测试结果。\nJson-mode验证 由于并非所有模型都能严格按要求输出所需要的json格式，考虑到这种情况，可以进行Json-mode的验证，以确保输出格式的正确性。\n优化版本\n通过ROUGE判断function_arguments\n目的：避免严格一致所带来的问题。 通过LLM辅助判断function_arguments\n优点：准确率更高。\n缺点：成本也更高。\n多轮调用 以上单轮tool-using测试在复杂场景下不太适用。\n在一些复杂场景中，如代码生成与执行、SQL生成并执行等，需要按照一定顺序调用多个tools。这些场景需要LLM根据前几次tool-using的结果反馈，调整function_arguments 或 function_name。\n这些场景无外乎都需要LLM根据前几次tool-using的结果反馈， 修改function_arguments 或者是function_name；\n将tool-using的过程抽象为强化学习中agent同环境(env)的交互过程。目标是减少agent与环境的交互次数，从而降低成本，并争取一次或者几次就能做对，避免重复错误。可以借用langchain中的思想，增加对中间和最终状态的检查，并比对实际交互次数和预期交互次数。这类测试需要额外构建虚拟环境，超出此次讨论范围。\n测试集 NousResearch/func-calling-eval-glaive\nNousResearch/func-calling-eval-singleturn\nNousResearch/func-calling-eval\n上手：测试LLM的tool-using 能力 这里，选择最简单的tool-using用于演示， 即直接调用OpenAI 的tool-using API\n环境 import os # os.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] = \u0026#34;...\u0026#34; from openai import OpenAI import json client = OpenAI() 定义工具函数 考虑了一个简单的医疗场景，共4个工具；\ntools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_medical_definition\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the definition of a medical term\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;term\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The medical term to define\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;term\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_treatment_options\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get treatment options for a disease\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;disease\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The disease to get treatment options for\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;disease\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_medication_side_effects\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the potential side effects of a medication\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;medication\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The name of the medication\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;medication\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_disease_symptoms\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the symptoms associated with a specific disease\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;disease\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The disease to get symptoms for\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;disease\u0026#34;] } } } ] 定义测试用例 创建测试用例数据集，每个测试用例包含查询、预期函数调用及其参数、以及期望的响应。\n使用GPT-4构建。\ntest_cases = [ { \u0026#34;query\u0026#34;: \u0026#34;What are the symptoms of influenza?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_disease_symptoms\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;disease\u0026#34;: \u0026#34;influenza\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Symptoms of influenza include fever, chills, muscle aches, cough, congestion, runny nose, headaches, and fatigue.\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;What is the definition of asthma?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_medical_definition\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;term\u0026#34;: \u0026#34;asthma\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Asthma is a condition in which your airways narrow and swell and may produce extra mucus, making breathing difficult and triggering coughing, wheezing, and shortness of breath.\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;What treatments are available for rheumatoid arthritis?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_treatment_options\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;disease\u0026#34;: \u0026#34;rheumatoid arthritis\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Treatment options for rheumatoid arthritis include medications such as NSAIDs, steroids, DMARDs, and biologics, as well as physical therapy and lifestyle changes.\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;What are the side effects of metformin?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_medication_side_effects\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;medication\u0026#34;: \u0026#34;metformin\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Common side effects of metformin include gastrointestinal issues such as diarrhea, nausea, and abdominal discomfort, as well as lactic acidosis in rare cases.\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;What symptoms are associated with hypothyroidism?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_disease_symptoms\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;disease\u0026#34;: \u0026#34;hypothyroidism\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Symptoms of hypothyroidism include fatigue, weight gain, cold intolerance, dry skin, constipation, and depression.\u0026#34; }, ... ] 定义测试metrics 自定义了pass-ratio，即function_name, function_arguments 严格一致为pass。\n运行测试并验证响应 def call_openai_tool(model, prompt, tools): response = client.chat.completions.create( model=model, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: prompt} ], tools=tools, tool_choice=\u0026#34;auto\u0026#34; ) return response def run_tests(test_cases, model=deployment_name): passed_tests = 0 failed_tests = 0 for case in test_cases: response = call_openai_tool(model, case[\u0026#39;query\u0026#39;], tools) if case[\u0026#39;expected_function\u0026#39;] and case[\u0026#39;function_arguments\u0026#39;]: if response.choices[0].message.tool_calls: tool_calls = response.choices[0].message.tool_calls # 验证函数调用名称和参数 try: assert tool_calls[0].function.name == case[\u0026#39;expected_function\u0026#39;], f\u0026#34;Expected function {case[\u0026#39;expected_function\u0026#39;]}, but got {tool_calls[0].function.name}\u0026#34; assert json.loads(tool_calls[0].function.arguments) == case[\u0026#39;function_arguments\u0026#39;], f\u0026#34;Expected arguments {case[\u0026#39;function_arguments\u0026#39;]}, but got {tool_calls[0].function.arguments}\u0026#34; print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 except AssertionError as e: print(e) print(f\u0026#34;Test failed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test failed for query (no tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: # # 验证响应内容 # response_text = response.choices[0].message.content.strip() # 验证没有调用工具 if response.choices[0].message.tool_calls: print(f\u0026#34;Test failed for query (unexpected tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 total_tests = passed_tests + failed_tests accuracy = (passed_tests / total_tests) * 100 if total_tests \u0026gt; 0 else 0 print(f\u0026#34;Total tests: {total_tests}, Passed: {passed_tests}, Failed: {failed_tests}, Accuracy: {accuracy:.2f}%\u0026#34;) run_tests(test_cases) 结果：\nTest passed for query: What are the symptoms of chronic kidney disease? Test passed for query: What does the medical term \u0026#39;bipolar disorder\u0026#39; mean? Expected arguments {\u0026#39;disease\u0026#39;: \u0026#39;chronic obstructive pulmonary disease\u0026#39;}, but got { \u0026#34;disease\u0026#34;: \u0026#34;COPD\u0026#34; } Test failed for query: What are the treatment options for chronic obstructive pulmonary disease (COPD)? Test passed for query: What side effects are associated with the use of aspirin? Test passed for query: Tell me a joke. Test passed for query: What is the capital of France? Total tests: 22, Passed: 21, Failed: 1, Accuracy: 95.45% 对于test failed case， 这只是个模凌两可的错误。\n如果采用LLM作为裁判是可以避免的。\n基于ROUGE的响应判断 环境\n! pip install rouge-score --quiet from rouge_score import rouge_scorer def calculate_rouge_l(predicted, expected): scorer = rouge_scorer.RougeScorer([\u0026#39;rougeL\u0026#39;], use_stemmer=True) scores = scorer.score(predicted, expected) return scores[\u0026#39;rougeL\u0026#39;].fmeasure def run_tests_with_rouge(test_cases, model=deployment_name, rouge_l_threshold=0.8): passed_tests = 0 failed_tests = 0 for case in test_cases: response = call_openai_tool(model, case[\u0026#39;query\u0026#39;], tools) if case[\u0026#39;expected_function\u0026#39;] and case[\u0026#39;function_arguments\u0026#39;]: if response.choices[0].message.tool_calls: tool_calls = response.choices[0].message.tool_calls # 验证函数调用名称和参数 try: assert tool_calls[0].function.name == case[\u0026#39;expected_function\u0026#39;], f\u0026#34;Expected function {case[\u0026#39;expected_function\u0026#39;]}, but got {tool_calls[0].function.name}\u0026#34; predicted_arguments = json.loads(tool_calls[0].function.arguments) # 计算ROUGE-L分数 rouge_l_score = calculate_rouge_l(json.dumps(predicted_arguments), json.dumps(case[\u0026#39;function_arguments\u0026#39;])) assert rouge_l_score \u0026gt;= rouge_l_threshold, f\u0026#34;ROUGE-L score {rouge_l_score} is less than threshold {rouge_l_threshold}\u0026#34; print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 except AssertionError as e: print(e) print(f\u0026#34;Test failed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test failed for query (no tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: # 验证没有调用工具 if response.choices[0].message.tool_calls: print(f\u0026#34;Test failed for query (unexpected tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 total_tests = passed_tests + failed_tests accuracy = (passed_tests / total_tests) * 100 if total_tests \u0026gt; 0 else 0 print(f\u0026#34;Total tests: {total_tests}, Passed: {passed_tests}, Failed: {failed_tests}, Accuracy: {accuracy:.2f}%\u0026#34;) 使用ROUGE-L 计算function_arguments 同预期的差距，若大于一定阈值，则判断失败。\n基于LLM验证和判断 def chat_completion_request(messages, tools=None, tool_choice=None, model=deployment_name, json_mode=False): try: params = { \u0026#39;model\u0026#39;: model, \u0026#39;messages\u0026#39;: messages, \u0026#39;tools\u0026#39;: tools, \u0026#39;tool_choice\u0026#39;: tool_choice } if json_mode: params[\u0026#39;response_format\u0026#39;] = { \u0026#34;type\u0026#34;: \u0026#34;json_object\u0026#34; } response = client.chat.completions.create(**params) return response except Exception as e: print(\u0026#34;Unable to generate ChatCompletion response\u0026#34;) print(f\u0026#34;Exception: {e}\u0026#34;) return e def evaluate_with_llm(predicted_arguments, expected_arguments, model, tools): prompt = f\u0026#34;\u0026#34;\u0026#34; Compare the following predicted arguments and expected arguments for a function call. Predicted Arguments: {json.dumps(predicted_arguments, indent=2)} Expected Arguments: {json.dumps(expected_arguments, indent=2)} Evaluate if the predicted arguments sufficiently match the expected arguments, considering minor differences acceptable. Respond with a JSON object containing a single key \u0026#34;match\u0026#34; with a boolean value indicating if they match. Example response: {{ \u0026#34;match\u0026#34;: true }} \u0026#34;\u0026#34;\u0026#34; response = chat_completion_request(messages=[{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: prompt}],model = model, json_mode=True) json_response = json.loads(response.choices[0].message.content) return json_response.get(\u0026#34;match\u0026#34;, False) def run_tests_with_llm(test_cases, model=deployment_name, rouge_l_threshold=0.8): passed_tests = 0 failed_tests = 0 for case in test_cases: response = call_openai_tool(model, case[\u0026#39;query\u0026#39;], tools) if case[\u0026#39;expected_function\u0026#39;] and case[\u0026#39;function_arguments\u0026#39;]: if response.choices[0].message.tool_calls: tool_calls = response.choices[0].message.tool_calls # 验证函数调用名称和参数 try: assert tool_calls[0].function.name == case[\u0026#39;expected_function\u0026#39;], f\u0026#34;Expected function {case[\u0026#39;expected_function\u0026#39;]}, but got {tool_calls[0].function.name}\u0026#34; predicted_arguments = json.loads(tool_calls[0].function.arguments) # 使用 LLM 来判断参数匹配 match = evaluate_with_llm(predicted_arguments, case[\u0026#39;function_arguments\u0026#39;], model, tools) assert match, \u0026#34;LLM evaluation determined the arguments do not match\u0026#34; print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 except AssertionError as e: print(e) print(f\u0026#34;Test failed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test failed for query (no tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: # 验证没有调用工具 if response.choices[0].message.tool_calls: print(f\u0026#34;Test failed for query (unexpected tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 total_tests = passed_tests + failed_tests accuracy = (passed_tests / total_tests) * 100 if total_tests \u0026gt; 0 else 0 print(f\u0026#34;Total tests: {total_tests}, Passed: {passed_tests}, Failed: {failed_tests}, Accuracy: {accuracy:.2f}%\u0026#34;) 附: prompt 生成示例 def chat_completion_request(messages, tools=None, tool_choice=None, model=deployment_name, json_mode=False): try: params = { \u0026#39;model\u0026#39;: model, \u0026#39;messages\u0026#39;: messages, \u0026#39;tools\u0026#39;: tools, \u0026#39;tool_choice\u0026#39;: tool_choice } if json_mode: params[\u0026#39;response_format\u0026#39;] = { \u0026#34;type\u0026#34;: \u0026#34;json_object\u0026#34; } response = client.chat.completions.create(**params) return response except Exception as e: print(\u0026#34;Unable to generate ChatCompletion response\u0026#34;) print(f\u0026#34;Exception: {e}\u0026#34;) return e def generate_test_cases_from_tools(tools, examples): tools_descriptions = \u0026#34;\\n\u0026#34;.join([ f\u0026#34;- {tool[\u0026#39;function\u0026#39;][\u0026#39;name\u0026#39;]}: {tool[\u0026#39;function\u0026#39;][\u0026#39;description\u0026#39;]} (Parameters: {\u0026#39;, \u0026#39;.join(tool[\u0026#39;function\u0026#39;][\u0026#39;parameters\u0026#39;][\u0026#39;properties\u0026#39;].keys())})\u0026#34; for tool in tools ]) prompt = f\u0026#34;\u0026#34;\u0026#34; Create a series of test cases for evaluating the tool-using capabilities of a language model. The test cases should be relevant to the domain and should utilize the provided tools. Each test case should include the following fields: - query: A question or request related to the domain. - expected_function: The function that should be called to answer the query. - function_arguments: The arguments that should be passed to the function. - expected_response: The expected response from the function. The available tools are: {tools_descriptions} Here are some examples to follow: {examples} Now, generate 10 more test cases in the same format utilizing the provided tools. Make sure the output format is JSON and enclose the result in triple backticks (```): \u0026#34;\u0026#34;\u0026#34; return prompt # Example usage tools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_medical_definition\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the definition of a medical term\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;term\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The medical term to define\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;term\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_treatment_options\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get treatment options for a disease\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;disease\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The disease to get treatment options for\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;disease\u0026#34;] } } } ] examples = \u0026#34;\u0026#34;\u0026#34; [ { \u0026#34;query\u0026#34;: \u0026#34;What is diabetes?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_medical_definition\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;term\u0026#34;: \u0026#34;diabetes\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Diabetes is a chronic condition that affects the way the body processes blood sugar (glucose).\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;How can hypertension be treated?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_treatment_options\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;disease\u0026#34;: \u0026#34;hypertension\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Treatment options for hypertension include lifestyle changes, such as diet and exercise, and medications like ACE inhibitors, beta-blockers, and diuretics.\u0026#34; } ] \u0026#34;\u0026#34;\u0026#34; sys_prompt = generate_test_cases_from_tools(tools, examples) messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: sys_prompt} ] resp = chat_completion_request(messages, json_mode=True) test_cases = eval(resp.choices[0].message.content) 参考 Function-calling \u0026amp; JSON-mode Evaluation\nBenchmarking Agent Tool Use\nWhat Are Tools Anyway? A Survey from the Language Model Perspective\nBerkeley Function Calling Leaderboard\nToolformer\nLATM\nAPI-Bank\nTool-bench\nToolAlpaca\n","permalink":"https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/","summary":"\u003cp\u003e本文将简单介绍如何评价LLM的tool-using 能力。\u003c/p\u003e\n\u003ch2 id=\"引言\"\u003e引言\u003c/h2\u003e\n\u003cp\u003e在工具使用评估方面，过去的研究主要有以下几种思路：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e对比工具使用和纯LLM在基准测试上的分数\u003c/strong\u003e：例如\u003ca href=\"https://arxiv.org/abs/2302.04761\"\u003eToolformer\u003c/a\u003e和\u003ca href=\"https://arxiv.org/abs/2305.17126\"\u003eLATM\u003c/a\u003e。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e在Toolformer研究中，通过下游任务如语言模型评估基准测试、数学推理任务和问答任务来验证工具使用的有效性。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLATM则采用了来自BigBench的六个数据集进行评估。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e测试工具使用的准确率和响应质量\u003c/strong\u003e：例如\u003ca href=\"https://arxiv.org/abs/2304.08244\"\u003eAPI-Bank\u003c/a\u003e。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e在评估过程中，首先初始化评估系统，确保每个API的数据库包含默认值。然后，将预测的API调用与手动标注的API调用进行比较，以确定它们的一致性。响应评估则使用ROUGE-L指标。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e利用LLM对工具使用的效果进行评价\u003c/strong\u003e：例如Tool-bench。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003etwo evaluation metrics:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePass Rate\u003c/strong\u003e: Calculates the proportion of successfully completing an instruction within limited OpenAI API calls.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePreference\u003c/strong\u003e: Measured by comparing two answers (action sequences) for a given instruction.We pre-define a set of criteria for a better answer, which are organized as prompts for ChatGPT.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e构造虚拟运行环境，测试代理与环境的交互结果\u003c/strong\u003e：例如ToolAlpaca。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e利用LLM模拟环境（用户代理和助手代理），并使用GPT-4对ToolAlpaca模型进行机器评估，评估其使用各种未见工具的能力。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e对于绝大多数企业和垂直场景下， 其中思路1需要构建额外的测试集成本比较高（但还是有必要的）， 而思路4构造虚拟运行环境实际上并不现实； 所以还是选择思路2，外加通过思路3辅助判断；换句话说， 根据场景，构造工具列表和工具调用的ground-truth（包括函数名， 和传入参数）  ，在存在歧义时，采用ROUGE评价响应质量， 或者使用LLM判断响应结果并评价。\u003c/p\u003e\n\u003cp\u003e顺带提一下Langchain 项目中有关Agent的tool-using能力测试的内容， 不过由于Langchain项目又臭又长，且有很大的局限性， 这里只讨论其思路。\u003c/p\u003e","title":"Agent学习笔记： 如何验证模型的tool-using能力"},{"content":"Sistemas Inestables是来自智利圣地亚哥的器乐三重奏乐队。他们的音乐以行进和复杂的结构为特征，并伴随着噪音和氛围的层次。\n风格与特点 多元音乐风格：Sistemas Inestables 融合了噪音、氛围、数学摇滚和后摇滚等多种音乐风格。他们通过混合装置、合成器和鼓机编织出复杂的音纹和和谐，形成了独特的音乐特点。\n即兴创作与实验：乐队在创作过程中强调即兴演奏与实验，探索人与机器的对话和斗争，创造出既真实又虚拟、既模拟又数字、既人工又自然的音乐体验。\n影响与灵感 主要影响：Sistemas Inestables 受到多位艺术家的影响，包括 Godspeed You! Black Emperor, Akinetón Retard, Cómo Asesinar a Felipes, tortuganónima, Pol del Sur, Jaga Jazzist, Floating Points, Brandt Brauer Frick, Jon Hopkins, Nils Frahm, The Cinematic Orchestra, Battles, Tortoise, Do Make Say Think 等。\n灵感来源：他们的创作灵感来自环境、过程、情感和挑战，音乐表现出对当下社会问题的深刻反思和回应，也是对当前事件的抗议和改变的呼吁。\n成立与早期阶段 2016年，Mauricio、Javier Hechenleitner 和 José Tomás 决定开始一个新项目。经过一年的实验，Sistemas Inestables 诞生。在创作首张专辑《O》的过程中，他们进行了大量即兴演奏，寻找三人之间的音乐连接，逐渐形成了他们的音乐风格。\n早期演出与发展 2017年，乐队首次在圣地亚哥的 La Batuta 现场演出，并在哥伦比亚和阿根廷进行了巡演。2018年，他们参加了由 LeRockPsicophonique 唱片公司组织的首届音乐节，并在智利各地巡演。\n国际巡演与成长 2019年，乐队首次前往欧洲，在巴塞罗那的 Primavera Sound 音乐节和比利时的 Dunk! Fest 演出。年底，他们邀请长期担任乐队音响工程师的 Santiago Corvalán 加入乐队担任贝斯手。\n新音乐与当前发展 尽管受到智利社会动荡和新冠疫情的影响，Sistemas Inestables 在此期间创作了新音乐，并在2022年发布了新 EP《Oppidum》。该 EP 的两首曲目“Signum”和“Praedatum”描绘了城市的反乌托邦景象，回应了社会和环境危机。\n乐队简介（翻译自官方Spotify介绍） Sistemas Inestables 是来自智利圣地亚哥的一个器乐三重奏。他们的音乐以进步和复杂的结构为特征，并伴随着噪音和氛围的层次。清晰的旋律和明确的部分从这种声音中浮现，创造出音乐旅程的演变，并通过不同的环境进行叙述。\nSistemas Inestables es un trío instrumental de Santiago de Chile. Su música se caracteriza por ser progresiva y de estructuras complejas, junto a capas de ruido y texturas ambientales. Melodías claras y secciones definidas emergen de este paisaje sonoro, creando una evolución en el viaje musical y narrando a través de diferentes ambientes.\nJavier、Santiago和José Tomás发挥到极致，操作一套混合乐器设备，将传统爵士和摇滚乐器与电子键盘、合成器、鼓机和模拟效果器的组合形成对比，赋予他们独特且充满活力的声音。所有这些元素与抽象的视觉方案同步，创造出一种简约却强大的现场体验。在 Sistemas Inestables 的音乐中，没有图像或形象化的表达，这是一场真实且原始的旅程。\nJavier, Santiago y José Tomás operan (al límite de sus capacidades) un set híbrido que contrasta la utilización de instrumentos tradicionales del jazz y el rock, con un conjunto electrónico de teclados, sintetizadores, cajas de ritmos y efectos análogos que les confiere un sonido único y vibrante. Todos estos recursos se sincronizan con una propuesta visual abstracta para crear una experiencia minimalista pero poderosa en directo. En S/I no hay imágenes ni representación, es un viaje concreto y elemental.\n自2017年4月首次登场以来，Sistemas Inestables 已在国际上巡回演出，在美国、阿根廷、乌拉圭、秘鲁、厄瓜多尔、哥伦比亚、比利时、西班牙和智利等国家的各种场馆和音乐节上演出。2018年9月，他们发行了首张专辑《O》，随后在2019年比利时 Dunk! 后摇滚音乐节上录制了一张现场和重新编排的专辑。目前，Sistemas Inestables 正在发布一系列 EP，这些 EP 将形成一个三部曲，最终将在未来几个月内发行他们的下一张完整专辑。\nDesde su debut en abril de 2017, SISTEMAS INESTABLES ha realizado giras internacionales, presentándose en diversas salas y festivales de países como Estados Unidos, Argentina, Uruguay, Perú, Ecuador, Colombia, Bélgica, España y Chile. En septiembre de 2018, lanzaron su álbum debut \u0026ldquo;O\u0026rdquo;, al que desde entonces le ha seguido un álbum de recomposiciones y en directo, grabado en el festival belga de post-rock Dunk! Festival en 2019. Actualmente S/I se encuentra lanzando una serie de EPs, trilogía que conformará el próximo larga duración de la banda a lanzarse los próximos meses.\n参考 Spotify:Sistemas Inestables\nTREEFORT FEST 2024 PROFILE: SISTEMAS INESTABLES\nFOCUS // SISTEMAS INESTABLES: HOW TO FUNCTION IN THE MIDST OF CHAOS\nSISTEMAS INESTABLES\n","permalink":"https://niraya666.github.io/musik/intorduction_of_si/","summary":"\u003cp\u003eSistemas Inestables是来自智利圣地亚哥的器乐三重奏乐队。他们的音乐以行进和复杂的结构为特征，并伴随着噪音和氛围的层次。\u003c/p\u003e\n\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/artist/6RGPbHSp1Rby5CCzH7psxm?utm_source=generator\" width=\"100%\" height=\"352\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\n\u003ch3 id=\"风格与特点\"\u003e风格与特点\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e多元音乐风格\u003c/strong\u003e：Sistemas Inestables 融合了噪音、氛围、数学摇滚和后摇滚等多种音乐风格。他们通过混合装置、合成器和鼓机编织出复杂的音纹和和谐，形成了独特的音乐特点。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e即兴创作与实验\u003c/strong\u003e：乐队在创作过程中强调即兴演奏与实验，探索人与机器的对话和斗争，创造出既真实又虚拟、既模拟又数字、既人工又自然的音乐体验。\u003c/p\u003e\n\u003ch3 id=\"影响与灵感\"\u003e影响与灵感\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e主要影响\u003c/strong\u003e：Sistemas Inestables 受到多位艺术家的影响，包括 Godspeed You! Black Emperor, Akinetón Retard, Cómo Asesinar a Felipes, tortuganónima, Pol del Sur, Jaga Jazzist, Floating Points, Brandt Brauer Frick, Jon Hopkins, Nils Frahm, The Cinematic Orchestra, Battles, Tortoise, Do Make Say Think 等。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e灵感来源\u003c/strong\u003e：他们的创作灵感来自环境、过程、情感和挑战，音乐表现出对当下社会问题的深刻反思和回应，也是对当前事件的抗议和改变的呼吁。\u003c/p\u003e\n\u003ch3 id=\"成立与早期阶段\"\u003e成立与早期阶段\u003c/h3\u003e\n\u003cp\u003e2016年，Mauricio、Javier Hechenleitner 和 José Tomás 决定开始一个新项目。经过一年的实验，Sistemas Inestables 诞生。在创作首张专辑《O》的过程中，他们进行了大量即兴演奏，寻找三人之间的音乐连接，逐渐形成了他们的音乐风格。\u003c/p\u003e\n\u003ch3 id=\"早期演出与发展\"\u003e早期演出与发展\u003c/h3\u003e\n\u003cp\u003e2017年，乐队首次在圣地亚哥的 La Batuta 现场演出，并在哥伦比亚和阿根廷进行了巡演。2018年，他们参加了由 LeRockPsicophonique 唱片公司组织的首届音乐节，并在智利各地巡演。\u003c/p\u003e\n\u003ch3 id=\"国际巡演与成长\"\u003e国际巡演与成长\u003c/h3\u003e\n\u003cp\u003e2019年，乐队首次前往欧洲，在巴塞罗那的 Primavera Sound 音乐节和比利时的 Dunk! Fest 演出。年底，他们邀请长期担任乐队音响工程师的 Santiago Corvalán 加入乐队担任贝斯手。\u003c/p\u003e","title":"【冷门乐队推荐】Sistemas Inestables"},{"content":"上周看了《坂本龙一：Opus》，特别喜欢其中有一首未收录在之前作品中的曲目《for Johann》\n第一反应是这首曲子可能是献给已故的冰岛作曲家Johann Johannsson，也是我最喜欢的音乐人之一\n不过，我找不到确切的证据\n万一是巴赫（Johann Sebastian Bach） 也有可能\n总觉得这首歌的旋律走向和Johann Johannsson的作品有某种神似，也有可能是我的错觉罢了吧\n试着弹一下这首歌， 顺带用AnthemScore扒了下谱子 可能有些小错误，但我希望能将这份音乐传递下去\n希望大家喜欢\nHe’s gone, but the music remains.\nありがとうございます\n感谢教授的最后礼物， 也感谢同样被迫包场的另两位陌生人\n","permalink":"https://niraya666.github.io/musik/for_johann/","summary":"\u003cp\u003e上周看了《坂本龙一：Opus》，特别喜欢其中有一首未收录在之前作品中的曲目《for Johann》\u003c/p\u003e\n\u003cp\u003e第一反应是这首曲子可能是献给已故的冰岛作曲家Johann Johannsson，也是我最喜欢的音乐人之一\u003c/p\u003e\n\u003cp\u003e不过，我找不到确切的证据\u003c/p\u003e\n\u003cp\u003e万一是巴赫（Johann Sebastian Bach） 也有可能\u003c/p\u003e\n\u003cp\u003e总觉得这首歌的旋律走向和Johann Johannsson的作品有某种神似，也有可能是我的错觉罢了吧\u003c/p\u003e\n\u003cp\u003e试着弹一下这首歌， 顺带用AnthemScore扒了下谱子\n可能有些小错误，但我希望能将这份音乐传递下去\u003c/p\u003e\n\u003cp\u003e希望大家喜欢\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/music/for_johnann/1.png\" alt=\"\"  /\u003e\n\n\u003cimg loading=\"lazy\" src=\"/img/music/for_johnann/2.png\" alt=\"\"  /\u003e\n\n\u003cimg loading=\"lazy\" src=\"/img/music/for_johnann/3.png\" alt=\"\"  /\u003e\n\n\u003cimg loading=\"lazy\" src=\"/img/music/for_johnann/4.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eHe’s gone, but the music remains.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eありがとうございます\u003c/p\u003e\n\u003cp\u003e感谢教授的最后礼物， 也感谢同样被迫包场的另两位陌生人\u003c/p\u003e","title":"【钢琴谱分享】坂本龙一《for Johann》"},{"content":"AI GPT4-o 发布 OpenAI 推出了新一代多模态模型 GPT-4o，它不仅支持文本输入，还能处理语音和视频输入。这款模型在速度、成本和性能方面都得到了显著提升，相比之前的版本快两倍，成本降低了50%，并且能够处理更长的输出\nChatGPT数据分析 最新的 ChatGPT 界面允许用户通过选择行或列来提问，并进行数据可视化。\nMistral-7B-v0.3 Mistral-7B-v0.3 模型引入了词表扩展功能，并支持工具调用\nDeepSeek-V2 该模型通过多头潜在注意力（MLA）和 DeepSeekMoE 架构，实现了高效推理，每个token仅激活 210 亿参数，从而显著降低了计算成本。\n关注的开源项目 Cover-Agent Cover-Agent\nCodiumAI Cover-Agent: An AI-Powered Tool for Automated Test Generation and Code Coverage Enhancement!\n自动化和增强测试的生成，目前主要是单元测试\nAnyNode v0.1 AnyNode\nA ComfyUI Node that uses the power of LLMs to do anything with your input to make any type of output.\nLlamaFS LlamaFS\n基于Llama 3模型的自组织文件管理系统，能自动重命名和组织文件，支持多种文件类型，包括图像和音频\nDSPy DSPy\nDSPy is a framework for algorithmically optimizing LM prompts and weights, especially when LMs are used one or more times within a pipeline. To use LMs to build a complex system without DSPy, you generally have to: (1) break the problem down into steps, (2) prompt your LM well until each step works well in isolation, (3) tweak the steps to work well together, (4) generate synthetic examples to tune each step, and (5) use these examples to finetune smaller LMs to cut costs. Currently, this is hard and messy: every time you change your pipeline, your LM, or your data, all prompts (or finetuning steps) may need to change.\nHoarder Hoarder\n自托管的全能书签管理应用，支持链接、笔记和图片的存储，具备基于AI的自动标签化和全文搜索功能\n我的足迹 杭州，大阪，泉州\n影音\u0026amp;阅读记录 精选歌单 演出 5.03 Fri. 闪千手音乐节 草东\u0026amp;万青 .et.al 杭州 第一次在现场看到了草东和万青，也发现了一些之前没接触过的乐队， 如HONNE。虽然很累， 但也非常开心。不论是草东的全场大合唱，还是惘闻演出时远处意外出现的烟花， 抑或是万青在《大石碎胸口》结尾处的solo。我他妈地热爱这个世界。\n5.16 Thur. Athletics \u0026amp; Pg.lost 万代南梦宫 仍然处在Pg.lost 的截断反应中\n5.22 Wed. the Ocean \u0026amp; A burial at sea 南梦宫2F 5.25 Sat. Max Cooper\u0026amp;吴卓玲 万代南梦宫 电影 《坂本龙一：杰作》\n书\u0026amp;阅读摘录 本月完成：《一人企业方法论》，《疯狂的尿酸：不只是痛风》\n中文互联网正在加速崩塌 我们曾经以为互联网可以保留一切，但结果是一切都没能保留。\n主要原因可能是两个： 一是经济原因。\n二是监管原因。\n本质上，互联网内容和生命一样，也受进化论的支配。其存在的标准只有一条：以尽可能低的成本争取尽可能多的注意力。\n新生代也许还能看看朋友圈，但是朋友圈也越来越多“三天可见”，越来越沉默不语。\nElon Musk 访谈： 讲述自己对于突破社交障碍的心得 不要把注意力集中在自己身上 - 告诉自己「别紧张」反而会更紧张 - 你应该把注意力向外发散 询问对方问题，倾听对方回答 - 社交能力是天生的，你只需要发挥它 - 精通这项技能需要3-4年，但是非常值得\n分享一下我的信息流戒断方法（from X 上的 Andrew Bamboo） 社媒账号（即刻、推特、公众号）。作为记事本来用（我的日常随笔记录在 flomo 上，私人的内容仅自己可见，对别人有用的内容会同步在社媒平台上，长篇的可以跨越时间的会进一步沉淀在公众号上）；\nPerplexity 产品开发的新模式 精简管理层： 他们优先考虑自我驱动的独立贡献者，避免聘请那些主要通过指导他人来发挥作用的管理者。 因此，管理流程或领导团队的能力并不是首要考虑的。我们更看重那些能对用户产生显著影响的优秀个体贡献者，而不是仅限于他们所在公司的影响。 但我们不再那么需要那些主导他人工作的人才，因为有了人工智能，这已经不是必需的了。\n对未来的洞察： Johnny 预见到，随着时间的推移，那些既懂技术又具备产品敏感度的项目经理或工程师，将成为公司中最具价值的资产。 我认为未来，整个行业的管理层会趋于精简。如果我要预测，具有技术背景且懂得产品美学的产品经理或工程师，将成为公司最宝贵的资产。\n虽然高层的目标和方向是由上而下制定的，但许多新的想法却是从基层团队中产生的。\nMilestone 第一次独自一人出国：日本 第一次音乐节：闪千手音乐节 这个月发了5篇blog 在小红书发攻略：达到了1000+阅读和100+收藏赞 把游记同步到了马蜂窝 ","permalink":"https://niraya666.github.io/monthly/2024-05/","summary":"\u003ch2 id=\"ai\"\u003eAI\u003c/h2\u003e\n\u003ch3 id=\"gpt4-o-发布\"\u003eGPT4-o 发布\u003c/h3\u003e\n\u003cp\u003eOpenAI 推出了新一代多模态模型 GPT-4o，它不仅支持文本输入，还能处理语音和视频输入。这款模型在速度、成本和性能方面都得到了显著提升，相比之前的版本快两倍，成本降低了50%，并且能够处理更长的输出\u003c/p\u003e\n\u003ch3 id=\"chatgpt数据分析\"\u003eChatGPT数据分析\u003c/h3\u003e\n\u003cp\u003e最新的 ChatGPT 界面允许用户通过选择行或列来提问，并进行数据可视化。\u003c/p\u003e\n\u003ch3 id=\"mistral-7b-v03\"\u003eMistral-7B-v0.3\u003c/h3\u003e\n\u003cp\u003eMistral-7B-v0.3 模型引入了词表扩展功能，并支持工具调用\u003c/p\u003e\n\u003ch3 id=\"deepseek-v2\"\u003eDeepSeek-V2\u003c/h3\u003e\n\u003cp\u003e该模型通过多头潜在注意力（MLA）和 DeepSeekMoE 架构，实现了高效推理，每个token仅激活 210 亿参数，从而显著降低了计算成本。\u003c/p\u003e\n\u003ch2 id=\"关注的开源项目\"\u003e关注的开源项目\u003c/h2\u003e\n\u003ch3 id=\"cover-agent\"\u003e\u003cstrong\u003eCover-Agent\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/Codium-ai/cover-agent\"\u003eCover-Agent\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eCodiumAI Cover-Agent: An AI-Powered Tool for Automated Test Generation and Code Coverage Enhancement!\u003c/p\u003e\n\u003cp\u003e自动化和增强测试的生成，目前主要是单元测试\u003c/p\u003e\n\u003ch3 id=\"anynode-v01\"\u003e\u003cstrong\u003eAnyNode v0.1\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/lks-ai/anynode\"\u003eAnyNode\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eA ComfyUI Node that uses the power of LLMs to do anything with your input to make any type of output.\u003c/p\u003e\n\u003ch3 id=\"llamafs\"\u003e\u003cstrong\u003eLlamaFS\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/iyaja/llama-fs\"\u003eLlamaFS\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e基于Llama 3模型的自组织文件管理系统，能自动重命名和组织文件，支持多种文件类型，包括图像和音频\u003c/p\u003e\n\u003ch3 id=\"dspy\"\u003e\u003cstrong\u003eDSPy\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/stanfordnlp/dspy\"\u003eDSPy\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDSPy is a framework for algorithmically optimizing LM prompts and weights\u003c/strong\u003e, especially when LMs are used one or more times within a pipeline. To use LMs to build a complex system \u003cem\u003ewithout\u003c/em\u003e DSPy, you generally have to: (1) break the problem down into steps, (2) prompt your LM well until each step works well in isolation, (3) tweak the steps to work well together, (4) generate synthetic examples to tune each step, and (5) use these examples to finetune smaller LMs to cut costs. Currently, this is hard and messy: every time you change your pipeline, your LM, or your data, all prompts (or finetuning steps) may need to change.\u003c/p\u003e","title":"2024-05 月刊"},{"content":"2024年 夏\n这是我第一次踏上泉州这片土地，虽然我是厦门人，已经快三十岁了，却一直没有机会来这座近在咫尺的城市。\n泉州在我想象中，是一座充满历史韵味的地方，同时也被一些暴发户的繁荣所点缀。几年前，这座城市成功申遗，从此逐渐成为小众旅游的热门选择。泉州的古老街区、传统建筑和浓厚的文化氛围，让人忍不住想一探究竟。\n大学时，我有一位好友家在泉州。我们是班里唯二的福建人，因此自然成了很好的朋友。每次听他讲起泉州的美食、风景，总让我心生向往。\n这次借着回家的机会，我终于决定亲自走一趟泉州。\n泉州，我来了！\n初印象 初到泉州，路上穿梭的电动车给我留下了深刻的第一印象。这些电动车在街头巷尾自由穿行，让我一度产生了身处越南的错觉。或许，这正是泉州的独特之处——在传统与现代之间，在历史与现实之中，找到一种和谐的平衡。\n作为古城，鲤城区似乎尽可能地保留着过去的模样。漫步在古城，却能产生一种记忆中的故乡的错觉，这一切似乎都太像了。\n那些熟悉的景象和气息，让人倍感亲切。有人说过，“离开了，故乡才称之为故乡。”庆幸的是，故乡以另一种形式呈现在我的面前，尽管这不是我的故乡。\n在鲤城区，街头的小贩、古早风格的便利店、上了年纪的理发店，无时无刻不把我拉回到记忆的深处。\n人 历史离不开人，特别是一个个普通人\n正是这些普通人，构成了这座城市的血脉与灵魂。他们的日常琐事，他们的勤劳与坚韧，使得这座古老的城市充满了生机与活力。在他们的身上，我看到了泉州的过去、现在和未来。\n宗教 泉州作为海上丝绸之路的起点，在那辉煌的历史长河中，不仅是贸易和文化交流的中心，也吸引了大量的外来文化和宗教。佛教、道教、伊斯兰教、基督教等多种宗教在这里交汇融合，形成了独特的宗教文化景观。经过千年的融合与发展，这些宗教在泉州和谐共存，互相尊重，不分彼此。\n吃 牛肉店 阿秋牛排馆\n牛排并不是传统意义上的steak，而是采用香料和咖喱炖煮而成的牛排骨。招牌牛排非常推荐，炖得非常软烂，入口即化，肉质瞬间脱骨。咖喱的香气与牛肉的原汁原味相得益彰，不会掩盖肉本身的美味。用汤汁拌饭，可谓是一绝。\n不过，对于从小习惯了晋江牛肉店的闽南人来说，阿秋牛排馆的汤味道可能稍显清淡，不够浓郁，因此未必合所有人的口味。此外，这家店的价格也比其他店稍高一些。\n除此之外，我的收藏夹里还有几家值得尝试的牛排店：\n阿波牛肉店\n天财牛肉店\n阿泉全牛馆\n面线糊 平阿面线糊\n我去的这家平阿面线糊，在周末早上8点左右已经挤满了人，足见其受欢迎程度。\n与厦门地区加入了猪血、虾米的面线糊相比，泉州的面线糊更多地呈现出字面上的意思——就是很单纯的面线糊。所用的面线更加细碎，完全不用担心吃太慢会坨，因为这甚至可以用面线汤来形容。但喝上一口汤，你会发现这绝不是一碗普通的面线汤，在汤头上，店家一定是下足了功夫的。\n食客可以根据自己的喜好添加额外的食材，这种模式在闽南地区基本相同。在泉州，根据我对本地食客的观察，基本上必加的食材有：醋肉、卤大肠、套肠、豆干等等，当然绝对不能忘了加一根油条。\n除了平阿面线糊，我还收藏了几家值得一试的面线糊店：\n水门国仔老店\n后城面线糊\n文啊面线糊\n烧肉粽 东街肉粽店\n“烧”在闽南语中的含义既包含了特定的烹饪方法，也体现了食物的热度（与“烫”同音）。在“烧肉粽”中，“烧”不仅指将肉粽通过炖、煮、蒸等方式烹饪至入味，还强调了粽子食用时热乎的特质。\n与在厦门吃的肉粽不同，除了甜辣酱外，泉州的肉粽更喜欢加入花生酱，增添了一份独特的香气和口感。\n原本计划去侯阿婆烧肉粽，但可惜饭点人太多，只能临时改变计划，选择了不远处的东街肉粽店。不过这家感觉有些失望，对粽子没有太多感觉，店里的海蛎煎下的油太多，实在无法恭维。\n可惜这次时间有限，还有很多地方想去但没来得及去， 有很多想吃的没吃上\n下次再来\n","permalink":"https://niraya666.github.io/travel/%E6%B3%89%E5%B7%9E%E8%A1%8C%E8%AE%B0%E5%8F%A4%E5%9F%8E%E6%BC%AB%E6%AD%A5%E4%B8%8E%E5%91%B3%E8%95%BE%E4%B9%8B%E6%97%85/","summary":"\u003cp\u003e2024年 夏\u003c/p\u003e\n\u003cp\u003e这是我第一次踏上泉州这片土地，虽然我是厦门人，已经快三十岁了，却一直没有机会来这座近在咫尺的城市。\u003c/p\u003e\n\u003cp\u003e泉州在我想象中，是一座充满历史韵味的地方，同时也被一些暴发户的繁荣所点缀。几年前，这座城市成功申遗，从此逐渐成为小众旅游的热门选择。泉州的古老街区、传统建筑和浓厚的文化氛围，让人忍不住想一探究竟。\u003c/p\u003e\n\u003cp\u003e大学时，我有一位好友家在泉州。我们是班里唯二的福建人，因此自然成了很好的朋友。每次听他讲起泉州的美食、风景，总让我心生向往。\u003c/p\u003e\n\u003cp\u003e这次借着回家的机会，我终于决定亲自走一趟泉州。\u003c/p\u003e\n\u003cp\u003e泉州，我来了！\u003c/p\u003e\n\u003ch2 id=\"初印象\"\u003e初印象\u003c/h2\u003e\n\u003cp\u003e初到泉州，路上穿梭的电动车给我留下了深刻的第一印象。这些电动车在街头巷尾自由穿行，让我一度产生了身处越南的错觉。或许，这正是泉州的独特之处——在传统与现代之间，在历史与现实之中，找到一种和谐的平衡。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/50F93B5D-5373-486C-A785-4BB341FD0679_1_105_c.jpeg\" alt=\"50F93B5D-5373-486C-A785-4BB341FD0679_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e作为古城，鲤城区似乎尽可能地保留着过去的模样。漫步在古城，却能产生一种记忆中的故乡的错觉，这一切似乎都太像了。\u003c/p\u003e\n\u003cp\u003e那些熟悉的景象和气息，让人倍感亲切。有人说过，“离开了，故乡才称之为故乡。”庆幸的是，故乡以另一种形式呈现在我的面前，尽管这不是我的故乡。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/458F4F0B-B35C-4AC9-A447-0A38E69CC35D_1_105_c.jpeg\" alt=\"458F4F0B-B35C-4AC9-A447-0A38E69CC35D_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e在鲤城区，街头的小贩、古早风格的便利店、上了年纪的理发店，无时无刻不把我拉回到记忆的深处。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/218DC3D6-D630-49FE-9796-64202907D7E3_1_105_c.jpeg\" alt=\"218DC3D6-D630-49FE-9796-64202907D7E3_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"人\"\u003e人 \u003c/h2\u003e\n\u003cp\u003e历史离不开人，特别是一个个普通人\u003c/p\u003e\n\u003cp\u003e正是这些普通人，构成了这座城市的血脉与灵魂。他们的日常琐事，他们的勤劳与坚韧，使得这座古老的城市充满了生机与活力。在他们的身上，我看到了泉州的过去、现在和未来。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/E5CBBA91-C9A6-4F93-853D-009FD2D568C5_1_105_c.jpeg\" alt=\"E5CBBA91-C9A6-4F93-853D-009FD2D568C5_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/BC390CC0-02B4-45A6-9266-1C7638C75D76_1_105_c.jpeg\" alt=\"BC390CC0-02B4-45A6-9266-1C7638C75D76_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/3F165220-A99D-4E4F-92AB-94F572A0B231_1_105_c.jpeg\" alt=\"3F165220-A99D-4E4F-92AB-94F572A0B231_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/0DA901A1-F620-4B8A-A722-63E95EDAA536_1_105_c.jpeg\" alt=\"0DA901A1-F620-4B8A-A722-63E95EDAA536_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/46A3B7FB-2306-4661-8B47-7DEDB3FF20AE_1_105_c.jpeg\" alt=\"46A3B7FB-2306-4661-8B47-7DEDB3FF20AE_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"宗教\"\u003e宗教\u003c/h2\u003e\n\u003cp\u003e泉州作为海上丝绸之路的起点，在那辉煌的历史长河中，不仅是贸易和文化交流的中心，也吸引了大量的外来文化和宗教。佛教、道教、伊斯兰教、基督教等多种宗教在这里交汇融合，形成了独特的宗教文化景观。经过千年的融合与发展，这些宗教在泉州和谐共存，互相尊重，不分彼此。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/22205648-89A8-41BE-B99C-56850A28D252_1_105_c.jpeg\" alt=\"22205648-89A8-41BE-B99C-56850A28D252_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/BB0999F1-EDEA-4AA2-BA72-D6954CD12BA8_1_105_c.jpeg\" alt=\"BB0999F1-EDEA-4AA2-BA72-D6954CD12BA8_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/5A6D2D91-D86E-4BBA-9248-272095117CE9_1_105_c.jpeg\" alt=\"5A6D2D91-D86E-4BBA-9248-272095117CE9_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"吃\"\u003e吃\u003c/h2\u003e\n\u003ch3 id=\"牛肉店\"\u003e牛肉店\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/FEA7D1E0-80AD-45BC-B2F9-E3BF31A1130A_1_201_a.jpg\" alt=\"FEA7D1E0-80AD-45BC-B2F9-E3BF31A1130A_1_201_a.jpg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e阿秋牛排馆\u003c/p\u003e\n\u003cp\u003e牛排并不是传统意义上的steak，而是采用香料和咖喱炖煮而成的牛排骨。招牌牛排非常推荐，炖得非常软烂，入口即化，肉质瞬间脱骨。咖喱的香气与牛肉的原汁原味相得益彰，不会掩盖肉本身的美味。用汤汁拌饭，可谓是一绝。\u003c/p\u003e\n\u003cp\u003e不过，对于从小习惯了晋江牛肉店的闽南人来说，阿秋牛排馆的汤味道可能稍显清淡，不够浓郁，因此未必合所有人的口味。此外，这家店的价格也比其他店稍高一些。\u003c/p\u003e\n\u003cp\u003e除此之外，我的收藏夹里还有几家值得尝试的牛排店：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e阿波牛肉店\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e天财牛肉店\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e阿泉全牛馆\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"面线糊\"\u003e面线糊\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/FC2DD610-927E-4E1E-829A-420ACD1A0418_1_105_c.jpeg\" alt=\"FC2DD610-927E-4E1E-829A-420ACD1A0418_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e平阿面线糊\u003c/p\u003e\n\u003cp\u003e我去的这家平阿面线糊，在周末早上8点左右已经挤满了人，足见其受欢迎程度。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/0615C07D-8BA9-484A-BBFC-FF59E764955B_1_201_a.jpg\" alt=\"0615C07D-8BA9-484A-BBFC-FF59E764955B_1_201_a.jpg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e与厦门地区加入了猪血、虾米的面线糊相比，泉州的面线糊更多地呈现出字面上的意思——就是很单纯的面线糊。所用的面线更加细碎，完全不用担心吃太慢会坨，因为这甚至可以用面线汤来形容。但喝上一口汤，你会发现这绝不是一碗普通的面线汤，在汤头上，店家一定是下足了功夫的。\u003c/p\u003e\n\u003cp\u003e食客可以根据自己的喜好添加额外的食材，这种模式在闽南地区基本相同。在泉州，根据我对本地食客的观察，基本上必加的食材有：醋肉、卤大肠、套肠、豆干等等，当然绝对不能忘了加一根油条。\u003c/p\u003e\n\u003cp\u003e除了平阿面线糊，我还收藏了几家值得一试的面线糊店：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e水门国仔老店\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e后城面线糊\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e文啊面线糊\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"烧肉粽\"\u003e烧肉粽\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/F2CA54E0-ADE3-42B7-A243-D90C9B559D7B_1_105_c.jpeg\" alt=\"F2CA54E0-ADE3-42B7-A243-D90C9B559D7B_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e东街肉粽店\u003c/p\u003e\n\u003cp\u003e“烧”在闽南语中的含义既包含了特定的烹饪方法，也体现了食物的热度（与“烫”同音）。在“烧肉粽”中，“烧”不仅指将肉粽通过炖、煮、蒸等方式烹饪至入味，还强调了粽子食用时热乎的特质。\u003c/p\u003e\n\u003cp\u003e与在厦门吃的肉粽不同，除了甜辣酱外，泉州的肉粽更喜欢加入花生酱，增添了一份独特的香气和口感。\u003c/p\u003e\n\u003cp\u003e原本计划去侯阿婆烧肉粽，但可惜饭点人太多，只能临时改变计划，选择了不远处的东街肉粽店。不过这家感觉有些失望，对粽子没有太多感觉，店里的海蛎煎下的油太多，实在无法恭维。\u003c/p\u003e","title":"泉州行记：古城漫步与味蕾之旅"},{"content":"2024-春夏之交 大阪\n旅行时间2天3夜\n在多邻国上学了快一年的散装日语，受到了看大河剧、日本电影和玩日本游戏的影响，我决定利用刚获得的三年多次入境签证，以及51假期的空闲时间，去日本看看。考虑到时间限制，我选择了关西的交通枢纽和经济中心——大阪，作为这次日本之行的第一站。\n对于日本，尤其是大阪，我的第一印象是热门景区和场所人非常多。这主要是因为赶上了日本的10天黄金周，同时由于日元汇率低迷，大量外国人涌入日本消费和旅游。然而，在居民区，特别是我所住的浪速区，情况则大为不同，晚上和清晨几乎见不到几个人，给人一种非常萧条的感觉。中国人会说，这叫做“缺乏人气”。此外，随处可见的大乌鸦加深了这种萧条感。或许这也可能是宫崎英高在《黑魂》系列中乌鸦的灵感来源吧。在日本，乌鸦似乎被视为吉祥的象征。\n游玩篇 出了民宿，我的第一站是不远处的难波八阪神社。这里以其狮子头形状的大狮子殿闻名，成为了一处热门的打卡地点。据说，这个狮子头具有驱除灾难和带来好运的力量。\n经过两站地下铁，即可到达动物园前站， 这里是新世界的入口。\n新世界，曾是日本向西方看齐、力图“脱亚入欧”时的产物。在20世纪初，日本大量吸纳西方文化元素，并在大阪建立了这一街区。然而时光流转，21世纪的今天，这里更像是一个保存良好的“旧世界”。街区内充满昭和时代的气息，从游戏厅、炸串店到浮夸的店面招牌，甚至粉红色影院，处处透露出时代的印记。\n作为泡沫经济时期产物， 粉红影院现在主要吸引了一部分中老年男性和非传统性别的人士。影院的“学生半价”标志显得有些讽刺，同时也透露出一种时代变迁的哀愁。鉴于这类场所的特殊性，不推荐旅行者单独前往。\n新世界的标志性建筑通天阁，则见证了区域的多重历史。这座铁塔最初在1912年仿照巴黎的埃菲尔铁塔建造，但在二战中因为“献纳”政策而被拆除，用其材料支持军工。通天阁的现代版本建于1956年，为了迎接万博会而重建，塔身醒目地印有日立的广告，成为了大阪的新地标。\n西成区，与新世界仅一路之隔，是大阪的旧城区。这个区域以较复杂的治安情况、流浪汉的较高出现率，以及成人娱乐业而知名。其中，著名的酒吧一条街和在中文互联网上广为人知的飞田新地均位于此地。游客在此区域应特别小心，避免随意使用手机或拍照，以尊重当地文化和增加个人安全。\n往新世界东北边走， 则能到达天王寺车站，商圈，以及以此命名此地的四天王寺。这里的天王寺车站作为从关西机场到大阪市区的两条主要电车线路之一JR西日本的终点站，同前面走过的西成区和新世界相比， 自然非常繁华。\n天王寺站前\nJR西日本机场线之HARUKA， 以Hello- Kitty涂装著称。\n日本的许多古迹因二战的轰炸和历史上的大地震而稀少，多数是在原址上修复或重建的。四天王寺就是这样的例子，它是日本历史悠久的寺庙之一，最初由飞鸟时期的圣德太子创建。虽然历经多次战火，我们今天所见的四天王寺主要是1957年后的重建。\n前往天王寺途中，偶遇的一心寺。\n在天王寺附近，我意外地发现了一个旧书集市。在那里，我用400日元买到了一本1994年的旧书。虽然还有很多书我想买想看，但考虑到海关的限制和行李空间的限制，我只能忍痛放弃。\n不可免俗的道顿堀格利高小人\n蟹道乐\n夜幕降临， 抵达梅田，乘坐hep five摩天轮，体验大阪夜景。\nhep five摩天轮\n第二天，前往大阪历史博物馆和大阪城， 以及shooping。\n大阪城\n大阪城始建于1583年，由丰臣秀吉下令建造。大阪城的天守阁如今是博物馆，展示了丰臣秀吉的生平、战国时期的武器和铠甲，以及大阪城的历史变迁。\n如果对于历史感兴趣的小伙伴， 大阪城公园边上的大阪历史博物馆也值得逛一逛。 大阪历史博物馆展示了古代大阪作为日本重要商业城市的发展过程，以及现代大阪的城市化进程。参观路线从10楼一路到7楼，6楼为特别展。\n日式连锁中餐王将的碳水加碳水再加碳水的定食\n剩下的shopping时间，逛了堂吉柯德，在西斋心桥发现一家二手唱片店\n位于 Big Step 大楼的地下一层，可惜根据网友的评论，似乎店面越来越小，东西越来越少了。\n似乎在日本不同城市，优衣库会有限定的特别款式， 在大阪则是御好烧（大阪烧）和章鱼烧的图案。\n美国村边上的小自由女神像\n攻略篇 入境 Visit Japan Web （VJW）为了替代入境卡而设计的， 需要在入境前提前申报，在入境时扫码即可。和纸质入境卡相比， 至少从我的观察而言， 使用VJW会更加快速，而没有存在需要排队的情况。\n交通 在大阪，从关西机场到市区有两条主要的铁路线路，南海电铁和JR西日本。两条线路隶属于不同的公司运营，在使用购票机购票时需要注意区分。平均时间在半个小时到一个小时不等， 票价在970到1800日元间，取决于所乘坐车次和制定席与否。除了特急列车（Rapi:t \u0026amp; HARUKA）,均和国内乘坐地铁没有太大差别。\n对于特急列车， 可以在网上买票，通过扫二维码进站，或者是在自助购票机上操作，以及通过刷西瓜卡进站，在候车处附近的机器上购买特急券。理论上有售票员会查票。\n赶了6:00的第一班Rapi:t alpha\n吃 居酒屋会在刚入座上小菜，也叫お通し（o-to-shi）,这部分一般是按人头收费，价格在330日元左右，一般是强制收取不给退的。\n日本餐厅一般是不提供打包服务的， 因为内用和外带属于不同执照，并且会因为害怕顾客吃坏肚子店家要负责任， 所以在日本餐厅，店家对于打包吃剩的食物十分抗拒。\n点餐时， 特别在旅游城市， 一般都会有多国语言版本或者是带图片版本的菜单， 有的店家甚至有扫码点单，可谓是非常友好的。所以， 只需要会几个日语单词即可，如\n日语单词 意思 罗马音 注文 点单 chūmon 会計 结账 kaikei メニュー 菜单 menyū 一つ 一个 hitotsu 二つ 两个 futatsu 三つ 三个 mittsu 少々 少量 shōshō 大盛り 大份 ōmori おすすめ 推荐 osusume トイレ 洗手间 toire 在便利店消费时，有几个常用的日语单词和表达可以帮助你更方便地交流。例如，店员可能会询问你是否需要袋子（ふくろ，fukuro）或加热食物（温め，atatame）。在不需要这些服务时，可以回答“大丈夫”（daijōbu，没关系）。\n在7-11一般是又店员负责扫码和年龄检查（买烟酒时），扫完后，有顾客在旁边的一台机器上选择付款方式并付款。当然，也可以直接出示Alipay 给店员， 店员会帮你操作的。\n大阪周游卡（Osaka Amazing Pass） or 大阪乐游券（Osaka e-Pass） 目前周游卡已停售(二日券)，一日券购买有效期截止到2024年6月30日。\n其中大阪周游卡需要购买后兑换成实体卡，兑换位置可查看 售票及换票点；而大阪乐游券直接展示二维码即可。二者都支持在Klook上购买。周游卡价格在¥3300包括了市区地铁随意乘坐， 乐游券价格为¥2400，只包括景点。\n用GPT-4 整理了一个周游卡和乐游券差异的表格（不能保证100%正确）：\n地点 (日本語) 地点 (中文) Location Regular fee Osaka Amazing Pass Osaka e-Pass 梅田スカイビル空中庭園展望台 梅田天空大厦空中庭园观景台 梅田 ¥ 1500 ✔️ ✔️ 梅田スカイビル・衣川邦彦天空美術館 梅田天空大厦衣川邦彦天空美术馆 梅田 ¥ 1000 ✔️ ✔️ HEP FIVE観覧車 HEP FIVE摩天轮 梅田 ¥ 600 ✔️ ✔️ 通天閣 通天阁 新世界 ¥ 1000 ✔️ ✔️ 通天閣タワースライダー 通天阁塔滑梯 新世界 ¥ 1000 ✔️ ✔️ 四天王寺 (中心伽藍・本坊庭園) 四天王寺（中心伽蓝、本坊庭园） 四天王寺 ¥ 300 ✔️ ✔️ とんぼりリバークルーズ 道顿堀河巡航 道顿堀 ¥ 1200 ✔️ ✔️ 天王寺動物園 天王寺动物园 四天王寺 ¥ 500 ✔️ ❌ 中之島川クルーズ 中之岛河巡航 北区中之岛 ¥ 1500 ✔️ ✔️ 大阪国立国際美術館 大阪国立国际美术馆 北区中之岛 ¥ 430 ✔️ ❌ 道頓堀ZAZA 道顿堀ZAZA 道顿堀 ¥ 800 ✔️ ✔️ 上方浮世絵館 上方浮世绘馆 难波 ¥ 700 ✔️ ✔️ 大阪歴史博物館 大阪历史博物馆 大阪城 ¥ 600 ✔️ ❌ 大阪平和の殿堂 大阪和平馆 大阪城 ¥ 250 ✔️ ✔️ 大阪城天守閣 大阪城天守阁 大阪城 ¥ 600 ✔️ ❌ ワンダークルーズ 奇迹巡航 ¥ 1200 ✔️ ✔️ 大阪くらしの今昔館 大阪生活今昔馆 天神橋 ¥ 600 ✔️ ✔️ 天保山大観覧車 天保山大观览车 天保山 ¥ 1200 ✔️ ❌ グリオンミュージアム GLION博物馆 天保山 ¥ 1200 ✔️ ✔️ サンタマリア日帰りクルーズ 圣玛丽亚日游巡航 ¥ 1800 ✔️ ✔️ サンタマリア夜景クルーズ 圣玛丽亚夜景巡航 ¥ 2300 ✔️ ✔️ キャプテンライン 队长线 ¥ 1500 ✔️ ✔️ レゴランド・ディスカバリー・センター大阪 大阪乐高探索中心 ¥2800～¥3000 ✔️ ✔️ 咲洲コスモタワー展望台 咲洲宇宙塔展望台 ¥1000 ✔️ ✔️ ボートレース住之江 住之江赛艇 ¥ 1500 ✔️ ✔️ 大阪水上バスアクアライナー 大阪水上巴士Aqua-Liner ¥ 1800 ✔️ ✔️ 桜川お花見クルーズ 樱川赏花巡航 ¥ 1200 ✔️ ✔️ 夕日クルーズ「寄道」 夕阳巡航“YORIMICHI” ¥ 1500 ✔️ ✔️ 大阪城御座船 大阪城御座船 ¥ 1500 ✔️ ✔️ エンタープライズイノベーションミュージアム 创业创新博物馈 ¥ 300 ✔️ ✔️ 大阪城重要文化財櫓 大阪城重要文化财瞭 ¥ 800 ✔️ ❌ 大阪城西の丸庭園 大阪城西之丸庭园 ¥ 200 ✔️ ❌ 咲くやこの花館 咲く家这花馆 ¥ 500 ✔️ ❌ 長居植物園 长居植物园 ¥ 200 ✔️ ❌ 大阪市立自然史博物館 大阪市立自然历史博物馆 ¥ 300 ✔️ ❌ 堺利晶の杜 堺利晶之森 ¥ 300 ✔️ ❌ 堺市博物館 堺市博物馆 ¥ 200 ✔️ ❌ 万博記念公園（自然文化園、日本庭園） 万博纪念公园（自然文化园、日本庭园） ¥ 260 ✔️ ❌ OSAKA WHEEL（日本最大の観覧車） 大阪摩天轮（日本最大） 天保山 ¥ 1000 ✔️ ✔️ 大阪科学館 大阪科学馆 ¥ 400 ✔️ ❌ 桂陵園 桂陵园 ¥ 150 ✔️ ❌ 日向の湯 日向温泉 ¥ 800 ❌ ✔️ 海洋堂ホビーランド 海洋堂模型乐园 ¥ 1000 ❌ ✔️ 忍者トリックハウス（エディオン難波本店） 忍者特技屋（EDION难波本店） ¥ 1000 ❌ ✔️ 道頓堀ミュージアムなみき座 道顿堀剧场 ❌ ✔️ 更多的攻略建议参考：小气少年的部落格 这是我所发现的最完整的日本旅行攻略，成功解决了我的旅行前焦虑。 此外，在推荐一本书：《日本點餐完全圖解》，这本书详细介绍了在日本点餐的注意事项，甚至教会你怎么吃。\n感受篇 在这次的旅途中，我在网上上结识了两位旅游搭子，分别各搭了一天。\nA是一位出生于1998年的年轻人，帅气的外表下藏着近期感情伤痕的痛楚。他独自一人前来关西，试图通过旅行洗涤感情上的创伤。尽管我不愿轻易给人贴上标签，诸如“渣男”之类的称呼，但A的行为难免让人费解：他同时与四五名女生保持联系，不断在Tinder上寻找新的可能，对每一个路过的女性都有自己的评价。然而，从他的话语中，我逐渐感知到他背后隐藏的故事——那些使他变得如此的伤痕累累。通过他，我也间接了解了日本的一些风俗业及他的个人感受体验。\nR则是一位三十多岁的体制内员工，表面上看似普通，内心却充满了对现状的不满和对自由的渴望。他的思想深受那个时代的河殇文化与十年前“意林”文学的影响。在他的眼中，日本社会的方方面面几乎都是模范，而国内的绝大多数则恰恰相反。他甚至考虑过一个大胆的想法：辞去体制内的工作，“润”到日本。用互联网上的用语形容他的思想就是妥妥“反贼”和“润人”，但又何妨。R还是个爱酒如命的人。\n日本人究竟相信什么？道德伦理？法律？还是抽象的社会潜规则 事实上，日本社会的一个显著特点是高度的循规蹈矩。人们极其重视集体，与社会脱节被视为所能想到的最严酷的惩罚之一。也许正是因为日本人对意识形态和教条缺乏关注，他们格外重视外在形象，注重符合各种场合的姿态，因为“面子”比“里子”更重要。这演化成了一种行为模式，即在私下里怎么搞都行，但在公众面前一定要维护自己的“形象”。这意味着日本人本质上追求的是集体认同，极度避免被社会边缘化。\n“日本的情况则不同，原始信仰从未遭到更精致的官方律条的碾压。尽管不同宗教之间的区分不甚清晰，尤其是在最广泛的层面上，但佛寺和神社仍然共存并立。两种教派的仪式人们都参与，尽管不一定同时同地。这或许是因为日本人对意识形态和教条缺乏关注，却格外重视外在，重视符合各种场合的姿态，因为“面子”比“里子”更重要。”\n在这种文化氛围下，个人行为被严格的社会规范和集体利益所约束。脱离集体，被视为严重的社会惩罚，比法律制裁更为严酷。社会关系和集体认同对个人生活至关重要，因此日本人普遍面临巨大的心理压力，必须时刻注意自己的行为是否符合社会期望，以避免被边缘化。\n这种面子文化强调外在形象的维护。日本人非常重视在各种场合的表现和形象管理，不论是在公共场合的礼仪，还是在工作中的表现，维护良好的外在形象是必不可少的。在私下场合，日本人可能会表现出更大的灵活性和自由度，但在公开场合，他们会极力维护自己的公众形象，遵守社会规范和礼仪，以获得集体的认可和尊重。\n不论是飞田新地的挂羊头卖狗肉，还是游戏厅的老虎机，日本人总是有能力绕过所谓的规则，显示出一种极强的变通能力；但在公共区域场合下， 日本人又总能展现出一种死板地对于规则的严格遵守。\n日本社会的这种双重性在于，私下和公开行为的巨大反差。这种现象可以通过对集体认同和避免边缘化的强烈需求来解释。正如《日本之镜：日本文化中的英雄与恶人》一书中所提到的，“制约日本人行为的不是社会规则，而是一套抽象的道德教训。”\n然而，这种“抽象的道德”在中文语境下显得陌生。中国古代追求的是儒家的仁义道德，而日本的道德观念更多来源于神道教的泛神信仰，强调避免在社会上出丑。例如，须佐之男被放逐的故事就是一种道德教训，提醒人们避免类似的羞辱。日本人常说，只要不被逮个正着，避免在社会上出丑，就能够为所欲为，不必担心后果。\n","permalink":"https://niraya666.github.io/travel/%E5%A4%A7%E9%98%AA%E6%B8%B8%E8%AE%B0%E6%97%B6%E5%85%89%E4%BA%A4%E9%94%99%E4%B8%8B%E7%9A%84%E6%97%A5%E6%9C%AC%E6%8E%A2%E7%B4%A2/","summary":"\u003cp\u003e2024-春夏之交 大阪\u003c/p\u003e\n\u003cp\u003e旅行时间2天3夜\u003c/p\u003e\n\u003cp\u003e在多邻国上学了快一年的散装日语，受到了看大河剧、日本电影和玩日本游戏的影响，我决定利用刚获得的三年多次入境签证，以及51假期的空闲时间，去日本看看。考虑到时间限制，我选择了关西的交通枢纽和经济中心——大阪，作为这次日本之行的第一站。\u003c/p\u003e\n\u003cp\u003e对于日本，尤其是大阪，我的第一印象是热门景区和场所人非常多。这主要是因为赶上了日本的10天黄金周，同时由于日元汇率低迷，大量外国人涌入日本消费和旅游。然而，在居民区，特别是我所住的浪速区，情况则大为不同，晚上和清晨几乎见不到几个人，给人一种非常萧条的感觉。中国人会说，这叫做“缺乏人气”。此外，随处可见的大乌鸦加深了这种萧条感。或许这也可能是宫崎英高在《黑魂》系列中乌鸦的灵感来源吧。在日本，乌鸦似乎被视为吉祥的象征。\u003c/p\u003e\n\u003ch2 id=\"游玩篇\"\u003e游玩篇\u003c/h2\u003e\n\u003cp\u003e出了民宿，我的第一站是不远处的难波八阪神社。这里以其狮子头形状的大狮子殿闻名，成为了一处热门的打卡地点。据说，这个狮子头具有驱除灾难和带来好运的力量。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/D22F4C9A-23D6-472A-B359-5A9DC656DE03_1_201_a.jpeg\" alt=\"D22F4C9A-23D6-472A-B359-5A9DC656DE03_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e经过两站地下铁，即可到达动物园前站， 这里是新世界的入口。\u003c/p\u003e\n\u003cp\u003e新世界，曾是日本向西方看齐、力图“脱亚入欧”时的产物。在20世纪初，日本大量吸纳西方文化元素，并在大阪建立了这一街区。然而时光流转，21世纪的今天，这里更像是一个保存良好的“旧世界”。街区内充满昭和时代的气息，从游戏厅、炸串店到浮夸的店面招牌，甚至粉红色影院，处处透露出时代的印记。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/6DA5908E-2DB7-48B0-9254-7B189FB7848A_1_201_a.jpeg\" alt=\"6DA5908E-2DB7-48B0-9254-7B189FB7848A_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/AF7FD137-8145-4DE2-91D7-116908DC6985_1_201_a.jpeg\" alt=\"AF7FD137-8145-4DE2-91D7-116908DC6985_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e作为泡沫经济时期产物， 粉红影院现在主要吸引了一部分中老年男性和非传统性别的人士。影院的“学生半价”标志显得有些讽刺，同时也透露出一种时代变迁的哀愁。鉴于这类场所的特殊性，不推荐旅行者单独前往。\u003c/p\u003e\n\u003cp\u003e新世界的标志性建筑通天阁，则见证了区域的多重历史。这座铁塔最初在1912年仿照巴黎的埃菲尔铁塔建造，但在二战中因为“献纳”政策而被拆除，用其材料支持军工。通天阁的现代版本建于1956年，为了迎接万博会而重建，塔身醒目地印有日立的广告，成为了大阪的新地标。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/6C8F7905-91AC-46AA-BEC9-79AF3A362781_1_105_c.jpeg\" alt=\"6C8F7905-91AC-46AA-BEC9-79AF3A362781_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/0B1EA1C4-DFF3-4FDA-ACF8-EFDB75E7A3C0_1_201_a.jpeg\" alt=\"0B1EA1C4-DFF3-4FDA-ACF8-EFDB75E7A3C0_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e西成区，与新世界仅一路之隔，是大阪的旧城区。这个区域以较复杂的治安情况、流浪汉的较高出现率，以及成人娱乐业而知名。其中，著名的酒吧一条街和在中文互联网上广为人知的飞田新地均位于此地。游客在此区域应特别小心，避免随意使用手机或拍照，以尊重当地文化和增加个人安全。\u003c/p\u003e\n\u003cp\u003e往新世界东北边走， 则能到达天王寺车站，商圈，以及以此命名此地的四天王寺。这里的天王寺车站作为从关西机场到大阪市区的两条主要电车线路之一JR西日本的终点站，同前面走过的西成区和新世界相比， 自然非常繁华。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/2E815B2C-F25B-4CB4-A8FB-8D993265A540_1_105_c.jpeg\" alt=\"2E815B2C-F25B-4CB4-A8FB-8D993265A540_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e天王寺站前\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/42E69559-0A2E-4F15-8B70-C4CD15948641_1_201_a.jpeg\" alt=\"42E69559-0A2E-4F15-8B70-C4CD15948641_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eJR西日本机场线之HARUKA， 以Hello- Kitty涂装著称。\u003c/p\u003e\n\u003cp\u003e日本的许多古迹因二战的轰炸和历史上的大地震而稀少，多数是在原址上修复或重建的。四天王寺就是这样的例子，它是日本历史悠久的寺庙之一，最初由飞鸟时期的圣德太子创建。虽然历经多次战火，我们今天所见的四天王寺主要是1957年后的重建。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/C316DC6A-106E-494C-9926-6F5ED52B11E3_1_105_c.jpeg\" alt=\"C316DC6A-106E-494C-9926-6F5ED52B11E3_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/30F7FC2C-4BFA-494F-A0EC-1C07AEBA1A5E_1_105_c.jpeg\" alt=\"30F7FC2C-4BFA-494F-A0EC-1C07AEBA1A5E_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/3BFFEA31-F958-4239-99FD-23B5D8F91CFF_1_105_c.jpeg\" alt=\"3BFFEA31-F958-4239-99FD-23B5D8F91CFF_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e前往天王寺途中，偶遇的一心寺。\u003c/p\u003e\n\u003cp\u003e在天王寺附近，我意外地发现了一个旧书集市。在那里，我用400日元买到了一本1994年的旧书。虽然还有很多书我想买想看，但考虑到海关的限制和行李空间的限制，我只能忍痛放弃。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/A0D7A507-9B4F-44D5-AA9C-6B771FA520D2_1_201_a.jpeg\" alt=\"A0D7A507-9B4F-44D5-AA9C-6B771FA520D2_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/96FA58A9-C223-40F4-9BC8-33B6A50D4BF0_1_105_c.jpeg\" alt=\"96FA58A9-C223-40F4-9BC8-33B6A50D4BF0_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e不可免俗的道顿堀格利高小人\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/17DC7E7D-8CD2-4FCD-A19E-EC4BCE661FF1_1_105_c.jpeg\" alt=\"17DC7E7D-8CD2-4FCD-A19E-EC4BCE661FF1_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e蟹道乐\u003c/p\u003e\n\u003cp\u003e夜幕降临， 抵达梅田，乘坐hep five摩天轮，体验大阪夜景。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/90FE62D5-F899-43B8-BBB7-D44B242C2CEB_1_201_a.jpeg\" alt=\"90FE62D5-F899-43B8-BBB7-D44B242C2CEB_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003ehep five摩天轮\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/5C716546-81DE-4FE8-BEAF-EA239F27DAB4_1_201_a.jpeg\" alt=\"5C716546-81DE-4FE8-BEAF-EA239F27DAB4_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e第二天，前往大阪历史博物馆和大阪城， 以及shooping。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/FDCCBE76-D57A-4EC6-8D79-D19D9066390F_1_105_c.jpeg\" alt=\"FDCCBE76-D57A-4EC6-8D79-D19D9066390F_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e大阪城\u003c/p\u003e\n\u003cp\u003e大阪城始建于1583年，由丰臣秀吉下令建造。大阪城的天守阁如今是博物馆，展示了丰臣秀吉的生平、战国时期的武器和铠甲，以及大阪城的历史变迁。\u003c/p\u003e\n\u003cp\u003e如果对于历史感兴趣的小伙伴， 大阪城公园边上的大阪历史博物馆也值得逛一逛。 大阪历史博物馆展示了古代大阪作为日本重要商业城市的发展过程，以及现代大阪的城市化进程。参观路线从10楼一路到7楼，6楼为特别展。\u003c/p\u003e","title":"大阪游记：时光交错下的日本探索"},{"content":"为什么要进行文本分块？ 大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。\n如何进行文本分块 **块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。\n文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：\n句子分割（Sentence Splitting） 这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。\ntext = \u0026#34;...\u0026#34; # 你的文本 from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter( separator = \u0026#34;\\n\\n\u0026#34;, chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 递归字符文本分割（Recursive Character Text Splitting） 这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。\ntext = \u0026#34;...\u0026#34; # 你的文本 from langchain.text_splitter import RecursiveCharacterTextSplitter text_splitter = RecursiveCharacterTextSplitter( chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 根据langchain 的默认分隔条件 [\u0026quot;\\n\\n\u0026quot;, \u0026quot;\\n\u0026quot;, \u0026quot; \u0026quot;, \u0026quot;\u0026quot;] ,也就是会将text根据该分割条件的顺序（两个换行-\u0026gt;一个换行-\u0026gt;空格）将文本进行递归分割。\n针对特定文档的分割方法（Document Specific Splitting） 例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。\nlangchain 提供了一些常见文档的分割方法：\nmardown的分割逻辑\n[ # First, try to split along Markdown headings (starting with level 2) \u0026#34;\\n#{1,6} \u0026#34;, # Note the alternative syntax for headings (below) is not handled here # Heading level 2 # --------------- # End of code block \u0026#34;```\\n\u0026#34;, # Horizontal lines \u0026#34;\\n\\\\*\\\\*\\\\*+\\n\u0026#34;, \u0026#34;\\n---+\\n\u0026#34;, \u0026#34;\\n___+\\n\u0026#34;, # Note that this splitter doesn\u0026#39;t handle horizontal lines defined # by *three or more* of ***, ---, or ___, but this is not handled \u0026#34;\\n\\n\u0026#34;, \u0026#34;\\n\u0026#34;, \u0026#34; \u0026#34;, \u0026#34;\u0026#34;, ] python的分割逻辑：\n[ # First, try to split along class definitions \u0026#34;\\nclass \u0026#34;, \u0026#34;\\ndef \u0026#34;, \u0026#34;\\n\\tdef \u0026#34;, # Now split by the normal type of lines \u0026#34;\\n\\n\u0026#34;, \u0026#34;\\n\u0026#34;, \u0026#34; \u0026#34;, \u0026#34;\u0026#34;, ] 表格 重点提示： 后来在我们对数据块进行语义搜索时，直接从表格中匹配嵌入可能会比较困难。开发者常用的做法是，在提取了表格之后，对其进行关键信息提取。然后对这些关键信息的总结进行嵌入。如果这个总结的嵌入与你的搜索目标匹配，那么就可以把原始表格交给你的大语言模型处理。\n语义分块 目前的文本分块方法大多基于结构或字符数量，忽视了文本的实际语义内容。有效的语义分块应当确保内容上相似的数据被归类在一起，这样不仅有助于数据的组织，还能提升后续处理的效率和准确性。\n根据Greg的做法：寻找连续句子间的分割点， 即从第一句话开始，获取其嵌入，然后与第二句进行比较，以此类推。在寻找嵌入距离较大的“分割点”。如果距离超过了一定阈值，就认为这标志着新的语义段落的开始。\n可以通过以下步骤来进行语义分块：\n文档初始处理：首先将你的文档分割成句子，每个句子通常包含关于一个主题的单一观点。\n句子嵌入：利用语言模型获取每个句子的嵌入表示。\n句子比较与分块：从第一句话开始，逐句比较嵌入的相似度。当相邻句子之间的嵌入距离超过预设的阈值时，标记为新的语义段落的开始。\n聚类相似句子：将语义上接近的句子聚集成块，同时保持句子的原始顺序。\n伪代码示例\narticle = \u0026#34;你的完整文章\u0026#34; chunks = [article[:1]] # 默认第一部分为一个独立分块 # 文章逐句审查 for sentence in article[1:]: if is_similar(sentence, chunks[-1][-1]): chunks[-1].append(sentence) # 如果新句子与当前块的最后一个句子相似，则加入当前块 else: chunks.append([sentence]) # 如果不相似，则创建新的分块 # 持续这个过程直至文章末尾 # 在这种方法中，is_similar 函数需要定义为比较句子嵌入之间的距离，并判断它们是否足够接近。 特殊分块以及后处理 不见得一定要在召回后，返回原始的chunks。\nSummary(摘要) 处理和存储大量文档的原始数据块往往不是最高效的方法。通过为每个文档创建摘要并进行嵌入，我们不仅可以减少处理的数据量，还能提高检索的速度和准确性。\nhttps://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector#summary\ncreate a summary for each document, embed that along with (or instead of) the document.\nimport uuid from langchain_core.documents import Document from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import ChatPromptTemplate from langchain_openai import ChatOpenAI chain = ( {\u0026#34;doc\u0026#34;: lambda x: x.page_content} | ChatPromptTemplate.from_template(\u0026#34;Summarize the following document:\\n\\n{doc}\u0026#34;) | ChatOpenAI(max_retries=0) | StrOutputParser() ) summaries = chain.batch(docs, {\u0026#34;max_concurrency\u0026#34;: 5}) # The vectorstore to use to index the child chunks vectorstore = Chroma(collection_name=\u0026#34;summaries\u0026#34;, embedding_function=OpenAIEmbeddings()) # The storage layer for the parent documents store = InMemoryByteStore() id_key = \u0026#34;doc_id\u0026#34; # The retriever (empty to start) retriever = MultiVectorRetriever( vectorstore=vectorstore, byte_store=store, id_key=id_key, ) doc_ids = [str(uuid.uuid4()) for _ in docs] summary_docs = [ Document(page_content=s, metadata={id_key: doc_ids[i]}) for i, s in enumerate(summaries) ] retriever.vectorstore.add_documents(summary_docs) retriever.docstore.mset(list(zip(doc_ids, docs))) Hypothetical questions HyDE\nhypothetical_document_embeddings\nHyDE (Hypothetical Document Embeddings)\nHyDE（Hypothetical Document Embeddings，假设性文档嵌入），通过生成假设性的答案并对这些生成的文档进行嵌入，而非嵌入原始文本。这种方法特别适用于用户问题简短且与需要查找的原始文本在语义上相似度不高的情况。\n当用户的问题与知识库中的原始文本在语义上相差较大时，传统的文档检索方法可能无法有效地匹配到相关内容。HyDE通过使用大型语言模型（LLMs）根据用户问题生成格式上类似于知识库中文本的假设性答案，从而提升匹配的准确率。\n尽管HyDE可以提升检索的准确性，但这种方法也会一定程度上增加检索的耗时。为了平衡检索准确率和响应速度，可以考虑使用更强大的重排模型（reranking models）。这些模型能够在检索后的阶段进一步优化结果，通过精准地评估和排序生成的假设性答案，以提供最相关的回答。\nParent Document Retriever (PDR) from Advanced RAG Techniques: an Illustrated Overview\nA.K.A Multi-size-chunks(Parent Document Retriever/ parent-child chunks retriever/ Auto Merging Retriever)\n核心思想是，尽管小片段的数据更容易在语义上与短小的用户查询匹配，但这些小片段往往缺乏提供全面回答所需的足够上下文。PDR的解决方案是在检索时优先获取这些小片段，然后识别并返回包含这些小片段的更大父文档，以此为基础进行问题的回答。\n在使用embedding模型召回时，尽可能的将对应文本拆成句子级别，因为往往人的问题都是比较短的句子，这样在语义匹配上能够较好的匹配上；但是在使用LLM做回答时，由需要足够的上下文让模型能够有足够多的背景进行回答；因此在召回的时候倾向于使用small-chunks用于匹配，再通过某些聚合方式合并成一个具备相对完整上下文的较大chunks用作模型回答之背景；\n在Langchain中提供了Parent Document Retriever这一方法。\nDuring retrieval, it first fetches the small chunks but then looks up the parent ids for those chunks and returns those larger documents.\n使用方法：\nfrom langchain.retrievers import ParentDocumentRetriever from langchain.storage import InMemoryStore from langchain.text_splitter import RecursiveCharacterTextSplitter # Retrieving larger chunks # This text splitter is used to create the parent documents parent_splitter = RecursiveCharacterTextSplitter(separators=\u0026#34;\\n\u0026#34;,chunk_size=2000) # This text splitter is used to create the child documents # It should create documents smaller than the parent child_splitter = RecursiveCharacterTextSplitter(separators=\u0026#34;\\n\u0026#34;,chunk_size=400) # define your docs = embeddings, and vectorstore # docs = loader.load(...) # emebeddings = OpenAIEmbeddings(...) # vectorstore = Chroma(...) # The storage layer for the parent documents store = InMemoryStore() retriever = ParentDocumentRetriever( vectorstore=vectorstore, docstore=store, child_splitter=child_splitter, parent_splitter=parent_splitter, ) retriever.add_documents(docs) 而在llama_index中也提供了类似的方法。\n# 创建较小的子块 from llama_index.schema import IndexNode sub_chunk_sizes = [256, 512, 864] sub_node_parsers = [ SimpleNodeParser.from_defaults(chunk_size=c) for c in sub_chunk_sizes ] all_nodes = [] for base_node in base_nodes: for n in sub_node_parsers: sub_nodes = n.get_nodes_from_documents([base_node]) sub_inodes = [IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes] all_nodes.extend(sub_inodes) original_node = IndexNode.from_text_node(base_node, base_node.node_id) all_nodes.append(original_node) all_nodes_dict = {n.node_id: n for n in all_nodes} # 创建索引、检索器和查询引擎 vector_index_chunk = VectorStoreIndex( all_nodes, service_context=service_context ) vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2) retriever_chunk = RecursiveRetriever( \u0026#34;vector\u0026#34;, retriever_dict={\u0026#34;vector\u0026#34;: vector_retriever_chunk}, node_dict=all_nodes_dict, verbose=True, ) query_engine_chunk = RetrieverQueryEngine.from_args( retriever_chunk, service_context=service_context ) response = query_engine_chunk.query( \u0026#34;Can you tell me about the key concepts for safety finetuning\u0026#34; ) print(str(response)) Sentence Window Retrieval 为了更好地分析找到的语境，我们在检索到的最相关单句之前后各扩展 k 个句子，然后把这个扩展后的语境送给 LLM 进行推理\nfrom Advanced RAG Techniques: an Illustrated Overview\n分块可视化小工具 推荐一个可视化chunk-spliting 工具chunkviz\n推荐阅读 Text splitting (chunking) for RAG applications\n5_Levels_Of_Text_Splitting\nlangchain:Semantic Chunking\nChunking Strategies for LLM Applications\nAdvanced RAG Techniques: an Illustrated Overview\nRAG系列05：基于语义的Chunk分割\n","permalink":"https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97/","summary":"\u003ch2 id=\"为什么要进行文本分块\"\u003e\u003cstrong\u003e为什么要进行文本分块？\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。\u003c/p\u003e\n\u003ch2 id=\"如何进行文本分块\"\u003e\u003cstrong\u003e如何进行文本分块\u003c/strong\u003e\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e**块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：\u003c/p\u003e\n\u003ch3 id=\"句子分割sentence-splitting\"\u003e\u003cstrong\u003e句子分割（Sentence Splitting）\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etext\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;...\u0026#34;\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 你的文本\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003elangchain.text_splitter\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eCharacterTextSplitter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etext_splitter\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eCharacterTextSplitter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eseparator\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003echunk_size\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e256\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003echunk_overlap\u003c/span\u003e  \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e20\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edocs\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etext_splitter\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_documents\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003etext\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"递归字符文本分割recursive-character-text-splitting\"\u003e\u003cstrong\u003e递归字符文本分割（Recursive Character Text Splitting）\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etext\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;...\u0026#34;\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 你的文本\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003elangchain.text_splitter\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eRecursiveCharacterTextSplitter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etext_splitter\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eRecursiveCharacterTextSplitter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003echunk_size\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e256\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003echunk_overlap\u003c/span\u003e  \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e20\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edocs\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etext_splitter\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_documents\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003etext\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e根据langchain 的\u003ca href=\"https://github.com/langchain-ai/langchain/blob/9ef2feb6747f5a69d186bd623b569ad722829a5e/libs/langchain/langchain/text_splitter.py#L842\"\u003e默认分隔条件\u003c/a\u003e \u003ccode\u003e[\u0026quot;\\n\\n\u0026quot;, \u0026quot;\\n\u0026quot;, \u0026quot; \u0026quot;, \u0026quot;\u0026quot;]\u003c/code\u003e ,也就是会将text根据该分割条件的顺序（两个换行-\u0026gt;一个换行-\u0026gt;空格）将文本进行递归分割。\u003c/p\u003e\n\u003ch3 id=\"针对特定文档的分割方法document-specific-splitting\"\u003e\u003cstrong\u003e针对特定文档的分割方法（Document Specific Splitting）\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。\u003c/p\u003e\n\u003cp\u003elangchain 提供了一些常见文档的分割方法：\u003c/p\u003e\n\u003cp\u003emardown的分割逻辑\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-py\" data-lang=\"py\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# First, try to split along Markdown headings (starting with level 2)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e#{1,6} \u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# Note the alternative syntax for headings (below) is not handled here\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# Heading level 2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# ---------------\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# End of code block\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;```\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# Horizontal lines\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\\\\\u003c/span\u003e\u003cspan class=\"s2\"\u003e*\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s2\"\u003e*\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s2\"\u003e*+\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e---+\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e___+\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# Note that this splitter doesn\u0026#39;t handle horizontal lines defined\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# by *three or more* of ***, ---, or ___, but this is not handled\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34; \u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003epython的分割逻辑：\u003c/p\u003e","title":"RAG工具箱：文本分块"},{"content":"写在开头 本文是基于最近组内技术交流的文字稿整理。\nWhat is Agent？ 在探讨复杂的人工智能技术之前，让我们先回顾一下生活中的一个简单例子：扫地机器人。这种智能设备在房间中自主导航，避开障碍物，寻找最有效的清洁路径。它就是一个现实生活中的Agent——一个可以自主决策和行动的实体。\n在人工智能领域，Agent指的是任何可以感知其环境并根据感知结果做出决策的实体。这些决策旨在完成某些任务或达成特定的目标。Agent的行为可以简单如游戏里的机器人，也可以复杂如自动驾驶汽车。\n开始于强化学习 在强化学习中， 我们往往能见到agent的概念。强化学习是一种机器学习方法，它教导Agent通过试错法找到最佳行动路径。就像训练小狗一样，我们通过奖励来引导Agent做出正确的决策。Agent的目标是在与环境的交互中寻找最优策略。理想情况下，如果Agent能够获取足够多的真实环境数据，它就能找到最佳解决方案。然而，由于真实环境的复杂性，完全模拟真实世界是不现实的。\n目前，强化学习主要适用于环境简单、问题定义明确的场景，如围棋或视频游戏。这种方法在虚拟环境中通过大量试错来探索解决方案，这种方法虽然有效，但缺乏灵活性和高效性。与人类学习新技能的方式相比，强化学习的效率远低。人们通常通过少量的尝试就能迅速掌握新技能，而强化学习可能需要成千上万次的试错。\n这时候，如果agent具有大脑就好了。\n将LLMs作为大脑: 赋能智能Agent的关键技术 相较于基于强化学习的Agent，人类的优势在于我们天生具备的记忆能力和逻辑判断能力，甚至包括反思和从经验中学习的能力。这些能力使得我们能够通过极少的试错迅速适应和掌握新技能。\n语言模型（LLMs）为AI领域带来了革命性的变化。LLMs通过其深度学习的新范式，以及在思维链和自然语言理解方面的强大能力，预示着Agent将拥有更强大的学习和迁移能力。这种能力的提升将使得创建广泛应用且实用的Agent成为可能。\n虽然LLM是否真正具备了推理能力仍然存疑，但LLM的出现无疑改变了很多。以COT（Chain of Thought）为例，这种模型通过打印解题的中间步骤，加强了在数学和逻辑推理方面的能力，减少了幻觉的出现。这一突破性的工作揭示了LLM在不同场景下的强大\u0026quot;in-context learning\u0026quot;能力，以及其在未经微调的情况下的泛化能力。\n将LLM视为AI Agent的大脑，为自动化系统提供了一种全新的构思方式。这种基于LLM的agent系统综合了规划、记忆、工具使用和行动的能力，通过API调用与外部世界互动，显示出了前所未有的灵活性和效率。\n根据LLM Powered Autonomous Agents一文对LLM-based agent系统的定义， agent需要具备的基本能力：规划+记忆+工具+行动。\n规划能力：将复杂的任务分解成小任务， 并管理每一个子任务的目标， 并从过去的失败中反思，以吸取经验。\n记忆：LLM的上下文长度有限， 通过额外的记忆系统以提升LLM作为大脑的能力。\n工具调用\u0026amp;行动：LLM通过API调用的方式，执行任务， 与外界交互，而不是只是输出文字。\n探索AI代理的独特能力：人类与单一LLM无法比拟 AI系统的主要优势在于它们的规模和效率。这些系统能够执行以下任务，超越人类能力：\n大规模数据处理：AI能够高效地分析和处理超出人类理解范围的数据量。\n无需休息的持续操作：AI系统可以不间断地运行，而无需像人类那样休息和恢复。\n超快速计算：AI可以迅速执行复杂的计算，处理速度和效率远超人类。\nAI代理与单一LLM的不同:\n根据Andrew Ng在讲座中分享的内容，使用相对“简单”模型的代理工作流程（例如GPT-3.5）在实际应用中往往能够超越使用“智能”模型（如GPT-4）的零次提示。这说明在特定场景下，选择适当的AI模型和策略可能比单一的高级模型更有效。\nAI代理在决策制定中的应用也显示出其独特的优势。它们可以在没有情感偏见的情况下，基于大量数据做出快速且精确的决策。这种能力在需要快速响应和高精确度的领域尤为重要，如金融交易和紧急响应系统。\nAgent的规划和思维过程 AI Agent在处理复杂任务时，通过将大任务分解成小任务来提高效率。此外，自我反思能力允许Agent从过去的行动中学习，通过评估过去的决策来改善未来的表现。\nCoT，Chain of Thought， Wei et al. 2022。 即“思维链”，是一种使Agent逐步思考的方法。它通过要求模型展示解决问题的中间步骤来加强其逻辑推理能力，从而提高决策的质量和准确性。\nTree of Thoughts， ToT (Yao et al. 2023)\n尽管语言模型在许多领域表现出色，但在需要复杂规划和全局决策的任务上，它们的能力受到了限制。ToT框架应运而生，旨在通过一个结构化的思考和评估过程来弥补这一缺陷。\nToT框架借鉴了人类心理学中的双系统决策理论，通过整合快速直觉判断和慢速深思熟虑的决策过程，极大地提升了模型的决策能力。这一框架通过自我评估的方式，允许模型在面对多种可能的决策路径时，能够进行有效的选择和全局优化。\nToT框架旨在克服现有语言模型在处理需要复杂规划或搜索任务的局限。它通过结构化的思想树来探索和评估不同的决策路径。ToT允许模型在考虑多个推理路径时自我评估其选择，以做出最佳的决策。此外，ToT结合了语言生成和搜索算法（如BFS和DFS），使模型能够在进行决策时前瞻和回溯，以实现全局最优选择。\nprompt example：\ncot_prompt = \u0026#39;\u0026#39;\u0026#39; Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph must be: {input} Make a plan then write. Your output should be of the following format: Plan: Your plan here. Passage: Your passage here. \u0026#39;\u0026#39;\u0026#39; vote_prompt = \u0026#39;\u0026#39;\u0026#39;Given an instruction and several choices, decide which choice is most promising. Analyze each choice in detail, then conclude in the last line \u0026#34;The best choice is {s}\u0026#34;, where s the integer id of the choice. \u0026#39;\u0026#39;\u0026#39; compare_prompt = \u0026#39;\u0026#39;\u0026#39;Briefly analyze the coherency of the following two passages. Conclude in the last line \u0026#34;The more coherent passage is 1\u0026#34;, \u0026#34;The more coherent passage is 2\u0026#34;, or \u0026#34;The two passages are similarly coherent\u0026#34;. \u0026#39;\u0026#39;\u0026#39; score_prompt = \u0026#39;\u0026#39;\u0026#39;Analyze the following passage, then at the last line conclude \u0026#34;Thus the coherency score is {s}\u0026#34;, where s is an integer from 1 to 10. \u0026#39;\u0026#39;\u0026#39; GoT， Graph of Thoughts，\nhttps://arxiv.org/abs/2308.09687\nhttps://arxiv.org/abs/2401.14295\nGoT（Graph of Thoughts）是在ToT（Tree of Thoughts）基础上的一种进阶，它通过引入图状结构，增强了模型处理复杂推理任务的能力。这种结构允许在生成的思考中进行更为灵活的图状转换，如合并多个思考或在思考间进行循环。\nGoT的核心特点在于其灵活的图状结构，这使得它能够通过合并和循环不同的思考节点来模拟更复杂的推理过程。每个思考节点可以从多个父节点聚合信息，也可以向多个子节点扩展，形成一个密集的思考网络。这种结构特别适合处理那些传统树状模型难以解决的复杂推理和决策任务。\nGoT设计之初就为了处理比ToT更为复杂的推理任务。通过允许广泛的依赖关系和中间步骤的聚合，GoT能够更有效地解决那些需要非线性思考路径的问题。例如，在处理涉及多个相互关联子问题的任务时，GoT的图状结构提供了一种比传统线性或树状结构更为有效的解决方案。\nXoT, Everything of Thoughts, https://arxiv.org/abs/2311.04254\nXoT代表了在AI领域中对复杂思考和决策过程的一次显著革新，它通过结合蒙特卡洛树搜索（MCTS）和大型语言模型求解器（LLM solver）来优化决策路径。\nXoT框架包含以下几个关键步骤和组件：\n预训练的MCTS模块：该模块通过在特定任务上的预训练，获得了有效导航复杂思考路径的能力。\n动态思考搜索：在实际应用中，MCTS模块继续利用其策略和价值网络来探索和优化潜在的思考轨迹。\n思考修正与优化：LLM评估并修正MCTS的输出，确保思考路径的逻辑严密性和有效性。\n决策执行：修正后的思考路径被送回LLM，用于解决具体的问题和挑战。\nReAct (Reason to Act) 是由 Yao et al. 2023 提出的一种新颖的提示框架，旨在通过交错的思考、行动和观察步骤，提高大型语言模型（LLM）的动态推理和计划调整能力。\nReAct通过“思考-行动-观察”结构，使LLM能够生成口头推理迹线和与任务相关的行动。这种结构允许模型动态地创建、维护并调整高层次的行动计划，同时与外部环境（如Wikipedia）互动，引入额外信息以丰富推理。\nReAct的独特特点\n直观且易于设计：ReAct的设计直观，易于实现，并能快速适应不同的应用场景。\n通用性与灵活性：适用于多种任务，能够灵活处理复杂的情境。\n高性能与鲁棒性：提供稳定且有效的推理输出。\n与人类行为一致且可控：增强了模型的可控性，与人类的推理和行动方式更为一致。\nReAct与CoT的对比\n相对于CoT（Chain of Thought），ReAct通过交错的思考、行动和观察步骤，改进了模型的根据性和可信度。然而，这种结构在提高模型实地操作的同时，也略微降低了在推理步骤制定的灵活性。此外，ReAct的有效性很大程度上依赖于成功检索到信息丰富的知识。\nThought: ... Action: ... Observation: ... ... (Repeated many times) Reflexion是由Shinn \u0026amp; Labash 2023提出的一种创新的决策支持框架。它包括三个核心模块：Actor（行动模块）、Evaluator（评估模块）、和Self-Reflection（自我反思模块），旨在通过增强的语言模型反馈机制提升任务处理效率和质量。\n框架组成与工作机制\nActor模块：负责生成针对特定任务的行动指令和文本。\nEvaluator模块：评估Actor的输出，保证行动的适宜性和效果。\nSelf-Reflection模块：反馈生成部分，通过深入分析和总结Actor的表现，指导未来的改进。\nReflexion框架的轻量级设计和对详细反馈的处理能力使其在多个高级任务中表现优异，包括编程、推理和复杂决策。实际应用显示，该框架能显著提升任务处理的正确率和效率。\n思考的快与慢。 在《思考，快与慢》一书中，丹尼尔·卡尼曼提出了人类思考的两种模式：“系统1”和“系统2”。系统1是快速、本能和情感性的，而系统2则更为缓慢、深思熟虑和逻辑性。这两种系统在处理不同类型的记忆和决策时发挥着不同的作用。\nAgent记忆 记忆是人类认知功能的核心，使我们能够从经验中学习并避免重复错误。在人工智能领域，尤其是在开发智能代理（Agent）时，构建有效的记忆系统也显得尤为重要。\nAI系统，尤其是依赖于大型语言模型的Agent，常面临有限的上下文记忆容量问题。这限制了它们在处理持续对话和复杂任务中的表现。这些系统通常受到有限上下文长度的制约，这限制了它们在处理连续对话或复杂任务时的效率。例如，一个没有有效记忆机制的Agent可能会重复犯同样的错误，或者忘记初始的任务目标。\n尽管现代LLMs的上下文长度已经可以处理超过100,000个标记，试图将所有对话历史和相关记忆直接置于模型的上下文中既不经济也不高效。因此，开发一个专门的记忆系统，如检索增强生成（Retrieval-Augmented Generation, RAG）成为提升Agent性能的有效手段。\n如果要为AI构建高效的记忆系统，借鉴和参考人类的记忆系统是必不可少的。人类的记忆系统包含多种类型的记忆，每种记忆都有其独特的生物学基础和功能，这些记忆类型不仅支持我们的日常活动，还是我们进行复杂决策和学习的基础。\n通过了解人类记忆的工作原理，我们可以设计出能够更好地模拟人类认知过程的AI系统。这不仅可以提高机器的任务执行能力，还可以使机器更加自主地适应复杂的环境和需求。\n根据维基百科的定义，人类的记忆系统可细分成：\n工作记忆：支持我们处理日常任务和进行决策。\n工具记忆：帮助我们形成习惯和自动化反应。\n语义记忆：允许我们累积知识和理解世界。\n情节记忆：使我们能够回忆过去的经历和事件。\n动作记忆：通过练习改善我们的物理技能和运动。\n遗忘的机制和认知卸载。记忆的形成经历过滤、压缩、遗忘和重组等环节。在这个过程中，大脑会删除大部分接收到的信息，只保留对当前活动或未来决策最关键的部分。\n建议阅读：\nA Survey on the Memory Mechanism of Large Language Model based Agents\nAgent的工具调用 我们更希望能帮助我们干活的agent 而不是一个只会说话的LLMs。换句话说人实际上并不需要一个聊天的对象，而是帮助解决问题的助手\n如何让LLMs具备工具调用的能力。 根据当前的主要工作， 主要是以openAI 的tool-using 的工作为主（也就是之前的function calling）。\n一句话解释：function calling从本质上并不是严格的工具调用， 而是作为工具调用的前奏，它通过更加结构化的方式指导LLM输出，为在本地执行具体函数提供了参数，铺平了道路。\n具体来说，function calling允许LLM在执行过程中通过指定的参数来调用并执行一个特定的函数。这种方式不仅实现了代码的重用和模块化处理，而且能够从模型中获取更可靠的结构化数据回应。在API调用过程中，开发者可以描述想要执行的功能，并让模型智能地选择输出包含所需参数的JSON对象。这个过程中，Chat Completions API本身不直接执行任何函数调用，而是生成了可以在开发者代码中实现函数调用的JSON。\n更详细的tool-using内容，可以查看之前的博文：Agent学习笔记：OpenAI Function Calling完全指南\n除了tool-using意外， 比较重要的工具还有：code interpreter， 在代码开发的场景下， code interpreter充当了RL中的Env角色，让agent能够根据环境的反馈做出对应决策，而不只是生成代码。 除了openAI所提供的code interpreter外， 还有一些开源的code interpreter，如Open Interpreter 可以使用。\n从单Agent到多agent协作 来自斯坦福的虚拟小镇，因其独特的话题性而被广泛讨论。\nGenerative Agents: Interactive Simulacra of Human Behavior\nMetaGPT 在MetaGPT看来，可以将智能体想象成环境中的数字人，其中\n智能体 = 大语言模型（LLM） + 观察 + 思考 + 行动 + 记忆\n多智能体系统可以视为一个智能体社会，其中\n多智能体 = 智能体 + 环境 + 标准流程（SOP） + 通信 + 经济\nCode = SOP(Team) 是核心哲学。我们将SOP具象化，并且用于LLM构成的团队\n一些讨论 LLMs真的具备逻辑推理能力吗 何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；**推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。**LLMs的推理能力似乎是”涌现“的结果，而非专门针对性训练，所以LLMs是否真正具备推理能力？从一些结果表明，LLMs似乎是在背答案而非真正的推理。\n在 Can Large Language Models Reason? 这篇文章中作者认为CoT过程中LLM可能是在背答案：\nGPT-4 solved 10 out of 10 problems that had been published before 2021 (GPT-4’s pre-training cutoff date) and zero out of 10 problems that had been published after 2021. 不过，我还是持保留意见的， 作者所观察到的现象和人类很像，更擅长在自己熟悉的领域，因为存在大量的记忆，记忆间存在大量“近道”（shortcut）用于加速推导过程，甚至直接给出答案；所要做的让LLMs去执行“慢思考”而不是“快思考”。\n如果从transformer 的原理上讨论， 一个自回归的模型本身是和推理，逻辑甚至是智能无缘的。\n但人类的语言中， 天生具备了逻辑，或者人类的语言中融入的人类本身的逻辑。那么通过模拟语言的生成，一定程度也能恢复出语言背后的逻辑。\nAgent真的只是商业上的吹捧或者泡沫吗 泡沫的成份一定是有点。但也是未来十年值得做的东西。\n如果把LLM类比成CPU的话， 一个完整的计算机系统，除了CPU以外， 还需要内存，控制，输入输出等组件。不可能让LLM实现所有功能，这并不现实。但通过一定合理的架构，工作流的编排，能够大大提升LLM的准确性，进而加快落地实现。\n传统行业要如何在agent上发力 所有公司都有SOP，和大量存在在员工脑子中的“隐性知识”。 这些“知识”只有转换成agent的工作流（思维方式），或者是LLM的system prompt，才会变得更有价值和意义。现阶段有很多公司在做所谓的知识管理， 本质上是用公司的内部文本作为RAG系统而已，但一个问答系统很难量化出收益，并且对于使用者的要求挺高的。 实际上我认为，发力点应该是将内部人类可使用的工具逐渐API化，标准化以方便agent的工具调用，然后定义智能代理在各种业务场景中的具体任务和行动。这包括从简单的数据检索到复杂的决策制定\nAgent应该从事简单重复劳动还是具有创造性的探索工作 这题让GPT-4来回答吧：\n关于“Agent应该从事简单重复劳动还是具有创造性的探索工作”的问题，我们可以从多个角度进行分析：\n经济效益：从经济角度考虑，如果简单重复的劳动可以被自动化或由机器人执行，这将大幅度降低成本，并提高效率。企业通常会选择自动化这类工作以减少人力成本。然而，对于创造性的探索工作，由于需要不断地创新和解决新问题，这种类型的工作更可能需要人类智能的参与，因此，这种工作对于推动技术进步和经济增长具有重要价值。\n技术发展：随着AI和机器学习技术的发展，越来越多的简单劳动可以被智能系统所取代。例如，数据输入、监控等任务已被自动化系统广泛接管。然而，对于需要高度创造性和判断力的工作，如科学研究、艺术创作、复杂决策制定等，目前的技术还无法完全替代人类。\n人类福祉：从心理学的角度来看，长期从事简单重复的劳动可能导致工作满意度下降，影响心理健康。相反，创造性工作通常能带来更高的个人成就感和职业满意度。因此，鼓励Agent从事创造性探索工作可能更有助于提升整体福祉。\n社会需求和未来趋势：社会对创新和创造的需求日益增加，这种趋势推动了对创造性职业的需求。例如，新兴技术、可持续发展解决方案和个性化产品等领域，都需要大量的创新思维和创造力。因此，社会和市场需求可能更倾向于从事具有创造性的探索工作。\n综上所述，虽然从事简单重复的劳动在某些情况下具有其经济和效率上的优势，但从长远和全面的角度来看，鼓励Agent从事具有创造性的探索工作似乎更具前瞻性和可持续性。这不仅有助于经济和技术的发展，还能改善工作者的心理福祉和职业满意度。\nAgent在制造业良率分析上如何应用 以Yield分析和提升为例，在进行Yield提升和案例分析时，存在大量重复的分析和判断工作，这些可以通过AI进行加速和辅助，而不需人工逐一检查。\n工程师每天可能需要处理超过100个与良率相关的预警。其中约40%可能是由于测试问题、设备故障或是之前已经标注过的案例。这些都需要工程师逐一检查。由于人力有限，他们只能优先审查良率特别低的情况，可能会错过一些潜在的问题。通过使用特定规则和AI Agent，可以自动检查这些数据并作出判断。\n在处理实际案例时，工程师通常会根据案例特征在知识库中查询处理方法，这一过程也可以由Agent自动完成，并缩小后续检查的范围。如果需要进一步分析，工程师会调用不同的工具用于检查，这些分析也可以通过Agent来执行。如果仍无法找到问题，可以提醒人工介入。当Agent成功分析出结果时，还会将分析过程和结果整理成图文并茂的报告，供工程师检查和使用。一旦这些分析被人工审核并采用，它们就会成为高质量的知识，自动加入知识库中供下次使用。\nReading LLM Powered Autonomous Agents\nA busy person’s Intro to AI Agents\n基于大语言模型的AI Agents—Part 1\nChain of Thought\nTree of Thoughts\nGraph of Thoughts\nReAct\nReflexion\nMetaGPT: Meta Programming for Multi-Agent Collaborative Framework\nGenerative Agents: Interactive Simulacra of Human Behavior\nLLM Agents Papers\nAI Agent \u0026amp; 大模型经典论文推荐\nAI Agents are disrupting automation: Current approaches, market solutions and recommendations\nAGI-Edgerunners-LLM-Agents-Papers\nThe Rise and Potential of Large Language Model Based Agents: A Survey\nAwesome AI Agents\nLarge Language Model based Multi-Agents: A Survey of Progress and Challenges\nThe Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey\n","permalink":"https://niraya666.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84-agent%E7%A7%91%E6%99%AE%E5%90%91/","summary":"\u003ch2 id=\"写在开头\"\u003e写在开头\u003c/h2\u003e\n\u003cp\u003e本文是基于最近组内技术交流的文字稿整理。\u003c/p\u003e\n\u003ch2 id=\"what-is-agent\"\u003eWhat is Agent？\u003c/h2\u003e\n\u003cp\u003e在探讨复杂的人工智能技术之前，让我们先回顾一下生活中的一个简单例子：扫地机器人。这种智能设备在房间中自主导航，避开障碍物，寻找最有效的清洁路径。它就是一个现实生活中的Agent——一个可以自主决策和行动的实体。\u003c/p\u003e\n\u003cp\u003e在人工智能领域，Agent指的是任何可以感知其环境并根据感知结果做出决策的实体。这些决策旨在完成某些任务或达成特定的目标。Agent的行为可以简单如游戏里的机器人，也可以复杂如自动驾驶汽车。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/Pasted%202024-05-10-14-58-28.webp\" alt=\"Pasted 2024-05-10-14-58-28.webp\"  /\u003e\n\u003c/p\u003e\n\u003ch3 id=\"开始于强化学习\"\u003e开始于强化学习\u003c/h3\u003e\n\u003cp\u003e在强化学习中， 我们往往能见到agent的概念。强化学习是一种机器学习方法，它教导Agent通过试错法找到最佳行动路径。就像训练小狗一样，我们通过奖励来引导Agent做出正确的决策。Agent的目标是在与环境的交互中寻找最优策略。理想情况下，如果Agent能够获取足够多的真实环境数据，它就能找到最佳解决方案。然而，由于真实环境的复杂性，完全模拟真实世界是不现实的。\u003c/p\u003e\n\u003cp\u003e目前，强化学习主要适用于环境简单、问题定义明确的场景，如围棋或视频游戏。这种方法在虚拟环境中通过大量试错来探索解决方案，这种方法虽然有效，但缺乏灵活性和高效性。与人类学习新技能的方式相比，强化学习的效率远低。人们通常通过少量的尝试就能迅速掌握新技能，而强化学习可能需要成千上万次的试错。\u003c/p\u003e\n\u003cp\u003e这时候，如果agent具有大脑就好了。\u003c/p\u003e\n\u003ch3 id=\"将llms作为大脑-赋能智能agent的关键技术\"\u003e将LLMs作为大脑: \u003cstrong\u003e赋能智能Agent的关键技术\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e相较于基于强化学习的Agent，人类的优势在于我们天生具备的记忆能力和逻辑判断能力，甚至包括反思和从经验中学习的能力。这些能力使得我们能够通过极少的试错迅速适应和掌握新技能。\u003c/p\u003e\n\u003cp\u003e语言模型（LLMs）为AI领域带来了革命性的变化。LLMs通过其深度学习的新范式，以及在思维链和自然语言理解方面的强大能力，预示着Agent将拥有更强大的学习和迁移能力。这种能力的提升将使得创建广泛应用且实用的Agent成为可能。\u003c/p\u003e\n\u003cp\u003e虽然LLM是否真正具备了推理能力仍然存疑，但LLM的出现无疑改变了很多。以COT（Chain of Thought）为例，这种模型通过打印解题的中间步骤，加强了在数学和逻辑推理方面的能力，减少了幻觉的出现。这一突破性的工作揭示了LLM在不同场景下的强大\u0026quot;in-context learning\u0026quot;能力，以及其在未经微调的情况下的泛化能力。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png\" alt=\"截屏2024-05-08 15.37.21.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e将LLM视为AI Agent的大脑，为自动化系统提供了一种全新的构思方式。这种基于LLM的agent系统综合了规划、记忆、工具使用和行动的能力，通过API调用与外部世界互动，显示出了前所未有的灵活性和效率。\u003c/p\u003e\n\u003cp\u003e根据\u003ca href=\"https://lilianweng.github.io/posts/2023-06-23-agent/\"\u003eLLM Powered Autonomous Agents\u003c/a\u003e一文对LLM-based agent系统的定义， agent需要具备的基本能力：规划+记忆+工具+行动。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e规划能力\u003c/strong\u003e：将复杂的任务分解成小任务， 并管理每一个子任务的目标， 并从过去的失败中反思，以吸取经验。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e记忆\u003c/strong\u003e：LLM的上下文长度有限， 通过额外的记忆系统以提升LLM作为大脑的能力。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e工具调用\u0026amp;行动\u003c/strong\u003e：LLM通过API调用的方式，执行任务， 与外界交互，而不是只是输出文字。\u003c/p\u003e\n\u003ch3 id=\"探索ai代理的独特能力人类与单一llm无法比拟\"\u003e\u003cstrong\u003e探索AI代理的独特能力：人类与单一LLM无法比拟\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eAI系统的主要优势在于它们的规模和效率。这些系统能够执行以下任务，超越人类能力：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e大规模数据处理\u003c/strong\u003e：AI能够高效地分析和处理超出人类理解范围的数据量。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e无需休息的持续操作\u003c/strong\u003e：AI系统可以不间断地运行，而无需像人类那样休息和恢复。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e超快速计算\u003c/strong\u003e：AI可以迅速执行复杂的计算，处理速度和效率远超人类。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eAI代理与单一LLM的不同:\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e根据Andrew Ng在讲座中分享的内容，使用相对“简单”模型的代理工作流程（例如GPT-3.5）在实际应用中往往能够超越使用“智能”模型（如GPT-4）的零次提示。这说明在特定场景下，选择适当的AI模型和策略可能比单一的高级模型更有效。\u003c/p\u003e\n\u003cp\u003eAI代理在决策制定中的应用也显示出其独特的优势。它们可以在没有情感偏见的情况下，基于大量数据做出快速且精确的决策。这种能力在需要快速响应和高精确度的领域尤为重要，如金融交易和紧急响应系统。\u003c/p\u003e\n\u003ch2 id=\"agent的规划和思维过程\"\u003e\u003cstrong\u003eAgent的规划和思维过程\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eAI Agent在处理复杂任务时，通过将大任务分解成小任务来提高效率。此外，自我反思能力允许Agent从过去的行动中学习，通过评估过去的决策来改善未来的表现。\u003c/p\u003e\n\u003cp\u003eCoT，Chain of Thought， \u003ca href=\"https://arxiv.org/abs/2201.11903\"\u003eWei et al. 2022\u003c/a\u003e。 即“思维链”，是一种使Agent逐步思考的方法。它通过要求模型展示解决问题的中间步骤来加强其逻辑推理能力，从而提高决策的质量和准确性。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png\" alt=\"截屏2024-05-08 15.37.21.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTree of Thoughts， ToT\u003c/strong\u003e  (\u003ca href=\"https://arxiv.org/abs/2305.10601\"\u003eYao et al. 2023\u003c/a\u003e)\u003c/p\u003e","title":"基于大语言模型的 Agent：科普向"},{"content":"值得关注的模型 mistralai/Mixtral-8x22B-Instruct-v0.1\nCohereForAI/c4ai-command-r-plus\nmeta-llama/Meta-Llama-3-8B-Instruct\nmeta-llama/Meta-Llama-3-70B-Instruct\nmicrosoft/Phi-3-mini-128k-instruct\ngpt2-chatbot: 一个神秘的模型\n基础建设 Groq提供了免费且非常高速的API服务\nGroqCloud\n值得关注的开源项目 Cleanlab RAG 基础数据质量处理组件 \u0026ndash; 自动发现数据问题并进行修复，提高数据质量和价值\nhttps://github.com/cleanlab/cleanlab\n支持任何数据，包括图片、文本、音频、表格等\n检测数据标注问题、改进、训练模型、价值提升\n支持任何框架或模型：OpenAI、HuggingFace、PyTorch\njina reader 抓取URL，将正文转换为良好的Markdown格式的工具\nReader API\n一些类似的工具，by ：\n九原客 on Twitter / X\nhttps://markdowndown.vercel.app\nWeb-scraper(open source):\nhttps://github.com/zzzgydi/webscraper…\ncode-html-to-markdown:\nhttps://github.com/SivilTaram/code-html-to-markdown…（偏向于更好地处理代码块）\nhttps://github.com/JimLiu/gpt-api\nhttps://www.firecrawl.dev/?x\nChainForge An open-source visual programming environment for battle-testing prompts to LLMs.\nGitHub - ianarawjo/ChainForge: An open-source visual programming environment for battle-testing prompts to LLMs.\nRAGFlow 一个RAG框架\nhttps://github.com/infiniflow/ragflow/blob/main/README_zh.md\n亮点： 分块后的可视化和修改功能\nSuperMemory 一个第二大脑项目， 提供插件保存网页作为memory和基于memory对话的功能。\nhttps://github.com/Dhravya/supermemory\nLLM Agents Papers Must-read Papers on LLM Agents.\nhttps://github.com/zjunlp/LLMAgentPapers\n本月精选歌单 LIVE记录 0420 数集无限追加-DA\n0428 Arch Enemy\n到过的城市 昆明、大理、苏州\n阅读\u0026amp;摘录 读完了上野千鹤子的《厌女》和弗洛伊德的《心理学导论》\nIlya——塑造世界的人工智能科学家 什么激励我？我喜欢思考根本问题，基本问题。我们的系统不能做什么，而人类却可以做到？我几乎以哲学的方式去思考这些问题。比如，什么是学习？什么是经验？什么是思考？大脑又是如何运作的呢？\n如果多个团队处于竞相开发通用人工智能的军备竞赛态势中，他们就会没有足够的时间来确保他们构建的通用人工智能会真正关心人类。因为在我看来，这就像是通用人工智能发展的雪崩，一发不可收拾。 我认为将来整个地球的表面很可能布满太阳能板和数据中心。考虑到这些担忧，未来的通用人工智能的建设应该是多国间的合作项目。\n台积电在美国郊区建造芯片工厂的艰辛历程 美国工程师们纷纷表示，公司的等级制度僵硬且效率低下；而久经沙场的台湾台积电员工则觉得他们的美国同事缺少了构筑公司顶尖成功的必要精神：奉献与服从。\n在某些部门，为了测试美国员工是否能承受和台湾同事相同的工作压力，管理层会突然宣布需要即刻完成的任务。据两名工程师透露，有时候这种做法会导致美国员工在同事面前受到羞辱，甚至被建议放弃工程职业。…此外，一些台湾员工还参加了有关美国文化的培训课程，了解到相较于批评，美国人更喜欢通过鼓励来提高工作效率。\n“台湾人对每个任务都制造一种不切实际的紧迫感，总是催促你必须立即完成所有工作。但这对于想保持正常工作与生活平衡的人来说，显然是不现实的。” 多位前美国员工表示，他们不介意加班，只要这些加班的工作富有意义。另一位前台积电工程师回忆说：“我曾多次询问我的经理‘你的最高优先级是什么？’他总是回答‘一切都是优先级’。结果我加班加点完成的工作，最后发现根本不是必需的。”\n但美国员工对每周撰写工作报告感到厌烦，并且对台湾同事无故加班表示反感。“这真让人难以忍受，”Bruce 表示，“他们这么做完全是为了表面功夫。”\n五位前美国员工向 Rest of World 透露，台积电的工程师有时会伪造或挑选数据以满足客户和管理层的需求。有时，员工会调整测试工具或晶圆的数据，以满足上级不切实际的期望。另一些时候，一位工程师透露：“因为人手严重不足，他们会想尽办法减轻自己的工作负担。”四位美国员工形容台积电的文化是“面子文化”，员工通常会不惜牺牲效率和员工福利，只为让团队、部门或公司显得更有面子。\n“一切都源于努力工作。没有这种文化，台积电不可能成为世界第一，”他充满激情地说。“我要支持台积电成为伟大的公司。这是我的信仰。”\nZ Potentials | 张佳圆，95后离开字节创业AI搜索，三个月达超百万月访 垂直的好处是可以针对性地构建index，Devv的底层包括了开发文档、代码，也包括搜索引擎里的一些数据，这是它和general search engine的区别。… 垂直搜索引擎最大的差异点就在于能够基于场景更好地构建index，这是我们认为Phind没有做好的。\n做一个60分水平的RAG完全可以通过包装一些外部的LangChain组件来实现，但如果要做到八九十分的RAG系统，需要做的优化点会非常多。\n“Good artists copy，great artists steal”\nCode Review 时，曾被我忽视的 3 件重要小事 人类是一种神奇的智慧生物，阅读一段文字，不仅能从中获取到信息，更能从字里行间感受到情绪，有时，这份情绪甚至会盖过信息，影响他们做出判断。因此，当你在参与评审时，请谨记这一点：保持谦逊、尊重他人。\n工业化时代建立的秩序正在加速瓦解 Andrew Bamboo on Twitter / X\n但就像之前我们将经济下行归咎于疫情，而忽略了债务周期才是主导因素一样，一些迹象表明，我们也不能因为债务周期的存在，而忽略了背后的时代趋势：工业化时代的秩序正在加速瓦解，生产关系正迈向原子化。\n我们看到，大厂占据着绝对的生态位，养着无数员工，人们集中在一起，按照标准化流程进行分工合作，虽然号称白领中产，但与工业时代的流水线工人有何区别？仍然是原子化的生活，集约化标准化的生产。\n几十年的发展，使得供应链、物流变得愈发繁荣，互联网大厂的内卷，使得拿起手机，即可发布几万几十万人看到的信息构建个人影响力，即可促成交易，即可靠 AI 完成专业人士才能完成的工作，这背后，成本得到了转移，带来的是属于个体和小团队的机会。\n近来明显可以看到，身边的自媒体人/独立开发者/小创业团队逐渐多了起来，YC 投资的 AIGC 公司清单（见附图），大部分公司都是 2-4 人。在互联网增量逐渐见顶的时候，利用大公司提供的优秀基建，个体和小团队也可以依靠利基市场生存下来。而随着利基市场不断被挖掘，社会分工进一步细化，人们可以利用更为丰富的细分服务完成更多的事情，又进一步扩充了个人能力的边界。随着越来越多人从工业时代的集约化标准化生活解放出来，又会产生更为多样化的需求及新的利基市场。工业化秩序的瓦解，生产的原子化正变为一种愈发明显的趋势，而得益还是受害，也取决于个人的选择了吧——老生常谈的，每个人都应当成为超级个体，都需要有个自己的小生意。\n吴恩达分享Agentic reasoning 而agent工作流程则更加迭代和自主,它会先分析问题,必要时进行研究,生成初步方案,然后不断自我检查和修正。\n这种工作方式能够显著提高语言模型的表现,有时甚至可以让较小的模型超越更大的模型。因此,agentic reasoning的设计模式对于提升语言模型的性能非常重要。\nAI agents的四种设计模式:\n第一种是自反,即让语言模型自己检查和修正生成的内容,比如代码;\n第二种是工具使用,语言模型可以使用各种工具进行分析、信息获取和行动;\n第三种是规划,语言模型可以自主地制定计划,执行一系列步骤以完成复杂任务;\n第四种是多智能体协作,通过prompt让同一语言模型扮演不同角色,互相配合完成任务。\nAndrew认为,通往AGI(人工通用智能)是一个旅程而非终点,agent工作流程的出现让我们向这个目标又迈进了一步。\nMilestone 昆明-大理旅行 3篇blog 画了个大饼用来“骗GPU” 完成了RAG-chatbot的初步架构设计 ","permalink":"https://niraya666.github.io/monthly/2024-04/","summary":"\u003ch2 id=\"值得关注的模型\"\u003e值得关注的模型\u003c/h2\u003e\n\u003cp\u003emistralai/Mixtral-8x22B-Instruct-v0.1\u003c/p\u003e\n\u003cp\u003eCohereForAI/c4ai-command-r-plus\u003c/p\u003e\n\u003cp\u003emeta-llama/Meta-Llama-3-8B-Instruct\u003c/p\u003e\n\u003cp\u003emeta-llama/Meta-Llama-3-70B-Instruct\u003c/p\u003e\n\u003cp\u003emicrosoft/Phi-3-mini-128k-instruct\u003c/p\u003e\n\u003cp\u003egpt2-chatbot: 一个神秘的模型\u003c/p\u003e\n\u003ch3 id=\"基础建设\"\u003e基础建设\u003c/h3\u003e\n\u003cp\u003eGroq提供了免费且非常高速的API服务\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://console.groq.com/docs/quickstart\"\u003eGroqCloud\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h2\u003e\n\u003ch3 id=\"cleanlab\"\u003eCleanlab\u003c/h3\u003e\n\u003cp\u003eRAG 基础数据质量处理组件 \u0026ndash; 自动发现数据问题并进行修复，提高数据质量和价值\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/cleanlab/cleanlab\"\u003ehttps://github.com/cleanlab/cleanlab\u003c/a\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e支持任何数据，包括图片、文本、音频、表格等\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e检测数据标注问题、改进、训练模型、价值提升\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e支持任何框架或模型：OpenAI、HuggingFace、PyTorch\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"jina-reader\"\u003ejina reader\u003c/h3\u003e\n\u003cp\u003e抓取URL，将正文转换为良好的Markdown格式的工具\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://jina.ai/reader/\"\u003eReader API\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e一些类似的工具，by ：\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://twitter.com/9hills/status/1779830990598549998\"\u003e九原客 on Twitter / X\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://t.co/buDyt3ixUJ\"\u003ehttps://markdowndown.vercel.app\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWeb-scraper(open source):\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://t.co/inuuZWQlwt\"\u003ehttps://github.com/zzzgydi/webscraper…\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ecode-html-to-markdown:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://t.co/PsxPWBkOKf\"\u003ehttps://github.com/SivilTaram/code-html-to-markdown…\u003c/a\u003e（偏向于更好地处理代码块）\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/JimLiu/gpt-api\"\u003ehttps://github.com/JimLiu/gpt-api\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.firecrawl.dev/?x\"\u003ehttps://www.firecrawl.dev/?x\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"chainforge\"\u003e\u003cstrong\u003eChainForge\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eAn open-source visual programming environment for battle-testing prompts to LLMs.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/ianarawjo/ChainForge?tab=readme-ov-file#installation\"\u003eGitHub - ianarawjo/ChainForge: An open-source visual programming environment for battle-testing prompts to LLMs.\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"ragflow\"\u003e\u003cstrong\u003eRAGFlow\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e一个RAG框架\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/infiniflow/ragflow/blob/main/README_zh.md\"\u003ehttps://github.com/infiniflow/ragflow/blob/main/README_zh.md\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e亮点： 分块后的可视化和修改功能\u003c/p\u003e\n\u003ch3 id=\"supermemory\"\u003e\u003cstrong\u003eSuperMemory\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e一个第二大脑项目， 提供插件保存网页作为memory和基于memory对话的功能。\u003c/p\u003e","title":"2024-04 月刊"},{"content":"写在最开始 当我们在讨论基于大型语言模型（LLM-based）的智能代理（agent）时，我们究竟在谈论什么？根据Lilian W在其文章《LLM Powered Autonomous Agents》中的讨论，一个智能代理需要具备几个核心能力：规划（Planning）、记忆（Memory）、以及工具使用（Tool use）。特别地，工具使用方面的进展，得益于OpenAI在API中提供的function calling功能，为我们开启了新的可能性。\nOpenAI function calling，作为智能代理与外部工具交互的基本方式，对于每位从业者来说都是必备技能。随着技术的发展，我们期望的不只是能与我们对话的LLM，而是能够辅助我们使用各种工具、做出决策的智能伙伴。\n不过需要特别指出的是，最近OpenAI在Chat Completions API中已经废弃了“函数（function）”的使用，转而采用“工具（tool）”。这一变更旨在拓宽LLM集成的功能范围，为更复杂的交互模式铺平道路，如构建能够相互作用的多代理系统。\n尽管如此，由于语言习惯的原因，本文中仍然会使用function calling的术语来描述OpenAI的tool using功能，因为“function calling”的说法已经深入人心了。\n核心内容概览\nFunction Calling的定义：解释什么是function calling，以及它在智能代理工作中的作用。\nOpenAI Cookbook示例：提供实际的function calling示例，帮助读者理解其在实际应用中的用途。\n开源LLM的Tool Using：探索如何在开源大型语言模型中实现工具使用，以及LLM在tool using的时候经历了什么。\n评价与训练：讨论如何评价开源模型的工具使用能力，以及如何训练LLM进行有效的工具使用。\n鉴于整理笔记的速度远赶不上更新的速度， 会将第四部份作为单独的部分整理。\n何为function calling 一句话解释：function calling从本质上并不是严格的工具调用， 而是作为工具调用的前奏，它通过更加结构化的方式指导LLM输出，为在本地执行具体函数提供了参数，铺平了道路。\n具体来说，function calling允许LLM在执行过程中通过指定的参数来调用并执行一个特定的函数。这种方式不仅实现了代码的重用和模块化处理，而且能够从模型中获取更可靠的结构化数据回应。在API调用过程中，开发者可以描述想要执行的功能，并让模型智能地选择输出包含所需参数的JSON对象。这个过程中，Chat Completions API本身不直接执行任何函数调用，而是生成了可以在开发者代码中实现函数调用的JSON。\nfunction calling的应用范围广泛，如\n创建智能助手：通过调用外部API回答问题。\n转换指令：将自然语言指令转换成API调用指令。\n数据提取：从文本中提取结构化数据。\nfunction calling的过程涵盖了从定义函数集、通过模型生成遵循自定义模式的JSON对象字符串，到在代码中解析这个字符串并调用相应函数的全过程。这一连串操作不仅自动化了交互过程，还确保了执行操作的安全性和准确性。\n一些常见的问题 JSON mode json mode 和tool-using 有什么关系？有了json mode 还需要用到tool-using吗？\n从json mode 的本质， 更多的是在system prompt 增加一句类似“请以json格式输出”之类的话，然后在LLM输出时增加json结果检查和格式转换。在使用时只需要在client.chat.completions.create 中 增加response_format={ \u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot; } 即可。\n那么json mode 什么时候会用到呢？一般在做文本提取，内容提取时可以使用；以RAG场景为例， 当我们希望LLM能够帮我们对用户的query进行改写时，我们肯定是希望模型能够返回干净的json格式改写结果，这样的结果可以直接使用，而不是在模型输出一些内容后，如：\n\u0026#34;\u0026#34;\u0026#34; 好的，以下是我的改写内容： ``` real-rewrite-query ``` \u0026#34;\u0026#34;\u0026#34; 其中包含了一些模型喜欢输出的客套话，此时我们需要通过正则匹配等方法将真正希望使用内容提取出来。而这时候json mode可以直接输出需要的内容， 而跳过了额外的提取步骤。在json mode 出现之前，这样的处理我们也尝试使用过tool-using 的模式，但有点大材小用了。\n很显然， tool-using的真正强大之处并不只是对输出格式进行处理， 而是能够让模型从提供的多个tools中选择需要使用的。\n如何使用OpenAI function calling 天气查询的简单示例 环境配置\n首先，我们需要安装一些必要的Python库。这些库将帮助我们与OpenAI的API进行交互，以及完成一些辅助功能。\n!pip install scipy --quiet !pip install tenacity --quiet !pip install tiktoken --quiet !pip install termcolor --quiet !pip install openai --quiet os.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] = \u0026#34;...\u0026#34; from openai import OpenAI from tenacity import retry, wait_random_exponential, stop_after_attempt from termcolor import colored client = OpenAI() 工具函数定义\n接下来，我们定义一些实用函数，这些函数旨在方便我们向Chat Completions API发送请求，并管理与跟踪对话状态。\n@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3)) def chat_completion_request(messages, tools=None, tool_choice=None, model=\u0026#34;gpt-3.5-turbo\u0026#34;): try: response = client.chat.completions.create( model=model, messages=messages, tools=tools, tool_choice=tool_choice, ) return response except Exception as e: print(\u0026#34;Unable to generate ChatCompletion response\u0026#34;) print(f\u0026#34;Exception: {e}\u0026#34;) return e def pretty_print_conversation(messages): role_to_color = { \u0026#34;system\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;user\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;assistant\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;function\u0026#34;: \u0026#34;magenta\u0026#34;, } for message in messages: if message[\u0026#34;role\u0026#34;] == \u0026#34;system\u0026#34;: print(colored(f\u0026#34;system: {message[\u0026#39;content\u0026#39;]}\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]])) elif message[\u0026#34;role\u0026#34;] == \u0026#34;user\u0026#34;: print(colored(f\u0026#34;user: {message[\u0026#39;content\u0026#39;]}\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]])) elif message[\u0026#34;role\u0026#34;] == \u0026#34;assistant\u0026#34; and message.get(\u0026#34;function_call\u0026#34;): print(colored(f\u0026#34;assistant: {message[\u0026#39;function_call\u0026#39;]}\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]])) elif message[\u0026#34;role\u0026#34;] == \u0026#34;assistant\u0026#34; and not message.get(\u0026#34;function_call\u0026#34;): print(colored(f\u0026#34;assistant: {message[\u0026#39;content\u0026#39;]}\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]])) elif message[\u0026#34;role\u0026#34;] == \u0026#34;function\u0026#34;: print(colored(f\u0026#34;function ({message[\u0026#39;name\u0026#39;]}): {message[\u0026#39;content\u0026#39;]}\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]])) 函数规范定义\n我们还需要创建一些函数规范，以接口化与假设的天气API的交互。\ntools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the current weather\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;format\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;celsius\u0026#34;, \u0026#34;fahrenheit\u0026#34;], \u0026#34;description\u0026#34;: \u0026#34;The temperature unit to use. Infer this from the users location.\u0026#34;, }, }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;, \u0026#34;format\u0026#34;], }, } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_n_day_weather_forecast\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get an N-day weather forecast\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;format\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;celsius\u0026#34;, \u0026#34;fahrenheit\u0026#34;], \u0026#34;description\u0026#34;: \u0026#34;The temperature unit to use. Infer this from the users location.\u0026#34;, }, \u0026#34;num_days\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The number of days to forecast\u0026#34;, } }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;, \u0026#34;format\u0026#34;, \u0026#34;num_days\u0026#34;] }, } }, ] 对话示例\n当我们请求当前天气时， LLM会要求澄清问题，如地址等参数信息：\nmessages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Don\u0026#39;t make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What\u0026#39;s the weather like today\u0026#34;}) chat_response = chat_completion_request( messages, tools=tools ) assistant_message = chat_response.choices[0].message messages.append(assistant_message) assistant_message output:\nChatCompletionMessage(content=\u0026#39;Sure, may I know your current location?\u0026#39;, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=None) 当补充缺失的信息后， LLM将生成适当的函数参数\nmessages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;I\u0026#39;m in Shanghai, China.\u0026#34;}) chat_response = chat_completion_request( messages, tools=tools ) assistant_message = chat_response.choices[0].message messages.append(assistant_message) assistant_message output:\nChatCompletionMessage(content=None, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=\u0026#39;call_VdqOOMp9pagf5ho39Y2HmYV4\u0026#39;, function=Function(arguments=\u0026#39;{\\n \u0026#34;location\u0026#34;: \u0026#34;San Francisco, CA\u0026#34;,\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;,\\n \u0026#34;num_days\u0026#34;: 4\\n}\u0026#39;, name=\u0026#39;get_n_day_weather_forecast\u0026#39;), type=\u0026#39;function\u0026#39;)]) 完整流程如下：\nmessages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Don\u0026#39;t make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;what is the weather going to be like in Glasgow, Scotland over the next x days\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;in 5 days\u0026#34;}) chat_response = chat_completion_request( messages, tools=tools ) assistant_message = chat_response.choices[0].message messages.append(assistant_message) assistant_message 当然， 我们也可以强制要求使用特定的函数\nmessages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Don\u0026#39;t make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Give me a weather report for Toronto, Canada.\u0026#34;}) chat_response = chat_completion_request( messages, tools=tools, tool_choice={\u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: {\u0026#34;name\u0026#34;: \u0026#34;get_n_day_weather_forecast\u0026#34;}} ) chat_response.choices[0].message output:\nChatCompletionMessage(content=None, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=\u0026#39;call_0ldecDpV8Vdq8mGPoUewlue3\u0026#39;, function=Function(arguments=\u0026#39;{\\n \u0026#34;location\u0026#34;: \u0026#34;Toronto, Canada\u0026#34;,\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;,\\n \u0026#34;num_days\u0026#34;: 1\\n}\u0026#39;, name=\u0026#39;get_n_day_weather_forecast\u0026#39;), type=\u0026#39;function\u0026#39;)]) 并行函数调用\n对于一些特定模型，如**gpt-4-turbo-preview**, gpt-4-0125-preview, gpt-4-1106-preview, gpt-3.5-turbo-0125, and **gpt-3.5-turbo-1106**支持并行函数调用， 允许我们在单个回合中调用多个函数。\nmessages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Don\u0026#39;t make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;what is the weather going to be like in San Francisco and Glasgow over the next 4 days\u0026#34;}) chat_response = chat_completion_request( messages, tools=tools ) assistant_message = chat_response.choices[0].message.tool_calls assistant_message output:\n[ChatCompletionMessageToolCall(id=\u0026#39;call_tfl8eTCW64sHvHjiiatoYzku\u0026#39;, function=Function(arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;San Francisco, CA\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;fahrenheit\u0026#34;, \u0026#34;num_days\u0026#34;: 4}\u0026#39;, name=\u0026#39;get_n_day_weather_forecast\u0026#39;), type=\u0026#39;function\u0026#39;), ChatCompletionMessageToolCall(id=\u0026#39;call_bAqj55RygP2Y1T85RHqgskku\u0026#39;, function=Function(arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Glasgow, UK\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;, \u0026#34;num_days\u0026#34;: 4}\u0026#39;, name=\u0026#39;get_n_day_weather_forecast\u0026#39;), type=\u0026#39;function\u0026#39;)] 实现本地函数调用\n首先我们需要构造两个用于演示的假function\nimport json def get_current_weather(location, format=\u0026#34;fahrenheit\u0026#34;): \u0026#34;\u0026#34;\u0026#34; Simulates getting the current weather for a given location. The response is hardcoded for demonstration purposes. Args: location (str): The city and state, e.g., San Francisco, CA. format (str, optional): The temperature unit to use. Defaults to \u0026#34;fahrenheit\u0026#34;. Returns: str: JSON string with the current weather data. \u0026#34;\u0026#34;\u0026#34; if \u0026#34;tokyo\u0026#34; in location.lower(): return json.dumps({\u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Partly Cloudy\u0026#34;}) elif \u0026#34;san francisco\u0026#34; in location.lower(): return json.dumps({\u0026#34;location\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;72\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Sunny\u0026#34;}) elif \u0026#34;paris\u0026#34; in location.lower(): return json.dumps({\u0026#34;location\u0026#34;: \u0026#34;Paris\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Rainy\u0026#34;}) else: return json.dumps({\u0026#34;location\u0026#34;: location, \u0026#34;temperature\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Data Unavailable\u0026#34;}) def get_n_day_weather_forecast(location, num_days, format=\u0026#34;fahrenheit\u0026#34;): \u0026#34;\u0026#34;\u0026#34; Simulates getting an N-day weather forecast for a given location. The response is hardcoded for demonstration purposes. Args: location (str): The city and state, e.g., San Francisco, CA. num_days (int): The number of days to forecast. format (str, optional): The temperature unit to use. Defaults to \u0026#34;fahrenheit\u0026#34;. Returns: str: JSON string with the N-day weather forecast data. \u0026#34;\u0026#34;\u0026#34; # This example just returns a fixed response regardless of the input. # In a real scenario, the response would depend on the location, num_days, and format. forecast = [ {\u0026#34;day\u0026#34;: 1, \u0026#34;temperature\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Sunny\u0026#34;}, {\u0026#34;day\u0026#34;: 2, \u0026#34;temperature\u0026#34;: \u0026#34;18\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Cloudy\u0026#34;}, {\u0026#34;day\u0026#34;: 3, \u0026#34;temperature\u0026#34;: \u0026#34;15\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Rainy\u0026#34;} ] # Return only the forecast for the requested number of days. return json.dumps(forecast[:num_days]) available_functions = { \u0026#34;get_current_weather\u0026#34;: get_current_weather, \u0026#34;get_n_day_weather_forecast\u0026#34;: get_n_day_weather_forecast, } 尝试请求天气\nmessages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What\u0026#39;s the weather like in Tokyo!\u0026#34;}) chat_response = chat_completion_request(messages, tools=tools, tool_choice=\u0026#34;auto\u0026#34;) assistant_message = chat_response.choices[0].message assistant_message = json.loads(assistant_message.model_dump_json()) assistant_message[\u0026#34;content\u0026#34;] = str(assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;function\u0026#34;]) #a temporary patch but this should be handled differently # remove \u0026#34;function_call\u0026#34; from assistant message del assistant_message[\u0026#34;function_call\u0026#34;] assistant_message \u0026#34;\u0026#34;\u0026#34; {\u0026#39;content\u0026#39;: \u0026#39;{\\\u0026#39;arguments\\\u0026#39;: \\\u0026#39;{\\\\n \u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;,\\\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;\\\\n}\\\u0026#39;, \\\u0026#39;name\\\u0026#39;: \\\u0026#39;get_current_weather\\\u0026#39;}\u0026#39;, \u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;tool_calls\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;call_Tz8S1HgvnaBzf6CFZP1u4d1J\u0026#39;, \u0026#39;function\u0026#39;: {\u0026#39;arguments\u0026#39;: \u0026#39;{\\n \u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;,\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;\\n}\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;get_current_weather\u0026#39;}, \u0026#39;type\u0026#39;: \u0026#39;function\u0026#39;}]} \u0026#34;\u0026#34;\u0026#34; messages.append(assistant_message) 可以看到，LLM返回了json格式的参数信息（其实是str）以及需要调用的function名称， 拥有这些信息之后就可以调用之前定义的函数了\n# get the weather information to pass back to the model function_name_to_call = assistant_message[\u0026#39;tool_calls\u0026#39;][0][\u0026#39;function\u0026#39;][\u0026#39;name\u0026#39;] function_arguments = assistant_message[\u0026#39;tool_calls\u0026#39;][0][\u0026#39;function\u0026#39;][\u0026#39;arguments\u0026#39;] weather = available_functions[function_name_to_call](function_arguments) 将函数执行结果和对话历史返回给LLM\nmessages.append({\u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;id\u0026#34;], \u0026#34;name\u0026#34;: assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;function\u0026#34;][\u0026#34;name\u0026#34;], \u0026#34;content\u0026#34;: weather}) messages \u0026#34;\u0026#34;\u0026#34; [{\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#34;What\u0026#39;s the weather like in Tokyo!\u0026#34;}, {\u0026#39;content\u0026#39;: \u0026#39;{\\\u0026#39;arguments\\\u0026#39;: \\\u0026#39;{\\\\n \u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;,\\\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;\\\\n}\\\u0026#39;, \\\u0026#39;name\\\u0026#39;: \\\u0026#39;get_current_weather\\\u0026#39;}\u0026#39;, \u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;tool_calls\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;call_Tz8S1HgvnaBzf6CFZP1u4d1J\u0026#39;, \u0026#39;function\u0026#39;: {\u0026#39;arguments\u0026#39;: \u0026#39;{\\n \u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;,\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;\\n}\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;get_current_weather\u0026#39;}, \u0026#39;type\u0026#39;: \u0026#39;function\u0026#39;}]}, {\u0026#39;role\u0026#39;: \u0026#39;tool\u0026#39;, \u0026#39;tool_call_id\u0026#39;: \u0026#39;call_Tz8S1HgvnaBzf6CFZP1u4d1J\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;get_current_weather\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;fahrenheit\u0026#34;}\u0026#39;}] \u0026#34;\u0026#34;\u0026#34; 最终输出结果（for user）\nfinal_response = chat_completion_request(messages, tools=tools) final_response.choices[0].message.content output：\n\u0026#39;The current weather in Tokyo is partly cloudy with a temperature of 10°C (50°F).\u0026#39; 通过function calling 实现sql执行 下载演示所用的sqlite数据\n!wget https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip -O chinook.zip !unzip chinook.zip 连接数据库，和定义一些function\nimport sqlite3 conn = sqlite3.connect(\u0026#34;/content/chinook.db\u0026#34;) print(\u0026#34;Opened database successfully\u0026#34;) def get_table_names(conn): \u0026#34;\u0026#34;\u0026#34;Return a list of table names.\u0026#34;\u0026#34;\u0026#34; table_names = [] tables = conn.execute(\u0026#34;SELECT name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39;;\u0026#34;) for table in tables.fetchall(): table_names.append(table[0]) return table_names def get_column_names(conn, table_name): \u0026#34;\u0026#34;\u0026#34;Return a list of column names.\u0026#34;\u0026#34;\u0026#34; column_names = [] columns = conn.execute(f\u0026#34;PRAGMA table_info(\u0026#39;{table_name}\u0026#39;);\u0026#34;).fetchall() for col in columns: column_names.append(col[1]) return column_names def get_database_info(conn): \u0026#34;\u0026#34;\u0026#34;Return a list of dicts containing the table name and columns for each table in the database.\u0026#34;\u0026#34;\u0026#34; table_dicts = [] for table_name in get_table_names(conn): columns_names = get_column_names(conn, table_name) table_dicts.append({\u0026#34;table_name\u0026#34;: table_name, \u0026#34;column_names\u0026#34;: columns_names}) return table_dicts 获取db 的schema\ndatabase_schema_dict = get_database_info(conn) database_schema_string = \u0026#34;\\n\u0026#34;.join( [ f\u0026#34;Table: {table[\u0026#39;table_name\u0026#39;]}\\nColumns: {\u0026#39;, \u0026#39;.join(table[\u0026#39;column_names\u0026#39;])}\u0026#34; for table in database_schema_dict ] ) 定义tools工具列表\ntools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ask_database\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Use this function to answer user questions about music. Input should be a fully formed SQL query.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;\u0026#34;\u0026#34; SQL query extracting info to answer the user\u0026#39;s question. SQL should be written using this database schema: {database_schema_string} The query should be returned in plain text, not in JSON. \u0026#34;\u0026#34;\u0026#34;, } }, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;], }, } } ] 定义用于执行sql的function\ndef ask_database(conn, query): \u0026#34;\u0026#34;\u0026#34;Function to query SQLite database with a provided SQL query.\u0026#34;\u0026#34;\u0026#34; try: results = str(conn.execute(query).fetchall()) except Exception as e: results = f\u0026#34;query failed with error: {e}\u0026#34; return results def execute_function_call(message): if message.tool_calls[0].function.name == \u0026#34;ask_database\u0026#34;: query = json.loads(message.tool_calls[0].function.arguments)[\u0026#34;query\u0026#34;] results = ask_database(conn, query) else: results = f\u0026#34;Error: function {message.tool_calls[0].function.name} does not exist\u0026#34; return results messages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Answer user questions by generating SQL queries against the Chinook Music Database.\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Hi, who are the top 5 artists by number of tracks?\u0026#34;}) chat_response = chat_completion_request(messages, tools) assistant_message = chat_response.choices[0].message messages.append(assistant_message) if assistant_message.tool_calls: results = execute_function_call(assistant_message) messages.append({\u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: assistant_message.tool_calls[0].id, \u0026#34;name\u0026#34;: assistant_message.tool_calls[0].function.name, \u0026#34;content\u0026#34;: results}) 此时的messages\n[{\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;Answer user questions by generating SQL queries against the Chinook Music Database.\u0026#39;}, {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;Hi, who are the top 5 artists by number of tracks?\u0026#39;}, ChatCompletionMessage(content=\u0026#39;Function(arguments=\\\u0026#39;{\\\\n \u0026#34;query\u0026#34;: \u0026#34;SELECT artists.Name, COUNT(tracks.TrackId) AS num_tracks FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.ArtistId ORDER BY num_tracks DESC LIMIT 5\u0026#34;\\\\n}\\\u0026#39;, name=\\\u0026#39;ask_database\\\u0026#39;)\u0026#39;, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=\u0026#39;call_vSLysEQncbGvMgXGhttIow6v\u0026#39;, function=Function(arguments=\u0026#39;{\\n \u0026#34;query\u0026#34;: \u0026#34;SELECT artists.Name, COUNT(tracks.TrackId) AS num_tracks FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.ArtistId ORDER BY num_tracks DESC LIMIT 5\u0026#34;\\n}\u0026#39;, name=\u0026#39;ask_database\u0026#39;), type=\u0026#39;function\u0026#39;)]), {\u0026#39;role\u0026#39;: \u0026#39;tool\u0026#39;, \u0026#39;tool_call_id\u0026#39;: \u0026#39;call_vSLysEQncbGvMgXGhttIow6v\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;ask_database\u0026#39;, \u0026#39;content\u0026#39;: \u0026#34;[(\u0026#39;Iron Maiden\u0026#39;, 213), (\u0026#39;U2\u0026#39;, 135), (\u0026#39;Led Zeppelin\u0026#39;, 114), (\u0026#39;Metallica\u0026#39;, 112), (\u0026#39;Deep Purple\u0026#39;, 92)]\u0026#34;}] 最终输出：\nfinal_response = chat_completion_request(messages, tools=tools) final_response.choices[0].message.content # output \u0026#34;\u0026#34;\u0026#34; The top 5 artists by number of tracks are: 1. Iron Maiden - 213 tracks 2. U2 - 135 tracks 3. Led Zeppelin - 114 tracks 4. Metallica - 112 tracks 5. Deep Purple - 92 tracks \u0026#34;\u0026#34;\u0026#34; 基于function calling构建智能代理：自动获取与深度解析arXiv学术文章 在这一节中将介绍如何构建一个能够从arXiv上查找论文， 下载分析并总结学术论文的Agent。这个Agent不仅可以帮助用户快速了解特定领域的最新研究动态，而且还能深入分析和总结选定文章的核心内容。\nAgent核心功能\n获取arXiv文章 get_articles 代理通过**arxiv**库搜索关于特定主题的文章，为用户提供简要的文章摘要和链接。\n阅读并总结文章 read_article_and_summarize 利用**PyPDF2**库读取选中文章的PDF文件，代理能够提炼出文章的主要论点、支撑证据和结论。\n环境配置\n!pip install scipy --quiet !pip install tenacity --quiet !pip install tiktoken==0.3.3 --quiet !pip install termcolor --quiet !pip install openai --quiet !pip install arxiv --quiet !pip install pandas --quiet !pip install PyPDF2 --quiet !pip install tqdm --quiet import os import arxiv import ast import concurrent import json import os import pandas as pd import tiktoken from csv import writer from IPython.display import display, Markdown, Latex from openai import OpenAI from PyPDF2 import PdfReader from scipy import spatial from tenacity import retry, wait_random_exponential, stop_after_attempt from tqdm import tqdm from termcolor import colored GPT_MODEL = \u0026#34;gpt-3.5-turbo-0613\u0026#34; EMBEDDING_MODEL = \u0026#34;text-embedding-ada-002\u0026#34; client = OpenAI() 所有下载的论文都被存储在本地**./data/papers目录中，并且每篇文章的详细信息（包括其嵌入向量）都记录在arxiv_library.csv**文件中。\ndirectory = \u0026#39;./data/papers\u0026#39; # Check if the directory already exists if not os.path.exists(directory): # If the directory doesn\u0026#39;t exist, create it and any necessary intermediate directories os.makedirs(directory) print(f\u0026#34;Directory \u0026#39;{directory}\u0026#39; created successfully.\u0026#34;) else: # If the directory already exists, print a message indicating it print(f\u0026#34;Directory \u0026#39;{directory}\u0026#39; already exists.\u0026#34;) # Set a directory to store downloaded papers data_dir = os.path.join(os.curdir, \u0026#34;data\u0026#34;, \u0026#34;papers\u0026#34;) paper_dir_filepath = \u0026#34;./data/arxiv_library.csv\u0026#34; # Generate a blank dataframe where we can store downloaded files df = pd.DataFrame(list()) df.to_csv(paper_dir_filepath) 我们将定义一些utils function用于：\n文章获取与存储：通过**get_articles**函数查询主题相关的文章，系统自动下载文章并记录重要信息及embedding向量。\n文章选择与内容提取：根据用户的查询，系统通过计算embedding向量的相似度来选择最相关的文章，并提取出文章的文本内容。\n内容分块与总结：长文本被分割成多个较小的块，每个块被独立总结。\n汇总总结：所有独立块的总结被汇总成一篇全面的总结，更好地回应用户的查询。\n@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3)) def embedding_request(text): response = client.embeddings.create(input=text, model=EMBEDDING_MODEL) return response @retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3)) def get_articles(query, library=paper_dir_filepath, top_k=5): \u0026#34;\u0026#34;\u0026#34;This function gets the top_k articles based on a user\u0026#39;s query, sorted by relevance. It also downloads the files and stores them in arxiv_library.csv to be retrieved by the read_article_and_summarize. \u0026#34;\u0026#34;\u0026#34; client = arxiv.Client() search = arxiv.Search( query = query, max_results = top_k, sort_by = arxiv.SortCriterion.SubmittedDate ) result_list = [] for result in client.results(search): result_dict = {} result_dict.update({\u0026#34;title\u0026#34;: result.title}) result_dict.update({\u0026#34;summary\u0026#34;: result.summary}) # Taking the first url provided result_dict.update({\u0026#34;article_url\u0026#34;: [x.href for x in result.links][0]}) result_dict.update({\u0026#34;pdf_url\u0026#34;: [x.href for x in result.links][1]}) result_list.append(result_dict) # Store references in library file response = embedding_request(text=result.title) file_reference = [ result.title, result.download_pdf(data_dir), response.data[0].embedding, ] # Write to file with open(library, \u0026#34;a\u0026#34;) as f_object: writer_object = writer(f_object) writer_object.writerow(file_reference) f_object.close() return result_list def strings_ranked_by_relatedness( query: str, df: pd.DataFrame, relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y), top_n: int = 100, ) -\u0026gt; list[str]: \u0026#34;\u0026#34;\u0026#34;Returns a list of strings and relatednesses, sorted from most related to least.\u0026#34;\u0026#34;\u0026#34; query_embedding_response = embedding_request(query) query_embedding = query_embedding_response.data[0].embedding strings_and_relatednesses = [ (row[\u0026#34;filepath\u0026#34;], relatedness_fn(query_embedding, row[\u0026#34;embedding\u0026#34;])) for i, row in df.iterrows() ] strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True) strings, relatednesses = zip(*strings_and_relatednesses) return strings[:top_n] def read_pdf(filepath): \u0026#34;\u0026#34;\u0026#34;Takes a filepath to a PDF and returns a string of the PDF\u0026#39;s contents\u0026#34;\u0026#34;\u0026#34; # creating a pdf reader object reader = PdfReader(filepath) pdf_text = \u0026#34;\u0026#34; page_number = 0 for page in reader.pages: page_number += 1 pdf_text += page.extract_text() + f\u0026#34;\\nPage Number: {page_number}\u0026#34; return pdf_text # Split a text into smaller chunks of size n, preferably ending at the end of a sentence def create_chunks(text, n, tokenizer): \u0026#34;\u0026#34;\u0026#34;Returns successive n-sized chunks from provided text.\u0026#34;\u0026#34;\u0026#34; tokens = tokenizer.encode(text) i = 0 while i \u0026lt; len(tokens): # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens j = min(i + int(1.5 * n), len(tokens)) while j \u0026gt; i + int(0.5 * n): # Decode the tokens and check for full stop or newline chunk = tokenizer.decode(tokens[i:j]) if chunk.endswith(\u0026#34;.\u0026#34;) or chunk.endswith(\u0026#34;\\n\u0026#34;): break j -= 1 # If no end of sentence found, use n tokens as the chunk size if j == i + int(0.5 * n): j = min(i + n, len(tokens)) yield tokens[i:j] i = j def extract_chunk(content, template_prompt): \u0026#34;\u0026#34;\u0026#34;This function applies a prompt to some input content. In this case it returns a summarized chunk of text\u0026#34;\u0026#34;\u0026#34; prompt = template_prompt + content response = client.chat.completions.create( model=GPT_MODEL, messages=[{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: prompt}], temperature=0 ) return response.choices[0].message.content def summarize_text(query): \u0026#34;\u0026#34;\u0026#34;This function does the following: - Reads in the arxiv_library.csv file in including the embeddings - Finds the closest file to the user\u0026#39;s query - Scrapes the text out of the file and chunks it - Summarizes each chunk in parallel - Does one final summary and returns this to the user\u0026#34;\u0026#34;\u0026#34; # A prompt to dictate how the recursive summarizations should approach the input paper summary_prompt = \u0026#34;\u0026#34;\u0026#34;Summarize this text from an academic paper. Extract any key points with reasoning.\\n\\nContent:\u0026#34;\u0026#34;\u0026#34; # If the library is empty (no searches have been performed yet), we perform one and download the results library_df = pd.read_csv(paper_dir_filepath).reset_index() if len(library_df) == 0: print(\u0026#34;No papers searched yet, downloading first.\u0026#34;) get_articles(query) print(\u0026#34;Papers downloaded, continuing\u0026#34;) library_df = pd.read_csv(paper_dir_filepath).reset_index() library_df.columns = [\u0026#34;title\u0026#34;, \u0026#34;filepath\u0026#34;, \u0026#34;embedding\u0026#34;] library_df[\u0026#34;embedding\u0026#34;] = library_df[\u0026#34;embedding\u0026#34;].apply(ast.literal_eval) strings = strings_ranked_by_relatedness(query, library_df, top_n=1) print(\u0026#34;Chunking text from paper\u0026#34;) pdf_text = read_pdf(strings[0]) # Initialise tokenizer tokenizer = tiktoken.get_encoding(\u0026#34;cl100k_base\u0026#34;) results = \u0026#34;\u0026#34; # Chunk up the document into 1500 token chunks chunks = create_chunks(pdf_text, 1500, tokenizer) text_chunks = [tokenizer.decode(chunk) for chunk in chunks] print(\u0026#34;Summarizing each chunk of text\u0026#34;) # Parallel process the summaries with concurrent.futures.ThreadPoolExecutor( max_workers=len(text_chunks) ) as executor: futures = [ executor.submit(extract_chunk, chunk, summary_prompt) for chunk in text_chunks ] with tqdm(total=len(text_chunks)) as pbar: for _ in concurrent.futures.as_completed(futures): pbar.update(1) for future in futures: data = future.result() results += data # Final summary print(\u0026#34;Summarizing into overall summary\u0026#34;) response = client.chat.completions.create( model=GPT_MODEL, messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;\u0026#34;\u0026#34;Write a summary collated from this collection of key points extracted from an academic paper. The summary should highlight the core argument, conclusions and evidence, and answer the user\u0026#39;s query. User query: {query} The summary should be structured in bulleted lists following the headings Core Argument, Evidence, and Conclusions. Key points:\\n{results}\\nSummary:\\n\u0026#34;\u0026#34;\u0026#34;, } ], temperature=0, ) return response 实现一个**Conversation**类，用于支持与API进行多轮对话\n@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3)) def chat_completion_request(messages, functions=None, model=GPT_MODEL): try: response = client.chat.completions.create( model=model, messages=messages, functions=functions, ) return response except Exception as e: print(\u0026#34;Unable to generate ChatCompletion response\u0026#34;) print(f\u0026#34;Exception: {e}\u0026#34;) return e class Conversation: def __init__(self): self.conversation_history = [] def add_message(self, role, content): message = {\u0026#34;role\u0026#34;: role, \u0026#34;content\u0026#34;: content} self.conversation_history.append(message) def display_conversation(self, detailed=False): role_to_color = { \u0026#34;system\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;user\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;assistant\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;function\u0026#34;: \u0026#34;magenta\u0026#34;, } for message in self.conversation_history: print( colored( f\u0026#34;{message[\u0026#39;role\u0026#39;]}: {message[\u0026#39;content\u0026#39;]}\\n\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]], ) ) 完成以上基本工作， 接下来是agent的核心内容\n定义工具列表 tools\narxiv_functions = [ { \u0026#34;name\u0026#34;: \u0026#34;get_articles\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;\u0026#34;Use this function to get academic papers from arXiv to answer user questions.\u0026#34;\u0026#34;\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;\u0026#34;\u0026#34; User query in JSON. Responses should be summarized and should include the article URL reference \u0026#34;\u0026#34;\u0026#34;, } }, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;], }, }, { \u0026#34;name\u0026#34;: \u0026#34;read_article_and_summarize\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;\u0026#34;Use this function to read whole papers and provide a summary for users. You should NEVER call this function before get_articles has been called in the conversation.\u0026#34;\u0026#34;\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;\u0026#34;\u0026#34; Description of the article in plain text based on the user\u0026#39;s query \u0026#34;\u0026#34;\u0026#34;, } }, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;], }, } ] 定义function用于工具调用\ndef chat_completion_with_function_execution(messages, functions=[None]): \u0026#34;\u0026#34;\u0026#34;This function makes a ChatCompletion API call with the option of adding functions\u0026#34;\u0026#34;\u0026#34; response = chat_completion_request(messages, functions) full_message = response.choices[0] if full_message.finish_reason == \u0026#34;function_call\u0026#34;: print(f\u0026#34;Function generation requested, calling function\u0026#34;) return call_arxiv_function(messages, full_message) else: print(f\u0026#34;Function not required, responding to user\u0026#34;) return response def call_arxiv_function(messages, full_message): \u0026#34;\u0026#34;\u0026#34;Function calling function which executes function calls when the model believes it is necessary. Currently extended by adding clauses to this if statement.\u0026#34;\u0026#34;\u0026#34; if full_message.message.function_call.name == \u0026#34;get_articles\u0026#34;: try: parsed_output = json.loads( full_message.message.function_call.arguments ) print(\u0026#34;Getting search results\u0026#34;) results = get_articles(parsed_output[\u0026#34;query\u0026#34;]) except Exception as e: print(parsed_output) print(f\u0026#34;Function execution failed\u0026#34;) print(f\u0026#34;Error message: {e}\u0026#34;) messages.append( { \u0026#34;role\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;name\u0026#34;: full_message.message.function_call.name, \u0026#34;content\u0026#34;: str(results), } ) try: print(\u0026#34;Got search results, summarizing content\u0026#34;) response = chat_completion_request(messages) return response except Exception as e: print(type(e)) raise Exception(\u0026#34;Function chat request failed\u0026#34;) elif ( full_message.message.function_call.name == \u0026#34;read_article_and_summarize\u0026#34; ): parsed_output = json.loads( full_message.message.function_call.arguments ) print(\u0026#34;Finding and reading paper\u0026#34;) summary = summarize_text(parsed_output[\u0026#34;query\u0026#34;]) return summary else: raise Exception(\u0026#34;Function does not exist and cannot be called\u0026#34;) arXiv conversation, Start with a system message\npaper_system_message = \u0026#34;\u0026#34;\u0026#34;You are arXivGPT, a helpful assistant pulls academic papers to answer user questions. You summarize the papers clearly so the customer can decide which to read to answer their question. You always provide the article_url and title so the user can understand the name of the paper and click through to access it. Begin!\u0026#34;\u0026#34;\u0026#34; paper_conversation = Conversation() paper_conversation.add_message(\u0026#34;system\u0026#34;, paper_system_message) # Add a user message paper_conversation.add_message(\u0026#34;user\u0026#34;, \u0026#34;Hi, how does PPO reinforcement learning work?\u0026#34;) chat_response = chat_completion_with_function_execution( paper_conversation.conversation_history, functions=arxiv_functions ) assistant_message = chat_response.choices[0].message.content paper_conversation.add_message(\u0026#34;assistant\u0026#34;, assistant_message) display(Markdown(assistant_message)) output:\nFunction generation requested, calling function Getting search results Got search results, summarizing content I found several papers related to PPO reinforcement learning. Here are a few summaries: Title: \u0026#34;Bandit Profit-maximization for Targeted Marketing\u0026#34; Summary: This paper presents near-optimal algorithms for optimizing profit over multiple demand curves, which are dependent on different ancillary variables while maintaining the same price. It is relevant to PPO reinforcement learning as it tackles a sequential profit-maximization problem. Article URL: Link Title: \u0026#34;Inferring potential landscapes: A Schrödinger bridge approach to Maximum Caliber\u0026#34; Summary: This work extends Schrödinger bridges to account for integral constraints along paths, specifically in the context of Maximum Caliber, a Maximum Entropy principle applied in a dynamic context. While not directly related to PPO reinforcement learning, it can provide insights into stochastic dynamics and inference of time-varying potential landscapes. Article URL: Link Title: \u0026#34;a-DCF: an architecture agnostic metric with application to spoofing-robust speaker verification\u0026#34; Summary: This paper proposes an architecture-agnostic detection cost function (a-DCF) for evaluating spoofing-robust automatic speaker verification (ASV) systems. Although it does not focus on PPO reinforcement learning, it provides a metric for evaluating ASV systems in the presence of spoofing attacks. Article URL: Link These papers should provide insights into different aspects of reinforcement learning and related topics. Add another user message to induce our system to use the second tool\npaper_conversation.add_message( \u0026#34;user\u0026#34;, \u0026#34;Can you read the PPO sequence generation paper for me and give me a summary\u0026#34;, ) updated_response = chat_completion_with_function_execution( paper_conversation.conversation_history, functions=arxiv_functions ) display(Markdown(updated_response.choices[0].message.content)) output:\nFunction generation requested, calling function Finding and reading paper Chunking text from paper Summarizing each chunk of text 100%|██████████| 4/4 [00:04\u0026lt;00:00, 1.11s/it] Summarizing into overall summary Core Argument: The paper discusses the potential of using a general-purpose large language model (LLM) to learn the structural biophysics of DNA. The authors show that fine-tuning a LLM, specifically chatGPT 3.5-turbo, can enhance its ability to analyze and design DNA sequences and their structures. The study focuses on the formation of secondary structures in DNA, which are governed by base pairing and stacking bonds. The authors propose a method that involves chaining together models fine-tuned for subtasks and using a chain-of-thought approach to improve the model\u0026#39;s performance. Evidence: The authors use the NUPACK software suite to provide data for training and validation. The expert pipeline approach involves using models that have been fine-tuned for subtasks and feeding their outputs into each other. The models perform better when they explicitly consider the nearest neighbor window and the reverse complement of the sequences. The pipeline approach, where a separate model determines the reverse complement and feeds it to another model for secondary structure prediction, enhances the accuracy of the predictions. The performance of the models improves with larger training sets. Conclusions: The study demonstrates the potential of using LLMs to learn DNA structural biophysics. Integrating experimental data and machine learning is important in scientific research. The expert pipeline approach and breaking down the problem into smaller subtasks improve the performance of the models in DNA sequence analysis. The combination of chain-of-thought and model pipeline provides the best results in analysis tasks. The CoT approach, combined with the reverse complement transformation, yields the highest accuracy in design tasks. The addition of an error checking layer further improves accuracy in design tasks. Sequence design is more challenging than analysis, but error correction can compensate for the increased difficulty. Larger training sets benefit design tasks more. Future research directions include exploring chaining smaller models for performance improvement and using an LLM architecture involving both an encoder and decoder for direct sequence comparison. Function calling via open source LLMs 在考虑成本和隐私性的背景下，我们可能会倾向于在开源的大型语言模型（LLM）上实现函数调用功能。目前，有几个框架支持以类似OpenAI API的形式调用工具（tools call）：\nXinference\nText Generation Inference (TGI)\n而在开源大型语言模型（LLM）方面，支持工具调用的主要有：\nLlama-3\nMixtral-8x7B-Instruct-v0.1\nqwent\nchatGLM-6B\nNexusRaven-13B\ngorilla-openfunctions-v1\n等等\n以下以Xinference和chatGLM-6B为例，探索如何通过OpenAI API的形式调用开源模型的函数调用功能。\n环境\n%pip install -U -q xinference[transformers] openai langchain !pip install typing-extensions --upgrade ## Start Local Server !nohup xinference-local \u0026gt; xinference.log 2\u0026gt;\u0026amp;1 \u0026amp; 模型加载\n!xinference launch -u my-llm --model-name chatglm3 --size-in-billions 6 --model-format pytorch ## Interact with the running model import openai messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Who are you?\u0026#34; } ] client = openai.Client(api_key=\u0026#34;empty\u0026#34;, base_url=f\u0026#34;http://0.0.0.0:9997/v1\u0026#34;) client.chat.completions.create( model=\u0026#34;my-llm\u0026#34;, messages=messages, ) # ChatCompletion(id=\u0026#39;chatda6056ac-da01-11ee-b92e-0242ac1c000c\u0026#39;, choices=[Choice(finish_reason=\u0026#39;stop\u0026#39;, index=0, logprobs=None, message=ChatCompletionMessage(content=\u0026#34;I am an AI assistant named ChatGLM3-6B, which is developed based on the language model jointly trained by Tsinghua University KEG Lab and Zhipu AI Company in 2023. My job is to provide appropriate answers and support to users\u0026#39; questions and requests.\u0026#34;, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=None))], created=1709541198, model=\u0026#39;my-llm\u0026#39;, object=\u0026#39;chat.completion\u0026#39;, system_fingerprint=None, usage=CompletionUsage(completion_tokens=-1, prompt_tokens=-1, total_tokens=-1)) without tool using\ncompletion = client.chat.completions.create( model=\u0026#34;my-llm\u0026#34;, messages=[{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What is the weather like in London?\u0026#34;}] ) # print(handle_response(completion)) print(completion.choices[0].message.content) \u0026#34;\u0026#34;\u0026#34; London has a temperate climate with warm summers and cool winters. The average temperature during the summer months (June to August) is around 18°C, while the winter months (December to February) are around 6°C. The city experiences heavy rainfall throughout the year, with an annual precipitation of around 350 mm. The average precipitation on the weekends is around 40 mm. London\u0026#39;s cloudy skies are common throughout the year, but they are especially prevalent in December and January. \u0026#34;\u0026#34;\u0026#34; tool using\ntools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the current weather in a given location\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;unit\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;celsius\u0026#34;, \u0026#34;fahrenheit\u0026#34;]}, }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;], }, }, } ] def get_completion(messages, model=\u0026#34;my-llm\u0026#34;, temperature=0, max_tokens=500, tools=None, tool_choice=None): response = client.chat.completions.create( model=model, messages=messages, temperature=temperature, max_tokens=max_tokens, tools=tools, tool_choice=tool_choice ) return response.choices[0].message # Defines a dummy function to get the current weather def get_current_weather(location, unit=\u0026#34;fahrenheit\u0026#34;): \u0026#34;\u0026#34;\u0026#34;Get the current weather in a given location\u0026#34;\u0026#34;\u0026#34; weather = { \u0026#34;location\u0026#34;: location, \u0026#34;temperature\u0026#34;: \u0026#34;50\u0026#34;, \u0026#34;unit\u0026#34;: unit, } return json.dumps(weather) messages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What\u0026#39;s the weather like in Boston!\u0026#34;}) assistant_message = get_completion(messages, tools=tools, tool_choice=\u0026#34;auto\u0026#34;) assistant_message = json.loads(assistant_message.model_dump_json()) assistant_message[\u0026#34;content\u0026#34;] = str(assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;function\u0026#34;]) #a temporary patch but this should be handled differently # remove \u0026#34;function_call\u0026#34; from assistant message del assistant_message[\u0026#34;function_call\u0026#34;] messages.append(assistant_message) # get the weather information to pass back to the model weather = get_current_weather(messages[1][\u0026#34;tool_calls\u0026#34;][0][\u0026#34;function\u0026#34;][\u0026#34;arguments\u0026#34;]) messages.append({\u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;id\u0026#34;], \u0026#34;name\u0026#34;: assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;function\u0026#34;][\u0026#34;name\u0026#34;], \u0026#34;content\u0026#34;: weather}) final_response = get_completion(messages, tools=tools) final_response \u0026#34;\u0026#34;\u0026#34; ChatCompletionMessage(content=\u0026#39;The current weather in Boston is 50 degrees Fahrenheit.\u0026#39;, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[]) \u0026#34;\u0026#34;\u0026#34; LLM 在执行function calling时经历了什么 可惜我们并不能看到openAI的模型在服务器端发生了什么，但是根据开源的模型和推理框架，我们某种程度上，也能对LLM在执行function calling的背后逻辑一探究竟。\n这部分内容可以从推理框架和开源模型的源码中找到答案。\n根据xinference 的源码：https://github.com/xorbitsai/inference/blob/main/xinference/model/llm/utils.py#L42\n我们主要关注ChatGLM3 和Qwen\n当我们使用以下假设对话时：\nmessages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;今天北京的天气怎么样？\u0026#34; } ] tools = [ { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the current weather in a given location\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;unit\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;], }, } ] 根据GLM的官方文档，则最终给到ChatGLM3模型的prompt应该长这样：\n\u0026lt;|system|\u0026gt; Answer the following questions as best as you can. You have access to the following tools: [ { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the current weather in a given location\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;unit\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;], }, } ] \u0026lt;|user|\u0026gt; 今天北京的天气怎么样？ \u0026lt;|assistant|\u0026gt; 好的，让我们来查看今天的天气 \u0026lt;|assistant|\u0026gt;get_current_weather ```python tool_call(location=\u0026#34;beijing\u0026#34;, unit=\u0026#34;celsius\u0026#34;) ``` \u0026lt;|observation|\u0026gt; {\u0026#34;temperature\u0026#34;: 22} \u0026lt;|assistant|\u0026gt; 根据查询结果，今天北京的气温为 22 摄氏度。 根据xinference 中有关qwen的代码\nelif prompt_style.style_name == \u0026#34;QWEN\u0026#34;: if tools: tool_desc = \u0026#34;\u0026#34;\u0026#34;{name_for_model}: Call this tool to interact with the {name_for_human} API. What is the {name_for_human} API useful for? {description_for_model} Parameters: {parameters} Format the arguments as a JSON object.\u0026#34;\u0026#34;\u0026#34; react_instruction = \u0026#34;\u0026#34;\u0026#34;Answer the following questions as best you can. You have access to the following APIs: {tools_text} Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [{tools_name_text}] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can be repeated zero or more times) Thought: I now know the final answer Final Answer: the final answer to the original input question Begin!\u0026#34;\u0026#34;\u0026#34; tools_text = [] tools_name_text = [] for func_info in tools: parameters = [] required_parameters = func_info[\u0026#34;function\u0026#34;][\u0026#34;parameters\u0026#34;].get( \u0026#34;required\u0026#34;, [] ) for name, p in func_info[\u0026#34;function\u0026#34;][\u0026#34;parameters\u0026#34;][ \u0026#34;properties\u0026#34; ].items(): param = dict({\u0026#34;name\u0026#34;: name}, **p) if name in required_parameters: param[\u0026#34;required\u0026#34;] = True parameters.append(param) name = func_info[\u0026#34;function\u0026#34;][\u0026#34;name\u0026#34;] desc = func_info[\u0026#34;function\u0026#34;][\u0026#34;description\u0026#34;] tool_string = tool_desc.format( name_for_model=name, name_for_human=name, # Hint: You can add the following format requirements in description: # \u0026#34;Format the arguments as a JSON object.\u0026#34; # \u0026#34;Enclose the code within triple backticks (`) at the beginning and end of the code.\u0026#34; description_for_model=desc, parameters=json.dumps(parameters, ensure_ascii=False), ) tools_text.append(tool_string) tools_name_text.append(name) tools_text_string = \u0026#34;\\n\\n\u0026#34;.join(tools_text) tools_name_text_string = \u0026#34;, \u0026#34;.join(tools_name_text) tool_system = react_instruction.format( tools_text=tools_text_string, tools_name_text=tools_name_text_string, ) else: tool_system = \u0026#34;\u0026#34; ret = f\u0026#34;\u0026lt;|im_start|\u0026gt;system\\n{prompt_style.system_prompt}\u0026lt;|im_end|\u0026gt;\u0026#34; for message in chat_history: role = get_role(message[\u0026#34;role\u0026#34;]) content = message[\u0026#34;content\u0026#34;] ret += prompt_style.intra_message_sep if tools: if role == \u0026#34;user\u0026#34;: if tool_system: content = tool_system + f\u0026#34;\\n\\nQuestion: {content}\u0026#34; tool_system = \u0026#34;\u0026#34; else: content = f\u0026#34;Question: {content}\u0026#34; elif role == \u0026#34;assistant\u0026#34;: tool_calls = message.get(\u0026#34;tool_calls\u0026#34;) if tool_calls: func_call = tool_calls[0][\u0026#34;function\u0026#34;] f_name, f_args = ( func_call[\u0026#34;name\u0026#34;], func_call[\u0026#34;arguments\u0026#34;], ) content = f\u0026#34;Thought: I can use {f_name}.\\nAction: {f_name}\\nAction Input: {f_args}\u0026#34; elif content: content = f\u0026#34;Thought: I now know the final answer.\\nFinal answer: {content}\u0026#34; elif role == \u0026#34;tool\u0026#34;: role = \u0026#34;function\u0026#34; content = f\u0026#34;Observation: {content}\u0026#34; else: raise Exception(f\u0026#34;Unsupported message role: {role}\u0026#34;) if content: content = content.lstrip(\u0026#34;\\n\u0026#34;).rstrip() ret += f\u0026#34;\u0026lt;|im_start|\u0026gt;{role}\\n{content}\u0026lt;|im_end|\u0026gt;\u0026#34; else: ret += f\u0026#34;\u0026lt;|im_start|\u0026gt;{role}\\n\u0026#34; return ret 会稍微复杂一些， 利用了react的COT方式（代码中的react_instruction），要求模型以一系列的**Thought（思考）、Action（行动）、Action Input（行动输入）和Observation**（观察结果）步骤，最终给出问题的答案，以增加正确性。\n假设使用以下工具列表和对话历史：\n# 工具列表 tools = [ { \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;geo_lookup\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Retrieves geographical information.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;], \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The query to lookup.\u0026#34; } } } } } ] chat_history = [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What is the population of Tokyo?\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;tool_calls\u0026#34;: [ { \u0026#34;function\u0026#34;: \u0026#34;geo_lookup\u0026#34;, \u0026#34;arguments\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Tokyo\u0026#34; } } ], \u0026#34;content\u0026#34;: \u0026#34;The population of Tokyo is about 14 million.\u0026#34; } ] 可以推断出，最终输入Qwen的prompt应该长这样：\nsystem Answer the following questions as best you can. You have access to the following APIs: geo_lookup: Call this tool to interact with the geo_lookup API. What is the geo_lookup API useful for? Retrieves geographical information. Parameters: [{\u0026#34;name\u0026#34;: \u0026#34;query\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The query to lookup.\u0026#34;, \u0026#34;required\u0026#34;: true}] Format the arguments as a JSON object. Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [geo_lookup] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can be repeated zero or more times) Thought: I now know the final answer Final Answer: the final answer to the original input question Begin! user Question: What is the population of Tokyo? assistant Thought: I can use geo_lookup to find the information. Action: geo_lookup Action Input: {\u0026#34;query\u0026#34;: \u0026#34;Tokyo\u0026#34;} Observation: The population of Tokyo is about 14 million. Thought: I now know the final answer. Final answer: The population of Tokyo is about 14 million. 在这个例子中，用户询问东京的人口数量。助手利用**geo_lookup**工具进行查询，具体的行动步骤包括：\n思考：助手决定可以使用**geo_lookup**工具来查找信息。\n行动：实际调用**geo_lookup**工具。\n行动输入：向工具传递的参数，即查询**\u0026quot;Tokyo\u0026quot;**。\n观察：观察到的结果，这里是东京的人口大约为1400万。\n最终思考：基于观察结果，助手得出了最终答案。\n最终答案：向用户提供的答案，即东京的人口数量。\n更详细的内容，建议看这篇知乎文章：Qwen Function Calling 的对话模板及训练方法总结; 以及qwen的官方文档：ReAct Prompting 示例\n参考 openAI function calling\nHow to call functions with chat models\nHow_to_call_functions_for_knowledge_retrieval\nQwen Function Calling 的对话模板及训练方法总结\nqwen的官方文档\nGLM的官方文档\ntool-using via Groq API\nJson mode in Groq\nOpenAI JSON Mode \u0026amp; Seeding\nOpenAI API Guide: Using JSON Mode\n","permalink":"https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0openai-function-calling%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/","summary":"\u003ch2 id=\"写在最开始\"\u003e写在最开始\u003c/h2\u003e\n\u003cp\u003e当我们在讨论基于大型语言模型（LLM-based）的智能代理（agent）时，我们究竟在谈论什么？根据Lilian W在其文章《LLM Powered Autonomous Agents》中的讨论，一个智能代理需要具备几个核心能力：规划（Planning）、记忆（Memory）、以及工具使用（Tool use）。特别地，工具使用方面的进展，得益于OpenAI在API中提供的function calling功能，为我们开启了新的可能性。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://lilianweng.github.io/posts/2023-06-23-agent/agent-overview.png\" alt=\"AGI\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eOpenAI function calling，作为智能代理与外部工具交互的基本方式，对于每位从业者来说都是必备技能。随着技术的发展，我们期望的不只是能与我们对话的LLM，而是能够辅助我们使用各种工具、做出决策的智能伙伴。\u003c/p\u003e\n\u003cp\u003e不过需要特别指出的是，最近OpenAI在Chat Completions API中已经废弃了“函数（function）”的使用，转而采用“工具（tool）”。这一变更旨在拓宽LLM集成的功能范围，为更复杂的交互模式铺平道路，如构建能够相互作用的多代理系统。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.16.54.png\" alt=\"截屏2024-03-28 15.16.54.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.17.38.png\" alt=\"截屏2024-03-28 15.17.38.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e尽管如此，由于语言习惯的原因，本文中仍然会使用function calling的术语来描述OpenAI的tool using功能，因为“function calling”的说法已经深入人心了。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e核心内容概览\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eFunction Calling的定义\u003c/strong\u003e：解释什么是function calling，以及它在智能代理工作中的作用。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eOpenAI Cookbook示例\u003c/strong\u003e：提供实际的function calling示例，帮助读者理解其在实际应用中的用途。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e开源LLM的Tool Using\u003c/strong\u003e：探索如何在开源大型语言模型中实现工具使用，以及LLM在tool using的时候经历了什么。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cdel\u003e评价与训练\u003c/del\u003e\u003c/strong\u003e\u003cdel\u003e：讨论如何评价开源模型的工具使用能力，以及如何训练LLM进行有效的工具使用。\u003c/del\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e鉴于整理笔记的速度远赶不上更新的速度， 会将第四部份作为单独的部分整理。\u003c/p\u003e\n\u003ch2 id=\"何为function-calling\"\u003e何为function calling\u003c/h2\u003e\n\u003cp\u003e一句话解释：\u003cstrong\u003efunction calling从本质上并不是严格的工具调用， 而是作为工具调用的前奏，它通过更加结构化的方式指导LLM输出，为在本地执行具体函数提供了参数，铺平了道路。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e具体来说，function calling允许LLM在执行过程中通过指定的参数来调用并执行一个特定的函数。这种方式不仅实现了代码的重用和模块化处理，而且能够从模型中获取更可靠的结构化数据回应。在API调用过程中，开发者可以描述想要执行的功能，并让模型智能地选择输出包含所需参数的JSON对象。\u003cstrong\u003e这个过程中，Chat Completions API本身不直接执行任何函数调用，而是生成了可以在开发者代码中实现函数调用的JSON。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003efunction calling的应用范围广泛，如\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e创建智能助手：通过调用外部API回答问题。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e转换指令：将自然语言指令转换成API调用指令。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e数据提取：从文本中提取结构化数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003efunction calling的过程涵盖了从定义函数集、通过模型生成遵循自定义模式的JSON对象字符串，到在代码中解析这个字符串并调用相应函数的全过程。这一连串操作不仅自动化了交互过程，还确保了执行操作的安全性和准确性。\u003c/p\u003e\n\u003ch2 id=\"一些常见的问题\"\u003e一些常见的问题\u003c/h2\u003e\n\u003ch3 id=\"json-mode\"\u003eJSON mode\u003c/h3\u003e\n\u003cp\u003ejson mode 和tool-using 有什么关系？有了json mode 还需要用到tool-using吗？\u003c/p\u003e\n\u003cp\u003e从json mode 的本质， 更多的是在system prompt 增加一句类似“请以json格式输出”之类的话，然后在LLM输出时增加json结果检查和格式转换。在使用时只需要在\u003ccode\u003eclient.chat.completions.create \u003c/code\u003e中 增加\u003ccode\u003eresponse_format={ \u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot; }\u003c/code\u003e 即可。\u003c/p\u003e","title":"Agent学习笔记：OpenAI Function Calling完全指南"},{"content":"个人介绍 后现代人类 AI从业者与终身学习者 工作狂 世界探索者 INFJ 阅读 听歌 创作 欢迎来到我的个人博客！\n","permalink":"https://niraya666.github.io/about/","summary":"\u003ch3 id=\"个人介绍\"\u003e个人介绍\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e后现代人类\u003c/li\u003e\n\u003cli\u003eAI从业者与终身学习者\u003c/li\u003e\n\u003cli\u003e工作狂\u003c/li\u003e\n\u003cli\u003e世界探索者\u003c/li\u003e\n\u003cli\u003eINFJ\u003c/li\u003e\n\u003cli\u003e阅读 听歌 创作\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e欢迎来到我的个人博客！\u003c/p\u003e","title":"About"},{"content":" 引言 在信息化时代，数据和知识的快速提取变得尤为重要。特别是对于学术和技术文档，如何从格式丰富且结构复杂的PDF文件中准确地提取信息，是提高研究效率的关键。本文将探讨几种先进的技术方法，用于优化学术论文的PDF解析及其表格内容的处理。\n对于文档解析，langchain 和 llama_index 提供的 document loader 能够支持多种文件类型，覆盖绝大多数文档格式的需求。但对于pdf解析而言还存在着一些挑战。\n人类与机器的阅读差异 尽管PDF格式适合人类阅读，提供了优秀的视觉体验和格式保真，但它并不适合机器阅读。PDF文件通常包含复杂的布局和多样的内容元素，如多列布局、公式和表格，这些都给自动解析带来了挑战。\n常见的PDF解析问题 使用传统的PDF解析库可能遇到多种问题：\n多列布局导致的文本流读取错误。\n公式和表格的解析效果差，难以正确提取信息。\n解析过程中结构化信息（如标题和列表）的丢失。\n影印版PDF的文本无法被标准OCR工具识别。\n高级解析技术 根据unstractued提供的方案，文档解析可以大致分为两种方法：结构化解析和基于图像的解析。结构化解析侧重于从文档中提取文字和其它字符数据。而图像基解析则包括以下两种技术：\nOCR技术：首先使用目标检测模型对文档布局进行分析，识别出标题、表格等关键元素的位置，然后在这些位置上使用OCR技术提取文字。\n基于Transformer的端到端解析：使用深度学习模型直接将图像转换为相应的文字内容。在这方面，Dount 和 Nougat 模型表现出色，尤其是 Nougat 能够将图像中的文章整理成Markdown或Latex格式，非常适合需要保留结构信息（如标题层级、公式和表格）的场景。\n只可惜Nougat只针对英文的学术论文做了训练，但遇到其他语言如中文论文的效果就不是那么的好了。\n必须强调一点的是，Markdown格式因其简洁性和易于解析的特点，被广泛认为是LLM（大型语言模型）友好的文档格式。Markdown通过明确的标记语法，帮助模型更好地理解文档结构和内容，从而提高信息提取的准确性和效率。特别在存在大量公式，表格的学术论文场景下，Markdown可能是更合适的格式选择。\n快速上手：使用Nougat将pdf解析成适合LLM读取的markdown 依赖按照\n!pip install -q pymupdf python-Levenshtein nltk !pip install -q git+https://github.com/huggingface/transformers.git Load model and processor\nfrom transformers import AutoProcessor, VisionEncoderDecoderModel import torch processor = AutoProcessor.from_pretrained(\u0026#34;facebook/nougat-base\u0026#34;) model = VisionEncoderDecoderModel.from_pretrained(\u0026#34;facebook/nougat-base\u0026#34;) device = \u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34; model.to(device) 将pdf转成图像\nfrom typing import Optional, List import io import fitz from pathlib import Path def rasterize_paper( pdf: Path, outpath: Optional[Path] = None, dpi: int = 96, return_pil=False, pages=None, ) -\u0026gt; Optional[List[io.BytesIO]]: \u0026#34;\u0026#34;\u0026#34; Rasterize a PDF file to PNG images. Args: pdf (Path): The path to the PDF file. outpath (Optional[Path], optional): The output directory. If None, the PIL images will be returned instead. Defaults to None. dpi (int, optional): The output DPI. Defaults to 96. return_pil (bool, optional): Whether to return the PIL images instead of writing them to disk. Defaults to False. pages (Optional[List[int]], optional): The pages to rasterize. If None, all pages will be rasterized. Defaults to None. Returns: Optional[List[io.BytesIO]]: The PIL images if `return_pil` is True, otherwise None. \u0026#34;\u0026#34;\u0026#34; pillow_images = [] if outpath is None: return_pil = True try: if isinstance(pdf, (str, Path)): pdf = fitz.open(pdf) if pages is None: pages = range(len(pdf)) for i in pages: page_bytes: bytes = pdf[i].get_pixmap(dpi=dpi).pil_tobytes(format=\u0026#34;PNG\u0026#34;) if return_pil: pillow_images.append(io.BytesIO(page_bytes)) else: with (outpath / (\u0026#34;%02d.png\u0026#34; % (i + 1))).open(\u0026#34;wb\u0026#34;) as f: f.write(page_bytes) except Exception: pass if return_pil: return pillow_images from transformers import StoppingCriteria, StoppingCriteriaList from collections import defaultdict class RunningVarTorch: def __init__(self, L=15, norm=False): self.values = None self.L = L self.norm = norm def push(self, x: torch.Tensor): assert x.dim() == 1 if self.values is None: self.values = x[:, None] elif self.values.shape[1] \u0026lt; self.L: self.values = torch.cat((self.values, x[:, None]), 1) else: self.values = torch.cat((self.values[:, 1:], x[:, None]), 1) def variance(self): if self.values is None: return if self.norm: return torch.var(self.values, 1) / self.values.shape[1] else: return torch.var(self.values, 1) class StoppingCriteriaScores(StoppingCriteria): def __init__(self, threshold: float = 0.015, window_size: int = 200): super().__init__() self.threshold = threshold self.vars = RunningVarTorch(norm=True) self.varvars = RunningVarTorch(L=window_size) self.stop_inds = defaultdict(int) self.stopped = defaultdict(bool) self.size = 0 self.window_size = window_size @torch.no_grad() def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor): last_scores = scores[-1] self.vars.push(last_scores.max(1)[0].float().cpu()) self.varvars.push(self.vars.variance()) self.size += 1 if self.size \u0026lt; self.window_size: return False varvar = self.varvars.variance() for b in range(len(last_scores)): if varvar[b] \u0026lt; self.threshold: if self.stop_inds[b] \u0026gt; 0 and not self.stopped[b]: self.stopped[b] = self.stop_inds[b] \u0026gt;= self.size else: self.stop_inds[b] = int( min(max(self.size, 1) * 1.15 + 150 + self.window_size, 4095) ) else: self.stop_inds[b] = 0 self.stopped[b] = False return all(self.stopped.values()) and len(self.stopped) \u0026gt; 0 将pdf转成markdown\nfrom tqdm import tqdm def trans_pdf_to_markdown(filepath): output = \u0026#34;\u0026#34; images = rasterize_paper(pdf=filepath, return_pil=True) for i in tqdm(range(len(images))): image = Image.open(images[i]) pixel_values = processor(images=image, return_tensors=\u0026#34;pt\u0026#34;).pixel_values # autoregressively generate tokens, with custom stopping criteria (as defined by the Nougat authors) outputs = model.generate(pixel_values.to(device), min_length=1, max_length=3584, bad_words_ids=[[processor.tokenizer.unk_token_id]], return_dict_in_generate=True, output_scores=True, stopping_criteria=StoppingCriteriaList([StoppingCriteriaScores()]), ) generated = processor.batch_decode(outputs[0], skip_special_tokens=True)[0] generated = processor.post_process_generation(generated, fix_markdown=True) output+=generated output+=\u0026#34;\\n\\n\u0026#34; return output filepath = \u0026#39;xxx.pdf\u0026#39; makrdown_ = trans_pdf_to_markdown(filepath) 具体参考Nougat的官方示例。\n表格类数据的RAG问题 表格类目前的解决方案主要有两种：\n对于内容较小的表格，一般采用LLM对表格进行summary， 以table summary构建查询的index，在召回后， 进行表格内容的复原或者根据问题后处理提供至LLM进行生成。\n对于内容较多的表格， 一般采取结构化处理， 也就是存储至数据库， 在查询阶段根据问题匹配对应的表schema， 有模型执行text-to-sql任务，生成sql并执行获得结果，最终根据结果回答内容。\n对于第一种方案，在Langchain 的cookbook中提到了Semi-structured RAG的方法值得借鉴；\n此外在HRoT这篇工作中， 也提到了类似的方法；\n在HRoT这篇工作中， 增加了将table基于问题进行重构的算法，\nType-Aware Table Reconstruction algorithm\n该算法的实现步骤如下：\n问题分类：首先，算法对问题进行分类，判断问题是算术问题还是跨列选择问题。这有助于确定需要从表格中检索的信息类型。\n获取表格和证据：对于算术问题，算法获取与问题相关的表格集合。然后，从这些表格中提取出作为证据的文本和表格片段。\n表格分区：对于每个表格，算法将其分区为多个子表格。这是通过获取表格的跨度列表（Lt）来完成的，该列表包含了表格中每个头部（行和列）的起始和结束位置。\n确定保留的行和列：算法根据问题类型和证据来确定哪些行和列是回答问题所必需的。这是通过分析每个证据的子标题（即表格中的行和列标题）来实现的。\n重建表格：在确定了需要保留的行和列之后，算法根据这些信息重建表格。重建的表格只包含对问题回答有帮助的信息，从而减少了无关信息的干扰。\n在TableQuery 这篇工作中， 利用一系列模块组件，实现了基于LLM对数据库的高效查询。\nTableQuery的架构设计包括以下几个主要模块：\nDatastore：Datastore是一个表格集合，可以通过自然语言查询。这些表格可以是数据库或电子表格目录。除了表格数据，Datastore还包含模式文件，这些文件包含每个表的元数据，如表关键词、列名、列类型、列关键词（用户为列名提供的关键词）等。模式文件可以手动为这些表创建，也可以通过应用各种启发式方法自动生成。\nTable Selector：表选择器根据输入查询从Datastore中选择合适的表。这是通过从输入查询中提取关键词，并找到与问题关键词（以及模式中的表关键词、列名、列关键词等）重叠系数最大的表来完成的。\nKnown Fields Extractor：已知字段提取器提取查询中已经给出值的列。对于这些列中的每一个，也提取了相应的值。这是通过一个预训练的深度学习模型来完成的，该模型用于在自由文本上执行问答。\nUnknown Fields Extractor：未知字段提取器提取需要从选定表中检索值的列。这是通过排除已知字段提取器已经从查询中提取的列，并找到其列关键词与问题关键词重叠系数最大的列来完成的。\nAggregate Function Classifier：一些查询可能需要对选定表中的未知字段的值执行进一步操作。这是通过在生成的SQL查询中包含SQL聚合函数（如COUNT、SUM、MIN、MAX、AVG等）来实现的。聚合函数分类器决定给定输入查询要使用的聚合函数。为了执行这项任务，作者训练了一个两层的神经网络，该网络以使用通用句子编码器编码的查询作为输入，并输出要使用的适当聚合函数（如果有的话）。\nSQL Generator：结合已知字段和值、未知字段和聚合函数来构建SQL查询，当该查询在选定的表上运行时，返回所需的结果。\n关于text-to-sql的更详尽内容， 可以参考这篇综述文章：Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey。 限于篇幅就不展开了。\n参考文献 langchain: Document loaders\nNougat: Neural Optical Understanding for Academic Documents\nlangchain: Semi-structured RAG\nHRoT: Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering\nTableQuery： Querying tabular data with natural language\nNatural Language Interfaces for Tabular Data Querying and Visualization: A Survey\n","permalink":"https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E4%B8%8E%E8%A1%A8%E6%A0%BC%E5%A4%84%E7%90%86/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/post-cover/rag_toolkits_2.JPG\" alt=\"image\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"引言\"\u003e\u003cstrong\u003e引言\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e在信息化时代，数据和知识的快速提取变得尤为重要。特别是对于学术和技术文档，如何从格式丰富且结构复杂的PDF文件中准确地提取信息，是提高研究效率的关键。本文将探讨几种先进的技术方法，用于优化学术论文的PDF解析及其表格内容的处理。\u003c/p\u003e\n\u003cp\u003e对于文档解析，\u003cstrong\u003e\u003ccode\u003elangchain\u003c/code\u003e\u003c/strong\u003e 和 \u003cstrong\u003e\u003ccode\u003ellama_index\u003c/code\u003e\u003c/strong\u003e 提供的 \u003cstrong\u003e\u003ccode\u003edocument loader\u003c/code\u003e\u003c/strong\u003e 能够支持多种文件类型，覆盖绝大多数文档格式的需求。但对于pdf解析而言还存在着一些挑战。\u003c/p\u003e\n\u003ch3 id=\"人类与机器的阅读差异\"\u003e\u003cstrong\u003e人类与机器的阅读差异\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e尽管PDF格式适合人类阅读，提供了优秀的视觉体验和格式保真，但它并不适合机器阅读。PDF文件通常包含复杂的布局和多样的内容元素，如多列布局、公式和表格，这些都给自动解析带来了挑战。\u003c/p\u003e\n\u003ch3 id=\"常见的pdf解析问题\"\u003e\u003cstrong\u003e常见的PDF解析问题\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e使用传统的PDF解析库可能遇到多种问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e多列布局导致的文本流读取错误。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e公式和表格的解析效果差，难以正确提取信息。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e解析过程中结构化信息（如标题和列表）的丢失。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e影印版PDF的文本无法被标准OCR工具识别。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"高级解析技术\"\u003e\u003cstrong\u003e高级解析技术\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e根据\u003ca href=\"https://unstructured.io/\"\u003eunstractued\u003c/a\u003e提供的方案，文档解析可以大致分为两种方法：结构化解析和基于图像的解析。结构化解析侧重于从文档中提取文字和其它字符数据。而图像基解析则包括以下两种技术：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eOCR技术\u003c/strong\u003e：首先使用目标检测模型对文档布局进行分析，识别出标题、表格等关键元素的位置，然后在这些位置上使用OCR技术提取文字。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e基于Transformer的端到端解析\u003c/strong\u003e：使用深度学习模型直接将图像转换为相应的文字内容。在这方面，\u003cstrong\u003e\u003ccode\u003eDount\u003c/code\u003e\u003c/strong\u003e 和 \u003cstrong\u003e\u003ccode\u003eNougat\u003c/code\u003e\u003c/strong\u003e 模型表现出色，尤其是 \u003cstrong\u003e\u003ccode\u003eNougat\u003c/code\u003e\u003c/strong\u003e 能够将图像中的文章整理成Markdown或Latex格式，非常适合需要保留结构信息（如标题层级、公式和表格）的场景。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e只可惜Nougat只针对英文的学术论文做了训练，但遇到其他语言如中文论文的效果就不是那么的好了。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://unstructured-io.github.io/unstructured/_images/strategy.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e必须强调一点的是，Markdown格式因其简洁性和易于解析的特点，被广泛认为是LLM（大型语言模型）友好的文档格式。Markdown通过明确的标记语法，帮助模型更好地理解文档结构和内容，从而提高信息提取的准确性和效率。特别在存在大量公式，表格的学术论文场景下，Markdown可能是更合适的格式选择。\u003c/p\u003e\n\u003ch2 id=\"快速上手使用nougat将pdf解析成适合llm读取的markdown\"\u003e快速上手：使用Nougat将pdf解析成适合LLM读取的markdown\u003c/h2\u003e\n\u003cp\u003e依赖按照\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e!\u003c/span\u003e\u003cspan class=\"n\"\u003epip\u003c/span\u003e \u003cspan class=\"n\"\u003einstall\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003eq\u003c/span\u003e \u003cspan class=\"n\"\u003epymupdf\u003c/span\u003e \u003cspan class=\"n\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003eLevenshtein\u003c/span\u003e \u003cspan class=\"n\"\u003enltk\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e!\u003c/span\u003e\u003cspan class=\"n\"\u003epip\u003c/span\u003e \u003cspan class=\"n\"\u003einstall\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003eq\u003c/span\u003e \u003cspan class=\"n\"\u003egit\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"n\"\u003ehttps\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"o\"\u003e//\u003c/span\u003e\u003cspan class=\"n\"\u003egithub\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecom\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003ehuggingface\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003etransformers\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egit\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eLoad model and processor\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etransformers\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eAutoProcessor\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eVisionEncoderDecoderModel\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eprocessor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eAutoProcessor\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efrom_pretrained\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;facebook/nougat-base\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eVisionEncoderDecoderModel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efrom_pretrained\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;facebook/nougat-base\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;cuda\u0026#34;\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecuda\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eis_available\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;cpu\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eto\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e将pdf转成图像\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etyping\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eOptional\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eio\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003efitz\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epathlib\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ePath\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erasterize_paper\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003ePath\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eoutpath\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eOptional\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ePath\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003edpi\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e96\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003ereturn_pil\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epages\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eOptional\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eio\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\u003cspan class=\"p\"\u003e]]:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    Rasterize a PDF file to PNG images.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    Args:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        pdf (Path): The path to the PDF file.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        outpath (Optional[Path], optional): The output directory. If None, the PIL images will be returned instead. Defaults to None.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        dpi (int, optional): The output DPI. Defaults to 96.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        return_pil (bool, optional): Whether to return the PIL images instead of writing them to disk. Defaults to False.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        pages (Optional[List[int]], optional): The pages to rasterize. If None, all pages will be rasterized. Defaults to None.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    Returns:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        Optional[List[io.BytesIO]]: The PIL images if `return_pil` is True, otherwise None.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    \u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epillow_images\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eoutpath\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ereturn_pil\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003etry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"nb\"\u003eisinstance\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003estr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ePath\u003c/span\u003e\u003cspan class=\"p\"\u003e)):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003epdf\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003efitz\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003epages\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003epages\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003elen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003epages\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003epage_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003ebytes\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_pixmap\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edpi\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edpi\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epil_tobytes\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eformat\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;PNG\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ereturn_pil\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"n\"\u003epillow_images\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eio\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epage_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutpath\u003c/span\u003e \u003cspan class=\"o\"\u003e/\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"si\"\u003e%02d\u003c/span\u003e\u003cspan class=\"s2\"\u003e.png\u0026#34;\u003c/span\u003e \u003cspan class=\"o\"\u003e%\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)))\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;wb\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                    \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewrite\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epage_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eexcept\u003c/span\u003e \u003cspan class=\"ne\"\u003eException\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003epass\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ereturn_pil\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003epillow_images\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etransformers\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eStoppingCriteria\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eStoppingCriteriaList\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ecollections\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edefaultdict\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eRunningVarTorch\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eL\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e15\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enorm\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eL\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eL\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enorm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003enorm\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epush\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTensor\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eassert\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edim\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e[:,\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshape\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eL\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecat\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e[:,\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e]),\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecat\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"p\"\u003e[:,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:],\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e[:,\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e]),\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003evariance\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enorm\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e/\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshape\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eStoppingCriteriaScores\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eStoppingCriteria\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ethreshold\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003efloat\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.015\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e200\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nb\"\u003esuper\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethreshold\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ethreshold\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evars\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eRunningVarTorch\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enorm\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evarvars\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eRunningVarTorch\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eL\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estop_inds\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edefaultdict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edefaultdict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003ebool\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nd\"\u003e@torch.no_grad\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__call__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003einput_ids\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eLongTensor\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003escores\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eFloatTensor\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003elast_scores\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003escores\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evars\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epush\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elast_scores\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emax\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efloat\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecpu\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evarvars\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epush\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evars\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evariance\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e \u003cspan class=\"o\"\u003e+=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"kc\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003evarvar\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evarvars\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evariance\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eb\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003elen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elast_scores\u003c/span\u003e\u003cspan class=\"p\"\u003e)):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003evarvar\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethreshold\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estop_inds\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e \u003cspan class=\"ow\"\u003eand\u003c/span\u003e \u003cspan class=\"ow\"\u003enot\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                    \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estop_inds\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026gt;=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                    \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estop_inds\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                        \u003cspan class=\"nb\"\u003emin\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003emax\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.15\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"mi\"\u003e150\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e4095\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                    \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estop_inds\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"nb\"\u003eall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e \u003cspan class=\"ow\"\u003eand\u003c/span\u003e \u003cspan class=\"nb\"\u003elen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e将pdf转成markdown\u003c/p\u003e","title":"RAG工具箱：文档解析与表格处理"},{"content":"游记：2024-春 昆明大理 昆明 时间似乎停止了 不知为何在昆明有一种回到兰州的感觉，一样的三线省会，似曾相识的破败老城区街道，赫鲁晓夫楼，砖瓦房，和五六十年代的家属大院，似乎时间就停止流动了。我不认为这是种贬义的表达，至少清晨行走在老街区，唤起了我上学时，清晨走出校园到火车站赶火车的尘封记忆。 不过需要提一嘴的是，似乎当前的实体经济，特别是在老城区，不论是这次旅行所看到的，还是之前在故乡和别的城市所看到的，可以说是很糟糕了。目光所及有一半的店面处于关门转让的状态，而开着的那一半，又有近乎三成处于清仓甩卖中。\n古镇PTSD 在全国绝大多数古镇逐渐趋同演化的当下，不知这是否是件悲哀的事。因为去云南省博物馆的途中会路过官渡古镇，遂决定顺便去看看。从古镇的东北边进入至正门而出，这次访问让我有幸同时见证了从破败而真实的古镇到商业化过度开发的古镇的转变。\n在历史长河中被剥夺了名字的人 在昆明这个城市名字的由来中，有一段被历史辗转淡忘的故事。昆明这一名称起源于昆明夷——西汉时期活跃在洱海周边的一个游牧民族。而在这片土地上生活的滇人，一个拥有先进青铜技术的农耕文明，不断地抵抗游牧民族的侵扰。尽管如此，在历史的长河中，正是这些滇人创造了辉煌的文明，却在历史的演进中失去了自己的名字。这不禁让人感受到一种悲剧的讽刺——在自己孕育辉煌的土地上，却被剥夺了命名的权力。这反映出历史的无情，以及文化与权力之间复杂的交织。\n故乡与迁徙 在省博的临时展区，有幸看到了一个关于迁徙和故乡的特别展。 正巧这次来云南的最初目的也是为了探寻人生的下一个迁徙地。\n今天，流动成为常态。我们祖辈所拥有的那种一生居于一地的安稳逐渐被打破。很多人离开熟悉的地方，到另一处，与来自天南地北的人一起，不知不觉将异乡生活成故乡。\n而提到故乡，你会想到什么？是那方伴你长大的土地，是老屋里围炉团聚的家人，是家乡菜的味道和浓浓的乡音，是家门口熟悉的街道、树林和田地，是小时候玩耍的院子，和那群如今已各奔东西的伙伴。无论走多远，想到那一草一木，一人一景，就安宁。\n这也许就是人们一直以来追寻的栖息地。在远方，在心里，它叫“香格里拉”。\n现代的我们因为各种原因，在故乡与异乡之间辗转，继续着“迁徙与流动”。展览策划过程中，我们以“故乡”“现居地”“理想地”为题，以“故事+展品”的方式开启活动征集，鼓励不同身份的人群通过不同角度的讲述，分享他们的感受与思考。在近一个月的时间里，我们得到了大家的积极回响。在大家的分享中，我们与不同的故事和记忆相连，也看到因为不同而更加多元、广阔的世界。\n这里展示的文字和物品，是记忆的承载，也是对“故的未来。\n乡”的“好久不见”，它记录着我们的成长，也指引着我们\n大理 这次来大理的初始动机是实地考察和调研“数字游民”这个群体，他们是否真正像想象中的自由，他们是如何工作和生活的， 他们背后的故事又是什么？ 以及他们为什么选择大理？\n感谢Dalihub， 让我有幸认识一群有趣的人。\n来自海边房子\nDalihub的秘密空间\n救火途中的直升机\n自由飞翔\n猜你喜欢是“坏”的吗 在大理的第二天，我便幸运地参与了一场与我的工作密切相关的线下沙龙活动，主题涉及推荐系统。我的工作列表中正好有一项是关于如何防止大型科技公司通过推荐系统作恶的问题。 活动中，主讲人“西雅图大黄蜂”提出了一个观点：所有的算法和技术本质上都是中性的，真正的“恶”是由使用它们的人带来的。作为技术从业者，我们当然不希望看到自己的发明像原子弹一样被用于恶劣的目的。但现实往往很残酷，技术的接受与否很大程度上是由资本决定的，而非我们。\n之前我考虑过一个想法：将推荐系统的召回和排序分开，召回过程保留在服务器端，而排序则转移到用户端，这样一来可以提高用户的隐私保护。技术上并不复杂，真正的挑战来自于资本或大公司缺乏推行此类改变的动力。除非有一天，大多数用户愿意为保护隐私牺牲一定的便利性，否则这种改变还遥遥无期，至少在当前的中国是这样的。\n再次感谢主理人Nian和主讲人魏峰，一次难忘的体验。\n真的躺平吗？不，只是喘口气 选择大理的理由： 成本，气候， 和有趣的人们\n在大理，你可以遇到形形色色的人物：那些选择在此旅居的设计师，决定在退休后移居大理的上海夫妇，因成本考虑而搬来的独立开发者，还有视大理为家的咨询师小姐姐。这些都是构成大理独特社群氛围的不同面貌。\n当你不确定下一步该做什么时，不妨去洱海边走走，那里的美景足以让你放慢脚步，深呼吸，重新找回自己的节奏。在大理，即便是“躺平”，也是一种享受生活、与自然和谐共处的态度。\n洱海边落日\n取舍，及时调整自己的欲望 在网上能看到很多对于大理的劝退文， 无外乎就是过度商业化网红化， 城市规划稀烂，交通不方便，宰客现象严重等等。 以上我都认同， 对于一个习惯了大城市便利的人而言， 初到大理的感受的确是如此。 和在地的小伙伴聊下来，发现及时调整自己的欲望还是挺重要的。\n但是，在早晨拉开窗帘看到洱海的一瞬间， 似乎这一切都是值得的。\n随处可见的丁达尔效应\n去跳海，去发疯！\n西南旅游小Tips 注意防晒， 保湿，加湿器和润唇膏很重要。 尽量避开春季，因为春季是风季，很有可能因为大风而错过苍山的缆车。 大理古城的主干道不值得驻足，真正有趣的东西隐藏在巷子里\n这一切就像是一场梦\n感谢在大理遇到的所有人事物\n下一次再见\n","permalink":"https://niraya666.github.io/travel/%E6%B8%B8%E8%AE%B02024-%E6%98%A5-%E6%98%86%E6%98%8E%E5%A4%A7%E7%90%86/","summary":"\u003ch1 id=\"游记2024-春-昆明大理\"\u003e游记：2024-春 昆明大理\u003c/h1\u003e\n\u003ch2 id=\"昆明\"\u003e昆明\u003c/h2\u003e\n\u003ch3 id=\"时间似乎停止了\"\u003e时间似乎停止了\u003c/h3\u003e\n\u003cp\u003e不知为何在昆明有一种回到兰州的感觉，一样的三线省会，似曾相识的破败老城区街道，赫鲁晓夫楼，砖瓦房，和五六十年代的家属大院，似乎时间就停止流动了。我不认为这是种贬义的表达，至少清晨行走在老街区，唤起了我上学时，清晨走出校园到火车站赶火车的尘封记忆。\n不过需要提一嘴的是，似乎当前的实体经济，特别是在老城区，不论是这次旅行所看到的，还是之前在故乡和别的城市所看到的，可以说是很糟糕了。目光所及有一半的店面处于关门转让的状态，而开着的那一半，又有近乎三成处于清仓甩卖中。\u003c/p\u003e\n\u003ch3 id=\"古镇ptsd\"\u003e古镇PTSD\u003c/h3\u003e\n\u003cp\u003e在全国绝大多数古镇逐渐趋同演化的当下，不知这是否是件悲哀的事。因为去云南省博物馆的途中会路过官渡古镇，遂决定顺便去看看。从古镇的东北边进入至正门而出，这次访问让我有幸同时见证了从破败而真实的古镇到商业化过度开发的古镇的转变。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53659997366_7bdf10738b_w.jpg\" alt=\"官渡古镇\"  /\u003e\n\u003c/p\u003e\n\u003ch3 id=\"在历史长河中被剥夺了名字的人\"\u003e在历史长河中被剥夺了名字的人\u003c/h3\u003e\n\u003cp\u003e在昆明这个城市名字的由来中，有一段被历史辗转淡忘的故事。昆明这一名称起源于昆明夷——西汉时期活跃在洱海周边的一个游牧民族。而在这片土地上生活的滇人，一个拥有先进青铜技术的农耕文明，不断地抵抗游牧民族的侵扰。尽管如此，在历史的长河中，正是这些滇人创造了辉煌的文明，却在历史的演进中失去了自己的名字。这不禁让人感受到一种悲剧的讽刺——在自己孕育辉煌的土地上，却被剥夺了命名的权力。这反映出历史的无情，以及文化与权力之间复杂的交织。\u003c/p\u003e\n\u003ch3 id=\"故乡与迁徙\"\u003e故乡与迁徙\u003c/h3\u003e\n\u003cp\u003e在省博的临时展区，有幸看到了一个关于迁徙和故乡的特别展。 正巧这次来云南的最初目的也是为了探寻人生的下一个迁徙地。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e今天，流动成为常态。我们祖辈所拥有的那种一生居于一地的安稳逐渐被打破。很多人离开熟悉的地方，到另一处，与来自天南地北的人一起，不知不觉将异乡生活成故乡。\u003c/p\u003e\n\u003cp\u003e而提到故乡，你会想到什么？是那方伴你长大的土地，是老屋里围炉团聚的家人，是家乡菜的味道和浓浓的乡音，是家门口熟悉的街道、树林和田地，是小时候玩耍的院子，和那群如今已各奔东西的伙伴。无论走多远，想到那一草一木，一人一景，就安宁。\u003c/p\u003e\n\u003cp\u003e这也许就是人们一直以来追寻的栖息地。在远方，在心里，它叫“香格里拉”。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e现代的我们因为各种原因，在故乡与异乡之间辗转，继续着“迁徙与流动”。展览策划过程中，我们以“故乡”“现居地”“理想地”为题，以“故事+展品”的方式开启活动征集，鼓励不同身份的人群通过不同角度的讲述，分享他们的感受与思考。在近一个月的时间里，我们得到了大家的积极回响。在大家的分享中，我们与不同的故事和记忆相连，也看到因为不同而更加多元、广阔的世界。\u003c/p\u003e\n\u003cp\u003e这里展示的文字和物品，是记忆的承载，也是对“故的未来。\u003c/p\u003e\n\u003cp\u003e乡”的“好久不见”，它记录着我们的成长，也指引着我们\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"大理\"\u003e大理\u003c/h2\u003e\n\u003cp\u003e这次来大理的初始动机是实地考察和调研“数字游民”这个群体，他们是否真正像想象中的自由，他们是如何工作和生活的， 他们背后的故事又是什么？ 以及他们为什么选择大理？\u003c/p\u003e\n\u003cp\u003e感谢Dalihub， 让我有幸认识一群有趣的人。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53660356884_1676ae103e_z.jpg\" alt=\"E0322096-D284-4044-BFAD-C6655AA9EAB9_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e来自海边房子\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53660223478_846693b3a1_w.jpg\" alt=\"259DFD62-6C94-4135-9D79-CD1A775DCFF1_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eDalihub的秘密空间\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53660223473_2d7c23b817_w.jpg\" alt=\"5E8B65D3-9970-41AB-9E2A-133E8CB0952C_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e救火途中的直升机\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53660223468_35ffcb583c_w.jpg\" alt=\"7F7303CF-6B12-4417-B71A-B0826682E0F2_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e自由飞翔\u003c/p\u003e\n\u003ch3 id=\"猜你喜欢是坏的吗\"\u003e猜你喜欢是“坏”的吗\u003c/h3\u003e\n\u003cp\u003e在大理的第二天，我便幸运地参与了一场与我的工作密切相关的线下沙龙活动，主题涉及推荐系统。我的工作列表中正好有一项是关于如何防止大型科技公司通过推荐系统作恶的问题。\n活动中，主讲人“西雅图大黄蜂”提出了一个观点：所有的算法和技术本质上都是中性的，真正的“恶”是由使用它们的人带来的。作为技术从业者，我们当然不希望看到自己的发明像原子弹一样被用于恶劣的目的。但现实往往很残酷，技术的接受与否很大程度上是由资本决定的，而非我们。\u003c/p\u003e\n\u003cp\u003e之前我考虑过一个想法：将推荐系统的召回和排序分开，召回过程保留在服务器端，而排序则转移到用户端，这样一来可以提高用户的隐私保护。技术上并不复杂，真正的挑战来自于资本或大公司缺乏推行此类改变的动力。除非有一天，大多数用户愿意为保护隐私牺牲一定的便利性，否则这种改变还遥遥无期，至少在当前的中国是这样的。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://mmbiz.qpic.cn/mmbiz_png/XVQWiaVrXNFVWAFWZMMYiczNYLvg9dPX3JKlYNQexPiceosvQXz4CHIic0ZN0Naw6BHDxQj7Rd1kZvFoBV9HBxKZ4A/640?wx_fmt=png\u0026amp;from=appmsg\u0026amp;tp=webp\u0026amp;wxfrom=5\u0026amp;wx_lazy=1\u0026amp;wx_co=1\" alt=\"的多面人生.JPG\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e再次感谢主理人Nian和主讲人魏峰，一次难忘的体验。\u003c/p\u003e\n\u003ch3 id=\"真的躺平吗不只是喘口气\"\u003e真的躺平吗？不，只是喘口气\u003c/h3\u003e\n\u003cp\u003e选择大理的理由： 成本，气候， 和有趣的人们\u003c/p\u003e\n\u003cp\u003e在大理，你可以遇到形形色色的人物：那些选择在此旅居的设计师，决定在退休后移居大理的上海夫妇，因成本考虑而搬来的独立开发者，还有视大理为家的咨询师小姐姐。这些都是构成大理独特社群氛围的不同面貌。\u003c/p\u003e\n\u003cp\u003e当你不确定下一步该做什么时，不妨去洱海边走走，那里的美景足以让你放慢脚步，深呼吸，重新找回自己的节奏。在大理，即便是“躺平”，也是一种享受生活、与自然和谐共处的态度。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53659998511_c358f49f0b_c.jpg\" alt=\"458FFF9D-2F2B-44BA-97C6-61BCE1D4637D_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e洱海边落日\u003c/p\u003e\n\u003ch3 id=\"取舍及时调整自己的欲望\"\u003e取舍，及时调整自己的欲望\u003c/h3\u003e\n\u003cp\u003e在网上能看到很多对于大理的劝退文， 无外乎就是过度商业化网红化， 城市规划稀烂，交通不方便，宰客现象严重等等。 以上我都认同， 对于一个习惯了大城市便利的人而言， 初到大理的感受的确是如此。 和在地的小伙伴聊下来，发现及时调整自己的欲望还是挺重要的。\u003c/p\u003e\n\u003cp\u003e但是，在早晨拉开窗帘看到洱海的一瞬间， 似乎这一切都是值得的。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53659999386_a95d8713d9_w.jpg\" alt=\"732C07E9-39CD-430A-87F5-2C0D20084DF2_1_105_c.jpeg\"  /\u003e\n\n随处可见的丁达尔效应\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e去跳海，去发疯！\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53660223128_1d2709b4df_w.jpg\" alt=\"63447450-9DD1-4BE2-8450-25E4E5F54DBA_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e","title":"游记：2024-春 昆明大理"},{"content":"写在最前面 在过去的几个月中，我主要致力于与RAG（检索增强生成模型）相关的研究和实验工作。通过深入地分析众多论文和项目代码，我发现虽然在RAG领域取得基本成就相对容易，但要实现出色的成果却异常困难。\n此系列文章旨在分享我在RAG研究中的心得和挑战。正如我们从OpenAI的开发者日活动中看到的，即使是在这个领域的领头羊也在不断试验和努力以寻求突破。\n在我们深入探索RAG系统提升的各种方法之前，有一个基本问题需要解决：我们如何准确地评估一个RAG系统的性能？这就像是在机器学习或深度学习任务中没有给定的测试集和评价标准，我们难以判断实验的成功与否。\n因此，本系列的第一篇文章将聚焦于介绍RAG系统的评价方法、相关指标以及测试框架，为我们接下来的探索设定明确的标准和目标。\n测试框架 以下是一些测试框架，为RAG系统评估提供了强大的支持。\nTruLens TruLens提供了一个独特的视角来评估和跟踪大型语言模型（LLM）实验，通过一系列创新的功能和方法，帮助开发者和研究人员更深入地了解模型性能和行为。\nTruLens的反馈功能（Feedback Functions）是其核心概念之一，提供了一种程序化的方法来评估应用的运行表现。这些函数从“可扩展性”和“有意义性”两个维度出发，考虑评估的范围，旨在为用户提供有价值的反馈，帮助他们理解和改进他们的LLM应用。\n在RAG应用中，提供准确的上下文信息至关重要，以避免生成不真实的“幻觉”答案。TruLens采用了创新性的RAG三元组评估方法，专门针对RAG架构的每个环节进行幻觉风险评估，确保模型的每个部分都能有效地工作，从而减少误导信息的产生。\n上下文相关性（Context Relevance） 上下文相关性是评估RAG应用的第一步，确保每一段检索到的上下文都与提出的查询紧密相关。TruLens利用序列化记录的结构来评估上下文的相关性，这是一个关键的步骤，确保模型在正确的信息上生成回答。\n真实性（Groundedness） 在检索到的上下文信息的基础上，大型语言模型将生成答案。TruLens强调了独立验证每个回答的重要性，以确保它们基于可靠信息，并且能够在检索到的上下文中找到支持的证据。这一步骤是确保模型回答的真实性和可靠性的关键。\n答案相关性（Answer Relevance） 最后，评估需要确保最终回答有效地解答了原始问题，这通过评估应用的最终回答与用户输入的相关性来实现。这一过程确保了模型的输出不仅是真实的，而且是对用户查询有用的。\nTruLens还提出了“诚实、无害和有帮助”的评估原则（Honest, Harmless, and Helpful Evaluations），这些原则旨在确保LLM应用在提供帮助的同时，也是安全和可信的。\nRagas Ragas框架专为评估检索增强生成（RAG）系统而设计，定义了四个核心评估指标：上下文相关性（context_relevancy）、上下文回溯（context_recall）、忠实度（faithfulness）和答案相关性（answer_relevancy）。这些指标共同构成了Ragas的评分体系，提供了一个全面的方法来评价RAG系统的性能。\n此外，Ragas巧妙地利用大语言模型（LLM）进行无参考评估，有效降低了评估成本。通过这种方法，Ragas能够提供一种既经济又有效的方式来评估RAG系统，尤其是在处理大量数据和复杂查询时。\n其他测试框架\nDeepEval\nDeepEval How to Evaluate RAG Applications in CI/CD Pipelines with DeepEval\nARES\ngithub: https://github.com/stanford-futuredata/ARES\nPaper: ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems\nLangChain Evals\nLlama Index Evals\nUpTrain\n数据 在评估数据集时，不必依赖人工标注的标准答案，而是通过底层的大语言模型 (LLM) 来进行评估。\n为了对 RAG 流程进行评估，需要以下几种信息：\nquestion：这是RAG流程的输入，即用户的查询问题。\nanswer：这是由RAG流程生成的答案，也就是输出结果。\ncontexts：这是为了解答question而从外部知识源检索到的相关上下文信息。\n指标 在深入研究检索增强生成（RAG）系统和其他相关技术时，了解和使用正确的评估指标至关重要。以下是几个关键指标，它们帮助我们量化和评估检索系统的效能：\n检索指标 MRR（平均倒数排名） MRR是衡量检索系统性能的一种方法，特别关注于检索结果中的首次正确命中的排名。MRR的高值表示系统能够更频繁地将相关结果排在前列。\n$$ MRR = \\frac{1}{查询数量}\\sum_{i=1}^{查询数量} \\frac{1}{首次正确命中的排名} $$\n这个指标特别有用，因为它直接关注于用户最有可能查看的第一个搜索结果的质量。\n召回率（Recall） 召回率是另一个重要指标，它衡量了系统检索到的相关文档数量与总的相关文档数量之间的比例。高召回率意味着系统能够检索到更多的相关文档。\n$$ Recall = \\frac{检索到的相关文档数量}{总的相关文档数量} $$\nNDCG（标准化折扣累积增益） NDCG（Normalized Discounted Cumulative Gain）是一个在信息检索、推荐系统和机器学习领域常用的评估指标，用于衡量一个系统或模型返回的结果列表的质量。NDCG特别关注于结果的排序质量，即最相关或最有价值的结果是否排在了列表的前面。与其他评估指标相比，NDCG的独特之处在于它考虑了结果的相关性（relevance）不仅是二元的（相关或不相关），而且可以是多级的（例如，从不相关到非常相关的多个级别）。\nEM（精确匹配） EM度量了系统输出的答案与标准答案完全一致的比例，是评估系统准确度的直接方式。在某些场景下，即使是非常小的差异也可能导致答案被视为不正确，这使得EM成为一个严格的评估标准。\n基于大语言模型评估的LLM生成指标 在RAG任务中，对LLM回答的问题主要关注了回答的可验证性（verifiability），即是否严格遵循检索到的上下文如实回答。可验证性由两部分组成：\n高引用召回率（high citation recall）：即所有生成的内容都有充分的引用（外部知识）支持。\n高引用精度（high citation precision）：每个引用是否真的支持生成的内容。\n回答相关性（Answer Relevance） 回答相关性关注的是系统生成的回答与用户提出的问题之间的相关性。理想情况下，回答应该直接且准确地对应于问题，没有偏离主题或提供不相关的信息。\nTruLens中回答相关性的计算方式： TruLens通过提供一种基于LLM的评估方法，允许开发者和研究人员通过编程方式获取对系统生成回答的相关性评估。这种方法利用链式推理（Chain of Thought, CoT）增强理解和推理过程，为评估提供透明度和可解释性。\nfrom trulens_eval.feedback.provider.openai import OpenAI openai_provider = OpenAI() qa_relevance = ( Feedback(openai_provider.relevance_with_cot_reasons, name=\u0026#34;Answer Relevance\u0026#34;) .on_input_output() ) 在relevance_with_cot_reasons方法中，使用聊天完成模型来评估回答对于提示的相关性，并揭示评分背后的推理过程。这种方法不仅考虑回答的内容和长度，而且还评估其是否全面回答了问题，并提供了与问题所有部分相关的上下文信息。\nRAGAS中回答相关性的计算逻辑： RAGAS通过利用LLM重新生成问题（QUESTION_GEN），然后计算这个重新生成的问题与原始问题之间的相似度来评估回答的相关性。这种方法特别关注于系统生成回答的准确性和与原始问题的对应关系。\n# https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/_answer_relevance.py QUESTION_GEN = HumanMessagePromptTemplate.from_template( \u0026#34;\u0026#34;\u0026#34; Generate question for the given answer. Answer:\\nThe PSLV-C56 mission is scheduled to be launched on Sunday, 30 July 2023 at 06:30 IST / 01:00 UTC. It will be launched from the Satish Dhawan Space Centre, Sriharikota, Andhra Pradesh, India Question: When is the scheduled launch date and time for the PSLV-C56 mission, and where will it be launched from? Answer:{answer} Question: \u0026#34;\u0026#34;\u0026#34; ) 不过，由于用户提出的问题通常比较简略，使用RAGAS计算出的回答相关性通常较低。\n上下文相关性（Context Relevance） 上下文相关性专注于评估给定上下文（例如从数据库或文档中检索到的信息片段）与用户查询之间的相关性。高相关性的上下文信息为大型语言模型（LLM）提供了生成准确回答的基础。\n在TruLens中上下文相关性的计算方式： 在TruLens，上下文相关性的评估使用了与回答相关性相同的反馈函数，但是采用了不同的选择器来专注于输入（用户问题）和检索到的上下文信息之间的相关性。这通过对输入问题和来源节点中的文本应用.on_input().on(TruLlama.select_source_nodes().node.text)选择器并计算它们的平均相关性得分来实现。\nqs_relevance = ( Feedback(openai_provider.relevance_with_cot_reasons, name=\u0026#34;Context Relevance\u0026#34;) .on_input() .on(TruLlama.select_source_nodes().node.text) .aggregate(np.mean) ) 底层计算逻辑：此过程首先识别出与用户问题直接相关的上下文信息，评估这些信息的相关性，可能会应用链式推理（CoT）方法来提高评分的准确性和深度。最终生成的平均分表示了上下文信息的整体相关性，分值范围从0到1。\n在RAGAS中上下文相关性的计算逻辑： RAGAS采用了一种略有不同的方法来计算上下文相关性。它通过提取与问题相关的上下文句子（candidate sentences），并对这些句子进行自洽性检查。然后，使用提取的句子数量与检索到的上下文中的总句子数量的比率作为评分标准。\n$$ \\text{context relevancy} = \\frac{|S|}{|\\text{Total number of sentences in retrieved context}|} $$\n这个方法通过使用LLM根据问题和上下文，从上下文中提取出能够支持回答的句子，进而计算这些候选句子和上下文的长度占比（这里使用的是词元数量的比值）。\n# https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/_context_relevancy.py CONTEXT_RELEVANCE = HumanMessagePromptTemplate.from_template( \u0026#34;\u0026#34;\u0026#34;\\ Please extract relevant sentences from the provided context that is absolutely required answer the following question. If no relevant sentences are found, or if you believe the question cannot be answered from the given context, return the phrase \u0026#34;Insufficient Information\u0026#34;. While extracting candidate sentences you\u0026#39;re not allowed to make any changes to sentences from given context. question:{question} context:\\n{context} candidate sentences:\\n\u0026#34;\u0026#34;\u0026#34; ) 真实性或忠实度（Groundedness or Faithfulness） 在TruLens和RAGAS中，真实性或忠实度的评估旨在衡量生成的声明或回答在事实上的准确性及其对源材料的依赖程度。这一评估标准对于确保生成内容的质量和可信度至关重要。\nTruLens中的Groundedness 在TruLens框架中，groundedness的评估通过检查声明中的每个句子是否在源材料中有支持来进行。这个过程利用大型语言模型（LLM）和链式推理（Chain of Thought, CoT）方法来增强评估的准确性和深度。具体来说，评估方法会将整个声明作为一个整体进行处理，并对声明中的每个句子赋予一个从0到10的评分，0代表没有任何信息重叠，而10代表信息完全重叠。\ngrounded = Groundedness(groundedness_provider=openai_provider) groundedness = ( Feedback(grounded.groundedness_measure_with_cot_reasons, name=\u0026#34;Groundedness\u0026#34;) .on(TruLlama.select_source_nodes().node.text) .on_output() .aggregate(grounded.grounded_statements_aggregator) ) RAGAS中的Faithfulness 而在RAGAS框架中，Faithfulness（忠实度）的概念与TruLens中的Groundedness（真实性）相似，旨在评估生成回答的事实一致性。忠实度得分通过比较生成回答中的声明与给定上下文的一致性来计算，特别是检查回答中的声明是否可以从给定的上下文中推断出来。\n$$ \\text{Faithfulness score} = \\frac{|\\text{Number of claims that can be inferred from given context}|}{|\\text{Total number of claims in the generated answer}|} $$\n# https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/_faithfulness.py LONG_FORM_ANSWER_PROMPT = HumanMessagePromptTemplate.from_template( \u0026#34;\u0026#34;\u0026#34;\\ Given a question and answer, create one or more statements from each sentence in the given answer. question: Who was Albert Einstein and what is he best known for? answer: He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics. statements:\\nAlbert Einstein was born in Germany.\\nAlbert Einstein was best known for his theory of relativity. question: Cadmium Chloride is slightly soluble in this chemical, it is also called what? answer: alcohol statements:\\nCadmium Chloride is slightly soluble in alcohol. question: Were Shahul and Jithin of the same nationality? answer: They were from different countries. statements:\\nShahul and Jithin were from different countries. question:{question} answer: {answer} statements:\\n\u0026#34;\u0026#34;\u0026#34; # noqa: E501 ) NLI_STATEMENTS_MESSAGE = HumanMessagePromptTemplate.from_template( \u0026#34;\u0026#34;\u0026#34; Prompt: Natural language inference Consider the given context and following statements, then determine whether they are supported by the information present in the context.Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. Context:\\nJohn is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects. statements:\\n1. John is majoring in Biology.\\n2. John is taking a course on Artificial Intelligence.\\n3. John is a dedicated student.\\n4. John has a part-time job.\\n5. John is interested in computer programming.\\n Answer: 1. John is majoring in Biology. Explanation: John\u0026#39;s major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology. Verdict: No. 2. John is taking a course on Artificial Intelligence. Explanation: The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI. Verdict: No. 3. John is a dedicated student. Explanation: The prompt states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication. Verdict: Yes. 4. John has a part-time job. Explanation: There is no information given in the context about John having a part-time job. Therefore, it cannot be deduced that John has a part-time job. Verdict: No. 5. John is interested in computer programming. Explanation: The context states that John is pursuing a degree in Computer Science, which implies an interest in computer programming. Verdict: Yes. Final verdict for each statement in order: No. No. Yes. No. Yes. context:\\n{context} statements:\\n{statements} Answer: 微调模型评估 在评估RAG系统时，虽然GPT-4等大型语言模型（LLM）因其高性能而被广泛使用，但由于成本和本地部署的需要，选择一个有效的本地部署开源模型也成为了许多研究和应用场景的必需。然而，与GPT-4等高级模型相比，这些本地开源模型的能力通常存在差距，特别是在特定领域内的应用效果上。因此，针对特定领域微调一个LLM用于评估变得尤为重要。\n以下是使用Trulens测试框架，基于笔者所在领域的语料库，对同一个RAG系统使用不同的开源LLM进行评价的结果展示。特别关注的是不同验证模型的失败评分率，这里的失败评分率指的是模型无法按照提示给出有效评分的情况（例如，要求在0～1范围内打分，但模型未给出评分或评分超出范围）。\n失败评分率对比\neval model Groundedness-FailRatio Context-Relevance-FailRatio Answer-Relevance-FailRatio Records gpt-3.5-turbo 0.00 0.00 0.00 41 gpt-4-turbo 0.00 0.00 0.00 41 Qwen1.5-14B-chat 0.07 0.05 0.02 41 Qwen1.5-7B-chat 0.10 0.10 0.07 41 zephyr-7b-beta 0.27 0.22 0.22 41 Qwen1.5-4B-chat 0.32 0.15 0.17 41 chatGLM3-6b-32K 0.36 0.71 0.54 41 微调策略和建议 为了确保评价结果的稳定性和准确性，微调模型时使用的数据集应特别关注于测试框架中使用的提示格式。这样做旨在提高模型对特定提示格式的响应能力，从而提高评价的准确度和一致性。\n此外，从测试结果来看，建议至少使用13B以上的模型进行评价。较小的模型可能在遵循指令和评分准确性方面存在挑战，从而影响评价结果的可靠性。\n对于这个场景的微调，一般采用LoRA微调方法即可满足需求。LoRA（Low-Rank Adaptation）是一种有效的微调技术，可以在不大幅增加模型参数的前提下，通过更新模型的少数关键参数来实现性能的提升。这种方法特别适用于需要特定领域知识增强的场景。\n如果能够收集到足够多的人类反馈结果，采用RLHF（Reinforcement Learning from Human Feedback）专门训练一个评价模型也是一个可行的选择。RLHF通过从人类反馈中学习来优化模型的性能，这可以在成本可控的范围内提供更精确的评价结果。\n传统NLP评估 BLEU BLEU（Bilingual Evaluation Understudy）通过计算机器翻译输出与一个或多个人工翻译的参考译文之间的词汇精确度来评价翻译的质量。BLEU的主要目的是自动地评估文本翻译的好坏，尽量接近人类翻译质量评估的结果。\nROUGE ROUGE（Recall-Oriented Understudy for Gisting Evaluation）是自然语言处理（NLP）任务中常用的一种评估指标，尤其在自动文摘（自动摘要）和机器翻译等领域中非常流行。它主要用于评估自动生成的文本与人工编写的参考文本之间的相似度。ROUGE指标通过计算生成文本与参考文本之间的重叠来量度生成文本的质量。\n常见的ROUGE度量方式有：基于n-gram的重叠度量方法(如ROUGE-1, ROUGE-2)。它计算生成文本与参考文本之间共有的n-grams的数量，并以此评估生成文本的质量。以及基于最长公共子序列（LCS） 的 ROUGE-L，它考虑了句子级别的结构相似性，不仅仅是简单的词汇重叠。通过计算最长公共子序列的长度，ROUGE-L能够捕捉到生成文本和参考文本之间的顺序依赖性，从而提供更全面的相似度评估。\n对于n-gram ROUGE有两个变体： 召回率（Recall）：参考文本中与生成文本共有的n-grams数量除以参考文本中的n-grams总数。精确率（Precision）：参考文本中与生成文本共有的n-grams数量除以生成文本中的n-grams总数。以及二者的调和平均 F1-score。\nMore Details：\npaper: ROUGE: A Package for Automatic Evaluation of Summaries\nblog: GenAI model evaluation metric — ROUGE\n例子：\n# !pip install rouge from rouge import Rouge rouge = Rouge() long = \u0026#39;It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us.\u0026#39; short = \u0026#39;It was an age of wisdom, foolishness, belief, Light, Darkness, hope, and despair, with both light and darkness.\u0026#39; scores = rouge.get_scores(short, long) print(scores) # output: \u0026#39;\u0026#39;\u0026#39; [{\u0026#39;rouge-1\u0026#39;: {\u0026#39;r\u0026#39;: 0.39285714285714285, \u0026#39;p\u0026#39;: 0.6470588235294118, \u0026#39;f\u0026#39;: 0.4888888841876543}, \u0026#39;rouge-2\u0026#39;: {\u0026#39;r\u0026#39;: 0.06976744186046512, \u0026#39;p\u0026#39;: 0.17647058823529413, \u0026#39;f\u0026#39;: 0.09999999593888906}, \u0026#39;rouge-l\u0026#39;: {\u0026#39;r\u0026#39;: 0.39285714285714285, \u0026#39;p\u0026#39;: 0.6470588235294118, \u0026#39;f\u0026#39;: 0.4888888841876543}}] \u0026#39;\u0026#39;\u0026#39; where r, p, and f representing for recall, precision, and f_score.\nROUGE指标的缺点：\n依赖于参考文本： 如果参考文本的质量不高或者数量不足，可能会导致评分不准确\n忽略语义信息： 即使两段文本表达相同的意思，但使用了不同的词汇或表达方式，ROUGE评分也可能较低\n无法评价文本的流畅性和一致性\n对长文本的评价能力有限\n无法全面评估信息的新颖性和重要性\n数据集 一些公开的RAG数据集\nHotpotQA (HQA) 数据集链接：HotpotQA at Hugging Face\n特点：基于维基百科的问答数据集，需要阅读多个支持文档来回答和推理问题。问题多样，不局限于任何预先存在的知识库。提供了句子级别的支持以强化LLM的推理需求。最后，提供了新类型的事实对比问题，测试LLMs提取和比较文本中各种实体属性的能力。\nQasper (QASP) 数据集链接：Qasper at Hugging Face\n特点：基于NLP论文的问答数据集，筛选自Semantic Scholar Open Research Corpus (S2ORC)。\nNarrativeQA (NQA) 数据集链接：NarrativeQA at Hugging Face\n特点：NarrativeQA是一个英语语言的故事和相应问题的数据集，旨在测试阅读理解能力，特别是对长文档的理解。\nQuALITY (QLTY) 数据集链接：QuALITY at Hugging Face\n特点：一个基于故事和文章的多项选择问答数据集，来源包括Project Gutenberg和Open American National Corpus等资源。\nPopQA 论文链接：PopQA Paper\n数据集链接：PopQA at Hugging Face\n特点：PopQA是一个大规模的开放领域问答（QA）数据集，包含14k个以实体为中心的QA对。每个问题都是通过使用模板将从Wikidata检索到的知识元组转换而来的。\nTriviaQA 数据集链接：TriviaQA at Hugging Face\n特点：TriviaqQA是一个阅读理解数据集，包含超过650K的问题-答案-证据三元组。TriviaqQA包括由琐事爱好者编写的95K个问题-答案对。\nASQA 数据集链接：ASQA at Hugging Face\n特点：ASQA是第一个专注于含糊事实问题的长形式问答数据集。与以往的长形式答案数据集不同，每个问题都标注了长形式答案和可由生成段落回答的提取式问答对。\nPUBHEALTH 数据集链接：PUBHEALTH at Hugging Face\n特点：一个包含11,832个用于事实检查的声明的数据集，这些声明涉及一系列健康话题，包括生物医学主题（如传染病、干细胞研究）、政府医疗政策（如堕胎、心理健康、妇女健康）以及其他与公共健康相关的故事。\n推荐阅读 RAGAS Paper\n用 RAGAs（检索增强生成评估）评估 RAG（检索增强型生成）应用 [译]\n如何构建高效的 RAG 系统\nEvaluating Verifiability in Generative Search Engines\nBuilding and Evaluating Advanced RAG\nSteps In Evaluating Retrieval Augmented Generation (RAG) Pipelines\nGenAI model evaluation metric — ROUGE\nRetrieval Augmented Generation (RAG) for LLMs\nRAG Evaluation\n","permalink":"https://niraya666.github.io/posts/rag_toolkit_eval/","summary":"\u003ch2 id=\"写在最前面\"\u003e写在最前面\u003c/h2\u003e\n\u003cp\u003e在过去的几个月中，我主要致力于与RAG（检索增强生成模型）相关的研究和实验工作。通过深入地分析众多论文和项目代码，我发现虽然在RAG领域取得基本成就相对容易，但要实现出色的成果却异常困难。\u003c/p\u003e\n\u003cp\u003e此系列文章旨在分享我在RAG研究中的心得和挑战。正如我们从OpenAI的开发者日活动中看到的，即使是在这个领域的领头羊也在不断试验和努力以寻求突破。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/rag_toolkits/1_1.png\" alt=\"from openAI devday\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e在我们深入探索RAG系统提升的各种方法之前，有一个基本问题需要解决：我们如何准确地评估一个RAG系统的性能？这就像是在机器学习或深度学习任务中没有给定的测试集和评价标准，我们难以判断实验的成功与否。\u003c/p\u003e\n\u003cp\u003e因此，本系列的第一篇文章将聚焦于介绍RAG系统的评价方法、相关指标以及测试框架，为我们接下来的探索设定明确的标准和目标。\u003c/p\u003e\n\u003ch2 id=\"测试框架\"\u003e测试框架\u003c/h2\u003e\n\u003cp\u003e以下是一些测试框架，为RAG系统评估提供了强大的支持。\u003c/p\u003e\n\u003ch3 id=\"trulens\"\u003e\u003cstrong\u003eTruLens\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eTruLens提供了一个独特的视角来评估和跟踪大型语言模型（LLM）实验，通过一系列创新的功能和方法，帮助开发者和研究人员更深入地了解模型性能和行为。\u003c/p\u003e\n\u003cp\u003eTruLens的反馈功能（Feedback Functions）是其核心概念之一，提供了一种程序化的方法来评估应用的运行表现。这些函数从“可扩展性”和“有意义性”两个维度出发，考虑评估的范围，旨在为用户提供有价值的反馈，帮助他们理解和改进他们的LLM应用。\u003c/p\u003e\n\u003cp\u003e在RAG应用中，提供准确的上下文信息至关重要，以避免生成不真实的“幻觉”答案。TruLens采用了创新性的RAG三元组评估方法，专门针对RAG架构的每个环节进行幻觉风险评估，确保模型的每个部分都能有效地工作，从而减少误导信息的产生。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://www.trulens.org/assets/images/RAG_Triad.jpg\" alt=\"TruLens RAG_Triad\"  /\u003e\n\u003c/p\u003e\n\u003ch4 id=\"上下文相关性context-relevance\"\u003e上下文相关性（Context Relevance）\u003c/h4\u003e\n\u003cp\u003e上下文相关性是评估RAG应用的第一步，确保每一段检索到的上下文都与提出的查询紧密相关。TruLens利用序列化记录的结构来评估上下文的相关性，这是一个关键的步骤，确保模型在正确的信息上生成回答。\u003c/p\u003e\n\u003ch4 id=\"真实性groundedness\"\u003e真实性（Groundedness）\u003c/h4\u003e\n\u003cp\u003e在检索到的上下文信息的基础上，大型语言模型将生成答案。TruLens强调了独立验证每个回答的重要性，以确保它们基于可靠信息，并且能够在检索到的上下文中找到支持的证据。这一步骤是确保模型回答的真实性和可靠性的关键。\u003c/p\u003e\n\u003ch4 id=\"答案相关性answer-relevance\"\u003e答案相关性（Answer Relevance）\u003c/h4\u003e\n\u003cp\u003e最后，评估需要确保最终回答有效地解答了原始问题，这通过评估应用的最终回答与用户输入的相关性来实现。这一过程确保了模型的输出不仅是真实的，而且是对用户查询有用的。\u003c/p\u003e\n\u003cp\u003eTruLens还提出了“诚实、无害和有帮助”的评估原则（Honest, Harmless, and Helpful Evaluations），这些原则旨在确保LLM应用在提供帮助的同时，也是安全和可信的。\u003c/p\u003e\n\u003ch3 id=\"ragas\"\u003eRagas\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://docs.ragas.io/en/stable/_static/imgs/component-wise-metrics.png\" alt=\"Ragas\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eRagas框架专为评估检索增强生成（RAG）系统而设计，定义了四个核心评估指标：上下文相关性（context_relevancy）、上下文回溯（context_recall）、忠实度（faithfulness）和答案相关性（answer_relevancy）。这些指标共同构成了Ragas的评分体系，提供了一个全面的方法来评价RAG系统的性能。\u003c/p\u003e\n\u003cp\u003e此外，Ragas巧妙地利用大语言模型（LLM）进行无参考评估，有效降低了评估成本。通过这种方法，Ragas能够提供一种既经济又有效的方式来评估RAG系统，尤其是在处理大量数据和复杂查询时。\u003c/p\u003e\n\u003cp\u003e其他测试框架\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDeepEval\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/confident-ai/deepeval\"\u003eDeepEval\u003c/a\u003e \u003ca href=\"https://www.confident-ai.com/blog/how-to-evaluate-rag-applications-in-ci-cd-pipelines-with-deepeval\"\u003eHow to Evaluate RAG Applications in CI/CD Pipelines with DeepEval\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eARES\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003egithub: \u003ca href=\"https://github.com/stanford-futuredata/ARES\"\u003ehttps://github.com/stanford-futuredata/ARES\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePaper: ARES: \u003ca href=\"https://arxiv.org/abs/2311.09476\"\u003eAn Automated Evaluation Framework for Retrieval-Augmented Generation Systems\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"https://python.langchain.com/docs/guides/evaluation/\"\u003eLangChain Evals\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://docs.llamaindex.ai/en/stable/module_guides/evaluating/root.html\"\u003eLlama Index Evals\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/uptrain-ai/uptrain\"\u003eUpTrain\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"数据\"\u003e数据\u003c/h2\u003e\n\u003cp\u003e在评估数据集时，不必依赖人工标注的标准答案，而是通过底层的大语言模型 (LLM) 来进行评估。\u003c/p\u003e","title":"RAG工具箱：评估RAG系统的方法论"},{"content":"AI大纪事 Suno V3 发布 V3版本带来了卓越的音频品质、更丰富的音乐风格和类型选择，以及在准确响应创作提示方面的显著提升。\n更好的音频质量 更多的风格和流派 改进的提示遵循，包括更少的幻觉和更优美的结尾 Suno V3\nMetaGPT 更新V0.8 V0.8版本的主要亮点包括：\n数据解释器的引入：这一新特性大大增强了MetaGPT的数据处理能力，为用户分析和解释数据提供了强大的支持。 与RAG模块的集成：通过与RAG模块的集成，MetaGPT现在能够更好地理解和处理用户的需求，提高了生成内容的相关性和准确性。RAG底层使用的是llama_index 参考其GitHub页面和官方文档\nNvidia GTC大会 新一代Nvidia B200 GPU\n首个AI程序员Devin 发布 Devin是由Cognition公司开发的全球首个完全自主的AI软件工程师，具备多项先进的编程技能，包括自主学习新技术、全面掌握开发工具、自动化代码修复和错误检测、以及端到端应用的构建和部署能力。\n不过目前，Devin还处于内测阶段，对公众的完全开放还需要一段时间。\nCognition的官网\nAnthropic发布Claude 3 Anthropic发布了其最新的AI模型系列Claude 3，包括三个子模型：Claude 3 Haiku、Claude 3 Sonnet和Claude 3 Opus，其中Opus是最强大的。Claude 3 在多项基准测试中超越了GPT-4和Gemini Ultra，特别是在数学推理（GSM-8k）和专家级知识（MMLU）方面，显示出其领先的能力。于此同时，Claude 3 Opus 首次 Chatbot Arena 排行榜上超越了 GPT-4\n推荐的开源项目 **MoneyPrinterTurbo : 利用大模型，一键生成短视频**\nMediaCrawler: 自媒体爬虫工具, 支持小红书、抖音、快手、B 站、微博等自媒体平台的视频、图片、评论、点赞、转发信息抓取。\nLapisCV: 基于 Markdown 格式的简历模版\nLLMs Interview 八股文： 大模型面试题\n影音记录 本月精选歌单 本月Live记录 0307 Explosions in the Sky\n0315 Fayzz\n本月观影记录 《周处除三害》\n《沙丘2》\n《坠落的审判》\n《完美的日子》\n网飞版三体\n","permalink":"https://niraya666.github.io/monthly/2024-03/","summary":"\u003ch2 id=\"ai大纪事\"\u003eAI大纪事\u003c/h2\u003e\n\u003ch3 id=\"suno-v3-发布\"\u003eSuno V3 发布\u003c/h3\u003e\n\u003cp\u003eV3版本带来了卓越的音频品质、更丰富的音乐风格和类型选择，以及在准确响应创作提示方面的显著提升。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e更好的音频质量\u003c/li\u003e\n\u003cli\u003e更多的风格和流派\u003c/li\u003e\n\u003cli\u003e改进的提示遵循，包括更少的幻觉和更优美的结尾\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"https://www.suno.ai/blog/v3\"\u003eSuno V3\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"metagpt-更新v08\"\u003eMetaGPT 更新V0.8\u003c/h3\u003e\n\u003cp\u003eV0.8版本的主要亮点包括：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e数据解释器的引入\u003c/strong\u003e：这一新特性大大增强了MetaGPT的数据处理能力，为用户分析和解释数据提供了强大的支持。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e与RAG模块的集成\u003c/strong\u003e：通过与RAG模块的集成，MetaGPT现在能够更好地理解和处理用户的需求，提高了生成内容的相关性和准确性。RAG底层使用的是llama_index\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e参考其\u003ca href=\"https://github.com/geekan/MetaGPT\"\u003eGitHub页面\u003c/a\u003e和\u003ca href=\"https://docs.deepwisdom.ai/\"\u003e官方文档\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"nvidia-gtc大会\"\u003eNvidia GTC大会\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e新一代Nvidia B200 GPU\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"首个ai程序员devin-发布\"\u003e首个AI程序员Devin 发布\u003c/h3\u003e\n\u003cp\u003eDevin是由Cognition公司开发的全球首个完全自主的AI软件工程师，具备多项先进的编程技能，包括自主学习新技术、全面掌握开发工具、自动化代码修复和错误检测、以及端到端应用的构建和部署能力。\u003c/p\u003e\n\u003cp\u003e不过目前，Devin还处于内测阶段，对公众的完全开放还需要一段时间。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.cognition-labs.com/\"\u003eCognition的官网\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"anthropic发布claude-3\"\u003eAnthropic发布Claude 3\u003c/h3\u003e\n\u003cp\u003eAnthropic发布了其最新的AI模型系列Claude 3，包括三个子模型：Claude 3 Haiku、Claude 3 Sonnet和Claude 3 Opus，其中Opus是最强大的。Claude 3 在多项基准测试中超越了GPT-4和Gemini Ultra，特别是在数学推理（GSM-8k）和专家级知识（MMLU）方面，显示出其领先的能力。于此同时，Claude 3 Opus 首次 Chatbot Arena 排行榜上超越了 GPT-4\u003c/p\u003e\n\u003ch2 id=\"推荐的开源项目\"\u003e推荐的开源项目\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/harry0703/MoneyPrinterTurbo/tree/main\"\u003e**MoneyPrinterTurbo\u003c/a\u003e : 利用大模型，一键生成短视频**\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"github.com/NanmiCoder/MediaCrawler\"\u003eMediaCrawler\u003c/a\u003e: 自媒体爬虫工具, 支持小红书、抖音、快手、B 站、微博等自媒体平台的视频、图片、评论、点赞、转发信息抓取。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"github.com/BingyanStudio/LapisCV\"\u003eLapisCV\u003c/a\u003e: 基于 Markdown 格式的简历模版\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"github.com/wdndev/llm_interview_note?tab=readme-ov-file\"\u003eLLMs Interview 八股文\u003c/a\u003e： 大模型面试题\u003c/p\u003e\n\u003ch2 id=\"影音记录\"\u003e影音记录\u003c/h2\u003e\n\u003ch3 id=\"本月精选歌单\"\u003e本月精选歌单\u003c/h3\u003e\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/playlist/0CDpNxmeMlZ44uEPjjj0J6?utm_source=generator\" width=\"100%\" height=\"460\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\u003ch3 id=\"本月live记录\"\u003e本月Live记录\u003c/h3\u003e\n\u003cp\u003e0307  Explosions in the Sky\u003c/p\u003e","title":"2024-03 月刊"},{"content":"Hello-World! 欢迎来到我的博客\n在这里，我将深入探索生成式人工智能的奥秘，同时也会涉猎音乐、电影等领域，分享一些个人的思考和感悟。\n为什么我决定写博客 在生活的纷扰和无尽的日常中，我发现自己一直在与拖延症作斗争。直到今天，我终于下定决心，决定将心中的思绪和感悟记录下来，开启我的博客之旅。\n有几个原因驱使我做出了这个决定。\n首先，岁月不饶人，尤其是经历了新冠疫情之后，我明显感觉到我的记忆力不如以往。过去能够轻松驾驭多重任务的我，如今却常在走入客厅的半路上忘记初衷，或是在浏览器的搜索框前失去了寻找的目的。这种突如其来的迷茫，让我开始思索，我的思绪是否正如秋日里的落叶，悄然飘落。\n其次，在深夜的静思中，我时常回想起坂本龙一那句引人深思的话：“我还能看到几次满月？”这不仅是对时间流逝的感慨，更是一种对生命有限性的深刻体悟。在这有限的时光里，我究竟能留下什么？假如我的时间之沙仅剩下几颗，我的存在又有何意义？我不求答案，但愿通过这些文字，如同在时间的长河中种下一棵树，哪怕是最微小的存在，也能留下自己生命的痕迹。\n最后，我被“数据主义”（Dataism）这一概念深深吸引，它如同一面镜子，映照出在数字时代，我们的数据、思考和情感不仅仅是信息的载体，更是构成我们数字化身份的基石。随着AI的羽翼日渐丰满，我开始憧憬一个可能的未来，其中一个由我的数据、思想和经历塑造出的“我”，在某个未知的时间点复苏。这种思考，如同在深海中发现了一座灯塔，为我的存在指明了一条全新的路径。在这个时代，我选择不再是沉默的旁观者，而是通过我的文字，积极参与到这场未知的探索中。\n因此，这篇博客标志着我的新开始。虽然不确定未来的路会怎样，但至少，在这个过程中，我会找到自己的声音，并希望能够与你共鸣。\n","permalink":"https://niraya666.github.io/posts/helloworld/","summary":"\u003ch1 id=\"hello-world\"\u003eHello-World!\u003c/h1\u003e\n\u003cp\u003e欢迎来到我的博客\u003c/p\u003e\n\u003cp\u003e在这里，我将深入探索生成式人工智能的奥秘，同时也会涉猎音乐、电影等领域，分享一些个人的思考和感悟。\u003c/p\u003e\n\u003ch2 id=\"为什么我决定写博客\"\u003e为什么我决定写博客\u003c/h2\u003e\n\u003cp\u003e在生活的纷扰和无尽的日常中，我发现自己一直在与拖延症作斗争。直到今天，我终于下定决心，决定将心中的思绪和感悟记录下来，开启我的博客之旅。\u003c/p\u003e\n\u003cp\u003e有几个原因驱使我做出了这个决定。\u003c/p\u003e\n\u003cp\u003e首先，岁月不饶人，尤其是经历了新冠疫情之后，我明显感觉到我的记忆力不如以往。过去能够轻松驾驭多重任务的我，如今却常在走入客厅的半路上忘记初衷，或是在浏览器的搜索框前失去了寻找的目的。这种突如其来的迷茫，让我开始思索，我的思绪是否正如秋日里的落叶，悄然飘落。\u003c/p\u003e\n\u003cp\u003e其次，在深夜的静思中，我时常回想起坂本龙一那句引人深思的话：“我还能看到几次满月？”这不仅是对时间流逝的感慨，更是一种对生命有限性的深刻体悟。在这有限的时光里，我究竟能留下什么？假如我的时间之沙仅剩下几颗，我的存在又有何意义？我不求答案，但愿通过这些文字，如同在时间的长河中种下一棵树，哪怕是最微小的存在，也能留下自己生命的痕迹。\u003c/p\u003e\n\u003cp\u003e最后，我被“数据主义”（Dataism）这一概念深深吸引，它如同一面镜子，映照出在数字时代，我们的数据、思考和情感不仅仅是信息的载体，更是构成我们数字化身份的基石。随着AI的羽翼日渐丰满，我开始憧憬一个可能的未来，其中一个由我的数据、思想和经历塑造出的“我”，在某个未知的时间点复苏。这种思考，如同在深海中发现了一座灯塔，为我的存在指明了一条全新的路径。在这个时代，我选择不再是沉默的旁观者，而是通过我的文字，积极参与到这场未知的探索中。\u003c/p\u003e\n\u003cp\u003e因此，这篇博客标志着我的新开始。虽然不确定未来的路会怎样，但至少，在这个过程中，我会找到自己的声音，并希望能够与你共鸣。\u003c/p\u003e\n\u003cscript src=\"https://utteranc.es/client.js\"\n        repo=\"https://github.com/Niraya666/niraya666.github.io\"\n        issue-term=\"pathname\"\n        theme=\"github-dark\"\n        crossorigin=\"anonymous\"\n        async\u003e\n\u003c/script\u003e","title":"My First Post: Hello-World!"}]