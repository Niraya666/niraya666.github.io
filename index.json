[{"content":"值得关注的模型和新技术 DeepSeek-V3.2\nQwen/Qwen-Image-Layered\nzai-org/GLM-4.7\nMiniMaxAI/MiniMax-M2.1\nJina-VLM\nSAM Audio\n值得关注的开源项目 Awesome Claude Skills: A curated list of Claude Skills.\nMinne: a read-it-later \u0026amp; personal knowledge management solution\nEbook-MCP: A MCP server that supports mainstream eBook formats including EPUB, PDF and more. Simplify your eBook user experience with LLM.\nvibe-vibe: 首个系统化 Vibe Coding 开源教程\ndata-juicer: Data processing for and with foundation models\nopen-ptc-agent: An open source implementation of code execution with MCP (Programatic Tool Calling)\nAgent-Skills-for-Context-Engineering: A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems.\n值得关注的研究和论文 DeepSeek V3.2 DeepSeek稀疏注意力（DSA） RL协议 Agent任务合成流水线 DeepSeek-V3.2-Speciale： 放宽了长度限制，推理能力增强 DSA\nWhy：解决长序列的计算复杂度\n$O(L^2) -\u0026gt; O(Lk)$\n其中 $k \\ll L$\n通过稀疏化机制减少计算量\nLightning Indexer： 用于计算当前 Query Token 与前序 Token 之间的索引评分 I_{t,s} 。使用 ReLU 作为激活函数，且只包含少量的 Head\nFine-grained Token Selection：基于索引器的评分，只检索 Top-k 个分数最高的 KV 条目\nCore Attention： 仅针对筛选出的这部分稀疏 KV 条目计算注意力输出，而不是针对全序列\nDSA 通过Continued Training完成：\nDense Warm-up Stage：初始化闪电索引器，保持主模型使用Dense Attention，冻结除索引器外的所有参数， 使用 KL 散度损失，强制索引器的输出分布去拟合主模型全量注意力的分布 Sparse Training Stage： 引入细粒度选择机制，让模型适配稀疏模式，开启 Top-k 选择，优化所有模型参数。索引器继续通过 KL 散度学习对齐注意力分布，而主模型则通过语言建模损失进行优化；索引器的输入会从计算图中分离，即索引器的优化仅依赖 KL 损失，不接受语言建模损失的梯度 特性 Vanilla Attention (标准) MLA (DeepSeek-V3.1) DSA (DeepSeek-V3.2) 计算复杂度 $O(L^2)$ (核心注意力) 优化了 KV 缓存，但计算仍较密集 $O(Lk)$ (核心注意力)，显著降低 16 KV 检索方式 全量检索 (Dense) 压缩/潜在向量 (Latent Vector) 稀疏检索 (Top-k Sparse) 17 实现模式 MHA (多头注意力) 支持 MHA 和 MQA 模式 强制使用 MLA 的 MQA 模式 以共享 KV 18 索引机制 无 无 引入 Lightning Indexer，虽然本身复杂度 $O(L^2)$ 但计算量极小 19 性能影响 基准 高性能 无明显降级，在长上下文任务中甚至优于旧版本 20202020 DSA 相比之前的架构，最大的区别在于引入了一个轻量级的“向导”（Indexer）来预先筛选重要的 Token，从而避免了对无关 Token 的大量无效计算。相比于 DeepSeek-V3.1 的 MLA，V3.2 的 DSA 保持了架构兼容性，仅通过训练策略的调整（引入 Indexer 和稀疏化）就实现了显著的效率提升。\n后训练\nSpecialist Distillation\n构建了多个领域的“专家模型”，然后将它们的能力迁移给主模型。（针对 数学、编程、逻辑推理、通用 Agent 任务、Agent 编码、Agent 搜索 这六个领域，分别训练了专门的专家模型），使用训练好的专家模型生成高质量的领域数据，用于微调最终的 DeepSeek-V3.2 检查点\nMixed RL Training\n这一阶段的核心策略是多任务融合，以避免分阶段训练可能导致的“灾难性遗忘”\n沿用了 GRPO 将 Reasoning、Agent 任务 和 Human Alignment的数据整合在同一个 RL 阶段进行训练 奖励： 推理和 Agent 任务： 基于规则的结果奖励，长度惩罚，语言一致性奖励 通用任务： generative reward model，针对每个 prompt 有专门的评分标准 Scaling GRPO\n稳定 GRPO 算法，防止训练崩溃\nUnbiased KL Estimate： ？ Off-Policy Sequence Masking： 推理和训练之间存在不一致（Off-policy），计算数据采样策略与当前策略的 KL 散度，并掩盖掉那些策略差异过大且优势为负的样本 Keep Routing： 强制训练时的专家路由路径与推理采样时保持一致 Keep Sampling Mask： 在训练时复用采样时的截断掩码（Top-p/Top-k mask），确保新旧策略在相同的动作空间子集上进行比较，维护重要性采样的原则 Agentic Task Synthesis\n合成数据流水线\n冷启动，通过设计包含 \u0026lt;think\u0026gt; 标签的 System Prompt，将非 Agent 的推理数据与非推理的 Agent 数据结合，引导模型在调用工具前先进行思考 合成任务：利用 DeepSeek-V3.2 构建自动化 Agent 来生成训练环境和数据 搜索 Agent： 自动挖掘长尾实体，构建问答对，并验证答案的正确性 代码 Agent： 从 GitHub 挖掘 Issue-PR 对，自动构建可执行的测试环境（包含 Python, Java, C++ 等多种语言） 通用 Agent： 自动合成超过 1800 个任务导向的环境（如旅行计划） DeepSeek-V3.2-Speciale\n解除对模型思考长度的限制，训练过程中显著降低了对生成长度的惩罚\n为了提升在复杂数学证明任务上的能力，该模型额外整合了来自 DeepSeekMath-V2 的数据集和奖励方法\n在推理能力上显著强于标准版\nHow Far Are We from Genuinely Useful Deep Research Agents? arXiv:2512.01948\n核心贡献:\nFinder (Fine-grained DEepResearch bench)： 一个细粒度的深度研究基准， 引入了419个结构化的检查清单，用于标准化评估报告的结构、分析深度和事实依据 DEFT (Deep rEsearch Failure Taxonomy)： 对深度研究智能体的失败分类学， 将错误细分为3个核心维度（推理、检索、生成）下的14种具体失败模式 DEFT 的构建\nOpen Coding， 使用5种不同的LLM作为编码员，分析失败案例，生成初始概念 Axial Coding 结合人类专家介入，计算一致性， 将概念归纳为14个轴向类别 Selective Coding， 提炼出“推理”、“检索”、“生成”三个核心维度 Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory arXiv:2511.20857\n缺乏一个统一的框架来评估智能体在部署期间（Test-time）如何检索、整合和进化其记忆\n创新点\nEvo-Memory 基准测试：提出了一个新的评估基准，将传统的静态数据集重构为顺序任务流， 要求模型在完成一个任务后，必须更新记忆以供后续任务使用\n评估框架： 归纳了一个通用的记忆智能体公式：(Search -\u0026gt; Synthesis -\u0026gt; Evolve)，即检索、合成上下文、进化记忆的循环\nReMem： 传统的 ReAct 只有“思考”和“行动”， ReMem 引入了 Action–Think–Memory Refine 循环，让智能体主动地推理、修剪和重组记忆\nExpRAG 基准： 一个基于检索的简单基准，专门用于检索过去的“经验”（输入-输出-反馈三元组），而不仅仅是检索知识\nReMem 的工作机制\nThink (思考)： 分解任务，规划步骤。 Act (行动)： 与环境交互。 Refine (优化)： 这是核心。智能体在每一步都会进行“元推理”（Meta-reasoning），决定哪些记忆是杂音需要删除，哪些经验值得保留或重组。 ExpRAG 的工作机制\n将每次任务的 (输入, 预测, 反馈) 作为一个经验单元存入。 在遇到新任务时，检索最相似的 k 个过往经验作为上下文参考 Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs https://alignment.anthropic.com/2025/selective-gradient-masking/\nSelective GradienT Masking (SGTM): 针对LLM中危险知识的移除问题\n在 Transformer 的每一层中，将部分注意力头和 MLP 神经元指定为“遗忘参数”，其余为“保留参数” 在训练过程中，当模型遇到被标记为“危险”的数据时，只更新“遗忘参数”（通过掩盖其他参数的梯度） 当遇到普通数据时，更新“保留参数”。 对于未标记数据，允许更新所有参数 训练结束后，直接将遗忘参数置零。这样就物理上移除了危险知识，同时保留了存储在其他参数中的通用能力。 Budget-Aware Tool-Use Enables Effective Agent Scaling arXiv:2511.17006\nReAct 模式下简单地增加工具调用预算，并不能带来性能提升；往往在预算耗尽前就过早停止搜索，或者在死胡同里浪费资源\n创新：\nBudget Tracker: 在每一轮对话中显式地告诉代理“当前已用多少资源，还剩多少资源”\nBATS (Budget-Aware Test-time Scaling) 框架：\n利用预算感知来动态调整Planning和Verification策略。它能根据剩余预算决定是Dig Deeper当前线索，还是Pivot尝试新路径。\n统一成本指标: 将“Token消耗成本”和“工具调用成本”结合的统一指标 （性价比）\nQwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management arXiv:2512.12967\n长文本数据合成管线 稳定化长文本 RL 策略 记忆增强架构（Memory Agent） 数据合成管线 核心突破在于生成需要在全局分布的证据中进行多跳关联和推理的任务\n通过将文档去构造为原子事实及其底层关系，再通过程序化手段组合成可验证的复杂问题\n合成策略： 基于知识图谱（KG）： 挖掘文档中的实体关系，构建跨文档的多跳推理路径。 基于结构化表（SQL）： 将文档中的数值信息转化为表格，通过 SQL 生成复杂的数值计算问题。 多智能体自进化（MASE）： 使用三个智能体（提问者、解答者、验证者）迭代生成并验证难度递增的问题。 验证： 知识落地检查（Knowledge Grounding Check）：移除源文档，测试模型是否仍能回答。若能回答，说明该问题依赖内部知识而非上下文，会被剔除 上下文鲁棒性检查（Contextual Robustness Check）：通过插入无关文档扩展上下文，确保问题及其答案在复杂的噪声干扰下依然稳健 长文本 RL 长文本RL存在的问题：\n奖励信号，错误答案中往往包含大量正确的推理步骤，导致模型难以区分哪些动作导致了最终的失败 长文本数据涉及多个领域且分布极不均匀，传统的随机采样会导致训练Batch内的任务分布失衡 在长序列训练中，模型很容易陷入响应长度失控或熵崩溃（过度收敛）的陷阱 创新策略：\n采样策略：不再随机选取数据，而是确保每个训练批次中平均分配五类任务 优势估计：改进了 GRPO 算法中的优势计算方式。改为**在同一任务类型内计算奖励的标准差，**隔离不同任务间的奖励噪声 Negative Gradient Clipping， 高熵（模型不确定）的负向样本会产生巨大的梯度，从而扰乱优化过程，通过裁剪或屏蔽这些高熵负面响应的梯度，可以保护模型在探索过程中的潜力 AEPO 算法： AEPO 会根据模型当前的熵动态调整训练：当熵过高（太随机）时，暂时屏蔽负向优势样本以降低熵；当熵过低（太死板）时，重新引入负向梯度以鼓励探索\nProgressive Paradigm： 从 20K 到 60K，再到 120K 输入长度的阶梯式训练；\nMemory Agent 将超长文档切片（Chunking）。 模型按顺序阅读切片，每一步输出：1. 记忆更新（提炼关键信息）；2. 导航计划（决定下一步关注什么，小本子？）。 最后基于累积的记忆生成答案。 采用多阶段融合训练：先训练全上下文推理能力，再训练记忆管理能力，最后通过模型融合（Model Merging）结合两者。 推荐内容 一篇agent-memory综述： Memory in the Age of AI Agents: A Survey\n一系列年度报告：\nOpenRouter: The 2025 State of AI Report Anthropic: How enterprises are building AI agents in 2026 OpenAI: The state of enterprise AI Langchain: State of AI Agents 如何写好Claude.md: Writing a good CLAUDE.md\nLLM 评估时的各式各样细节问题\nChasing 100% Accuracy: A Deep Dive into Debugging Kimi K2\u0026rsquo;s Tool-Calling on vLLM Why benchmarking is hard Physics of Language Models\n影音记录 精选歌单 Live演出 12.08 L\u0026rsquo;Impératrice\n12.09 Godspeed you! Black Emperor\n12.13 Diels-Alder\n书\u0026amp;阅读摘录 面向业务落地的AI产品评测体系设计与平台实现 在AI产品落地过程中，它的不确定性、动态性和复杂性，给质量和体验保障带来了前所未有的挑战。AI产品的特性使得测试既不是简单的功能验证，也不是纯算法模型的评测\n工程产品是“需求明确 → 设计实现 → 测试验证”，AI产品则是“技术驱动 → 场景探索 → 效果迭代”的螺旋式过程。 评测需前置至需求阶段，与产品和研发共同定义“好”的标准\n在算法评测中，金标评测集可以长期复用；在agent场景：每次评测时，外部服务数据、时间、接口行为可能变化；即使输入相同，也会因为外围导致答案偏离原始金标。\n以前一个版本是一次代码发布；现在一个版本可能是：模型更换、prompt 改写、检索策略调整、工具编排改造或它们的任意组合；\n评测标准的制定从研发单一角色制定转变到产品、设计、研发、业务方（BD/运营）共同参与指标，从“研发自说自话”转向“业务-技术目标同频”，解决AI产品常见的“技术达标但体验崩坏”问题 回收研发评测、产设验收及线上运营标注数据——将优质数据沉淀为金标集\n我们推荐大部分AI产品的评测基于端到端评测\n针对有参考答案的评测，我们核心要解决的是构造一个稳定可复现的“环境”。\n我们建议按“变更范围 × 变更风险”来设计三档评测策略，并通过用例标签体系自动筛选推荐用例\n怎么评估线上效果 形成“监测-分析-优化”完整闭环\n作为一名科技从业者，如何总结你的 2025？ 在我看来，人类正面临一个自身难以克服的挑战——知识爆炸让我们都成了越来越细分的专家，而创新往往发生在知识的交叉边缘。 当一个人穷其一生都无法触及某个领域的边缘时，跨领域的创新就变得异常困难。而AI正是帮助我们突破知识壁垒，探索未知世界的很好的工具，我对这一点充满了期待。\nAI Agent 很火，但 Agent Infra 准备好了吗？ 之所以 Infra 层会有很大的变化，核心在于，AI Agent 今天的开发和落地范式，与以往的 App 完全不同了。 核心的区别就是不确定性的存在。\n但在 Agent 工程里，失败往往是模型对开发者意图的误解，或者说是概率上的「漂移」。你没办法像修水管一样去修复一个 Agent，只能像教育孩子一样，去引导它、说服它、约束它。\n现在交付的是一种概率性的能力，你很难去定义什么是绝对的「正确」。\n绝大多数工程师从入职第一天起，工作就是在确定性系统里进一步提升确定性，判断标准只有「对」和「错」。但现在我们面对的是不确定性的复杂系统，工作方式必须彻底转变。 这种转变主要体现在两点： 第一，从工程思维转向科学实验思维。而科学实验思维的核心，是建立一套评测体系，把复杂系统拆解成一个个子系统，屏蔽其他子系统的干扰，去单独评测每个子系统的影响。只有通过这种控制变量的方式，一步步摸索，才能驾驭 Agent 的复杂性； 第二，从 Day One 思维转向 Day Two 思维\nAI Infra 更关注的是模型的算力、优化和推理，如何以最快、最稳定的算力服务让模型输出内容。 而 Agent Infra 关注的是项目的最终结果输出，上层的逻辑、记忆和工具调用。如何编排、如何管理记忆、如何调用各种工具接口，如何更稳定在沙盒里运行的问题。\nAI Agent 第一次把「计算」这件事，真正意义上地民主化了。很多以前算不过账的事情，不太经济的商业模式，突然变得合理了。\nDify 认为可调试性、记忆管理和低延迟性能是下一阶段的重点。\n上下文工程：AI-Native时代的软件研发新范式 真正有价值的，不是 AI 写了多少行代码，而是——你是不是在做 AI-Native 的软件工程。\n人定边界，AI 填细节。 想业务、抽象、模型、trade-off，而不是某个库的 API 写法\n上下文就是新的源码（Context is the new Source Code）。\nAgent Engineering: A New Discipline Traditional software assumes you mostly know the inputs and can define the outputs. Agents give you neither: users can say literally anything, and the space of possible behaviors is wide open Agent engineering is the iterative process of refining non-deterministic LLM systems into reliable production experiences. It is a cyclical process: build, test, ship, observe, refine, repeat.\nWe see agent engineering as a new discipline that combines 3 skillsets working together: Product thinking defines the scope and shapes agent behavior Engineering builds the infrastructure that makes agents production-ready. Data science measures and improves agent performance over time\nLLMs are powerful enough to handle complex, multi-step workflows. We’re starting to cross the threshold where agents are delivering meaningful business value in production. Every input is an edge case. You can’t debug the old way. “Working” isn’t binary.\nTo achieve a reliable agent system, shipping is how you learn, not what you do after learning. Build your agent’s foundation. Test based on scenario you can imagine Ship to see real-world behavior Observe. Refine Repeat\nThe teams shipping reliable agents today share one thing: they\u0026rsquo;ve stopped trying to perfect agents before launch and started treating production as their primary teacher. In other words, tracing every decision, evaluating at scale, and shipping improvements in days instead of quarters.\n微信杂谈：AI 产品 \u0026amp; 品味 agent 也只是当下使用 ai 的一种形式，形式可能会淘汰（比如大模型迭代），但底层的能力不会，应该去关注更本质的东西。\n最近和人聊到 ai 产品，在 vibe coding 大行其道的今天，其实想做出让人眼前一亮的产品，就是需要靠品味和细节来打动人。因为你能做的事情，ai 基本都能做，但是品味这个东西，只可意会不可言传，ai 很难去平衡这个度。\n“情绪价值函数”，它不是简单的对错运算，而是一些感性的东西在帮你做决策\n地下阿根廷：犹太钱庄、华人超市、摆烂的年轻人与返贫的中产 所有的热情，最终都指向了一个赤裸裸的动词：逃生。\n他们并不关心什么是 Web3，他们只关心一件事：USDT 能不能让我手里的钱不缩水。\n当穷人在用现金避税，富人在用 Crypto 转移资产时，谁成了这场危机中唯一的输家？答案令人心碎：是那些遵纪守法的「老实人」。\n中产阶级的崩溃，往往是无声的。他们不会像底层那样上街烧轮胎抗议，也不会像富人那样直接移民。他们只是默默地取消了周末的聚餐，换掉了孩子的私立学校，然后在每一个深夜焦虑地计算着下个月的账单。\n他们是这个国家最听话的纳税人，也是被收割得最彻底的一群人。\n","permalink":"https://niraya666.github.io/monthly/2025-12-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/deepseek-ai/DeepSeek-V3.2/blob/main/assets/paper.pdf\"\u003eDeepSeek-V3.2\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/Qwen/Qwen-Image-Layered\"\u003eQwen/Qwen-Image-Layered\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/zai-org/GLM-4.7\"\u003ezai-org/GLM-4.7\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/MiniMaxAI/MiniMax-M2.1\"\u003eMiniMaxAI/MiniMax-M2.1\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/jinaai/jina-vlm\"\u003eJina-VLM\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://ai.meta.com/blog/sam-audio/\"\u003eSAM Audio\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/BehiSecc/awesome-claude-skills\"\u003eAwesome Claude Skills\u003c/a\u003e: A curated list of Claude Skills.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/perstarkse/minne\"\u003eMinne\u003c/a\u003e: a read-it-later \u0026amp; personal knowledge management solution\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/onebirdrocks/ebook-mcp?tab=readme-ov-file\"\u003eEbook-MCP\u003c/a\u003e: A MCP server that supports mainstream eBook formats including EPUB, PDF and more. Simplify your eBook user experience with LLM.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/datawhalechina/vibe-vibe\"\u003evibe-vibe\u003c/a\u003e: 首个系统化 Vibe Coding 开源教程\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/datajuicer/data-juicer\"\u003edata-juicer\u003c/a\u003e: Data processing for and with foundation models\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/Chen-zexi/open-ptc-agent\"\u003eopen-ptc-agent\u003c/a\u003e: An open source implementation of code execution with MCP (Programatic Tool Calling)\u003c/p\u003e","title":"2025-12 月刊"},{"content":"值得关注的模型和新技术 Gemini 3\nSAM 3\nKimi-K2-Thinking\nKIMI LINEAR\n值得关注的开源项目 DocETL: A system for agentic LLM-powered data processing and ETL\nhow-to-build-a-coding-agent: A workshop that teaches you how to build your own coding agent. Similar to Roo code, Cline, Amp, Cursor, Windsurf or OpenCode.\nreader 3: Quick illustration of how one can easily read books together with LLMs.\nOlmo 3： 不仅发布模型，还发布了用于构建模型的所有数据（Dolma 3）、代码、训练日志和中间检查点\nMusic Flamingo: Scaling Music Understanding in Audio Language Models Claude Scientific Skills：A set of ready to use scientific skills for Claude\n值得关注的研究和论文 AgentFold: Long-Horizon Web Agents with Proactive Context Management arXiv:2510.24699\n如何有效进行context Management\n目前context Management遇到的问题\nReAct：只追加，不处理，随着任务变长，上下文会迅速膨胀 固定历史摘要：每步都总结；任何一次总结的失误都可能导致关键细节丢失 提出AgentFold：核心是主动式、多尺度的上下文管理\n将context看作是一个“草稿纸”—需要主动管理和塑造的动态空间 引入Folding操作：agent不仅要决定下一步的行动，还要决定如何“折叠”和管理自己的历史记录 支持两种不同的粒度folding： Granular Condensation： 将最近一步的详细交互，压缩成一个精简的摘要 Deep Consolidation：将过去连续的多步交互合并成一个总结 通过SFT让LLM学会根据当前任务状态，自主决定何时、对哪些内容、以及用何种粒度进行folding Defeating the Training-Inference Mismatch via FP16 https://arxiv.org/pdf/2510.26788\nLLM 在RL阶段普遍存在Training-Inference Mismatch问题\n根源： Inference/Rollout 和Training/Gradient Computation 采用不同计算引擎，尽管这两个引擎在数学上是等价的，但由于硬件优化和数值精度的差异，它们会产生微小的数值偏差； 这种不匹配会导致Biased Gradient，容易出现性能突然下降和崩溃。\n当前广泛使用的 BF16 格式是罪魁祸首：\nBF16 虽然动态范围大（与FP32相同），能有效防止预训练中的溢出和下溢，但其精度极低 低精度使得计算结果对微小的实现差异非常敏感，舍入误差在自回归生成过程中不断累积，最终导致训练和推理策略的概率分布产生显著差异 转而使用 FP16 进行RL微调 Deep Research Tulu https://www.datocms-assets.com/64837/1763496622-dr_tulu_draft.pdf\n创新点\nRLER (Reinforcement Learning with Evolving Rubrics): 在训练过程中动态生成和更新评分标准,而非固定的评分标准\nInitial Search-based Rubrics\n在训练开始前\n操作： 对于训练集中的每一个问题 x，系统首先调用搜索引擎获取相关的背景文档。 生成： 将问题 x 和搜索到的文档输入给一个教师模型（Rubric Generator），让其生成一组初始的评分标准 R_{persist}。 目的： 确保评分标准是**基于事实（Grounded）**的，而不是基于模型幻觉的。例如，如果问题是关于某个具体的医学基因突变，初始标准会明确要求“答案必须提到该突变会导致 FHM1 疾病”，而不是泛泛地要求“答案要准确”。 Evolving Rubrics\n每一步训练中，评分标准会根据模型当前的表现进行更新\n采样 (Rollout)： 待训练的模型（Policy Model）针对问题 x 生成 G 个不同的回答，每个回答都包含搜索过程和最终答案。 对比生成 (Contrastive Generation)： 系统将这 G 个回答（包括它们新搜索到的信息）连同当前已有的评分标准，一起扔给 Rubric Generator。 指令核心： 系统会问 Generator：“对比这些回答，找出区分好回答和坏回答的关键点是什么？有哪些新的优点是之前的标准没覆盖的？有哪些新的投机取巧（Reward Hacking）的行为？” 生成两类新标准： 正向标准 (Positive Rubrics)： 捕捉模型探索到的新知识或高质量推理。例如：“回答中引用了 2024 年最新的 X 论文来反驳旧观点。” 负向标准 (Negative Rubrics)： 捕捉模型新出现的错误模式。例如：“回答为了凑字数，大量复制粘贴了搜索结果中的无关段落。” 合并： 将新生成的标准 R_{new} 加入到当前的活跃评分标准池 R_{active} 中。 Rubric Buffer Management\n如果一直添加新标准，计算量会爆炸，且很多标准可能失效。因此需要进行筛选。\n计算区分度 (Discriminative Power)： 系统使用当前的评分标准池对那 G 个回答进行打分。 计算每个评分标准在 G 个回答上的得分方差 (Standard Deviation)。 筛选逻辑： 剔除无效标准： 如果某个标准对所有回答的打分都是 1（大家都做到了）或者都是 0（大家都做不到），说明这个标准在当前阶段没有区分度，直接剔除。 保留高价值标准： 按照方差从大到小排序，只保留前 K_{max} 个（例如 5 个）最具区分度的标准。 目的： 确保奖励信号始终关注模型当前最需要改进的地方（即那些模型有时候能做对、有时候做不对的地方）。 奖励计算与更新\n最终的奖励信号由三部分组成，用于指导 GRPO 算法更新模型：\n评分标准奖励： 由 LLM Judge 根据筛选后的评分标准对答案打分（0, 0.5, 1）。 引用奖励 (Citation Reward)： 检查引用的准确性（Precision）和召回率（Recall）。如果模型引用了不存在的文献或引用内容不支持论点，会受到惩罚。 格式奖励 (Format Reward)： 确保模型遵守 \u0026lt;think\u0026gt;, \u0026lt;call_tool\u0026gt;, \u0026lt;answer\u0026gt; 等结构化标签。 Think in Diffusion, Talk in Autoregression arXiv:2511.08923\nAR 生成质量高，但必须逐个 token 串行生成\ndLM支持并行生成多个 token，但生成质量不佳\n创新点\n在Speculative Decoding基础上，利用dLM进行并行的 Token Drafting，利用AR做Sampling/Verification\nSingle Forward Pass：利用 GPU 在内存受限场景下的Free Token Slots，在一次模型前向计算中，同时完成对上一步草稿的验证和对下一步内容的并行起草。\nNested Learning: The Illusion of Deep Learning Architectures https://abehrouz.github.io/files/NL.pdf\n如何解决LLMs静态性和持续学习能力缺失的问题\n对此提出了 Nested Learning (NL，嵌套学习)\n不将模型视为简单的层级堆叠，而是将其视为一组嵌套的、多层级的优化问题。每个组件（如注意力机制、前馈网络、优化器）都有自己的“更新频率” Linear Attention 被重构为一个两层优化问题：内层通过梯度下降更新记忆矩阵 M_t 以压缩上下文，外层通过梯度下降更新投影层 W_q, W_k, W_v Momentum被重构为一个试图记忆过去梯度的“元记忆模块” HOPE 架构\n使用了一种基于 Titans 和 Delta-rule的Self-referential学习模块。 引入了 CMS，包含一系列 MLP 块 (MLP^{(f_1)}, \u0026hellip;, MLP^{(f_k)})。不同的块有不同的更新周期 C^{(\\ell)}。 更新规则：参数 \\theta 不是固定的，而是根据输入数据通过L2 regression 进行实时更新。这意味着模型在推理过程中也在进行某种形式的“训练”或“记忆压缩”。 推荐内容 Ultimate Guide to Vibe Coding V1.2\nSupercharge your OCR Pipelines with Open Models\nGoogle agent系列白皮书：\nintroduction-to-agents Agent Tools \u0026amp; Interoperability with MCP Context Engineering: Sessions \u0026amp; Memory Agent Quality Prototype to Production The GenAI Divide STATE OF AI IN BUSINESS 2025： GenAI鸿沟，企业在采用GenAI时普遍遇到的问题，和如何跨越鸿沟。\nOpenAI：building-an-ai-native-engineering-team\nHow to Think About GPUs\n影音记录 精选歌单 Live演出 11.15 Cory Wong\n11.28 死亡搁浅 音乐会\n书\u0026amp;阅读摘录 罗汉堂 | Diego Comin：什么将决定全球 AI 生产率的分化？ 很多企业引入了新技术，却没有真正将其广泛地融入核心业务和工作流程。这种“拥有但未充分使用” 的现象，是导致全球生产力分化的深层原因\n当前 AI 的 “拥有率” 和 “使用强度” 都仍然很低。未来，决定企业乃至国家生产率分化的，不是谁率先拥有 AI，而是谁能充分拥抱和使用 AI。\n新技术究竟是如何推动生产率增长的（productivity growth）？要回答这个问题，我们需要从两个维度来理解技术扩散与生产率之间的关系。第一，是新技术被引入一个国家所需要的时间，这通常被称为‘采纳滞后’（adoption lag）；第二，当一项技术被引入后，它究竟在多大程度上被使用，也就是我们在经济学中所说的‘使用强度’或‘集约边际’（intensive margin）\n这意味着，那些能够把 AI 融入核心流程、提升使用强度的企业，将在未来的生产率竞争中走得更快、更远；而那些虽然采纳了 AI，却没有真正使用或只做浅尝辄止的企业，即便站在同一技术前沿，也很难从 AI 中获益\n因为，最终决定生产率差异的不在技术本身，而在技术的使用强度。\n“AI 浏览器是最差的交互形态，搜索也是” 信息爆炸与有限人类：生而有涯，知也无涯\n但问题是，底层基础设施并没有同步演化。所有浏览器的核心仍是“人”——必须由人来全程参与、观察、控制。它或许能让速度快几倍，但永远受制于人类自身的时间维度：我们是有限生物，有 24 小时、有睡眠、有寿命。\n问题不在于 Agent，而在于浏览器本身——是浏览器这套架构需要被抛弃。\n这其实回到一个核心概念——Intention（意图）。我们在互联网上常常忽略自己的真实意图，以为自己在交互，其实只是被算法牵着走。\nCode execution with MCP: Building more efficient agents As MCP usage scales, there are two common patterns that can increase agent cost and latency:Tool definitions overload the context window;Intermediate tool results consume additional tokens.\nLLMs are adept at writing code and developers should take advantage of this strength to build agents that interact with MCP servers more efficiently.\n企业 IT 部门是 AI 转型的最大阻力？| 任鑫 x 徐文浩 从MVP到MMP： AI产品的营销成本越来越贵，现在大家谈论的是MMP（Minimum Marketable Product），产品特性必须从设计之初就考虑好如何在社交媒体上传播 。\nAgent和Workflow并非对立 。在对交付结果准确性要求高的B端场景，Workflow是必需的 ；而在C端，Agent的不确定性反而是“抽卡”式成瘾性的来源 。\n不确定性的价值： AI的“智能感”并非来自100%准确，而是来自“意料之外” 。如同“抽卡”，不确定性会带来多巴胺奖励 。人们更喜欢AI提供自己无法产生的“全新维度”（如心理侧写、玄学分析）。\nIT部门的阻力： 传统企业AI落地的一大阻力是其内部IT部门 。他们想主导这件事，但往往既缺乏外部公司的技术能力，也不懂内部业务，最终卡住流程 。\n从特定场景开始自动化： 评估你公司内部的工作流，使用Cherry Studio 、N8N 或开源工具，从一个非常具体的需求，如分析云账单 、处理发票 开始构建内部Agent。\n","permalink":"https://niraya666.github.io/monthly/2025-11%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://deepmind.google/models/gemini/\"\u003eGemini 3\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://ai.meta.com/sam3/\"\u003eSAM 3\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://moonshotai.github.io/Kimi-K2/thinking.html\"\u003eKimi-K2-Thinking\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/pdf/2510.26692\"\u003eKIMI LINEAR\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/ucbepic/docetl\"\u003eDocETL\u003c/a\u003e: A system for agentic LLM-powered data processing and ETL\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/ghuntley/how-to-build-a-coding-agent\"\u003ehow-to-build-a-coding-agent\u003c/a\u003e: A workshop that teaches you how to build your own coding agent. Similar to Roo code, Cline, Amp, Cursor, Windsurf or OpenCode.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/karpathy/reader3\"\u003ereader 3\u003c/a\u003e: Quick illustration of how one can easily read books together with LLMs.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.datocms-assets.com/64837/1763662397-1763646865-olmo_3_technical_report-1.pdf\"\u003eOlmo 3\u003c/a\u003e： 不仅发布模型，还发布了用于构建模型的所有数据（Dolma 3）、代码、训练日志和中间检查点\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://research.nvidia.com/labs/adlr/MF/\"\u003eMusic Flamingo: Scaling Music Understanding in Audio Language Models\u003c/a\u003e\n\u003ca href=\"https://github.com/K-Dense-AI/claude-scientific-skills\"\u003eClaude Scientific Skills\u003c/a\u003e：A set of ready to use scientific skills for Claude\u003c/p\u003e","title":"2025-11 月刊"},{"content":"看着Tongyi Deep Research （TDR）用着30B的参数量能够跑出媲美闭源模型的效果，总是好奇究竟怎么做到的?\n最近一个多月断断续续，总算读完了了Tongyi Deep Research 的一系列论文，虽说越往后，官方透露的技术细节越少，但细读下来，依然能一窥其背后的“门道”。\n最大的感受是，TDR在训练算法上并没有太多黑科技，反倒是数据的合成、训练环境的设计和大量的工程化设计，或许才是其成功的关键，以及重点。\n大概从以下3个角度出发，整理了下TDR系列论文中的最佳实践和创新点：\nAgent的训练方式\n训练所使用的数据合成管道和方法论\n工程化优化和设计\n训练方式 通过LLM+工程化实现agent，还是直接将agent能力内化至LLM中？TDL选择了后者，并提供了更完整的训练链路：Agentic Mid-training + Agentic post-training。\nAgentic Mid-training\n这一概念主要源于AgentFounder论文，其核心思想是在传统的后训练（Post-training）之前，增加一个Agentic Continual Pre-training (CPT) 阶段。\n为什么需要CPT？\n后训练流程面临一个核心困境：要求一个用来预测下一个token的LLM，在后训练阶段同时学习两件截然不同的事：\n如何理解和调用工具、如何进行多步规划 （基础的agent能力）\n如何在特定复杂任务上做出最优决策 （专家能力）\nAgentic CPT的目标就是解决这一矛盾，先将一个通用的LLM转变为Agentic Foundation Model，将更强的工具调用和推理能力内化其中。\n相比之下，后一个阶段（agentic post-training）方法基本上成为共识： SFT+RL，并没有太多新的东西。\n在RL的环境构建，采用了双环境的设计， 针对web-agent场景， 一个虚拟环境确实可以节约大量的时间和成本：\n模拟环境： 构建一个离线的搜索和查询环境，用于快速验证算法和策略\n真实世界环境： 真实的外部API，用于训练和评估；采用5种工具（Search, Visit, Python Interpreter, Google Scholar, and File Parser）；\n数据合成 如何获得大量高质量的合成数据来支撑CPT、SFT和RL？\nWebWalker \u0026amp; WebDancer 这两个工作中对应着几个benchmark和数据集的构建：WebWalkerQA 和 CRAWL QA (模拟浏览) \u0026amp; E2HQA(由易到难)\n目的都是为了解决现有的QA对数据集太浅的问题；\n主流基于RAG的检索方式，是一种“横向搜索”，仅仅依靠关键词获取大量页面信息，缺乏像人类一样，深入点击、多页面联动的“深度搜索”。\nWebWalkerQA： 通过递归遍历（从首页开始收集所有可访问子链接及其内容），然后结合预设角色让LLM生成查询问题，最后经过验证和过滤（剔除不自然、保留答案简短且含实体的QA）来生成数据\nCRAWL QA：通过模拟人类浏览行为，从知识型网站（如维基、GitHub）上爬取多层页面信息，收集权威网站的根URL，程序化地点击链接、抓取子页面内容，然后使用GPT-4o根据收集到的信息生成需要整合多个页面信息才能回答的问题。\nE2HQA (Easy-to-Hard QA)：采用一种“由易到难”的逆向构建策略，将一个简单的问题通过迭代式地增加信息约束和子问题，逐步演化成一个复杂的多跳（multi-hop）问题； 具体而言，从一个简单问答开始，然后围绕答案实体搜索更多信息，并将这些信息改写成限定条件，融入原问题，使其变得更复杂。这个过程可以重复多次\nE2HQA的核心在于**“逆向构造”**：通常我们是从“描述”推理出“实体”，这里是反过来，利用LLM和搜索引擎，将问题中明确的“实体”替换为关于该实体的“描述性查询”。\n例子：\n原始问题 ($Q_0$)：爱因斯坦是哪里人？（答案：德国）\n迭代 1：选中实体“爱因斯坦”。搜索并将其重述为“提出相对论的物理学家”。\n新问题 ($Q_1$)：提出相对论的物理学家是哪里人？ 迭代 2：选中实体“相对论”。搜索并将其重述为“包含质能方程 E=mc² 的理论”。\n新问题 ($Q_2$)：提出包含质能方程 E=mc² 的理论的物理学家是哪里人？ Agent Trajectories Rejection Sampling： 在构建了QA数据后，基于ReAct框架（只提供search和visit工具）来解决这些问题，并记录下完整的交互轨迹。通过一系列筛选（符合ReAct格式、答案正确、过滤幻觉和重复逻辑），保留下高质量的轨迹，用于SFT。\nWebSailor WebSailor的工作标志着一个重要的转折点：问题难度并非来自路径的长度，而是来自信息的不确定性。\nWebSailor提出了一种新的任务难度分类法，它真正要攻克的是Level 3：非结构化高不确定性任务。这类任务没有预设解决路径，Agent必须进行复杂的探索、比较、排除错误路径，并综合多方证据才能得出结论。\n三种等级的任务难度分类法\nLevel 1: 低不确定性任务。这类任务可以通过单次搜索或利用模型自身的参数化知识直接解决。\nLevel 2: 结构化高不确定性任务。这类任务初始看不出答案，但存在一条清晰、结构化的解决路径，例如标准的多跳问答，每一步的目标都相对明确。\nLevel 3: 非结构化高不确定性任务。这是WebSailor关注的核心。\n在知识图谱中，通过Random Walk在图谱中生成长路径，这些长路径天然代表了多跳的推理路径；为此，WebSailor提出了SailorFog-QA，一种基于知识图谱和随机游走的高不确定性任务生成方法。\n具体而言：\n从一个模糊的实体（来自Wikidata）开始，通过模拟网页浏览（搜索、访问网页）进行随机游走，提取相关实体和关系，构建一个复杂的知识图谱\n从图谱中随机采样一个子图，基于子图中的实体和关系，生成一个问题和答案\n对问题中的关键信息进行模糊处理，增加其不确定性\n而后采用一个推理模型回答SailorFog-QA的问题，生成完整的轨迹（Thought-Action-Observation），保留其中成功的Action-Observation，丢弃原始的Thought，并使用另一个模型为每一步重新生成简洁、精炼的Thought，形成最终的SFT数据。（这一步的原因是，直接用专家模型的COT进行SFT过于冗长）\n简而言之，就是通过在真实网站上随机游走构建复杂知识图谱，采样多跳路径，然后对问题中的关键信息进行模糊处理（例如，将实体名替换为描述），从而大幅增加任务的不确定性。\nWebShaper WebSailor虽然引入了不确定性，但合成过程还是“Information-Driven”（先搜集信息，再造问题），这可能导致问题结构和答案的不一致。\nWebShaper则更进一步，提出了一种**“Formalization-Driven”的范式。其核心思想从“先有信息，再造问题”转变为“先定义问题的逻辑结构，再寻找信息填充”**。\n为此，WebShaper基于集合论提出了**知识投影（Knowledge Projections, KP）**的概念。\n什么是KP？ KP的本质是一个实体集合。这个集合里的所有实体，都通过一个特定的关系(R)与另一个已知实体集(V)相关联。例如，bornIn({90s}) 就是所有在90年代出生的人的集合；\n同时KP定义了并集(∪)和交集(∩)来组合出更复杂的情况；如：\n“寻找在2000年踢球并且出生于1990年代的球员” = playAt({2000}) ∩ bornIn({1990年代})\n“寻找在2004年或2005年效力于某支球队的球员” = playAt({2004}) ∪ playAt({2005})\nKP还支持递归构建，一个查询的条件(V)本身可以是另一个查询的结果\nWebShaper 的数据合成流程\n构建种子问题：通过在维基百科文章的链接网络上进行随机游走，收集大量相关联的文章内容，LLM基于这些内容生成一批初始的、相对简单的seeds，筛选，确保其质量和可解性\nAgentic 扩展：\n将形式化的任务结构（如 R1(T1) ∩ R2(T2)）转换成一种 LLM 能理解的、基于三元组 [变量, 关系, 变量/常量] 的表示形式\n对于一个已有的形式化问题，Expander Agent 会识别出其中的“叶子节点”\nExpander 选取一个常量，通过调用工具（Search**、**Summarize、Validate）自主构建一个新的、更复杂的子问题，而这个子问题的答案恰好是原来的那个常量\n将新生成的子问题替换掉原来的常量，从而使整个问题的推理链条变得更长、更复杂。这个过程可以迭代多次，以控制最终任务的难度\n小结 从数据合成角度分析，能够看到思路的演化。\n最初，难度被简单地等同于一个量化指标，即完成任务所需的点击次数或路径长度。然而，这种线性增加的路径可能依然由一系列简单的操作组成，并未触及更高级的认知挑战。也就是WebDancer中E2HQA方法的理念，通过增加迭代和约束增加推理长度。\nWebSailor的工作标志着一个重要的转折点—问题难度并非来自路径的长度，而是来自信息的不确定性。通过构建复杂的知识图谱并对关键信息进行模糊化处理，agent不能再简单地沿着一条预设的路径前进，而必须在探索过程中维护多种可能性，对比和评估相互矛盾的证据，并最终综合出一个最可靠的结论。\nWebShaper则更进一步，引入知识投影KP，从数学的角度给出形式化的描述，确保了每一个生成的任务都有可验证的逻辑基础，而不是随机的；同时难度也变得可量化，使得curriculum learning成为可能。\n工程化优化 如何避免上下文爆炸：ReSum｜IterResearch\n如何让agent具备开放式报告撰写能力：WebWeaver\nReSum 与 IterResearch 目前主流Agent采用的ReAct框架，会将每一轮的“think-action-observation”全部追加到上下文中。随着搜索轮次增加，上下文迅速膨胀，不仅超出模型上下文长度限制，累积的噪声还会干扰推理。\nReSum 的核心目标：通过周期性上下文压缩（摘要），让智能体在不丢失关键信息的前提下，突破上下文长度限制。\n在 ReAct 基础上，周期性调用摘要工具，将历史对话压缩为结构化摘要（包含已确认证据 + 信息缺口 + 下一步方向），用摘要 + 原始问题组成“压缩状态”，重启推理，从而绕过上下文长度限制\n不是直接用通用大模型做摘要，而是专门训练一个30B参数的模型\n专门设计 ReSum-GRPO算法：自动将长轨迹按摘要点分段，每段作为独立训练样本，将整个轨迹的最终奖励（是否答对）广播到所有分段\n相比ReSum的“压缩”，IterResearch更为彻底，将Deep Research建模为马尔可夫决策过程（MDP）。\n在每一轮交互后，非简单地追加信息，而是重构其workspace，其中workspace只包含三个关键部分：原始问题、一个不断演进的**报告（evolving report）**作为记忆，以及上一步的直接交互上下文。\nMDP：\nState, S： 在第 t 轮，状态 s_t 由三部分组成：{问题 q, 当前报告 M_t, 上一步的动作和工具响应 {a_{t-1}, TR_{t-1}}}\nDecision, D： 在每个状态 s_t，LLM生成一个结构化的决策 d_t，包含三部分：{思考 (Think), 更新后的报告 (M_{t+1}), 下一步动作 (a_t)}\nEnvironment, E： 一系列工具，如谷歌搜索、谷歌学术、网页浏览器和Python解释器\nTransition, T： 从 s_t 到 s_{t+1} 的转移是重构而非累加。新的状态 s_{t+1} 由 {问题 q, 智能体刚生成的更新报告 M_{t+1}, 当前动作和工具响应 {a_t, TR_t}} 构成。历史信息通过 M_{t+1} 被压缩和提炼，旧的原始信息被丢弃。\n两阶段训练：\nSFT：用Qwen3-235B生成轨迹，教会30B模型这种迭代式思考格式\nRL： 筛选出一批具有挑战性（成功率在20%-60%之间）的问题，采用GRSO，引入了基于轨迹长度的几何折扣奖励，鼓励模型学习更直接、更专注的解决路径。\nWebWeaver 针对Open-Ended Deep Research (OEDR) 任务，即没有标准答案、需要自主生成长报告的场景，TDR提出了WebWeaver框架。\n传统方法通常将“制定大纲”和“信息搜索”解耦，且一次性加载所有信息容易导致Lost-in-the-middle。WebWeaver的创新在于：\nDynamic Research Cycle： 不再采用静态的“规划-搜索”分离模式。新发现的证据会用来优化和扩展大纲，而优化后的大纲又会指导下一轮搜索。\nPlanner + Writer 双agent\nPlanner： 负责探索性研究。它在一个循环中不断通过Search工具获取URL、解析网页、提取详细证据并存入记忆库（分配唯一ID）。获取新证据后，Planner会重新审视并优化报告大纲（write_outline）\nWriter： 负责报告合成。它按照大纲结构逐章生成。\n首先根据大纲中的引用ID，从记忆库精确检索证据。（retrieve）；分析已写好的前文内容和新检索到的证据，形成一个连贯的写作思路（Think）；基于思考结果，撰写当前章节的内容(write)；完成一个章节后，用于该章节的证据会从上下文中移除，以保持上下文的简洁和高相关性，为写作下一章节做准备 (Pruning)\n；当所有章节都完成后，writer执行 terminate ，输出完整的报告\n写在最后 一些思考：\n工程化实现 vs. 训练内化 这并非非此即彼的选择，更多是基于场景和成本的权衡。 通用Agent目前仍难以通过训练实现，但在Web-Agent等垂直领域，通过训练让小参数模型（如30B）掌握特定工具的使用和特定格式输出，具有性价比；那么代价是什么呢？模型的泛化性会降低。TDR的成功很大程度上依赖于其预设的工具集，“TDR+预设工具”和“TDR+自定义工具”完全是两种不同的体验\nmid-training | CPT 是否是必须的，业内暂时还没有共识，但显而易见的是，LLM必须经过针对多轮对话和工具调用的深度微调。如果缺乏这种专项训练，现阶段最稳妥的方案依然是使用最大参数量的基座模型来保证指令遵循能力。\n个人认为TDR最值得借鉴是数据合成和工程化上的创新\n参考 Tongyi DeepResearch Technical Report\nWebWalker\nWebDancer\nWebSailor\nWebShaper\nReSum\nIterResearch\nWebWeaver\nWebWatcher\nAgentFounder\nWebSailor-V2\nAgentScaler\n附录：论文阅读笔记 WebWalker: Benchmarking LLMs in Web Traversal https://arxiv.org/pdf/2501.07572\n当前主流的检索增强生成（RAG）系统虽然能通过搜索引擎获取外部信息，但其检索方式通常是“横向搜索”（horizontal search），即在多个网页中找关键词匹配的内容，无法深入网站内部结构，难以处理需要“多层点击、多页面联动、深度推理”的复杂任务。\n提出新任务：Web Traversal, 系统性地在网站内导航，挖掘深层信息,任务形式为QA\n构建新基准：WebWalkerQA, 包含 680个高质量QA对，覆盖4个真实领域, 包含单源和多源 两种类型, 每个QA标注了深度、难度、路径\n采用 “探索者（Explorer）+ 批判者（Critic）”双智能体架构: Explorer负责点击导航，Critic负责记忆和判断是否已收集足够信息\nWebDancer WebDancer\n解决如何合成数据用于训练web-agent\n现有的方法存在的问题：\n数据质量和复杂性不足： “浅”问题，只需一两步搜索就能解决，高质量的复杂问答数据集数据量又太少\n缺乏系统性构建方法\n缺乏明确的训练方法\nWebDancer 提出了一个四阶段的 cohesive paradigm， 将复杂的智能体构建过程分解为四个阶段：\n第一步：高质量浏览数据构建\n第二步：高质量轨迹采样\n第三步：监督微调（SFT）进行有效冷启动\n第四步：强化学习（RL）增强泛化能力\n第一阶段：数据构建：\nCRAWL QA：通过模拟人类浏览行为，从知识型网站（如维基、GitHub）上爬取多层页面信息，收集权威网站的根URL，程序化地点击链接、抓取子页面内容，然后使用GPT-4o根据收集到的信息生成需要整合多个页面信息才能回答的问题。\nE2HQA (Easy-to-Hard QA)：采用一种“由易到难”的逆向构建策略，将一个简单的问题通过迭代式地增加信息约束和子问题，逐步演化成一个复杂的多跳（multi-hop）问题； 具体而言，从一个简单问答开始，然后围绕答案实体搜索更多信息，并将这些信息改写成限定条件，融入原问题，使其变得更复杂。这个过程可以重复多次\n第二阶段：轨迹采样 基于经典的ReAct框架， 只提供两个工具：search（搜索）和visit（访问网页）\n使用GPT-4o（生成Short-CoT）和QwQ-Plus（生成Long-CoT）来解决第一阶段构建的QA问题，记录下完整的交互轨迹\n轨迹筛选：符合ReAct格式，只保留最终答案正确的轨迹，通过规则和模型过滤掉存在幻觉、严重重复、逻辑不通的轨迹\n第三阶段：Agent SFT\n冷启动， 将筛选后的轨迹数据格式化为对话形式，包含think和工具调用标签，目的是让模型能够按照格式回答，为RL提供一个良好的初始模型。\n计算损失时，屏蔽掉Observation部分，让模型专注于学习生成Thought和Action。\n第四阶段： Agent RL\n使用DAPO，采用SFT时未见过的数据进行rollout\nReward Design： score_format （权重0.1） 和score_answer （权重0.9，LLM-as-a-judge 评分）\nWebSailor WebSailor\nWebSailor提出了一种基于知识图谱的高不确定性任务生成方法 （SailorFog-QA）\n当前大多数训练数据都属于以下两类：\nLevel 1 任务：不确定性低，通过单次搜索或利用模型自身知识就能解决\nLevel 2 任务：初始不确定性高，但有清晰、结构化的解决路径（如标准的多跳问答）\n真正需要且缺乏的**Level 3 任务：**不仅初始不确定性极高，而且没有预设的解决路径，需要智能体进行复杂的探索、推理和信息整合\nSailorFog-QA： 通过在真实网站上进行随机游走，构建复杂的知识图谱，并从中采样拓扑结构多样的子图来生成问题。具体而言：\n从一个模糊的实体（来自Wikidata）开始，通过模拟网页浏览（搜索、访问网页）进行随机游走，提取相关实体和关系，构建一个复杂的知识图谱\n从图谱中随机采样一个子图，基于子图中的实体和关系，生成一个问题和答案\n对问题中的关键信息进行模糊处理，增加其不确定性\n而后采用一个推理模型回答SailorFog-QA的问题，生成完整的轨迹（Thought-Action-Observation），保留其中成功的Action-Observation，丢弃原始的Thought，并使用另一个模型为每一步重新生成简洁、精炼的Thought，形成最终的SFT数据。（这一步的原因是，直接用专家模型的COT进行SFT过于冗长）\n训练阶段，依旧是两阶段：SFT冷启动+RL\nRejection Sampling，对轨迹进行过滤，只保留最终答案正确、长度在32k token以内、且工具调用次数超过5次的复杂轨迹\nRL采用DUPO (Duplicating Sampling Policy Optimization)：在训练前过滤掉过于简单的任务，然后在训练中，对于那些部分成功、部分失败的批次（通过随机复制批次内的有效样本来填满被过滤掉的空位。\nWebShaper https://arxiv.org/abs/2507.15061\n提出了一种基于Formalization-Driven的数据合成方式。\n主流的数据合成方法采用Information-Driven，即先从网络上搜集信息，然后基于这些信息生成问题，但会导致两个主要缺陷：生成的问题的推理结构可能与原始信息的组织结构不匹配（结构不一致） 和 生成的问题和对应的答案之间可能存在矛盾或错误 （答案不一致）\nWebShaper 的数据合成范式，从“先有信息，再造问题”转变为“先定义问题的结构，再寻找信息填充”，基于集合论提出了知识投影的概念，为信息寻求任务建立了一套数学形式化语言，即；设计了一个名为 Expander 的自主智能体，用于系统性地将简单问题扩展为复杂问题；\nKnowledge Projections, KP\n核心思想：将一个复杂的信息查询问题，拆解成一系列基于集合论的“寻找实体集合”的操作\nKP的本质是一个实体集合 。这个集合里的所有实体，都通过一个特定的关系 (Relation, R) 与另一个已知实体集 (V) 相关联，例如，bornIn({90s}) 就是所有在90年代出生的人的集合\n定义了并集和交集两种操作来组合 KP； 如问题: “寻找在2000年踢球并且出生于1990年代的球员。”，则可以拆解成：第一个条件 “在2000年踢球” 可以构建一个KP playAt({2000})第二个条件 “出生于1990年代” 是另一个KP：bornIn({1990年代})，将这两个集合取交集，就得到了最终的目标集合：playAt({2000}) ∩ bornIn({1990年代})\n或问题 “寻找在2004年或2005年效力于某支球队的球员。”，则KP写成：playAt({2004}) ∪ playAt({2005})。\n除此之外，KP还支持递归构建，一个查询的条件（已知实体集V）本身可以是另一个查询的结果；对于问题 *“寻找一名球员，他所在的球队成立于1966年并且是一支东德球队，而他本人在2004-05赛季为该队效力，且出生于90年代。”，*第一层，先找出是哪支球队，T1 = foundIn({1966}) ∩ isA({East German football team})\n第二层查询,寻找球员 T = playIn(T1) ∩ (playAt({2004}) ∪ playAt({2005})) ∩ bornIn({1990s})\nWebShaper 的数据合成流程\n构建种子问题：通过在维基百科文章的链接网络上进行随机游走，收集大量相关联的文章内容，LLM基于这些内容生成一批初始的、相对简单的seeds，筛选，确保其质量和可解性\nAgentic 扩展：\n将形式化的任务结构（如 R1(T1) ∩ R2(T2)）转换成一种 LLM 能理解的、基于三元组 [变量, 关系, 变量/常量] 的表示形式\n对于一个已有的形式化问题，Expander Agent 会识别出其中的“叶子节点”\nExpander 选取一个常量，通过调用工具（Search**、**Summarize、Validate）自主构建一个新的、更复杂的子问题，而这个子问题的答案恰好是原来的那个常量\n将新生成的子问题替换掉原来的常量，从而使整个问题的推理链条变得更长、更复杂。这个过程可以迭代多次，以控制最终任务的难度\nagent训练\n使用一个agent来解决这些新生成的复杂问题\n记录下 Agent 解决问题的完整思考和行动轨迹（保留答案正确且合理的）\nSFT冷启动+RL\nReSum arXiv:2509.13313\nReAct会将每一轮的“思考-动作-观察”全部追加到上下文中，导致随着搜索轮次增加，上下文迅速膨胀，最终超出模型的上下文长度限制\nReSum 的核心目标：通过周期性上下文压缩（摘要），让智能体在不丢失关键信息的前提下，突破上下文长度限制。\n创新点：\n在 ReAct 基础上，周期性调用摘要工具，将历史对话压缩为结构化摘要（包含已确认证据 + 信息缺口 + 下一步方向），用摘要 + 原始问题组成“压缩状态”，重启推理，从而绕过上下文长度限制\n不是直接用通用大模型做摘要，而是专门训练一个30B参数的模型\n专门设计 ReSum-GRPO算法：自动将长轨迹按摘要点分段，每段作为独立训练样本，将整个轨迹的最终奖励（是否答对）广播到所有分段\nIterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction https://arxiv.org/html/2511.07327v1\n目前deep-research agent主流所采用的ReAct的框架，把所有历史信息、思考过程和工具调用结果不断累加到同一个上下文中，容易导致：\n上下文爆炸\n噪声干扰\n提出**IterResearch，**用“周期性综合”和“策略性遗忘”取代“线性累积”\n将deep-research 建模为马尔可夫决策过程（MDP），在每一轮交互后，非简单地追加信息，而是重构其workspace，其中workspace只包含三个关键部分：原始问题、一个不断演进的**报告（evolving report）**作为记忆，以及上一步的直接交互上下文\nWebWeaver https://arxiv.org/abs/2509.13312\nOpen-Ended Deep Research, OEDR 任务要求AI智能体在面对一个没有标准答案的开放性问题时，能够自主地从海量的网络信息中进行搜索、筛选、整合，并最终生成一份结构清晰、内容深刻、引用准确的深度研究报告\n现有方法通常将制定大纲和信息搜索这两个阶段解耦,单向流程无法根据新发现动态调整研究方向, 同时，在写作阶段一次性加载至context中，容易造成lost-in-the-middle的问题\nWebWeaver框架上的创新：\nDynamic Research Cycle，不再采用静态的“规划-搜索”分离模式，而是让大纲优化与信息搜索一同进行，新发现的证据会用来优化和扩展大纲，而优化后的大纲又会指导下一轮的搜索\n双智能体设计， Planner 负责探索性研究阶段，最终产出一个带有精确引用的、结构完整的研究大纲； Writer负责报告合成阶段，依据规划器提供的大纲进行写作，逐个章节地写作\nPlanner\n在一个循环中不断做出决策，提供三种工具：search， write_outline, terminate;\n执行search时，返回URL、标题和摘要，Planner筛选相关URL，然后进一步解析网页，提取与查询相关的摘要和详细证据， 摘要被送回Planner上下文中， 详细证据被存入记忆库并分配一个唯一的ID\n在获取新证据后，Planner会重新审视和优化报告大纲（write_outline）\nWriter\n按照大纲的结构，一个章节一个章节地生成报告\n首先识别当前要写的章节，并根据大纲中为该章节提供的引用ID，从记忆库中精确检索出相关的证据（retrieve）\n分析已写好的前文内容和新检索到的证据，形成一个连贯的写作思路（Think）\n基于思考结果，撰写当前章节的内容(write)\n完成一个章节后，用于该章节的证据会从上下文中移除，以保持上下文的简洁和高相关性，为写作下一章节做准备 (Pruning)\n当所有章节都完成后，写作者执行 terminate 行动，输出完整的报告\nWebWatcher https://arxiv.org/abs/2508.05748\n多模态深度研究设计的智能体框架\n提出一个新的基准测试集BrowseComp-VL，和数据合成pipeline， QA-to-VQA转换pipeline 和自动化的轨迹生成与筛选\nBrowseComp-VL 构建\n在前作CRAWL-QA（WebDancer）基础上，加入WebSailor中采用的实体模糊化，构建出纯文本的QA数据\nQA到VQA的转换，采用：\n针对QA对中的核心实体，使用搜索引擎检索相关的真实网络图片\n使用GPT-4o将原文本问题中的实体指代词改写为指向图片的描述，如“图片中的这个物体”\n通过一个三阶段的筛选流程（包括Selector和Examiner），利用GPT-4o评估图片与问题的相关性、问题的清晰度以及答案的可验证性，确保最终生成的VQA数据质量\n其中Selector包含两阶段，初步完整性检查和图文相关性评估；自动化检查包括检查问题是否被改写，检查实体是否被成功掩码 （实体是否被“图中的物体”之类代词取代）；图文相关性评估阶段，将原始QA对+VQA问题+检索到的候选图像 给到GPT-4o，从三个角度评估（上下文对齐， 语义匹配 和视觉推理的合理性）\nExaminer视觉可回答性验证，模拟了一个真实的VQA场景，以验证仅凭图像是否足以识别出问题的核心实体；在QA-to-VQA转换过程中，系统会为每个实体生成一个专门的“图像查询字符串”，如“图中的人物是谁？”，将字符串和图像给到GPT-4o做回答；如果GPT-4o无法根据提供的有限信息正确回答，被认为是“视觉基础薄弱”的，会被最终丢弃 （确保图像本身是自洽且信息丰富的）\nWebWatcher Agent训练\n配备了五种工具：Web Image Search；Web Text Search；Visit；Code Interpreter；OCR\n使用GPT-4o为每个训练VQA样本生成解决问题的完整轨迹\n保留那些最终答案正确、每一步逻辑一致且工具使用次数不少于三次的轨迹\n训练阶段依旧是SFT冷启动加RL（GRPO）\nAgentFounder https://arxiv.org/abs/2509.13310\n单纯使用Post-training训练Agent存在局限性，需要在post-training 前增加一步Agentic Continual Pre-training（CPT），以提升LLM在agent方面的基础能力（工具使用和推理能力）\n提出两种无需真实调用外部API的数据合成方法：\nFirst-order Action Synthesis, FAS ： 从网页、文档中自动生成（问题-规划-行动）数据对；用于训练模型的初始规划和逻辑推理能力\nHigher-order Action Synthesis, HAS： 将agent解决问题的轨迹，重塑为一系列的多步决策问题，通过在每一步生成多个备选方案，而非单一路径\n第一阶段使用大量FAS数据和短的HAS数据在32K上下文中进行训练，初步建立智能体能力；\n第二阶段则使用高质量的长HAS数据在128K长上下文中进行精调，提升模型处理长程、复杂任务的能力\nWebSailor-V2 https://arxiv.org/abs/2509.13305\n一个完整的agent post-training方案\n数据构建创新：SailorFog-QA-V2\n从种子实体出发，利用网络工具进行扩展，并特意建立节点间的密集连接和循环结构，使其更接近真实世界的知识网络，构建了一个comprehensive knowledge graph，密集的图结构以更好地模拟真实世界知识\n由于图谱变得密集，放弃了计算量巨大的暴力枚举，转而采用基于“随机游走”（random-walk）的方法来高效地采样出结构多样的子图。\n在生成问答任务时，系统性地将问题中的实体、日期、数值等关键信息替换为模糊的描述和范围，引入多种不确定性来生成需要复杂推理才能解决的QA pairs。\nRL框架创新\n创建了一个“模拟环境+真实环境”的双轨制训练框架\n模拟环境基于离线的维基百科数据库从零开始构建，专门用于快速的算法实验和数据筛选；真实环境即可真实调用的API；\ndual-environment RL framework\n模拟环境： 基于一个**大规模的离线维基百科知识库，**还配备了“一套相应的网络工具”；用于快速迭代和算法验证\nReal Environment： 与真实世界网络 API 相连接的训练设置，包括多个工具（search，visit，Google Scholar，Python interpreter）；用于agent训练\nAgentScaler https://arxiv.org/abs/2509.13311\n如何获得高质量agent 与环境交互的完整轨迹\n提出：\n可扩展的全模拟环境构建框架\n**两阶段Agent学习策略：**通用领域提升工具调用和交互能力 + 垂直领域专门训练以提升具体场景能力\n环境构建\n收集了超过3万个来自真实世界的API，并对其进行清洗和标准化\n将每个API视为图中的一个节点。通过计算API之间参数的相似性，来判断它们之间是否存在调用依赖关系，从而构建一个庞大的“工具依赖图”\n使用社区发现算法（Louvain）对工具图进行聚类，将功能相近、依赖关系紧密的API划分到同一个Domain，\n在每个领域内，根据所有工具的参数，自动生成一个该领域专属的Schema\n将该领域内的每个工具都转换成可执行的Python代码，使其能够对这个数据库进行真实的读写操作\nAgent Experience Learning\n在特定领域的工具图中，通过遍历图来采样一条逻辑上连贯的工具调用序列。然后，为这个序列生成相应的参数和初始数据库状态，并将它们整合成一个高级的用户意图Intent\n实例化一个“模拟用户”和一个“智能体”。模拟用户提出高级意图，智能体则需要通过多轮对话和工具调用来完成任务\n智能体每次调用工具，都会在程序化实现的环境（数据库）中执行，并获得真实的返回结果。 . 整个交互过程被记录下来，形成一条原始的交互轨迹\n轨迹过滤： format → 筛选数据库的最终状态与预设的golden状态完全一致的轨迹 → 工具调用序列和参数筛选\n两阶段微调\n","permalink":"https://niraya666.github.io/posts/tongyi-deep-research-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/","summary":"\u003cp\u003e看着\u003ca href=\"https://www.modelscope.cn/studios/jialongwu/Tongyi-DeepResearch\"\u003eTongyi Deep Research\u003c/a\u003e （TDR）用着30B的参数量能够跑出媲美闭源模型的效果，总是好奇究竟怎么做到的?\u003c/p\u003e\n\u003cp\u003e最近一个多月断断续续，总算读完了了Tongyi Deep Research 的一系列论文，虽说越往后，官方透露的技术细节越少，但细读下来，依然能一窥其背后的“门道”。\u003c/p\u003e\n\u003cp\u003e最大的感受是，TDR在训练算法上并没有太多黑科技，反倒是\u003cstrong\u003e数据的合成、训练环境的设计和大量的工程化设计\u003c/strong\u003e，或许才是其成功的关键，以及重点。\u003c/p\u003e\n\u003cp\u003e大概从以下3个角度出发，整理了下TDR系列论文中的最佳实践和创新点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eAgent的训练方式\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e训练所使用的数据合成管道和方法论\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e工程化优化和设计\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"训练方式\"\u003e训练方式\u003c/h2\u003e\n\u003cp\u003e通过LLM+工程化实现agent，还是直接将agent能力内化至LLM中？TDL选择了后者，并提供了更完整的训练链路：Agentic Mid-training + Agentic post-training。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAgentic Mid-training\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这一概念主要源于\u003ca href=\"https://arxiv.org/abs/2509.13310\"\u003eAgentFounder\u003c/a\u003e论文，其核心思想是在传统的后训练（Post-training）之前，增加一个\u003cstrong\u003eAgentic Continual Pre-training (CPT)\u003c/strong\u003e 阶段。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/Tongyi%20Deep%20Research%20%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0-assets/%e6%88%aa%e5%b1%8f2025-10-24%20%e4%b8%8b%e5%8d%881.32.19.png\" alt=\"截屏2025-10-24 下午1.32.19.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e为什么需要CPT？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e后训练流程面临一个核心困境：要求一个用来预测下一个token的LLM，在后训练阶段同时学习两件截然不同的事：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e如何理解和调用工具、如何进行多步规划 （基础的agent能力）\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e如何在特定复杂任务上做出最优决策 （专家能力）\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAgentic CPT的目标就是解决这一矛盾，先将一个通用的LLM转变为Agentic Foundation Model，将更强的工具调用和推理能力内化其中。\u003c/p\u003e\n\u003cp\u003e相比之下，后一个阶段（agentic post-training）方法基本上成为共识： SFT+RL，并没有太多新的东西。\u003c/p\u003e\n\u003cp\u003e在RL的环境构建，采用了双环境的设计， 针对web-agent场景， 一个虚拟环境确实可以节约大量的时间和成本：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e模拟环境：\u003c/strong\u003e 构建一个离线的搜索和查询环境，用于快速验证算法和策略\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e真实世界环境：\u003c/strong\u003e 真实的外部API，用于训练和评估；采用5种工具（Search, Visit, Python Interpreter, Google Scholar, and File Parser）；\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"数据合成\"\u003e数据合成\u003c/h2\u003e\n\u003cp\u003e如何获得\u003cstrong\u003e大量高质量的合成数据\u003c/strong\u003e来支撑CPT、SFT和RL？\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/Tongyi%20Deep%20Research%20%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0-assets/image.png\" alt=\"image.png\"  /\u003e\n\u003c/p\u003e\n\u003ch3 id=\"webwalker--webdancer\"\u003eWebWalker \u0026amp; WebDancer\u003c/h3\u003e\n\u003cp\u003e这两个工作中对应着几个benchmark和数据集的构建：\u003cstrong\u003eWebWalkerQA 和 CRAWL QA\u003c/strong\u003e (模拟浏览) \u0026amp; \u003cstrong\u003eE2HQA\u003c/strong\u003e(由易到难)\u003c/p\u003e","title":"Tongyi Deep Research 论文笔记"},{"content":"关于濑户内艺术祭 濑户内国际艺术祭（注意！是濑户内，不是濑户内海！）自2010年首次举办，每三年一届，至今已是第五届。\n艺术祭的举办地——濑户内海诸岛，曾因泡沫经济破灭、人口老龄化、工业污染等历史问题而一度失去活力。为了振兴这些岛屿，艺术祭应运而生，通过艺术联结世界各地的访客与岛上居民，为这里重新注入生命力。它的愿景宏大而温暖：让濑户内海重现人与自然和谐共生的原始魅力，成为照亮世界的「希望之海」。“海之复权“便是濑户内艺术祭的主题。\n艺术祭的灵感，承袭自新潟县的“越后妻有大地艺术祭”这一传奇的户外艺术盛典。无论你是当代艺术爱好者、建筑迷，还是徒步旅行者，濑户内国际艺术祭都是一场不容错过的。\n地理和交通\n艺术祭的主要举办地点都是濑户内海上的一些岛屿和少部分港口城市，绝大多数位于香川县。\n季节 地区 全年 直岛、丰岛、女木岛、男木岛、小豆岛、大岛、犬岛、高松港区、宇野港区 春季 濑户大桥区 夏季 志度、津田区、引田地区 秋季 本岛、高见岛、粟岛、伊吹岛、宇多津区 对于跳岛玩的游客，高松往往是第一选择，因为有着更多的住宿选择和吃饭的选择，还有更多的旅游资源（栗林公园、金刀比罗宫等），当然最重要的是，高松有开通国内的直通航线（上海和香港），而且在日本国内的交通相对方便（飞机、JR、渡船或者巴士）；除此之外还有宇野和小豆岛也是可选择的，这里距离犬岛会比高松更近，排队坐船的人也更少。\n会期与参观建议\n艺术祭在2025年有三个会期：\n春季会期：4月18日～5月25日\n夏季会期：8月1日～8月31日\n秋季会期：10月3日～11月9日\n虽说会期外也有常设作品可看，不过在艺术祭期间能够亲身感受到艺术祭的氛围，和欣赏到期间限定的作品和区域开放，同时艺术祭专门增加的交通路线也提供了交通上的便利性。\n但实际体验下来，对于直岛和丰岛这两个绝大多数作品都是常设的岛屿，我强烈建议在艺术祭会期之外参观。这两个岛的热门美术馆均无法使用艺术祭通票，需要提前单独预约购票。会期内参观意味着可能要提前1个小时去排队买船票，甚至还可能买不到回程票。拥挤嘈杂的人潮对于艺术品欣赏的体验也是大打折扣的。\n而且，不止是要避开日本的几个黄金周，还要考虑到周边几个国家地区的假期，尽可能错峰出行。（官方也非常贴心提供了预计拥堵日期）\n艺术鉴赏护照Passport\npass 是一本集合了盖章和作品鉴赏通票的小册子，也可以选择电子版的，当然就没有集印章的功能了，不过app上不止只有pass还有交通票的购买功能。\n只要JPY 4500，便可覆盖艺术祭期间，除了直岛丰岛上几个热门馆的门票外的绝大多数美术馆，同时可以享受一次在官方商店购买周边的5%折扣，以及在几个美术馆的门票优惠（如丸龟的猪熊弦一郎美术馆，高松市立美术馆，香川县博物馆等）\n关于这次行程 这一次参加的是艺术祭的秋会期，大致的行程：\nDay1 大阪-丸龟 （宿丸龟）\nDay2 本岛，高见岛，栗岛\nDay3 宇多津，高松 （宿高松）\nDay4 直岛\nDay5 女木岛男木岛\nDay6 大岛\u0026amp;高松\nDay7 丰岛\nDay8 回程\n说实话，艺术祭是我目前为止做攻略难度最大的旅行，当然也是满满的成就感的。需要考虑的不止是简单的从哪到哪，还需要精确考虑到船的时间表，公交电车的时刻表，美术馆的休馆日等等，可谓对于J人而言也是难度满满的。\n丸龟：艺术、古城与骨付鸡 说起“丸龟”，大多数人的第一反应或许和我一样，是那家遍布各地的乌冬面连锁店。直到在旅行博主老宋的视频里，我才第一次真正了解了这座位于香川县的小城。在规划濑户内海的跳岛行程时，我被它得天独厚的地理位置所吸引——从这里出发，前往秋季限定开放的几个小岛极为便利。于是，丸龟便从地图上的一个名字，变成了我旅途中的重要落脚点。\n尽管丸龟也是濑户内国际艺术祭的一站，但它似乎更像一个宁静的中转港。大多数游客和我一样，看中的是这里直达本岛的航线，以及JR站与港口近在咫尺的便利。不过，这座小城自有其独特的魅力，比如车站旁那座为纪念画家猪熊弦一郎而建的现代美术馆，便是我此行的另一个重要目标。\n此行我从大阪出发，结束了两天的世博会之旅后，在新大阪站搭上了新干线，先到冈山，再换乘JR特急“南风号”前往丸龟。根据观察，新大阪站虽是JR西日本的地盘，但能兑换网络预订票的绿色机器（标有5489）却屈指可数，大部分反而是JR东海道的机器，初来乍到，确实需要留心，以免因此误车。\nJR West取票机；新干线车票、特急券和乘车券；\n第一次乘坐新干线，难免手忙脚乱。在冈山站换乘时，我本应将乘车券与特急券投入改札口，却错放入乘车券和新干线车票。不过好在丸龟站是个人工检票口。\n于濑户内海大桥上\n这次定的是东横Inn丸龟站前店。酒店就在JR站前，离港口也很近，艺术祭期间基本都是满房的状态。除此之外，酒店在晚上6点到8点还提供一人一碗的免费乌冬面，可谓是非常有当地特色了。\nJR丸龟站前\nMIMOCA 一出车站，浓厚的艺术气息便扑面而来。这座仅有两台两线、历史悠久的车站，门口就点缀着几件艺术装置。而一旁由建筑大师谷口吉生设计的猪熊弦一郎现代美术馆（MIMOCA），更是以其简洁的姿态展示着对于艺术的理解。\nMIMOCA\nMIMOCA的建筑本身就是一件的艺术品。于1991年开馆，为纪念与丸龟市渊源深厚的画家猪熊弦一郎而建。清水混凝土的冷静与几何线条的切割，在自然光线的调和下，营造出一种宁静而舒适的观展氛围。美术馆的常设展展出了猪熊弦一郎先生捐赠的两万余件作品，而入口处巨大的壁画《创造的广场》便足以让人驻足良久。一楼是售票处和商店，二楼是展馆和一个对外开放的阅览室，三楼则有一个Cafe和瀑布广场。\nMIMOCA\n我到访时，特展恰好是《大竹伸朗展 網膜》，同样也是本次艺术祭的参展作品。顺带一提，大竹伸朗的作品在艺术祭的多个岛屿上也清晰可见，如丰岛上的针工厂和直岛上的“Ｉ♥湯”。《網膜》系列源于废弃的宝丽来胶片，艺术家通过放大与树脂涂层处理，探讨着“时间”与“记忆”的永恒主题。而另一件装置《網膜屋／记忆滤过小屋》，则像一个由无数复古旧物拼接而成的装置艺术。\n《網膜》\n习惯了大阪世博会期间的摩肩接踵，丸龟的街头显得格外宁静。路上行人寥寥，车辆也只是偶尔驶过。这种宁静，反而让我更能沉下心来感受它的独特韵味。\n丸龟曾是日本第一的“团扇之乡”，产量一度占据全国九成。泡沫经济的破灭曾让这座小城面临挑战，但如今，它正走在一条“产业现代化”与“文旅振兴”的转型之路上。漫步街头，能看到不少城市更新项目正在进行。在一个普遍被认为发展趋于停滞的国度，这份建设的活力显得尤为难得。\n丸龟城 丸龟城\n丸龟的魅力，不止于现代艺术，更沉淀在历史的脉络中。城市的制高点，便是拥有日本现存十二天守之一的丸龟城。这座建于龟山之上的“平山城”，以其日本第一高的石垣而闻名。\n丸龟城-大手门前\n城下的观光案内所里，弥漫着一股独特的清香，想来是制作团扇的原材料气息。这里不仅售卖各式精美的团扇，似乎还提供制作体验课，不过需要提前预约。旁边的市立资料馆可以免费参观，详尽地介绍了丸龟城的历史与曾在此地留下印记的三大家族。\n见返り坂\n既然来了，总要登上城顶，一览小城全貌。进入大手门，便是著名的“见返り坂”（回望坡）。这段坡道名副其实，越往上走越是陡峭，最大斜度几乎达到三四十度。气喘吁吁地登顶后，任何人都会忍不住回头望向自己征服过的路，那一刻的成就感难以言喻。\n天守阁\n山顶的天守阁小巧而精致，是日本现存的十二座木造天守之一。内部虽已搬空，倒也对得起其400日元的门票。说来好笑，当我操着多邻国水平的日语说出“きっぷを一つください”时，卖票的老爷爷笑着着用英语问我“Where are you from?”。我心知肚明，一定是哪里说错了。后来一查才恍然大悟，“きっぷ”多指车票，门票一般用“チケット”（Ticket），量词也应该是“一枚”。\n天守阁上一览小城全貌\n骨付鸡 若说团扇是丸龟的文化名片，那“骨付鸡”（带骨烤鸡腿）便是这座城市的味觉灵魂。街头巷尾，随处可见其官方吉祥物“とり奉行骨付じゅうじゅう”的可爱身影。而要品尝最正宗的骨付鸡，就不能不提它的创始者——“一鹤”。\n官方吉祥物“とり奉行骨付じゅうじゅう”\n据说，一鹤的创始人夫妇在看一部好莱坞电影时，被女演员豪迈啃食鸡腿的场景所启发，从而创造了这道美食。我到访的便是一鹤的丸龟本店。下午五点开门，我准时抵达，门口已排起小队。\n贴心的多语言菜单\n骨付鸡分两种：老鸡（おや）和雏鸡（ひな）。老鸡肉质紧实，嚼劲十足，是绝佳的下酒菜；雏鸡则鲜嫩多汁，更适合初尝者。用盐、胡椒和大蒜等调料腌制后放入烤箱烤制，表皮焦香酥脆，内里肉汁丰盈。盘中鸡油是整道菜的精华，无论是搭配饭团还是爽口的卷心菜，都能将美味提升到新的层次。\n骨付鸡\n走在丸龟的中央商业街，艺术祭的旗帜在晚风中飘扬。然而，两旁的店铺大多已经拉下了卷帘门，显得有些冷清。或许，在网络购物与大型商场的冲击下，这样传统商店街的落寞是难以避免的宿命。我想，若不是因为艺术祭，或许不会有这么多人将目光投向这座安静的小城。但它依然在努力着，用艺术、历史和美食，向世界展示着它的魅力。\n中央商业街\n丸龟市猪熊弦一郎现代美术馆\n大竹伸朗展 網膜\n团扇制作体验课\nとり奉行骨付じゅうじゅう\n本岛、高见岛和栗岛 在濑户内海跳岛，一天两岛本已是极限挑战，但在查阅官方指南时，一条“秋会期限定”的跳岛航线（本岛-高见岛-粟岛）闯入了视线，一个更大胆的念头萌生了。奈何天公不作美，阴沉的天气和冰冷的海风，让我被迫成了时间的“奴隶”，严格跟随着船班时刻表，在岛屿间匆匆赶路。如果天气晴好，这三座风情各异的小岛，绝对值得花更多时间驻足。\n本岛 Honjima 作为盐饱水军的根据地，本岛的历史底蕴深厚。这里曾是航海技术出众的海上武装集团的大本营，如今，已是一座普通的小岛。\n清晨7点40分的渡轮从丸龟港出发，船上不少是“小虾队”的志愿者。他们来自不同国家，年龄各异，脸上洋溢的热情瞬间点燃了艺术祭首日的氛围。\nho01 Departure\n抵达本岛时刚过八点，大多数展品还未开放。我们便趁此机会，从港口漫步至北端的笠岛村。小岛万籁俱寂，路上偶遇的，除了同行的游客与志愿者，便是那些比人还多的慵懒猫咪。它们似乎才是这里真正的主人。漫步其中，竟有种昔日在香港离岛上的错觉——这或许就是小岛独有的宁静魔力吧。\n海边垂钓者\n笠岛村的艺术品，多由古民居改造而成，延续了直岛“家计划”的脉络。进屋脱鞋是常态，一双方便穿脱的鞋子在此刻显得尤为重要。\n竟在巴士站找到了19年艺术祭的作品\nho14《The World from one and only Perspective》：艺术家碾碎濑户内各岛的石头，用其天然的色彩与质地，在黑色砂纸上“绘制”出他眼中的风景。岩石粉身碎骨，却以另一种形式永存。\nho14 The World from one and only Perspective\nho12《Revolution / WorldLines》：这无疑是本岛的明星作品之一。旧屋之内，大阪城曾经的基石与不锈钢环构成了行星轨道。而真正令人拍案叫绝的，是“WorldLines”部分。艺术家巧用梁柱、榻榻米与镜面，构建出一个虚实难辨的对称世界。你完全分不清眼前的，究竟是真实，还是镜像的无限延伸。\nho12 Revolution\nho12 WorldLines\n在寻找作品的路上，我们偶遇一位老爷爷的路边咖啡摊，惊喜地发现竟是现磨手冲。爷爷还贴心地送上小饼干。\nho15附近的路边咖啡摊\n港口处所记录的当日来岛人数\n【交通攻略与TIPS】\nPasted 2025-11-05-20-43-05.xml\n从丸龟港出发是最常规的路线。航程约30分钟，在艺术祭期间会有临时加开，建议查看官网和官方的手册。港口买票仅支持现金，开船前40分钟开始售票。\n除此之外，还有从冈山，儿岛观光港出发的航线，以及艺术祭期间开通的本岛⇄ 高见岛 ⇄ 粟岛之间的高速船\n本岛比较大，艺术品分散在本岛港和北部的笠岛村两个区域，可搭乘岛上巴士在两区间移动，单程200 JPY（不支持IC卡）\n也可以在港口租借自行车\n岛上作品多是改造的古民居，需要频繁脱鞋进入，一双易穿脱的鞋子会省力很多\n展品大多9:30后开放，早到的话可以在海边逛一逛，或是坐bus环岛一圈。\n吃饭的店多集中在港口附近\n【链接】\n本岛汽船\n本岛Bus时刻表\n高见岛 Takamijima 正是因为那条艺术祭限定航线，我们才得以从本岛直接跃向高见岛。 高见岛-港口\n高见岛的“见面礼”，是连绵不绝的陡坡。全岛仅有约11位居民，房屋如阶梯般紧贴山壁而建，由不规则的乱石墙支撑，保留着最原始的岛屿风貌。这里曾因除虫菊种植而兴盛，如今繁华落尽，只剩宁静。\nta18 Merry Gates\n攀登的过程确实辛苦，但艺术品就藏在这些需要费力才能抵达的地方。\nta02《Time falls》 一个特别奇妙的作品。艺术家在老屋的墙壁上贯通了无数亚克力板，完全依赖自然光。当光线穿过切割的亚克力板，便如锐利的“光之雨”射入黑暗的室内，照亮了时间的痕迹。\nta02 Time falls\nTa22《Alien Food》：或许是听到了游客们“岛上没饭吃”的抱怨，这届艺术祭竟诞生了这样一个以“吃”为主题的作品。它用岛上的“外来入侵植物”制作料理，一份1500日元的咖喱饭。爬了半天山，饥肠辘辘，这盘咖喱饭出乎意料的好吃。策展人希望这道料理成为一个契机，让我们思考与各种“外来者”共存的方式。菜单上的那句“你在这里，是外来物种吗？”更是引人深思。\nTa22 Alien Food - I\u0026rsquo;m Alien！\nTa23《家具φ》 在半山腰的学校操场上，摆放着一系列椅子。这是BankART策展的项目，他们从高见岛与多度津收集废弃椅子，改造后摆放在小岛的各个角落，让你总能找到一个可以坐下看海的绝佳位置。\nTa23 家具φ\nTa23 家具φ\n在峰回路转处，我还发现了Ta23的另一个作品**《星屑之子》，以及在废弃民宅中创作的ta07《过去的同居》**，都与这座孤寂小岛的气质完美融合。\nTa23 星屑之子\nta07 过去的同居\n【交通攻略与TIPS】\n登岛方式除了艺术祭期间的跳岛航线外，只有从多度津出发的航线\n岛上徒步是唯一的游览方式，且多为陡坡，非常考验体力。\n没有自动贩卖机和餐厅（除艺术项目外），务必自备充足的水和干粮\n虽然不大，但因地势原因，建议安排1-2小时\n【链接】\nたどつ汽船-時刻表\n粟岛 Awashima 栗岛\n告别陡峭的高见岛，我们跳上了前往最后一站——粟岛的船。这里曾是日本第一所国立海员学校的诞生地，培育了无数航海人才。如今，艺术为这座历史悠久的小岛注入了新的活力。\n在码头挥舞旗帜欢迎游客到来的本地人\n粟岛的艺术作品大多集中，逛起来相对轻松。\naw18《Awashima, Fall》 一座拥有一百多年历史的前邮局，被改造成一个小剧院。艺术家收集岛民和游客的信息，将其转换为摩斯电码，并操控各种乐器（如风琴、鼓）自动演奏出“信息的声音”。\naw06《Contours of Thinking》 在原粟岛幼稚园内，艺术家Esther Stocker将通往中庭的隧道涂白，用弯弯曲曲的黑线构建空间。她将这里视为“成年人的幼儿园”，一个供人进行审美“游戏”的场所。这些线条象征着思想的自由发散与逃离。\naw17《Immigrating Garden Temple》 在前粟岛小学的“灯塔花园”，艺术家使用了越南植物作为迁移、生存和文化韧性的“活档案”。这些植物很多是移民跨越国界带来的，连接着散居社区的情感福祉。我们正好遇到类似话剧的彩排，虽然听不懂日语，但那种氛围很有感染力。\naw17 和偶遇彩排\n粟岛艺术家村，一处位于粟岛上的艺术家驻留项目，将岛上废弃的粟岛中学，改造为一个充满活力的艺术空间。在这里我看到了一个在山洞里画壁画的项目，洞里还摆放着人造的鲸鱼骨架，非常震撼。\n粟岛艺术家村-这里有不少的艺术家在此地创作\n幸运的是，在海边，发现了一件未在地图上标记的旧作，一个名为ツクモガミ（付丧神）的2011年栗岛艺术家驻留项目，由废弃的船只零件构成，形态诡异又充满力量，完美诠释了“付丧神”——器物历经百年获得灵魂的概念。这些被遗弃的零件，仿佛在这里获得了重生。\nツクモガミ（付丧神）\n【交通攻略与TIPS】\nPasted 2025-11-05-20-43-05 1.xml\n常规航线，从须田港出发，最近的JR站是诧间站，港口和车站间有点距离，在艺术祭期间有免费的班车，车次同船的班次；上车前一定要看清楚班车上的目的地，否则会被传送至偏远的停车场，好在司机爷爷人特别好，发现我们坐错了，还是专程把我们送到了JR站。\n如果天气好，西海岸的白沙滩是观赏夕阳和“海萤”的绝佳地点。\n【链接】\n瀬戸芸期間中の粟島へのアクセス\n栗岛-行程推荐\n[Borderless]Vietnamese Immigrating Garden . No.11\n栗岛内公交\n宇多津 今年，濑户内国际艺术祭的版图上，出现了一个崭新的名字——宇多津。它是香川这个日本最小县里，最小的町。新与旧，活力与古韵，在此奇妙地共存。一边是因濑户大桥开通而拔地而起的新街景——林立的高层公寓、大型购物中心，以及那座在海上异常醒目的158米黄金塔；另一边则是神社、旧商店构成的古街景,沉静地诉说着这里曾作为“盐之城”的过去。\n宇多津-古街\n我与宇多津的初遇，纯属偶然。目的地是四国水族馆，老实说，起初是冲着它在社交网络上的“网红”出片照而去的。水族馆本身不大，物种也算不上繁多，但其空间设计和光影美学确实堪称一绝，随手一拍都是大片，难怪能在互联网上迅速走红。\n四国水族馆\n而最大的惊喜，莫过于在水族馆里，撞上了宇多津町的艺术祭开幕式。当地的议员政要、民俗表演团体、朝气蓬勃的学生乐队齐聚一堂。虽然听不懂冗长的致辞，但空气中那份发自内心的热情与期待，是任何语言都无法阻挡的。那一刻我才意识到，艺术祭对于当地人而言，远不止是吸引游客的活动，更是一场全情投入的盛会。\n艺术祭开幕式\n本届艺术祭的作品主要分布在「临海公园」和「古街」两部分。临海公园就在水族馆边上，是看海的好去处，秋会期有免费巴士穿梭两地。这里也遗留着过去制盐业的装置，无声地诉说着宇多津作为“盐城”的繁荣历史。\nut01 Far away of colorless wings\n进入「古街」部分，体验则完全不同。一下车，志愿者便会递上一份参观地图。这不仅是向导，更像一张“通关文牒”——你需要按照路线，在指定作品处领取后续作品的鉴赏凭证，仪式感十足。\n古街的氛围令人惊喜。它并非国内那种千篇一律、复制粘贴的“新”古镇，没有相似的小吃摊和网红标语。相反，这里尽可能保留了古街的历史风貌和生活气息。宇多津本是产盐之地，艺术也与“盐”紧密结合。例如作品「ut02 Capacity」，就在一个旧米仓和鞋店中，用盐结晶复现了各式各样的日常物品，无声地回应着此地的历史。\nut02 Capacity\n所有作品中，最让我心头一震的，是st04-3《Echoes as Air Flows》。它被巧妙地拆分成两部分，安置在不同地点。一端是带屏幕的吹气装置，另一端则是摄像头与泡泡机。我最早在本岛见过它的吹气部分，当时只当是个寻常的互动装置。直到在宇多津，我才窥得全貌：在屏幕这端的人，能看到另一端访客的影像；当你对着装置吹气，另一端便会实时飘起轻盈的泡泡。\nst04-3 Echoes as Air Flows\n那一刻，我才恍然大悟，这正是作者想传达的，在疫情隔绝的时代里，人与人之间那份渴望触碰、却又无形的连接。正如作品介绍所言：\nThis series was created during the COVID-19 pandemic\u0026hellip; It reconnects our bodies to distant landscapes that extend beyond the two-dimensional screen, inviting us to reflect on the presence of intangible elements such as air and wind.\n黄金塔\n而那座多次经过、引我好奇的黄金塔，我也终究没忍住，登上一探究竟。原来它是一个展望台，更奇特的是它主打“高空水族馆”。眼前是悠然游弋的金鱼，窗外则是濑户内海风光，两种截然不同的“景”在此交汇，也是挺奇妙的。\n【交通攻略与TIPS】\n艺术祭期间有免费shuffle bus可以从JR宇多津站出发到古街和临海公园 直岛 直岛，这个名字在当代艺术爱好者的心中，几乎等同于一场朝圣。它不仅是濑户内国际艺术祭的起点，更是一个关于“重生”的传奇——一座曾因金属冶炼而遭受公害污染的工业之岛，如何蜕变为世界瞩目的现代艺术圣地。\n故事始于1917年，三菱财阀在此设立的制炼所为小岛带来了产业，也留下了创伤。直到1987年，倍乐生（Benesse）公司带着一个宏大的愿景登岛，邀请建筑大师安藤忠雄，开启了一场持续至今的艺术实验。从兼具美术馆与旅馆功能的倍乐生之家（Benesse House），到深埋于地下的地中美术馆，再到与艺术家共创的李禹焕美术馆，将废弃建筑改造而成的家计划，直岛的每寸土地，似乎都在讲述艺术如何重塑这里。\n对于旅行者而言，直岛是一场精心策划的挑战，安藤忠雄、草间弥生、詹姆斯·特瑞尔、杉本博司……这些如雷贯耳的名字，也意味着，它是攻略最难做、游客最多的地方。\n旺季的直岛，连空气都弥漫着紧张感。清晨7点20分，抵达高松港的售票点，早已错过了传说中需要6点排队的首班高速船，好在我的目标是8:12的第一班渡轮。望着眼前蜿蜒的长队，心中不免忐忑。天公不作美，下起了雨，码头贴心准备的共享雨伞。幸运的是，有惊无险登上船。\n濑户内海的海水，似乎比别处更显浓稠。提前了一个月预约的美术馆，黄金时段早已售罄， 时间回廊和家计划-Kinza 也是完全预约不上的。我手中握着一张精确到分钟的行程表：13:00的地中美术馆，16:05的家计划南寺，中间穿插着轮渡、巴士的时刻表与徒步耗时。这不像旅行，更像一场定向越野。\n船一靠岸，便冲向艺术祭的特急巴士，直奔南部的つつじ荘。这意味着，必须放弃宫浦港附近那颗标志性的草间弥生《红南瓜》，这是旅途中必然的取舍。\n黄南瓜 和Benesse House つつじ荘是南部博物馆区的东缘。下车伊始，一座矮矮的鸟居矗立在沙滩上，一半被沙粒掩埋。据说惠比須被迁至八幡神社供奉后，这座鸟居便孤伶伶地留在了这里。\n沿着海边西行，便是直岛的标志之一 草间弥生的《黄南瓜》。其静静地栖于一座延伸入海的旧码头尽头。它早已超越一件艺术品，成为直岛在社交媒体上的视觉代名词。人们排着长队与它合影，这长队本身，或许也构成了作品完整性的一部分——一种朝圣般的仪式。这颗南瓜自1994年在此矗立，见证了近三十年的潮起潮落，直到2021年被台风卷入大海。2022年，一颗外观完全一致、内部结构加固的全新南瓜回归原位。它的重生，恰如直岛自身的命运象征。\n再往西，便是Benesse House区域，其中包含了杉本博司的《时间回廊》，可惜此次未能预约，权当为下一次重访留下一个念想。\nBenesse House是直岛艺术计划的起点，由安藤忠雄设计的复合体（实际上是酒店），包含Museum、Oval、Park、Beach四栋建筑。Oval位于 Museum 之上的山顶，最为私密和独特。它需要乘坐专用单轨缆车才能到达，必须是酒店客人才可前往；而Museum实现了“住在美术馆里”的理念——住客可以在闭馆后，独自在馆内静观艺术品。\n以今日的标准看，Museum与普通的现代美术馆并无太大差别。馆内，Bruce Nauman《100 Live and Die》最具代表性。在一个圆形剧场般的空间里，100个霓虹灯管组成的短句（如 \u0026ldquo;Live and Die\u0026rdquo;, \u0026ldquo;Love and Die\u0026rdquo;）交替闪烁，不巧的是，访时装置正在维修。\n另一件深刻的作品是杉本博司的《Time Exposed》（海景系列）。这一系列黑白照片均以地平线为中心，剥夺了每一片海洋的具体身份，“海洋是人类所见的第一道景观吗？”。\nMuseum南边的还散落着诸多杰作\nWalter De Maria《見えて/見えず 知って/知れず》：两颗巨大花岗岩球体和两组镀金木雕。只有在参观过地中美术馆的《Time/Timeless/No Time》后，方能理解这件“前作”中“可见/不可见”的空间关系。\nGeorge Rickey《三枚の正方形》：三片巨大的不锈钢方块随自然风缓慢移动。位置、角度和间距会不断变化。George Rickey 以几何抽象作品和可根据气流移动的动态雕塑而闻名。\n大竹伸朗的《シップヤード·ワークス 切断された船首》 和《シップヤード·ワークス 船尾と穴》。大竹伸朗“船厂作品”系列之一，使用了废弃船只的船体部件，对其进行切割和重新组合。\nValley Gallery 2022年新开放的Valley Gallery，藏于李禹焕美术馆对面的山谷中。安藤忠雄以日本传统神社为灵感，设计了一座半开放的祠堂式建筑，让光、风、雨自由穿行。\n室内外铺满了约1700个不锈钢镜面球，这是草间弥生的《Narcissus Garden》（水仙花园）。Narcissus，既是水仙，也是希腊神话中那位爱上自己倒影的美少年纳西瑟斯。\n当游客（包括我们自己）面对这成百上千个镜面球时，第一反应就是拿出手机，寻找最佳角度，拍摄自己和倒影。这是当代社会中最直白的“纳西瑟斯”行为——我们迷恋于自己的影像，并急于将其记录和分享。\n但这件作品的巧妙之处在于，它提供的不是一个“完美”的倒影，而是上千个、细小的、破碎的“你”，当所有人都在摆着姿态拍照时，作品（镜球）就像无数双眼睛，冷酷地反射着这种“迷恋外表”的集体行为。它用一种极其直白的方式，将我们的“自恋”放大并抛回给我们自己。\n但同时，它也通过“破碎”和“扭曲”的影像，打破了纳西瑟斯那“单一而完美的倒影”。它似乎在迫使我们思考：当“自我”被无限复制和肢解后，那个真实的“内心”又在哪里？\n草间弥生在1966年威尼斯双年展上首次展出此作时，打出的标语是“你的自恋正在出售”。\n与之并置的，是小沢刚的 《スラグブッダ88 ─豊島の産業廃棄物処理後のスラグで作られた88体の仏》\n(Slag Buddha 88 - 用丰岛产业废弃物处理后的炉渣制作的88尊佛像) 用隔壁丰岛非法倾倒的工业废弃物，在直岛处理后产生的炉渣制成，无声地连接了两座岛屿的过去，也象征“重生”的隐喻。\n李禹焕美术馆 李禹焕美术馆（馆内不可拍照），是艺术家李禹焕与安藤忠雄共同合作的结晶。安藤再次将建筑的半“埋”入地下，为“物派”艺术提供了完美的“场”。\n李禹焕是战后日本“物派”（Mono-ha）的核心理论家。这场运动反对“创作”，提倡“呈现”。这种回归物质本源的思考，无疑是对现代性的一次深刻反思。\n踏入了美术馆入口前那片名为照応の広場，陈列着几组大型雕塑，関係項系列作品，主角是未经雕琢的巨石和各种形状的钢，坚毅与可塑，自然与人造，原始与现代……无数对比关系在脑中浮现。李禹焕的作品，展现的从来不是单一的“事物”，而是事物之间那看不见却能被感知到的“关系”，或许是一种深刻的东方哲学思辨。\n地中美术馆 地中美术馆，是直岛的灵魂所在。为了保护濑户内海国立公园的自然景观，安藤忠雄将整座建筑几乎完全埋入地下，只留下几个简洁的几何天窗\n我在秋元雄史的《出界！艺术直岛》一书中读到，地中美术馆的缘起，是福武总一郎先生铁了心要在直岛展出莫奈。策展团队的挑战是，要“找出莫奈不同于以往的意义”，并让它与Walter De Maria、James Turrell的作品产生共鸣。\n“玛利亚与特瑞尔也在用超越个人生死、如宇宙般的视角来审视这个世界。莫奈也有同样的普遍世界观。他通过睡莲这种日常的风景眺望远方的彼岸……他想要超越战争这种人类愚蠢的行为，描绘时间永恒循环的世界。”\n这个共同的疑问是：“世界究竟是个怎样的地方？”\n于是，有了这座由艺术、建筑和自然三者完美融合的“巨型作品”。馆内没有任何人工照明，所有艺术品都完全依赖从安藤设计的几何天窗中倾泻而入的自然光。\n莫奈厅展出了5幅大型莫奈晚年的《睡莲》，纵使我对印象派风格无感，步入纯白的房间时，只有“哇！” 。地面是约70万个光滑的白色大理石块，自然光从天花板的柔光罩中均匀洒下。\nJames Turrell 厅，从早期作品《Afrum, Pale Blue》投射出的蓝色光立方体，到《Open Field》中引领你“走入”一片光幕的奇妙体验，再到《Open Sky》——安藤忠雄在天花板上开了一个巨大的正方形洞口，天空本身，就是一幅实时变化的画作。不愧是以光为媒介的艺术家。\nWalter De Maria厅，在一个如同神殿一般的空间中，放置着一颗直径2.2米的巨大黑色花岗岩球体。阶梯两侧，排列着27根镀金的几何木雕\nPhoto from benesse-artsite\n所以，“世界究竟是个怎样的地方？”，我依旧无法回答，但完全被震撼到了，无以言表。这种震撼，超越了单纯对“美”的欣赏，它是一种近乎“神性”的体验。\n直岛新美术馆 从南部的地中美术馆区域离开，我前往东北岸的本村地区。这里不仅有家计划，也迎来了直岛最新的艺术地标。\n直岛新美术馆无疑是今年直岛最受瞩目的焦点，于5月31日开幕，位于本村地区南边的一处高地上。\n这是安藤忠雄在直岛为Benesse Art Site设计的第10座建筑。一如既往，建筑采用了地上1层、地下2层的谦逊结构，将主体“藏”于地下。\n新美术馆的核心策展理念是“聚焦亚洲”，开馆纪念展「原点から未来へ」展出了12组来自日本及亚洲各国的艺术家的作品。\n（近期风评不太好）蔡国强的《撞墙》，99只形态逼真的狼排成队，义无反顾地集体撞向一面与“柏林墙”等高的透明玻璃墙。\n另一件焦点作品来自村上隆。这是一件宽度达13米的巨幅画作，重新诠释了日本国宝——17世纪画家岩佐又兵卫的《洛中洛外图屛风》，并将DOB君和Kiki等标志性卡通角色，融入到江户时代的京都风情的画中。\n家计划 家计划是直岛从一个“拥有美术馆的岛”转变为“整个岛屿就是一座美术馆”的关键转折点。\n90年代同日本许多乡镇一样，本村面临着严重的人口外流、空心化问题，大量住宅被废弃，失去活力。\n在初期直岛的艺术活动主要集中在岛屿南端的 Benesse House 区域。如果艺术只停留在高高在上的美术馆里，就无法与当地的真实生活产生联系。“家计划”的理念不是拆除老屋、建造新馆，而是活用这些见证了岛屿历史的空屋，根据房屋本身的历史，重建改造，让老屋获得重生。\n角屋（Kadoya）。家计划的第一个项目。展出的是宮島達男的《Sea of Time \u0026lsquo;98》。在约200年历史的老屋中，打造了一个浅水池，125个LED数字计数器在水中从1到9不断闪烁。计数器的速度是又村民们参与设定的。\nPhoto: Ken\u0026rsquo;ichi Suzuki\n碁会所（Gokaisho）：过去岛民下围棋的场所。榻榻米上散落着几朵山茶花。若非提前了解，很难发现这竟是须田悦弘的超写实木雕。\nPhoto: Osamu Watanabe\n護王神社。杉本博司对一座江户时代神社的重建。通往主殿的阶梯被替换成了晶莹剔透的光学玻璃块。地下还有一个石室（这才是重点），可惜排队的人太多，而我预约的南寺时间将至，只好放弃。\n家计划-南寺 （Minamidera）\n这是安藤忠雄在原址上新建的建筑，展示的是James Turrell的《Backside of the Moon》\n进入建筑前，所有人被要求关闭手机、智能手表等一切发光设备。在引导下进入一个全黑的建筑，在绝对的黑暗中摸索着坐下。漫长的10多分钟过去，眼睛逐渐适应了黑暗，一个极其微弱的长方形“屏幕”慢慢在房间尽头浮现。而这个屏幕居然是 ___（此处不剧透了，这是一个需要亲身体验的作品）\nBackside of the Moon, 在Turrell的语境中，指的是人由月球背面走向正面。月球本不发光，其实也并无正反面之分，只有在习惯了。或许在平日习惯了光之后，只有完全适应了寂静和黑暗之后，才能感受到真正到“光”，才会被光所解放，体会那一片漆黑到看到光亮的变化全过程。\n由于南寺的预约是最后一轮，结束时已无可能赶上返回高松的船。索性在本村闲逛一会，从本村港搭船前往对岸的宇野，再做JR回到高松。在JR上，读完了那本《出界！艺术直岛》，一段特别有感触的文字：\n人们开始寻回过去的历史与记忆，原本枯燥乏味的城镇也呈现出全新的面貌。这种改变并不像书页中记载的那种单纯的乡土史，它是在人们实际居住的城镇中，以生活所拥有的“深度”呈现出来的。不知不觉中，大家渐渐产生了这样一种意识：我们并不是在单纯地打造艺术作品，我们是在打造城镇的“当下”，同时重拾与过去的联系。原本闭门不出的岛民重新走上街头，聊起尘封已久的过去。这个变化与他们诉说的一切都反馈在了城镇的面貌中，充满了生命力。\n【行前核心提示】\n周一公休，若周一是日本法定节假日，则会改成周二休息。不要跑空。\n无论是购买船票还是搭乘岛上巴士，都强烈建议准备充足的现金\n地中美术馆等热门场馆必须在官网提前至少一个月预约购票，艺术祭通票（Pass）不包含这些场馆\n旺季（尤其是艺术祭期间）人流量巨大，无论是乘船还是参观，请务必预留至少1小时的排队时间\n直岛绝大多数艺术作品为常设展。如果想获得更宁静、深入的艺术体验，强烈推荐在非艺术祭的淡季前往\n直岛概况\n直岛有两个港口，分别是宫浦港和本村港。\n所有的艺术作品主要分布在三个大的区域：宫浦港、南部的倍乐生之家和东边的本村。想要在一天之内看完所有作品难度很大且没有必要，可以用1-2天时间或考虑在岛上住一晚。\n如何前往直岛\n高松港 → 直岛 (宫浦港) 这是最主流的路线，分为两种船型，售票处和乘船处均不相同。\n（如图中的4和5对应Ferry和高速船的买票点）\n**Ferry：**船体大，舱位多，可装载自行车和大型行李，旺季时相对更容易买到票。可购买往返票\n高速船： 船小，仅能容纳约80人，旺季时极有可能满员无法登船。只出售单程票\n四国汽船时刻表\n提醒：\n购票队伍与登船队伍是分开的。买到票不等于能上船，旺季时请务必提前到码头排队等候登船，即使持有返程票也需如此。\n船票只能使用现金购买\n船票无法提前预订，均为当日现场购买，且仅限当日有效\n宇野港 → 直岛\n**宇野港 → 宫浦港 ：**据说人会比高松少。\n宇野港 → 本村港：只有高速船，上船时购票\n跳岛航线\n**高松港 → 直岛(本村港) → 丰岛(家浦港) ：**此航线为高速船，大部分乘客目的地是丰岛。排队时，工作人员会询问目的地，前往直岛的乘客可能会被允许优先登船。\n丰岛渡轮时刻表\n其他航线\n直岛(宫浦) ↔ 丰岛(家浦) ↔ 犬岛\n小豆岛(土庄) ↔ 直岛(宫浦)\n艺术祭期间新增\n直岛内部交通\n1. 巴士\n岛上巴士是连接各区域最便捷的方式。\n支付方式：不能使用IC卡，需使用现金或信用卡。\n巴士类型：\n直岛町营巴士：常规公交（不要坐成町民専用bus）\nBenesse Art Site 免费接驳车：仅在“つつじ荘 (Tsutsuji-so)”和“地中美术馆”之间运行。\n官方艺术祭特急巴士：仅在艺术祭期间运行。\n2. 自行车\n宫浦港和本村港均可租赁自行车（含电动助力车）。旺季时非常抢手，建议乘坐早班船上岛租赁，或提前在网上预约。\n艺术场馆与作品\n1. 预约与购票\n需独立预约：以下热门场馆不包含在艺术祭通票内，必须通过Benesse Art Site官网预约购票，建议提前一个月以上操作：\n[na21-B] 地中美术馆 （Chichu Art Museum）\n[na13-B] 家计划-南寺 (Minamidera)\n[na17-B] 家计划-Kinza （周一至周三休息，每次只允许一个人进入，限时15分钟，预约难度非常大）\n[na24-B] 杉本博司 时间回廊\n[na26-2-B] Ring of Fire - Solar Yang \u0026amp; Lunar Weerasethakul Lunar (Night)\n[na05-B] Naoshima Bath \u0026ldquo;I♥湯\u0026rdquo;\n其余作品均包含在艺术祭Pass中\n非艺术祭期间，也可购买家计划套票（不包含Kinza和南寺）\n需要注意展馆的开放时间（部分展馆有午休如Ando Museum）\n参观提示 Benesse Art Site 区域内禁止骑自行车进入，需将车停在指定区域后步行或换乘免费接驳车\n请严格遵守各场馆的拍照规定，通常在入口处有明确标识\n地中美术馆：进入礼品店后的所有区域严禁拍照。\n李禹焕美术馆：室内区域禁止拍照。\nBenesse House Museum 及 直岛新美术馆：大部分区域可拍照，但个别展品旁会设有禁止拍照的标志。\n家计划的南寺是体验型作品，需要将智能设备关机，保持安静\n餐饮与其他设施\nBenesse House 区域，目测几乎没有自动贩卖机，但巴士站附近通常有免费饮水机，而本村区域有自动贩卖机。\n岛上餐厅选择不少，但旺季时排队时间极长，为了避免影响行程，需要提前规划。\n收藏的几个店\n店名 网站/链接 大致位置 菜单/描述 直島カフェコンニチハ (Naoshima Cafe Konnichiwa) \u0026lt;https://konichiwa.jp/menu\u0026gt; 本村港 咖啡、饮料、咖喱、轻食 Benesse House Museum cafe \u0026lt;https://benesse-artsite.jp/stay/benessehouse/restaurant.html#museum-cafe\u0026gt; Benesse House Museum 意式料理、轻食 地中美術館 cafe \u0026lt;https://benesse-artsite.jp/art/chichu_cafe_01Apr2025.pdf\u0026gt; 地中美术馆里（参观者only） 西式轻食为主 Cafe Salon Naka-Oku \u0026lt;https://cafesalon-naka-oku.jimdofree.com/%E3%83%95%E3%83%BC%E3%83%89/\u0026gt; 本村 日式与西式料理 玄米心食 あいすなお \u0026lt;http://aisunao.jp/restraunt-aisunao.html\u0026gt; 本村 日式定食 Luke’s Pizza \u0026amp; Grill \u0026lt;https://lukes-pizza-and-grill.com/\u0026gt; 本村 Pizza 直島ヌードル (Naoshima Noodles) \u0026lt;https://www.instagram.com/naoshima.noodles\u0026gt; 宫浦港 日式拉面 男木岛、女木岛 女木岛与男木岛是濑户内海上相邻的两座小岛，因航线便利，常被安排在同一天游览。“雌雄岛”，更因各自的传说与特色，被称为“鬼岛”与“猫岛”。这两个小岛不仅是濑户内国际艺术祭期间全年开放的展区，在非艺术祭时段，虽作品数量略减，却仍值得一访。\n从高松港出发，乘船约30分钟即可抵达女木岛——通常作为跳岛的第一站。选择先到女木岛，不仅因为距离更近，还有一个过来人的小贴士：旺季时，回程的末班船从男木岛始发，那里因“猫”而聚集了超高人气，若从女木岛上船，可能会面临没有座位的窘境。\n踏上码头，最先迎接我们的并非鬼怪，而是一件名为**《海鸥的停车场》（mg01）**的艺术品。近三百只海鸥雕塑整齐地排列在防波堤上，面朝大海，随着海风吹拂，随时会变换方向。\n岛上的“鬼”元素无处不在，最著名的莫过于山顶的**“鬼之岛大洞窟”**。传说这里是桃太郎讨伐的恶鬼所居住的巢穴。然而，褪去神话的外衣，它其实是古代的采石场遗迹，在近代被赋予传说色彩，成功转型为观光胜地。\nmg26 KONBO-YA\n2022年展出的《棍棒屋》，以传说中鬼使用的武器“棍棒”为意象，象征驱邪护岛。改建后的建筑左侧设有立像，其面部以抛光铜镜制成，能反射光线，在墙上投射出神秘图案。在日本文化中，“鬼”（Oni）并非纯粹的邪恶，更像是一种超越善恶的强大精神存在。棍棒作为当地保护神所持的法器，也延续了守护的象征意义。\nmg34 Colour Reading and Contexture\n艺术家Jacob Dahlgren将日常物品重新置于艺术语境中，回应20世纪抽象艺术被商业“驯化”的现象。他与当地居民合作，收集旧书籍、瓷砖、木箱等方形材料，按颜色分类堆叠，形成一片如城市景观的装置。观众需走动观赏，远看是色彩海洋，近观则能感受材质与细节的丰富。\nmg15-B 不在の存在\n阿根廷艺术家Leandro Erlich总能用最简单的元素创造出最不可思议的幻境。这栋看似普通的日式老屋里，藏着两个令人拍案叫绝的作品。\n《Invisible》，庭院里空无一人，耳边却传来“沙…沙…”的轻响，只见白石上凭空浮现出一串脚印，仿佛一位隐形的访客正在其中漫步；\n《Double Tea》茶室的墙壁是一面巨大的“镜子”，但你走近时，却发现镜中没有自己的倒影。原来，那并非镜子，而是一个通往另一个镜像对称房间的开口。\nmg35 Magnetic Fields\n已废校的女木小学。这座曾经承载着全岛希望的建筑，因人口外移和少子化在2005年关闭，如今却在艺术的浇灌下，焕发出新的生命力。\n（from setouchi-artfest）\n于女木小学展出的《Magnetic Fields》，是Christiaan Bastiaans“迁徙三部曲”的终章。前两部关注老龄化与疾病隔离，本作则聚焦移民议题。声音艺术家Roosmarijn Pallandt以录音与空间声场，讲述新居民如何在此扎根、重建生活。\nmg13-B 女根 / MECON\n同在女木小学的作品。在女木小学的校园空地上，散落着大竹伸朗标志性的混搭风格作品，马赛克拼贴、鳄鱼雕塑、造船木材，以及围绕热带椰子树盘绕的装置。“女”取自女木岛，“根”既指岛上虬结的树根，也隐喻岛屿生生不息的生命力。\nLittle Shops on the Island\n（島の小さなお店） 是一个温柔的艺术项目。面对离岛普遍的老龄化与空心化，艺术家们将废弃商铺改造成微型艺术空间，重现昔日杂货店、理发店、邮局的样貌。\nmg08 乒乓海\n由原倫太郎与原游打造的乒乓球乐园，色彩缤纷的异形球台，可以花100日元付费打球体验。\nmg09 Laundry\n同样是Leandro Erlich的作品，他将真实的洗衣机与播放着衣物旋转影像的装置并置。\n（from setouchi-artfest）\nmg28 Mekochan: Old School Bookstore\n绘本作家阿部健太朗与吉冈纱希将空屋变为奇幻书店，主角是他们虚构的“岛上最后一名小学生”——Mekochan。\n告别女木岛，只需二十分钟的船程，便可抵达截然不同的男木岛。\n登岛即见艺术家Jaume Plensa创作的《男木岛之魂》，实为男木交流馆，也是游客中心和渡轮售票处。建筑屋顶以贝壳为灵感，由八种语言文字镂空构成的屋顶，在阳光下投下斑驳的光影，迎接着每一位来客。\n男木岛的魅力，一半在于艺术，另一半则在于猫和它那迷宫般的山城景致。这里的房屋依山而建，层层叠叠，狭窄的坡道在屋舍间蜿蜒穿行，一不小心就会迷失方向。而就在这些石阶、墙角、屋檐下，随处可见慵懒的猫咪。它们才是岛上真正的主人，或酣睡，或理毛，或用好奇的眼神打量着我们这些闯入者。据说，它们是旧时渔民为防鼠患而饲养的猫的后代，如今已成为小岛最治愈的风景线。\n《我们的岛屿》（og23）\n位于“老人憩之家”的纺织雕刻，以传统织物与回收布料拼出男木岛形状，保留日常生活的温度。\n沿岛南海岸线前行，可见《og16 步行方舟》。这件作品以蓝白两色构成，造型独特，宛如一只长着四对细足、即将启航的方舟，灵感源自《圣经》中的诺亚方舟。其视觉冲击力强烈，成为岛上热门的拍照打卡点。\n方舟的“脚”朝向东北方——正是2011年东日本大地震灾区的方向，象征着迈向灾区、祈愿平息与重生的寄托。\n沿山路向上，在半山腰可见由建筑师坂茂设计的《Ogijima Pavilion》 （og18）。坂茂以“纸管建筑”闻名，这座展馆的梁柱结构亦由纸管构成，坐落于村落坡地，拥有大片玻璃窗。艺术家大岩奥斯卡更在玻璃上直接作画，使建筑本身成为一件内外皆可欣赏的艺术品。\n再往高处走，便抵达男木岛的主要神社——豊玉姫神社。神社位于村落制高点，需攀爬一段长而陡峭的石阶方能抵达。登顶回望，整个男木岛村落层叠的屋顶、港口与远处的濑户内海尽收眼底。作为岛的守护神社，豊玉姫神社自古便是岛民的信仰中心，主祭神丰玉姬命是日本神话中海神之女，传统上被视为安产与育儿的守护神。\n（from setouchi-artfest）\n《og08 Akinorium》是艺术家松本秋则在一栋古民居中打造的声音装置空间。其名“Akinorium”取自艺术家之名“Akinori”与意为“场所”的后缀“-rium”。在幽暗的室内，他以竹等自然材料制成精巧的自动发声装置，在微风或微动力驱动下轻轻摇曳，发出清脆自然的声响。同时，灯光将这些装置的影子投射于墙壁与天花板。\n（from setouchi-artfest）\n而在《og15 部屋の中の部屋》中，日裔巴西艺术家大岩奥斯卡则在一间六叠榻榻米的和室中玩转视觉游戏。榻榻米地板、茶几上的两杯茶、纸门上的华丽绘画、墙上的卷轴——一切都被旋转了90度，令观者瞬间陷入空间错置的错愕。\n旺季里，岛上的猫咪们似乎也被热情的游客“撸”得有些疲惫，各自寻了安静的角落打盹。船缓缓离岸，回头望去，岸上的村民和志愿者们正用力地挥舞着旗帜，向我们挥手告别。那一刻，海风拂面，心中涌起一股暖流。\n【交通攻略与TIPS】\n时刻表（from 雌雄岛海运）\n夏季女木岛有大量加开班次\n女木岛的作品基本上分布在港口和鬼岛大洞穴\n女木岛艺术祭期间有港口至大洞穴的班车\n男木岛坡度比较大，建议徒步\n大岛 名为“大岛”，实则是一座极小的岛屿，位于高松港东北约八公里的海面上。但它承载的历史却无比沉重，重到足以让每一个踏上它的人都感到窒息。\n大岛青松园，是日本十三所国立麻风病疗养所之一。在《麻风预防法》于1996年废除前的近九十年间，无数入所者被强制隔离于此，与世隔绝。\n正如福武总一郎在《艺术唤醒乡土》所说的：“我们并非只让人看到美好的一面。”大岛，便是那不容回避的、沉痛的另一面。\n登岛的航程，本身就是一场无声的隐喻。船上要求佩戴口罩、消毒双手、禁止喧哗，一切安静得近乎压抑。船窗高悬，视线被牢牢锁在天空之上——无法望见海，也无法望见岸。这种设计，或许正是对当年被秘密运送至此的患者的隐喻：他们被社会“看不见”，也“不该被看见”。\n踏上岛屿，喇叭中循环播放着两首曲子：《少女的祈祷》与《故乡》。这两首曲子，本应是温柔与慰藉的象征，但在得知历史后，音乐在此刻却显得格外悲凉。它们是为弱视的病人引路而设。同样的还有道路中央绘有醒目的白线。\n岛上的自由活动区域不大。小虾队志愿者会在固定时间于纳骨堂前集合，为访客讲述岛上的历史，备有中英文介绍册，语言并不是问题。\n火葬场曾遍布全国疗养所，如今仍在使用的，仅余大岛青松园。过去，火化工作由患者承担，以薪柴为燃料。火葬场上矗立着纪念碑《风之舞》，近千名志愿者共同堆砌石块建成。\n设计者桥本浩幸以“天上”象征无限宇宙，“天下”代表地球万物，意在营造一个让人感受自然、回归生命根源的场所。它慰藉那些离乡背井、在此终结生命的人，愿他们的灵魂随风解脱，因而得名。\n纳骨堂初建于1911年，1936年扩建为仿莲台的八角形建筑。旧堂因空间不足被拆除，2003年新建的半球形纳骨堂继承了“莲华藏”之名。\n然而，并非压抑，而是愤怒。是那座为“未能诞生的胎儿”设立的镇魂碑。当年，患者虽可通婚，却被严禁生育。怀孕的女性被迫接受流产手术。\n更显屈辱的，是那座曾被推入大海的解剖台。根据旧法，入院初期的患者会被要求签署解剖同意书，死后必须接受解剖。1996年法律废除时，人们愤怒地将它抛入海中。如今，它被重新打捞展出，混凝土台面上仍附着藤壶，与这段沉重的历史一同示众。\n山川冬樹的两个作品《歩みきたて》与《海峡の蔦》\n构成一组双重路径：一者以文本与遗物回溯生命，一者以肉身丈量历史。它们共同挖掘大岛的地层记忆，让沉默者发声。\nOS06《歩みきたて》聚焦于歌人政石蒙。他的一生颠沛流离，在蒙古被诊断患病后，于大岛度过余生。展览通过他的遗物、歌集与笔记，呈现了一个被制度压迫的个体，如何用诗歌进行生命的抗争。\nOS07《海峡の蔦》则以身体为媒介，艺术家在四国与大岛间的海峡中感知风与海流，用行动探讨“隔离”与“连接”。这两件作品，如同一枚硬币的两面，从微观的个体叙事和宏观的空间隐喻，共同重构了这段被边缘化的历史。\nos03《「Nさんの人生·大島七十年」－木製便器の部屋－》\n艺术家田岛征三根据疗养者“N先生”的真实经历创作。一间间房间传出的呐喊：与家人的分别、强制劳动、服药消毒、结婚与堕胎……他们不被允许告别，不被平等对待，不被允许拥有正常的家庭——只因为他们是病人。\n站在这压抑的空间里，一段尘封的记忆猛然向我袭来。那被封控的三年，那种与世隔绝的无力与无奈，那地狱般的感受，竟在此刻与N先生的七十年人生发生了短暂而剧烈的共鸣。我或许永远无法真正“感同身受”，但那一瞬间，我似乎理解了。相同的悲剧，在不同的时空，以不同的形式，从未停止上演。\n光田健辅医师一生致力于消灭麻风病，被誉为“救癩之父”。然而，错误的政策对患者造成的伤害，使他在病人眼中，又成了怎样的存在？\n光田先生站在强权（当权者和制药公司）以及大多数人（持有偏 见的人）地就哭：成了他们的盟友，成了“了不起的人”\n然而，我又是否可以批判他呢？\n在同一片国土，我和N先生度过了同样的70年，但我却对他的遭遇浑然不知。\n甚至从未试图去知晓\n对N先生，我一直是有罪的。\n──田島征三《「Nさんの人生·大島七十年」－木製便器の部屋－》\n在岛屿北部的山上，有一条由年轻患者们亲手开辟的“相爱之道”。多年荒废后，在日本艺术家鸿池朋子的艺术项目“Ringwanderung”支持下重见天日。\n“Ringwanderung”在德语中意为“循环游走”——指人在暴风雪或浓雾中迷失方向，无意识地绕圈行走，最终力竭倒下。\n走在这条名为“相爱之道”的环路上，人只能不断加快脚步，试图逃离这无尽的循环——仿佛亲身体验了患者当年的噩梦：被困于制度之圈，唯一能做的，只有不断向前。\n在岛上的Café SHIYORU，可以稍作喘息。这个由居民和志愿者共同运营的空间，既是咖啡馆，也是展览馆。鸿池朋子通过桌布刺绣与手偶，讲述着大岛居民的故事。\n后来我才知道，麻风病隔离政策并非日本独有。历史的悲剧具有惊人的相似性。\n如今，大岛的黑暗时代已经过去。在濑户内国际艺术节的推动下，它不再是一座被遗忘的悲伤孤岛。它提醒着我们，去正视那些“不美好的一面”，去记住那些被强权和偏见碾压过的生命。因为遗忘，才是对他们最残忍的二次伤害。\n【交通攻略与TIPS】\n艺术祭期间大岛有免费船可乘坐，在非艺术祭期间，仅在每月第二周的周六和周日对外开放 上船时需要做手部消毒，在船上需要佩戴口罩，避免交谈\n相爱之道全程走下来需要20多分钟，非常耗体力，几乎就是野路，需要注意安全和头顶的蜘蛛网\n禁止进入住民生活区\n小虾队在艺术祭期间会在10:30、12:00、14:50会组织讲解（约半小时），在纳骨堂集合\n没有可提供餐食的店铺，需自备食物\nCafé SHIYORU 仅在周六日和节假日的11:00-15:00营业\n岛上只有一台自动售货机\n高松 在乡间游荡多日后，当JR列车缓缓驶入高松站，一种“终于进城了”的熟悉与新奇感扑面而来。高松，作为香川县的首府和通往濑户内海诸岛的母港，它的重要性不言而喻。\n搭上古朴的琴电，从高松筑港前往市中心，首个目标是高松市立美术馆。正值艺术祭期间，凭Pass能享受门票折扣，美术馆大厅里悠扬的巴赫乐曲。\n由于恰逢艺术祭秋会期与中秋假期，热门的跳岛酒店早已一房难求。出于好奇与性价比的考量，我选择了一家位于城东町的情侣酒店。最初的疑虑，在推开房门的那一刻烟消云散——宽敞的空间、奢侈的浴缸和精致的早餐，性价比远超预期，同样的价格在商务酒店只能住到标准房间。\n唯一的小困扰，是每天需步行约一公里从港口返回住处。途中必定经过西日本最大的红灯区，除了醒目耀眼的霓虹招牌外，其实并无任何令人不适的景象。街上人迹稀少，偶尔可见保安身影，一切安静得出奇。\n高松港边矗立着全市最高建筑——高松地标塔。29层设有免费对外开放的观景台，可俯瞰整座城市与濑户内海的交界风光。\n香川县立博物馆的常设展内容不算多，当时特展是小沢剛的《讃岐七不可思议》，展出七样当地奇特风物。坦白说，由于对当地历史文化了解有限，看展时我有些似懂非懂。但最后一处“不可思议”却着实令人惊喜——根据提示，按图索骥找到博物馆外一个隐藏地点，竟在隔壁建筑的地下室里，发现了一段古城墙遗迹。或许，这栋建筑正是建于这段遗址之上吧。\n几次路过玉藻公园，却始终未曾入园一探。这里其实是高松城的遗址，相关历史在县立博物馆也有展示。高松城又名“玉藻城”，是日本三大“水城”之一，面海而建，引海水入护城河，在全国亦属罕见。只可惜，城堡的天守阁早已不复存在。\n艺术祭期间，高松展出的作品遍布城市角落。港口附近散布着几件装置，稍加探索，转个弯就可能与艺术不期而遇。就连在机场，登机前都还能发现一件作品——这趟旅程，始终充满了这样的惊喜。\n【高松跳岛食堂】\n以下收录了一些在高松吃过的餐厅\n兰丸 本店\n7-4 Daikumachi, Takamatsu, Kagawa\n（有中英文菜单，排队需要在门口小册子上登记名字）\n（与一鹤相比，兰丸的骨付鸡烤的更嫩）\nめりけんや 高松駅前店\n6-20 Nishinomarucho, Takamatsu, Kagawa\n在JR站前的乌冬面店，个人非常喜欢的\n徳島ラーメン麺王 高松駅前店\n高松ステーションホテル, 1F, 1-chome-1 Kotobukicho, Takamatsu, Kagawa\n德岛系拉面，打入一个生鸡蛋后，更显独特的风格\n【高松Tips】\n国内有直达高松的直航航班（上海和香港）\n如果主打跳岛，建议住在高松港附近，如JR克莱门特高松酒店 和JR克莱门特INN，下楼直达港口\n市中心瓦町挺繁华的，也有不少住宿和吃饭选择\n高松空港有到高松站的机场大巴，通过自动贩卖机购票或使用IC卡\n高松空港比较小，建议在安检前购物，安检完可购买的东西很少\n丰岛 丰岛，坐落于直岛与小豆岛之间，面积仅14.5平方公里，人口约七百。虽小巧，却是濑户内艺术岛屿中，仅次于直岛的热门目的地。\n然而，这座如今充满艺术气息的岛屿，曾有一段不堪回首的过往。自1975年起，丰岛长期遭受非法工业废弃物倾倒，成为“垃圾之岛”。“丰岛事件”震惊日本，也唤醒了岛民与地方政府。历经近五十年的清理与再生，丰岛终于洗去污名。\n与直岛相比，丰岛在艺术与自然的融合上，似乎更显和谐。直岛南部Benesse House 区域强烈的现代艺术风格与本村古老村落形成鲜明对比，那是Benesse集团早期探索留下的痕迹——如何在现代艺术、建筑与在地人文历史之间取得平衡，从来不是易事。而丰岛，作为稍晚开发的艺术岛屿，在我看来，更成功地调和了二者关系，呈现出一种浑然天成的美感，不见丝毫突兀。\n“丰岛的美，不在于打卡式的艺术巡礼，而在于静心感受”，在之前一起跳岛的G同学曾这么告诉我。带着这样的期待，我踏上了这次艺术祭的最后一站——丰岛，也在这里，留下了最美好的回忆。\n提前一小时到码头排队，原计划搭乘九点的船，最终只买到九点半的票。排队时发放整理券，凭券购票。适逢中台港与韩国的中秋连假，说中文与韩语的游客似乎比本地人还多。高松至丰岛仅有快船，更添几分拥挤。\n阴沉的天空仿佛随时要落雨，不料船驶出港口不久，天竟放晴。\n家浦港小巧而宁静，从港口规模便能感受到丰岛的迷你。然而岛虽小，却不宜徒步——起伏的山路、蜿蜒的坡道，以及散落各处的艺术作品，都让人不得不依赖巴士。\n丰岛的作品主要分布在家浦港、唐柜港、唐柜岡与甲生四个区域。于是规划了这样的路线：家浦 → 甲生 → 家浦 → 唐柜，以避开人潮。\n甲生 甲生位于丰岛南端，将其作为第一站，既为错峰，也因这里的几件室外作品24小时开放。\nte23 线的记忆\n步入废弃的民宅，瞬间就被一片血红色的丝网所吞噬。盐田千春标志性的红线，在这里象征这座岛屿记忆的血管，连接着那些被遗忘的旧物——三台锈迹斑斑的挂面机。它们曾是岛民生活的依靠，如今却静默无声。\n盐田千春曾问村民：“什么是你们不再需要，却又舍不得丢弃的东西？”答案就是这些机器。红线缠绕其上，织成一张巨大的、无法挣脱的网，既是记忆的封存，也是情感的羁绊。\nte19 海の夢を見る人々のための場所 （Place for sea dreamers）\n作为这一届艺术祭官方指南的封面，这里自然成了必访之地。一个铸铁长凳静卧在海滩上，形态既像独木舟，又似渔网。\n在艺术祭匆忙的行程中，这个作品显得格外温柔。它不强迫你思考，只是提供一个“场所”。\n依言坐下，眼前是无垠的濑户内海。那一刻，我不再是追逐艺术品的游客，而只是一个观海者。风吹过耳畔，浪花拍打沙滩，时间仿佛在这里放慢了脚步。这件作品最深刻的意义，或许就是让我们从“观看”艺术，回归到“感受”本身。\nte22 国境を越えて·祈り (Beyond the Border - Prayer)\n这是林舜龙“超越国境”系列的延续，2016年于小豆岛启程的“孩子们”在此刻“回归”。\n197个代表世界各国的孩童雕像，面朝各自祖国的首都方向，双手合十，在海风中为世界的和平与幸福默默祈祷。每个孩子的背上标注着对应国家首都的经纬度坐标，而正面胸前写着距离。\n世界には希望があり、この地球は美しいと言じているからです。\n家浦 te03-B 针工厂\n艺术家大竹伸朗将一座废弃的织针工厂与一艘从未下水的渔船木模巧妙融合。依旧是大竹伸朗擅长的拼接手法。\n走进工厂，首先冲击感官的是那具倒置的巨大船体，更像是一头巨鲸的遗骸，充满了悲剧性的力量感。工厂的墙壁被拆除，裸露的钢筋结构让空间显得更加原始。\n这件作品的核心在于“错位”与“重生”。本应在海上的船，被囚禁于陆地的工厂；本应生产细小织针的地方，却容纳了如此庞然大物。两个被时代抛弃的物件，在艺术家的手中相互碰撞，迸发出了新的生命力。\nte02-B 丰岛横尾馆\n横尾忠则与建筑师长山裕子联手改造的艺术空间。艺术家横尾忠则将“生与死”这个沉重的主题，用一种近乎波普艺术的、色彩斑斓的方式呈现出来。\n横尾忠则的艺术世界观，正如三岛由纪夫曾评价的，是“日本土俗的悲哀与美国波普艺术的奇妙结合”。红色的玻璃、扭曲的镜面、充满拼贴感的画作，共同营造出一个光怪陆离的异度空间。最令人震撼的是那座圆筒形的塔楼，内壁贴满了成千上万张世界各地的瀑布明信片，创造出一种“无限瀑布”的漩涡，视觉上的永恒延伸，巧妙呼应了“生与死”的哲学主题。\n唐柜 te14 无胜者─多个篮球\nte15-B 心脏音档案馆\n艺术家Christian Boltanski收集并封存了来自世界各地的心跳声。在幽暗的“心室”展厅里，一盏灯泡随着一个陌生人的心跳明灭闪烁，那通过扬声器放大的、震耳欲聋的声响，既是生命最原始的证明，也带来一丝直面存在的不安。\nfrom benesse-artsite\nBoltanski将这些心跳声收集、归档，像一座声音的墓园，每一份录音都是一个生命曾经存在过的证明。他曾说：“当心跳被记录下来，它就不再属于那个活生生的人，而那个人也正走向死亡。但它们作为记忆继续存在。”\nBoltanski已于2021年离世，但心跳的收集仍在继续，以一种特殊的方式延续着他的艺术生命。\n在这里可以花1570日元，将自己的心跳注册到档案馆内。\nte13-B 丰岛美术馆\n“没有艺术品的艺术馆”\n建筑师西泽立卫与艺术家内藤礼联手，在唐柜面朝大海的山坡上，创造了这个奇迹。\n沿着梯田间的小路缓缓走向美术馆，内心已开始沉静。脱鞋进入，是一个不成文的仪式，仿佛在进入一处圣地。当我踏入那个巨大的、水滴状的白色空间时，瞬间被一种难以言喻的寂静与空旷所包围。这里没有一根立柱，只有两个巨大的天窗，将天空、云朵和光线引入室内。\n空间里其实也并非空无一物，秘密被藏在了地上，艺术家内藤礼的作品《Matrix》，让无数细小的水珠从地面微不可见的孔洞中悄然涌出，像初生的生命，颤抖着、聚集着，形成小小的水洼，然后又像有意识一般，缓缓流动，最终汇入另一个孔洞，消失不见。整个过程无声无息，却充满了禅意。\n就在这时，天气变了。起初，我看到水洼上泛起一圈圈涟漪，还以为是馆内设计的另一重玄机。直到雨声渐响，光线变暗，我才恍然大悟——是真的下雨了。我索性坐下来，闭上眼睛，耳朵变得异常灵敏，所有声音在穹顶下回响、混合、放大。那种极致的宁静与充盈，让我想永远停留在此刻。语言在此刻显得苍白无力，我唯一能做的，就是用全身心去感受这份由衷的震撼与感动。\n如果说以一般的美术馆展览来归类的话，《Matrix》是丰岛美术馆的常设展，而各式各样的变化或许便是特展了吧。\n雨中，我沿着山路走向唐柜港，心中充满了一种难以言喻的兴奋与幸福。或许是因为看到了梦寐以求的景象，或许是因为在美术馆中获得了极致的体验，也或许，是因为这是此行艺术祭的终点，一切都圆满了。\n我没有选择直达高松的快船，而是绕道小豆岛，换乘更慢的渡轮。或许是潜意识里不想让这场梦醒得太快，想在缓缓航行的船上，将这份丰盈的感受，再回味久一点。\n【丰岛攻略】\n丰岛周二公休。\n【如何前往】\n丰岛有两个港口，家浦港和唐柜港。\n从高松出发，有两个可选航线，也可从宇野出发，以及从小豆岛、直岛和犬岛跳岛前往。\n高松-豊島\n旺季从高松港出发前往丰岛的人流量很大，需要提前一个小时以上前往排队购票。由于该航线只有高速船，由于载客量限制，一般也比较紧张。\nfrom teshima-ferry\n宇野-豊島(家浦)-豊島(唐櫃)-小豆島(土庄)\nfrom shodoshima-ferry\n直島(宮浦)-豊島(家浦)-犬島\nfrom 四国汽船\n【岛上交通】\n今年的作品分布在家浦，甲生和唐柜三个区域。不同区域间距离有点远坡度有点大。\n在两个港口区域可以租到自行车。\n岛上只有一辆唯一的Taxi。\n艺术祭期间有开通特急巴士。\n时间表：\nfrom 官网\n【岛上饮食】\n附上一张官方旅游手册\n","permalink":"https://niraya666.github.io/travel/2025%E6%BF%91%E6%88%B7%E5%86%85%E5%9B%BD%E9%99%85%E8%89%BA%E6%9C%AF%E7%A5%AD%E5%B7%A1%E7%A4%BC/","summary":"\u003ch2 id=\"关于濑户内艺术祭\"\u003e关于濑户内艺术祭\u003c/h2\u003e\n\u003cp\u003e濑户内国际艺术祭（注意！是濑户内，不是濑户内海！）自2010年首次举办，每三年一届，至今已是第五届。\u003c/p\u003e\n\u003cp\u003e艺术祭的举办地——濑户内海诸岛，曾因泡沫经济破灭、人口老龄化、工业污染等历史问题而一度失去活力。为了振兴这些岛屿，艺术祭应运而生，通过艺术联结世界各地的访客与岛上居民，为这里重新注入生命力。它的愿景宏大而温暖：让濑户内海重现人与自然和谐共生的原始魅力，成为照亮世界的「希望之海」。“海之复权“便是濑户内艺术祭的主题。\u003c/p\u003e\n\u003cp\u003e艺术祭的灵感，承袭自新潟县的“越后妻有大地艺术祭”这一传奇的户外艺术盛典。无论你是当代艺术爱好者、建筑迷，还是徒步旅行者，濑户内国际艺术祭都是一场不容错过的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e地理和交通\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e6%bf%91%e6%88%b7%e5%86%85%e5%9b%bd%e9%99%85%e8%89%ba%e6%9c%af%e7%a5%ad%e5%b7%a1%e7%a4%bc-assets/Pasted%202025-11-05-20-36-24.svg\" alt=\"Pasted 2025-11-05-20-36-24.svg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e艺术祭的主要举办地点都是濑户内海上的一些岛屿和少部分港口城市，绝大多数位于香川县。\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e季节\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e地区\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e全年\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e直岛、丰岛、女木岛、男木岛、小豆岛、大岛、犬岛、高松港区、宇野港区\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e春季\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e濑户大桥区\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e夏季\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e志度、津田区、引田地区\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e秋季\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e本岛、高见岛、粟岛、伊吹岛、宇多津区\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e对于跳岛玩的游客，高松往往是第一选择，因为有着更多的住宿选择和吃饭的选择，还有更多的旅游资源（栗林公园、金刀比罗宫等），当然最重要的是，高松有开通国内的直通航线（上海和香港），而且在日本国内的交通相对方便（飞机、JR、渡船或者巴士）；除此之外还有宇野和小豆岛也是可选择的，这里距离犬岛会比高松更近，排队坐船的人也更少。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e会期与参观建议\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e艺术祭在2025年有三个会期：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e春季会期：4月18日～5月25日\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e夏季会期：8月1日～8月31日\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e秋季会期：10月3日～11月9日\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e虽说会期外也有常设作品可看，不过在艺术祭期间能够亲身感受到艺术祭的氛围，和欣赏到期间限定的作品和区域开放，同时艺术祭专门增加的交通路线也提供了交通上的便利性。\u003c/p\u003e\n\u003cp\u003e但实际体验下来，对于直岛和丰岛这两个绝大多数作品都是常设的岛屿，我强烈建议在艺术祭会期之外参观。这两个岛的热门美术馆\u003cstrong\u003e均无法使用艺术祭通票，需要提前单独预约购票\u003c/strong\u003e。会期内参观意味着可能要提前1个小时去排队买船票，甚至还可能买不到回程票。拥挤嘈杂的人潮对于艺术品欣赏的体验也是大打折扣的。\u003c/p\u003e\n\u003cp\u003e而且，不止是要避开日本的几个黄金周，还要考虑到周边几个国家地区的假期，尽可能错峰出行。（官方也非常贴心提供了\u003ca href=\"https://setouchi-artfest.jp/zh/congestion-calendar/\"\u003e预计拥堵日期\u003c/a\u003e）\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e艺术鉴赏护照Passport\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003epass 是一本集合了盖章和作品鉴赏通票的小册子，也可以选择电子版的，当然就没有集印章的功能了，不过app上不止只有pass还有交通票的购买功能。\u003c/p\u003e\n\u003cp\u003e只要JPY 4500，便可覆盖艺术祭期间，除了直岛丰岛上几个热门馆的门票外的绝大多数美术馆，同时可以享受一次在官方商店购买周边的5%折扣，以及在几个美术馆的门票优惠（如丸龟的猪熊弦一郎美术馆，高松市立美术馆，香川县博物馆等）\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e6%bf%91%e6%88%b7%e5%86%85%e5%9b%bd%e9%99%85%e8%89%ba%e6%9c%af%e7%a5%ad%e5%b7%a1%e7%a4%bc-assets/5B5CEBA6-E65A-42AC-A040-53589D6AF6E0_1_201_a.jpeg\" alt=\"5B5CEBA6-E65A-42AC-A040-53589D6AF6E0_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"关于这次行程\"\u003e关于这次行程\u003c/h2\u003e\n\u003cp\u003e这一次参加的是艺术祭的秋会期，大致的行程：\u003c/p\u003e\n\u003cp\u003eDay1 大阪-丸龟 （宿丸龟）\u003c/p\u003e\n\u003cp\u003eDay2 本岛，高见岛，栗岛\u003c/p\u003e\n\u003cp\u003eDay3 宇多津，高松 （宿高松）\u003c/p\u003e\n\u003cp\u003eDay4 直岛\u003c/p\u003e\n\u003cp\u003eDay5 女木岛男木岛\u003c/p\u003e\n\u003cp\u003eDay6 大岛\u0026amp;高松\u003c/p\u003e\n\u003cp\u003eDay7 丰岛\u003c/p\u003e\n\u003cp\u003eDay8 回程\u003c/p\u003e\n\u003cp\u003e说实话，艺术祭是我目前为止做攻略难度最大的旅行，当然也是满满的成就感的。需要考虑的不止是简单的从哪到哪，还需要精确考虑到船的时间表，公交电车的时刻表，美术馆的休馆日等等，可谓对于J人而言也是难度满满的。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"丸龟艺术古城与骨付鸡\"\u003e丸龟：\u003cstrong\u003e艺术、古城与骨付鸡\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e说起“丸龟”，大多数人的第一反应或许和我一样，是那家遍布各地的乌冬面连锁店。直到在旅行博主老宋的视频里，我才第一次真正了解了这座位于香川县的小城。在规划濑户内海的跳岛行程时，我被它得天独厚的地理位置所吸引——从这里出发，前往秋季限定开放的几个小岛极为便利。于是，丸龟便从地图上的一个名字，变成了我旅途中的重要落脚点。\u003c/p\u003e\n\u003cp\u003e尽管丸龟也是濑户内国际艺术祭的一站，但它似乎更像一个宁静的中转港。大多数游客和我一样，看中的是这里直达本岛的航线，以及JR站与港口近在咫尺的便利。不过，这座小城自有其独特的魅力，比如车站旁那座为纪念画家猪熊弦一郎而建的现代美术馆，便是我此行的另一个重要目标。\u003c/p\u003e\n\u003cp\u003e此行我从大阪出发，结束了两天的世博会之旅后，在新大阪站搭上了新干线，先到冈山，再换乘JR特急“南风号”前往丸龟。根据观察，新大阪站虽是JR西日本的地盘，但能兑换网络预订票的绿色机器（标有5489）却屈指可数，大部分反而是JR东海道的机器，初来乍到，确实需要留心，以免因此误车。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e6%bf%91%e6%88%b7%e5%86%85%e5%9b%bd%e9%99%85%e8%89%ba%e6%9c%af%e7%a5%ad%e5%b7%a1%e7%a4%bc-assets/DAD72417-A643-4355-A36E-7B8C61515698.jpeg\" alt=\"DAD72417-A643-4355-A36E-7B8C61515698.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eJR West取票机；新干线车票、特急券和乘车券；\u003c/p\u003e\n\u003cp\u003e第一次乘坐新干线，难免手忙脚乱。在冈山站换乘时，我本应将乘车券与特急券投入改札口，却错放入乘车券和新干线车票。不过好在丸龟站是个人工检票口。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e6%bf%91%e6%88%b7%e5%86%85%e5%9b%bd%e9%99%85%e8%89%ba%e6%9c%af%e7%a5%ad%e5%b7%a1%e7%a4%bc-assets/23AFB3F7-F507-40D3-BB0A-F4BD78EE0A7B_1_105_c.jpeg\" alt=\"23AFB3F7-F507-40D3-BB0A-F4BD78EE0A7B_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e于濑户内海大桥上\u003c/p\u003e\n\u003cp\u003e这次定的是东横Inn丸龟站前店。酒店就在JR站前，离港口也很近，艺术祭期间基本都是满房的状态。除此之外，酒店在晚上6点到8点还提供一人一碗的免费乌冬面，可谓是非常有当地特色了。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e6%bf%91%e6%88%b7%e5%86%85%e5%9b%bd%e9%99%85%e8%89%ba%e6%9c%af%e7%a5%ad%e5%b7%a1%e7%a4%bc-assets/3F57F5AB-4BA8-4FD2-986E-A05FD086FB6B_1_105_c.jpeg\" alt=\"3F57F5AB-4BA8-4FD2-986E-A05FD086FB6B_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e","title":"2025濑户内国际艺术祭巡礼"},{"content":"值得关注的模型和新技术 OpenAI-Sora\nAnthropic introduced Agent Skills\nDeepSeek-OCR\nMiniMaxAI/MiniMax-M2\nzai-org/GLM-4.6\nChatGPT Atlas\nOCR-VL系列：\nPaddlePaddle/PaddleOCR-VL\nallenai/olmOCR-2-7B-1025\ndatalab-to/chandra\nlightonai/LightOnOCR-1B-1025\nnanonets/Nanonets-OCR2-3B\n值得关注的开源项目 MineContext： MineContext is your proactive context-aware AI partner（Context-Engineering+ChatGPT Pulse）\nDeepAnalyze: agentic LLM for autonomous data science.\nEnterprise Deep Research\nPokeeResearch-7B Agent: Pokee Deep Research Model Open Source Repo\n值得关注的研究和论文 ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory arXiv:2509.25140\nReasoningBank： 从成功与失败经验中提炼可迁移推理策略的记忆框架\n不再存储原始轨迹或仅成功流程，而是提取结构化、可复用的推理单元（title + description + content）\n并提出Memory-aware Test-Time Scaling (MaTTS)，Test-Time Scaling 与记忆系统结合，更多探索 → 更丰富对比信号 → 更高质量记忆 → 更好指导未来探索， 采用两种扩展方式：Parallel Scaling（多轨迹对比，提取稳定策略）和Sequential Scaling （单轨迹内自我修正）\n具体实现\n1. ReasoningBank\n使用 LLM-as-a-Judge 自动判断轨迹是“成功”还是“失败”， 对成功轨迹：提取“成功策略”， 对失败轨迹：提取“失败教训”或“反面警示”， 输出结构化记忆项， 如：\nTitle: “使用搜索功能定位商品” Description: “当页面无直接链接时，优先使用搜索框” Content: “在购物网站中，若未找到目标商品，应使用顶部搜索栏输入关键词，而非盲目点击分类”\n而后对当前任务embedding，通过语义检索召回相关top-k\n将检索到的记忆项注入系统提示\n每完成一个任务，自动提取新记忆项，直接追加到记忆库\nMaTTS 实现 Parallel Scaling： 对同一任务生成 k 条轨迹， self-contrast识别哪些策略导致成功，哪些导致失败，提炼出更鲁棒、可迁移的记忆项\nSequential Scaling： 在单条轨迹内进行多次self-refinement， 每次修正后记录中间推理过程，作为记忆信号\nReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization arXiv:2509.13313\nReAct会将每一轮的“思考-动作-观察”全部追加到上下文中，导致随着搜索轮次增加，上下文迅速膨胀，最终超出模型的上下文长度限制\nReSum 的核心目标：通过周期性上下文压缩（摘要），让智能体在不丢失关键信息的前提下，突破上下文长度限制。\n创新点：\n在 ReAct 基础上，周期性调用摘要工具，将历史对话压缩为结构化摘要（包含已确认证据 + 信息缺口 + 下一步方向），用摘要 + 原始问题组成“压缩状态”，重启推理，从而绕过上下文长度限制 不是直接用通用大模型做摘要，而是专门训练一个30B参数的模型 专门设计 ReSum-GRPO算法：自动将长轨迹按摘要点分段，每段作为独立训练样本，将整个轨迹的最终奖励（是否答对）广播到所有分段 Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models arXiv:2510.04618\n在context adaptation中，无需微调权重、仅通过动态演化上下文即可自我改进的框架，即ACE（Agentic Context Engineering）\nGenerator + Reflector + Curator： Generator（生成推理轨迹），Reflector（从成功/失败中提炼具体经验），以及Curator（将经验以结构化“增量条目”形式合并进上下文，避免整体重写） 上下文不是整体重写，而是以bullet points形式局部更新，每个条目包含元数据和内容 Grow-and-Refine： 新条目追加，旧条目可更新（如增加计数），并定期通过语义嵌入去重，保持上下文精炼、无冗余，同时支持长期扩展 Mem-α: Learning Memory Construction via Reinforcement Learning arXiv:2509.25911\n如何让 LLM 代理自主学会高效、结构化地构建和管理复杂记忆系统\n提出基于RL的记忆构建框架 Mem-α，不再依赖预设指令，而是通过**与环境交互 + 奖励反馈，**奖励信号直接来自下游任务表现\n记忆架构：\n核心记忆（Core）：512 token 的摘要，始终在上下文中，只支持 update，强制保持摘要简洁。 语义记忆（Semantic）：存储事实性知识，支持增删改。 情节记忆（Episodic）：按时间戳存储事件，支持时序推理。 每个组件配备专用操作工具（insert/update/delete） 所有操作通过结构化函数调用完成：\nmemory_insert(memory_type=\u0026#39;semantic\u0026#39;, content=\u0026#39;用户喜欢安静的环境\u0026#39;) RL设计：\n状态：当前记忆状态 ℳₜ₋₁ + 当前输入块 cₜ 动作：在每一步 t，模型可执行多个记忆操作（如 insert/update/delete），每个操作是结构化函数调用 奖励： r₁（正确性）：用 RAG 从最终记忆中回答问题，根据准确率打分。 r₂（工具格式）：检查函数调用是否符合规范（如参数类型、格式）。 r₃（压缩率）：鼓励记忆长度远小于原始输入长度（1 - lₘ/l꜀）。 r₄（语义有效性）：用 Qwen3-32B 作为“裁判”判断操作是否语义合理 优化算法： GRPO DeepSeek-OCR: Contexts Optical Compression https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/DeepSeek_OCR_paper.pdf\n通过Contexts Optical Compression将将文本信息“压缩”到视觉信息中。\n用比原始数字文本少得多的vision tokens来表示，从而实现信息压缩率。\n视觉编码器DeepEncoder\n将以Window Attention为主的SAM模型和以Global Attention为主的CLIP串联起来 在两者之间加入一个2层卷积层，以实现16倍下采样 Decoder\nDeepSeek-3B-MoE\n数据集\nOCR 1.0数据：包含3000万页多语言文档（粗略/精细标注）和场景文字图像，用于训练基础的文字识别能力。 OCR 2.0数据：包含图表、化学分子式、平面几何图形等复杂结构化图像的解析数据，提升模型的深度解析能力。 通用视觉数据：用于保留模型对自然图像的理解能力，如图像描述、目标检测等。 纯文本数据：用于维持和增强模型的语言能力 采用两阶段训练：\n第一阶段：单独训练DeepEncoder，使其学会从图像中提取有效的特征。 第二阶段：将训练好的DeepEncoder与DeepSeek-3B-MoE解码器连接起来，进行端到端的联合训练。训练时，编码器的部分参数被冻结，以稳定训练过程。 推荐内容 Hello-Agents: 从零开始的智能体原理与实践教程\ndeeplearningAI: agentic-ai-course\nHuggingface: The Smol Training Playbook\n影音记录 精选歌单 Live演出 10.17 Valentina Lisitsa钢琴独奏｜东艺\n书\u0026amp;阅读摘录 Not Another Workflow Builder An LLM agent runs tools in a loop to achieve a goal.\nThere’s two main reasons people are interested in this:\nMany companies are more resource constrained on engineering talent than others Non-technical users are the ones who know what agents to build / what they should do The issue with visual workflow builders: 1.Visual workflow builders are not “low” barrier to entry. 2.Complex tasks quickly get too complicated to manage in a visual builder.\nI think agents (prompt + tools) should be strictly easier to create in a no-code way than workflows.\n关于 AI Infra 的一切 算法人只有两年的保质期，两年后 Ta 把自己的聪明才智发挥完了，就会陷入思维定势，反而跟不上后面的新东西了。\n所以这里可以给从业者一个建议，就是不要做夹在模型和硬件中间的那个人。\n这正是我认为需要被纠正的观念。前面提到过，Infra 实际上是可以对模型效果有正向影响的，而不仅仅是只能降本。\n模型其实由算法、Infra 和数据这个铁三角决定。三者缺一不可，必须协同。\n所以实际上比较合理的组织架构是，让 Infra 人去设计模型结构，因为 Infra 人最知道该怎么提高效率、节省成本，让数据的人去负责刷模型的点数和 benchmark 分数，因为他们最懂怎么喂模型，而算法人应该主要负责训练的范式革新。\nBuilding in the AI Era: The HeyGen Way We move fast AND be the absolute best… moving fast allows us to build better quality… our success metric: the average video quality any user can achieve.\nWhy 2 months? This aligns with model upgrade cycles… 2-month roadmap… 6-12 month strategic bets… Daily shipping\nDay 1: Define hypothesis… Day 2: Build MVP… Days 3-5: Ship… Week 2: Analyze… Failure with learning = victory\nSpeed Is Everything… Embrace the Technology Wave… Disagree and Commit… When in doubt, ship an experiment\nGrowth teams are built for a different game… In the AI era, code is cheap. Impact is valuable\nAI落地为什么这么难？ 千万别，不要向老板卖降本的方案。 降本是个陷阱。 老板说要降本， 其实要的是利润。\nAI to B 落地，往往会遇到三方博弈：老板要利润，但说不清路径。 中层要业绩，不敢碰组织。 员工要饭碗，会软抵抗。\n但还有第三条路：找一个“无主之地”。不是取代现有岗位， 是做现在没人做的事，做增收，或者能帮采用部门，扩大预算或者人头的事。听起来好像跟老板原来降本的需求南辕北辙。但却是真实发生的案例。\nAI落地的关键， 不是证明 AI 比人强。是让人觉得： 我用了 AI，我更强。\n别动存量，找增量。\n别替代人， 武装人。\n对李想的第二次3小时访谈：智慧是我们和万物的关系 人类并不擅长处理特别复杂的信息——人类要做“熵减”，而不是“熵增”。人类之所以发明方法论、创造工具，本质是为了减少能量消耗——因为大脑运作需要能量。\n今天的人工智能，处理通用信息表现不错，但一旦进入专业领域，往往不如人。这是因为，这些领域需要更高质量的数据和更专业的CoT\n今天Chatbot，或者Reasoning，做更长链条思考和推理任务时，也能看到一系列严重的问题——几乎所有人，还是把它当成“信息工具”\n还是要站在用户价值的角度，如果大家拼命使用AI，为AI投资，但我的工作时长没减少，结果也没变好，问题到底在哪？ 今天通过对话（Chatbot），无论文本多么长，它都是“信息工具”，对大家是参考作用。 什么时候真正改善工作成果和减少工作时长？它必须变成“生产工具”。\n另外当我Action做完以后，我还会做一个Diffusion（扩散）预测，下边会发生什么样的时长的一个场景。这个主要根据性能，会做出4到8秒Diffusion的轨迹和环境预测\n五年内没有通用Agent， 但会有Agent OS\n先做好公司内部的Agent，因为公司内部需要有很多Agent——客服Agent、编程Agent\n搭建出一个有效的Agent OS，让每个专业的人在上面开发自己所在领域的Agent\n你不可能让智能商业团队做客服Agent，应该是客服团队借助这个Agent OS，开发出自己专业的客服Agent\n汽车会从智能终端变成人工智能终端。这是我们要做的。\n今天，工厂也面临这样的机会。很多人想的是，造一个人形机器人进工厂替代人，但我认为有两个问题： 工厂里人的成本占比并没有大家想象的那么高，替代起来并不划算； 这些就业岗位长期来看还是必要的\n只关注替代人，我认为是狭隘的。\n我们没有把握住用户的需求，我们会消失； 我们没有掌握最好的产品和技术，我们会消失； 我们的组织能力方面出现了巨大的问题，我们也会消失\n这些所有的讨论、争执、吵架，背后有一个更重要的一点——是能量。\n当人和人之间的能量始终存在的时候，这些争执、讨论、吵架就是一个更完善的大脑。 当这些能量消失的时候，这些争执、讨论、不同想法就会变成内耗。\n","permalink":"https://niraya666.github.io/monthly/2025-10-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/zh-Hans-CN/index/sora-2/\"\u003eOpenAI-Sora\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.anthropic.com/news/skills\"\u003eAnthropic introduced Agent Skills\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/html/2510.18234v1\"\u003eDeepSeek-OCR\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/MiniMaxAI/MiniMax-M2\"\u003eMiniMaxAI/MiniMax-M2\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/zai-org/GLM-4.6\"\u003ezai-org/GLM-4.6\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/zh-Hans-CN/index/introducing-chatgpt-atlas/\"\u003eChatGPT Atlas\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOCR-VL系列：\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/PaddlePaddle/PaddleOCR-VL\"\u003ePaddlePaddle/PaddleOCR-VL\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/allenai/olmOCR-2-7B-1025\"\u003eallenai/olmOCR-2-7B-1025\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/datalab-to/chandra\"\u003edatalab-to/chandra\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/lightonai/LightOnOCR-1B-1025\"\u003elightonai/LightOnOCR-1B-1025\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/nanonets/Nanonets-OCR2-3B\"\u003enanonets/Nanonets-OCR2-3B\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/volcengine/MineContext\"\u003eMineContext\u003c/a\u003e： MineContext is your proactive context-aware AI partner（Context-Engineering+ChatGPT Pulse）\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/ruc-datalab/DeepAnalyze\"\u003eDeepAnalyze\u003c/a\u003e: agentic LLM for autonomous data science.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/SalesforceAIResearch/enterprise-deep-research\"\u003eEnterprise Deep Research\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/Pokee-AI/PokeeResearchOSS\"\u003ePokeeResearch-7B Agent\u003c/a\u003e: Pokee Deep Research Model Open Source Repo\u003c/p\u003e\n\u003ch1 id=\"值得关注的研究和论文\"\u003e值得关注的研究和论文\u003c/h1\u003e\n\u003ch2 id=\"reasoningbank-scaling-agent-self-evolving-with-reasoning-memory\"\u003e\u003cstrong\u003eReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003earXiv:\u003ca href=\"https://arxiv.org/abs/2509.25140\"\u003e2509.25140\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eReasoningBank： 从成功与失败经验中提炼可迁移推理策略的记忆框架\u003c/p\u003e\n\u003cp\u003e不再存储原始轨迹或仅成功流程，而是提取\u003cstrong\u003e结构化、可复用的推理单元\u003c/strong\u003e（title + description + content）\u003c/p\u003e\n\u003cp\u003e并提出Memory-aware Test-Time Scaling (MaTTS)，Test-Time Scaling 与记忆系统结合，更多探索 → 更丰富对比信号 → 更高质量记忆 → 更好指导未来探索， 采用两种扩展方式：Parallel Scaling（多轨迹对比，提取稳定策略）和Sequential Scaling （单轨迹内自我修正）\u003c/p\u003e","title":"2025-10 月刊"},{"content":"距离上一次看世博，原来已有十五年了。\n说实话，对于2010年的上海世博会，记忆早已模糊。脑海中仅存的印象，是无尽的人潮与漫长的队伍。我甚至不记得自己是否真正走进过任何一座展馆，唯独清晰地记得，上海的生煎包好吃。\n十五年后的今天，世界已截然不同。当“脱钩”与“去全球化”的浪潮涌动，国家间的壁垒日益分明，大阪世博会“One Planet, One World“ 的口号，似乎显得有些不合时宜，甚至带有一丝理想主义的天真。是否还记得，上一次听到“地球村”这个词，是在什么时候吗？\n但或许这样也好。当世界不再沉浸于全球化的乐观中，我们反而获得了更多沉静下来，去思考科技、环保与可持续未来的空间。如今的世博会，早已脱离了其创立之初，老牌资本主义国家炫耀工业实力的舞台，转而成为一个对未来展望的思辨场。\n这份展望，又与1970年的大阪世博会不尽相同——那是一个对科技发展充满无限乐观的时代，而今天，科技的狂飙突进，却迫使我们不得不回过头来，审视其带来的环境问题、可持续发展的挑战，以及在科技面前，人类本身与生命的意义。这种审视，甚至带有些许沉重的底色。\n【几个角度的观察】\n在参观完几个展馆后，我有一种奇妙的感觉：日本人似乎真的生活在他们所创造的Anime世界里，这或许是他们最擅长的表达方式，在虚构的二次元中，延续着上世纪七十年代的黄金时代梦想。毕竟，现实往往是残酷的。\n这次参观的一大感受是，绝大多数展馆的核心形式都是“播片”，辅以一些互动体验装置来增强参与感。我主要参观了四个展馆，各有感触。（感谢某鱼的科技，否则我这种脸黑的非洲人必然是一个抽不中的）\n高达馆：对于并非高达迷的我而言，不同型号机体的名字和故事略显陌生。展馆将背景设定在公元2150年，作为参观者，从世博会场梦洲出发，搭乘宇宙电梯进入空间站，故事的高潮，是在高达的协助下，共同击败反派。整个过程充满了动漫式的热血与激情\n电力馆（電力館 可能性のタマゴたち）：显然对孩子们的吸引力更大。入场时，每人会领到一个蛋形装置，需要在第一阶段的展区中，通过各种有趣的互动游戏为这颗“蛋”收集“电力”。当能量积攒到一定程度，才能进入下一阶段——一个由音乐与光影交织而成的沉浸式装置艺术空间。\n日本馆：日本馆的设计是一座巨大的环形建筑，其核心主题是“循环”与“生命交织”。它探讨了一个深刻的命题：即使某些事物迎来了终结，它的一部分仍会被传承并转化为新的形态，开启另一段旅程。这是一种无始无终的生命接力。展馆内通过垃圾回收技术、微生物发酵分解、特殊的藻类植物等案例，生动地诠释了这一理念。有趣的是，他们还与三丽鸥合作，推出了32种不同形态的“藻类Hello Kitty”，用一种可爱的方式传递着循环共生的哲学。\nFuture of Life： 然而，给我留下最深刻印象的，是石黑浩所策展的future of life。这场不足一小时的演出，却带来了直击灵魂的思考。它将我们带到50年后的未来，抛出了一个尖锐的问题：当科技允许你将记忆和意识转移给机器人，从而获得一种形式上的“永生”时，面对肉体的有限与数据的“不朽”，你将如何选择自己的生命形态？演出并未给予一个标准答案，而是以一个开放式的结局，将选择权交还给了每一位参与者。\n【建筑之美】\n除了展馆内容，世博园区的建筑设计本身也值得观赏。\n被称为“大屋根”的环状主步道，是世界上最大的纯木质结构建筑。然而，令人惋惜的是，这座建筑将在世博会闭幕后被拆除，结束其短暂生命。\n不过转念一想，这或许也恰好呼应了日本馆所传递的“循环”理念吧。大屋根的实体消失了，但构成它的木材，或许会以另一种形式，继续存在于世界的某个角落。生命与物质，本就是一场盛大的循环，而无需伤感。\n原本，我还计划着第二天去万博纪念公园，拜访1970年世博会留下的精神图腾——太阳之塔。遗憾的是，直到登上地铁时才发现，公园周三闭馆，只能作罢。\n回想这趟旅程，世博会人山人海，预约困难重重。但如果问我，这一切值得吗？我的答案，依然是“值得”的。\n","permalink":"https://niraya666.github.io/travel/2025%E5%B9%B4%E5%A4%A7%E9%98%AA%E4%B8%96%E5%8D%9A%E4%BC%9A%E6%9C%AD%E8%AE%B0/","summary":"\u003cp\u003e距离上一次看世博，原来已有十五年了。\u003c/p\u003e\n\u003cp\u003e说实话，对于2010年的上海世博会，记忆早已模糊。脑海中仅存的印象，是无尽的人潮与漫长的队伍。我甚至不记得自己是否真正走进过任何一座展馆，唯独清晰地记得，上海的生煎包好吃。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/075E0233-D9AF-49F4-8D6C-64E28A63A69A_1_105_c.jpeg\" alt=\"075E0233-D9AF-49F4-8D6C-64E28A63A69A_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e十五年后的今天，世界已截然不同。当“脱钩”与“去全球化”的浪潮涌动，国家间的壁垒日益分明，大阪世博会“One Planet, One World“ 的口号，似乎显得有些不合时宜，甚至带有一丝理想主义的天真。是否还记得，上一次听到“地球村”这个词，是在什么时候吗？\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/4E286AC1-7615-429A-9101-A1832FE5221F_1_105_c.jpeg\" alt=\"4E286AC1-7615-429A-9101-A1832FE5221F_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e但或许这样也好。当世界不再沉浸于全球化的乐观中，我们反而获得了更多沉静下来，去思考科技、环保与可持续未来的空间。如今的世博会，早已脱离了其创立之初，老牌资本主义国家炫耀工业实力的舞台，转而成为一个对未来展望的思辨场。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/FF641B49-24DC-4FAB-85D8-3DFD33041AAB_1_105_c.jpeg\" alt=\"FF641B49-24DC-4FAB-85D8-3DFD33041AAB_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e这份展望，又与1970年的大阪世博会不尽相同——那是一个对科技发展充满无限乐观的时代，而今天，科技的狂飙突进，却迫使我们不得不回过头来，审视其带来的环境问题、可持续发展的挑战，以及在科技面前，人类本身与生命的意义。这种审视，甚至带有些许沉重的底色。\u003c/p\u003e\n\u003cp\u003e【几个角度的观察】\u003c/p\u003e\n\u003cp\u003e在参观完几个展馆后，我有一种奇妙的感觉：日本人似乎真的生活在他们所创造的Anime世界里，这或许是他们最擅长的表达方式，在虚构的二次元中，延续着上世纪七十年代的黄金时代梦想。毕竟，现实往往是残酷的。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/A74E745C-E6BA-4D0D-9702-19C7140DC0FA.jpeg\" alt=\"A74E745C-E6BA-4D0D-9702-19C7140DC0FA.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e这次参观的一大感受是，绝大多数展馆的核心形式都是“播片”，辅以一些互动体验装置来增强参与感。我主要参观了四个展馆，各有感触。（感谢某鱼的科技，否则我这种脸黑的非洲人必然是一个抽不中的）\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e高达馆\u003c/strong\u003e：对于并非高达迷的我而言，不同型号机体的名字和故事略显陌生。展馆将背景设定在公元2150年，作为参观者，从世博会场梦洲出发，搭乘宇宙电梯进入空间站，故事的高潮，是在高达的协助下，共同击败反派。整个过程充满了动漫式的热血与激情\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/6D3CEFDA-A49C-4516-B56A-5D79C81365CB.jpeg\" alt=\"6D3CEFDA-A49C-4516-B56A-5D79C81365CB.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e电力馆\u003c/strong\u003e（電力館 可能性のタマゴたち）：显然对孩子们的吸引力更大。入场时，每人会领到一个蛋形装置，需要在第一阶段的展区中，通过各种有趣的互动游戏为这颗“蛋”收集“电力”。当能量积攒到一定程度，才能进入下一阶段——一个由音乐与光影交织而成的沉浸式装置艺术空间。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e日本馆\u003c/strong\u003e：日本馆的设计是一座巨大的环形建筑，其核心主题是“循环”与“生命交织”。它探讨了一个深刻的命题：即使某些事物迎来了终结，它的一部分仍会被传承并转化为新的形态，开启另一段旅程。这是一种无始无终的生命接力。展馆内通过垃圾回收技术、微生物发酵分解、特殊的藻类植物等案例，生动地诠释了这一理念。有趣的是，他们还与三丽鸥合作，推出了32种不同形态的“藻类Hello Kitty”，用一种可爱的方式传递着循环共生的哲学。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/11BE48D6-2E72-42C7-BA13-31C061C07214_1_105_c.jpeg\" alt=\"11BE48D6-2E72-42C7-BA13-31C061C07214_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFuture of Life\u003c/strong\u003e： 然而，给我留下最深刻印象的，是石黑浩所策展的future of life。这场不足一小时的演出，却带来了直击灵魂的思考。它将我们带到50年后的未来，抛出了一个尖锐的问题：当科技允许你将记忆和意识转移给机器人，从而获得一种形式上的“永生”时，面对肉体的有限与数据的“不朽”，你将如何选择自己的生命形态？演出并未给予一个标准答案，而是以一个开放式的结局，将选择权交还给了每一位参与者。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/34DE9478-ED55-49FC-B673-573474029884.jpeg\" alt=\"34DE9478-ED55-49FC-B673-573474029884.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e【建筑之美】\u003c/p\u003e\n\u003cp\u003e除了展馆内容，世博园区的建筑设计本身也值得观赏。\u003c/p\u003e\n\u003cp\u003e被称为“大屋根”的环状主步道，是世界上最大的纯木质结构建筑。然而，令人惋惜的是，这座建筑将在世博会闭幕后被拆除，结束其短暂生命。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/82873FEB-7CD2-4E48-85A4-167599EEA194_1_105_c.jpeg\" alt=\"82873FEB-7CD2-4E48-85A4-167599EEA194_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e不过转念一想，这或许也恰好呼应了日本馆所传递的“循环”理念吧。大屋根的实体消失了，但构成它的木材，或许会以另一种形式，继续存在于世界的某个角落。生命与物质，本就是一场盛大的循环，而无需伤感。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/29BDA80B-2BF2-4C40-9500-B0F109E5C72A_1_105_c.jpeg\" alt=\"29BDA80B-2BF2-4C40-9500-B0F109E5C72A_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e原本，我还计划着第二天去万博纪念公园，拜访1970年世博会留下的精神图腾——太阳之塔。遗憾的是，直到登上地铁时才发现，公园周三闭馆，只能作罢。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/9B6C0E81-941D-4A61-AA08-8F5AD01160EF_1_105_c.jpeg\" alt=\"9B6C0E81-941D-4A61-AA08-8F5AD01160EF_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e回想这趟旅程，世博会人山人海，预约困难重重。但如果问我，这一切值得吗？我的答案，依然是“值得”的。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%e5%b9%b4%e5%a4%a7%e9%98%aa%e4%b8%96%e5%8d%9a%e4%bc%9a%e6%9c%ad%e8%ae%b0-assets/81B35BD5-A9E5-4A84-B61A-E54BD6428FA9_1_105_c.jpeg\" alt=\"81B35BD5-A9E5-4A84-B61A-E54BD6428FA9_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e","title":"2025年大阪世博会札记"},{"content":"值得关注的模型和新技术 Qwen3-VL\nQwen3Guard\ntongyi-deep-research\nEmbeddingGemma\nCode World Model (CWM)\n值得关注的开源项目 FineVision:Open Data Is All You Need\n大麦抢票脚本\nParlant: LLM agents built for control. Designed for real-world use.\nClaude Code Comprehensive Guide\nDayflow: Turns your screen activity into a clean timeline with AI summaries and distraction highlights.\n值得关注的研究和论文 MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains arXiv:2508.18260\n提出了**Parallel Multi-chain Inference，**将一个复杂问题分解成多个子问题，为每个子问题启动一个独立的、并行的推理链\n提出了**Adaptive Graph-based Retrieval，**与一个结构化的医学知识图谱进行交互，在推理过程中，模型可以动态地通过邻居节点扩展、多跳路径遍历等方式探索知识图谱中的实体关系和层次结构\nMIRAGE框架通过四个协同工作的组件实现其功能：\nQuestion Decomposer Evidence Retriever：为每个子问题启动一个并行的推理链，进行一种“边思考边搜索”的循环；检索分为两种模式：Anchor Mode（当查询涉及单个实体时，检索该实体在图谱中的局部邻居信息）；Bridge Mode （当查询涉及两个实体时，在图谱中寻找连接这两个实体的关系路径） Answer Synthesizer：收集所有并行推理链生成的答案和证据，并交叉验证 Coordinator：管理以上三个组件的执行流程 Why Language Models Hallucinate paper\n提出了基于socio-technical视角来解释幻觉的持续存在。指出，问题的根源不仅仅在于模型或算法本身，更在于评估手段— 特别是主流的benchmark多采用非黑即白的二元评分，鼓励模型“赌一把”而不是如实承认 “不知道”。\nOn the Theoretical Limitations of Embedding-Based Retrieval arXiv:2508.21038\n基于single vector embedding的检索模型是否存在根本性的理论上限？\n对于任何固定维度的嵌入模型，都存在一些它永远无法表示和检索的“相关文档组合”，这是由向量空间本身的几何特性决定的一个根本性限制\n定义：\n将检索问题形式化为一个m \\times n的相关性矩阵 A（m个查询，n个文档）。嵌入模型的目标是学习一个得分矩阵B（由查询向量和文档向量的点积生成，m \\times n），使得B中每一行的元素排序与A一致（即相关文档的得分高于不相关文档）；\n行序保持秩 rank_rop(A)：让相关文档得分 \u0026gt; 不相关文档得分的最低嵌入维度 d\n行级阈值秩 rank_rt(A): 对于每个查询 i，存在一个阈值 τ_i，能将相关和不相关文档的得分分开\n全局阈值秩 rank_gt(A): 存在一个全局阈值 τ 对所有查询都有效\nsign-rank rank_±(M) 定义： 给定一个矩阵M \\in {-1, 1}^{m \\times n}， \\operatorname{rank}{\\pm}(M) = \\min { \\operatorname{rank}(B) \\mid B \\in \\mathbb{R}^{m \\times n} \\text{ 并且对于所有 } i, j, \\text{ 我们有 } \\operatorname{sign}(B{ij}) = M_{ij} }\n先给出结论：由于存在sign-rank任意高的矩阵，因此对于任何给定的嵌入维度d，总会存在一个相关性矩阵（即一个检索任务）是它无法表示的\nParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute arXiv:2509.04475\n并非思考越长越好\nTunnel Vision， 即模型在生成思考过程的最初几步，一旦犯了错或选择了一条并非最优的路径，就很容易被“锁定”在这条错误的轨道上，后续无论再花多少计算量进行思考和修正，都很难再回到正确的路径上； 因此主流的sequential-thinking，基于“深度”扩展（单一路径加长）策略存在缺陷\n对此，提出了Native Parallel Thinking；\n引入一组Specialized Tokens \u0026lt;think i\u0026gt;在推理时显式地引导模型开启第 i 条独立的思考路径 为了在汇总阶段解决位置混淆问题，引入thought embedding 通过从教师模型采样多条解题路径来构建训练数据，同时，通过两阶段的注意力掩码，确保在“并行思考”阶段各路径相互独立，在“总结”阶段又能看到所有路径的信息 Parallel Reasoning Stage：\n给定一个问题，模型输入被构造成 [问题] \u0026lt;think 1\u0026gt; \u0026lt;think 2\u0026gt; ... \u0026lt;think P\u0026gt; 的形式 以batch方式，同时为 P 个 \u0026lt;think i\u0026gt; Token并行生成 P 条独立的推理路径 当任意一条路径生成EOS或达到预设的Token预算时，所有路径同时停止生成，以保证各路径长度大致均衡 Summarization Stage\n上下文整合，直接复用了并行推理阶段生成的KV-Cache，无需re-prefilling。\nSFT\n使用教师模型，对一个问题多次采样，生成多条不同的解题思路，将这些思路整合成一个训练样本，格式为：[问题] \u0026lt;think 1\u0026gt;[思路1]\u0026lt;/think 1\u0026gt; ... \u0026lt;think P\u0026gt;[思路P]\u0026lt;/think P\u0026gt; \u0026lt;summary\u0026gt;[最终答案]\u0026lt;/summary\u0026gt;。\n在训练时，随机选择一部分特殊Token（如从6个可用路径中随机选4个）进行训练，这使得模型能够泛化，在推理时可以生成比训练时更多的并行路径\nReinforcement Learning with Rubric Anchors arXiv:2508.12790\n如何RL的应用范围，从有明确、可自动验证答案的任务，扩展到更广泛、更主观、没有唯一正确答案的开放式任务中\n使用一套精心设计的、结构化的、可被模型理解的评分标准（Rubric），来为开放式任务的输出自动打分，并以此作为奖励信号来训练模型\nRubric System设计\n首先设计评分准则。每个准则包含多个维度（如创意性、共情能力、逻辑性），每个维度都有明确的评价标准、评分等级和权重；\n模型的输出会根据这些准则被打出一个多维度的分数向量；为了让奖励信号更有效，并非简单地加权求和，采用了更复杂的策略：\n在一些关键维度上失败，则总分直接为零 避免模型在单一维度上过度优化而忽略其他维度 在高分区间放大分数差异，提供更精细的优化梯度 训练流程\n在训练前，先用基础模型对候选数据生成回答，再用一个“批评家模型”根据准则打分，只保留得分适中的数据（去掉太简单和太难/低质量的），以提高训练效率 第一阶段：使用静态、可验证的准则，专注于训练模型遵循指令和约束的基础能力 第二阶段：使用更复杂的、甚至是针对每个样本动态生成的准则，专注于训练开放式、创意和社交等高级能力 如何避免reward-hacking： 专门设计“反作弊”的评分准则\nIs In-Context Learning Learning? arXiv:2509.10414\n在传统的机器学习中，“学习”等同于“泛化”， In-Context Learning, ICL ， 究竟算不算是一种真正的“学习”？\n实验设计\n测试了4个主流的LLM （GPT-4 Turbo、GPT-4o、Mixtral 8x7B、Phi-3.5 MoE） 设计了9个形式化的、基于合成数据的任务， 大致可分成：有限状态自动机可识别的任务（奇偶校验， 模式匹配等）和下推自动机可识别的任务（字符串反转，堆栈操作等） 所有任务的数据都是通过带概率的自动机生成的，可通过参数\\delta 控制ID和OOD数据分布 对每个任务，测试了多种提示策略， 如Modus Ponens（只给范例，没有任务描述）， Description（标准的任务描述+范例）， CoT，APO（用一个元提示让模型自己优化任务描述），Word Salad / SoT （将Description和CoT中的自然语言文本替换为随机单词） eval metrics： Accuracy，并分析其随范例数量和OOD程度关系 一些发现\n随着范例数量的增加，模型的平均准确率稳步提升，证明ICL确实在从范例中“学习”。然而，其泛化能力有限 在极限情况下，模型主要是在学习范例的结构和统计模式，而不是理解自然语言指令的语义 CoT虽然能提升解决特定问题的能力，但它也让模型过度拟合了范例的分布和推理模式，导致其在OOD场景下的泛化能力变得更差 ICL并非真正地编码数据内部的因果或逻辑关系。相反，它通过自回归的方式，对上下文中的统计特征进行一种 ad hoc encoding 推荐内容 Agentic Design Patterns\nWriting effective tools for agents — with agents\ngoogle：Startup technical guide AI agents\n5-Day AI Agents Intensive Course with Google\n影音记录 精选歌单 Live演出 09.05 downy ｜万代2F\n09.19 mammal hands ｜blue notes\n09.20 羊文学 ｜Vas est\n09.21 ひとひら　\u0026amp; その感激と记录｜Vas\n09.26 明日の叙景 ｜Vas\n书\u0026amp;阅读摘录 深度｜张小珺独家对话OpenAI姚顺雨：语言推理才是AGI主线，交互创新决定创业壁垒 我反而认为模型越强创业机会越大。真正的壁垒是 设计新的交互方式。… 反而如果你只是照搬聊天式助手，很容易被 ChatGPT 替代。\n目前大多数公司还没有数据飞轮，只是依赖模型公司能力提升。要形成飞轮，必须具备：① 能够自己训练模型；② 有明确的 reward 去区分好坏数据；③ reward 与业务高度一致\n社会网络既有资源集中度，也有边缘跃迁速度。未来可能同时中心化和多元化。\n因为 AGI 需要智能、环境和用户 context 三者结合，后两者往往被忽视\n最重要的是想清楚你要为用户创造什么价值。技术是工具，理解技术趋势固然重要，但更重要的是产品敏锐度（Product Sense）和第一性思考，找到痛点并提供解决方案\n“If someone else can do it, then it\u0026rsquo;s OK to let them do it.” 这让我相信，如果别人已经在做某件事，我可以选择不去卷，而去探索更具潜力的边界，因为最终目标是为社会创造价值\n中美 Agent 创业者闭门：一线创业者的教训、抉择与机会 隐性知识的获取是一个核心挑战，尤其在2B领域。大模型能力不再是主要瓶颈，但是Agent如何能够给到大模型足够的context来实际落地，依然面临几个方面的挑战。 一是默会知识 … 二是协作需要的共识性知识 … 三是企业内部在长期实践中形成的自定义规则\n以前软件都是在做工具给人使用，因为工具直接解决问题的成本过高，问题由人来解决\nWorkflow or Agentic？ … 一个实用的选择标准，是看客户的工作是否天然由工作流驱动。对于企业里可以用非常强规则描述的工作，用Workflow去做，会更高效、准确，成本更低，合规性也更好 … 需要多步骤、灵活操作的任务，则更适合交给自主编排Agent … RPA公司沉淀的RPA资产可以转化为MCP Server中的工具，企业原先接入的系统可以直接转化为Agent落地的基础设施优势。\n对2B领域的Agent创业者而言，另一个重要决策是在客户选择上：先攻KA（大客户）还是SMB（中小客户）？ … 但KA市场有几个不可忽视的挑战：实施成本高昂、决策链条冗长、各部门利益协调复杂。很多项目最终卡在\u0026quot;试点成功但无法推广\u0026quot;的尴尬境地。 … 用中小企业市场快速验证产品价值和商业模式，积累标准化场景，打磨\u0026quot;低实施成本加标准SOP加轻量集成\u0026quot;的产品形态；同时选择性地用能量化价值的案例敲开关键大客户的大门，建立标杆项目\n但GUI操作的长期价值仍存在很大争议：GUI本质上是为人类认知优化的界面，对Agent来说并非最优路径。当Agent能直接调用API、操作服务器甚至编写代码时，绕开GUI似乎是更优解。在这种情况下，还有什么必要坚持GUI操作吗？ … 我们有两点考虑：一是现实世界过去几十年积累了大量基于GUI的应用，短期内完全绕过并不现实 … 而更深层的原因，在于GUI承载的不仅仅是操作功能，还有丰富的上下文信息。\nWriting effective tools for agents — with agents We conclude with key principles for writing high-quality tools we’ve identified along the way: Choosing the right tools to implement (and not to implement)Namespacing tools to define clear boundaries in functionalityReturning meaningful context from tools back to agentsOptimizing tool responses for token efficiencyPrompt-engineering tool descriptions and specs\nTo build effective tools for agents, we need to re-orient our software development practices from predictable, deterministic patterns to non-deterministic ones.\nWriting Code Is Easy. Reading It Isn’t. But the hard part isn’t the writing. It’s the reading. It’s the time it takes to load the mental model of the system into your head. That’s where all the cost really is.\nReading code is harder than writing it. Much harder. Writing code is forward motion: you’re laying down fresh pavement. Reading code means retracing someone else’s steps, which usually means jumping between files, chasing function calls, inferring side effects, and deciphering intentions that aren’t written down.\nUnderstanding one function often means looking at five other files. Only after all that do you have enough of a map to even begin.\nMaybe it wasn’t the tech after all The technology acted as a catalyst – a reason to look hard at how work gets done, to invest in skills, and to rethink decision-making.\nWhat the evidence does show, overwhelmingly, is that technology adoption only succeeds when it comes hand-in-hand with organisational change.\nTech without organisational change delivers little benefit\n","permalink":"https://niraya666.github.io/monthly/2025-09-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://qwen.ai/blog?id=99f0335c4ad9ff6153e517418d48535ab6d8afef\u0026from=research.latest-advancements-list\"\u003e\u003cstrong\u003eQwen3-VL\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://qwen.ai/blog?id=f0bbad0677edf58ba93d80a1e12ce458f7a80548\u0026from=research.research-list\"\u003eQwen3Guard\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://tongyi-agent.github.io/zh/blog/introducing-tongyi-deep-research/\"\u003etongyi-deep-research\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://developers.googleblog.com/en/introducing-embeddinggemma/\"\u003eEmbeddingGemma\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/facebookresearch/cwm\"\u003eCode World Model (CWM)\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/spaces/HuggingFaceM4/FineVision\"\u003eFineVision:Open Data Is All You Need\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/WECENG/ticket-purchase\"\u003e大麦抢票脚本\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/emcie-co/parlant\"\u003eParlant\u003c/a\u003e: LLM agents built for control. Designed for real-world use.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/Cranot/claude-code-guide\"\u003eClaude Code Comprehensive Guide\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/JerryZLiu/Dayflow\"\u003eDayflow\u003c/a\u003e: Turns your screen activity into a clean timeline with AI summaries and distraction highlights.\u003c/p\u003e\n\u003ch1 id=\"值得关注的研究和论文\"\u003e值得关注的研究和论文\u003c/h1\u003e\n\u003ch2 id=\"mirage-scaling-test-time-inference-with-parallel-graph-retrieval-augmented-reasoning-chains\"\u003eMIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains\u003c/h2\u003e\n\u003cp\u003earXiv:\u003ca href=\"https://arxiv.org/abs/2508.18260\"\u003e2508.18260\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e提出了**Parallel Multi-chain Inference，**将一个复杂问题分解成多个子问题，为每个子问题启动一个独立的、并行的推理链\u003c/p\u003e\n\u003cp\u003e提出了**Adaptive Graph-based Retrieval，**与一个结构化的医学知识图谱进行交互，在推理过程中，模型可以动态地通过邻居节点扩展、多跳路径遍历等方式探索知识图谱中的实体关系和层次结构\u003c/p\u003e\n\u003cp\u003eMIRAGE框架通过四个协同工作的组件实现其功能：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://arxiv.org/html/2508.18260v1/x2.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eQuestion Decomposer\u003c/li\u003e\n\u003cli\u003eEvidence Retriever：为每个子问题启动一个并行的推理链，进行一种“边思考边搜索”的循环；检索分为两种模式：Anchor Mode（当查询涉及单个实体时，检索该实体在图谱中的局部邻居信息）；Bridge Mode （当查询涉及两个实体时，在图谱中寻找连接这两个实体的关系路径）\u003c/li\u003e\n\u003cli\u003eAnswer Synthesizer：收集所有并行推理链生成的答案和证据，并交叉验证\u003c/li\u003e\n\u003cli\u003eCoordinator：管理以上三个组件的执行流程\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"why-language-models-hallucinate\"\u003eWhy Language Models Hallucinate\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://cdn.openai.com/pdf/d04913be-3f6f-4d2b-b283-ff432ef4aaa5/why-language-models-hallucinate.pdf\"\u003epaper\u003c/a\u003e\u003c/p\u003e","title":"2025-09 月刊"},{"content":" 现阶段的RAG是个缝合怪。\n写在开头 如果回顾RAG那短暂的历史，其最初主要是为了解决模型知识的动态更新和降低模型幻觉而设计的，核心假设是知识存在于离散的、纯文本的段落中。然而，随着多模态大模型能力的提升，依然沿用着这种“先解析、再分块、后嵌入”的旧思想来处理蕴含丰富视觉信息的文档，这套当初的设计放在现在就显得有些“刻舟求剑”，甚至成了一种历史包袱。这便引出了我们今天要探讨的核心问题：为了让模型“读懂”图文并茂的复杂文档，我们真的需要如此繁琐的预处理吗？\n现阶段RAG中存在的问题 先细数一下当前主流RAG架构中，所存在的普遍问题：\n依赖专门的OCR模型，layout分析模型对文档进行信息提取：一个典型的PDF文档处理流程可能需要 layout分析模型，OCR模型，表格识别模型等。多模型则增加了系统的复杂度和延迟，而且每一步都存在一定的信息损失。\n不同文件格式需要不同的处理方式：PDF、Word、Markdown、PPTX\u0026hellip; 每一种文件类型都需要一套不同的解析策略。这导致解析系统变得越来越臃肿，维护成本上升。\n图像信息的丢失：传统的RAG几乎是纯文本的。当遇到图像、复杂表格、流程图时，信息丢失是必然的。即便引入多模态模型做Image-Captioning，将图像转译成一段描述性文字，其信息的精确度和完整度也远远无法与原始图像相比。\n需要针对性调整分块策略和索引设计：往往需要为不同类型的文档、不同类型的场景，设计分块策略和索引结构。是按固定大小分块，还是按章节分块？对于一篇论文和一份产品手册，最佳策略显然不同。这种高度定制化的设计，使得RAG系统难以扩展和迁移，架构过于复杂。\n在前作中，曾展望过VLM在RAG领域的巨大潜力，特别是构建一个End-to-End的RAG系统。这个设想的目标，正是为了彻底推翻上述复杂的“预处理”，让信息处理回归简洁和高效。\n为什么现阶段End-to-End的RAG是可行的？ 端到端的RAG，其核心思想是“所见即所得”。不再费力地将文档“翻译”成模型能理解的纯文本格式，而是直接将文档的“视觉形态”——即文档页面图像，直接输入给VLM。\n为什么这个方案是可行的？\nVLM的VQA能力强于OCR：必须承认，在复杂文档的理解上，VLM的能力强于其OCR能力的。与其在OCR这条路上“象牙里雕花”，将复杂文档转换成纯文本形式， 不如直接将文档页面视为一张图片，利用VLM的VQA能力直接在图像上进行信息定位和回答，这不仅跳过了中间繁琐的步骤，更从根本上避免了信息在多次转换中的损失。\nLate Interaction模型的出现：以ColBERT为代表的Late Interaction模型，提供全新的思路。传统的向量检索是将整个文本块压缩成一个单一的向量，这无疑会丢失大量细节。而ColBERT则是为文本块中的每个Token都生成一个向量。检索时，则通过MaxSim操作计算相关性分数。 而这个思想可以迁移到视觉领域：将图像中的每个Patch作为向量化的基本单位，而不是对整张图片构建索引（CLIP）。 同时文档的每一页天然就是一个分块后VLM的输入单元，省去了设计Chunking策略的步骤。\n模型能力和基础设施的成熟：主流的VLM已经支持多张高分辨率图片作为输入，并且拥有足够长的上下文窗口来处理整个文档。主流的LLM推理框架也支持了多图像输入，这也为端到端的文档级理解提供了基础。\nCopali系列模型 Contextualized Late Interaction Over PaliGemma （Copali）便是该系列的开山之作。其核心思想是ColBERT在图像数据上的扩展。（ColBERT相关内容可参考前作）\n选用 PaliGemma-3B 作为基础模型（以SigLIP作为vision-encoder，通过一个线性层将图像patch映射至LLM，即Gemma-2B的嵌入空间），类似ColBERT，在LLM的输出后再增加一个投影层，从而实现多向量表示。\n文档侧（构建索引时）：将一张文档页面图像输入到ColPali中。直接通过视觉编码器将其转换为一系列图像patch（1024），这些嵌入随后被送入LLM，最终通过一个投影层，为每个图像块生成一个128维向量。这样，一页文档就被表示为一个bag-of-embeddings。\n查询侧（检索）：用户输入的文本查询（query）被送入模型的语言模型部分，同样为查询中的每个token生成一个向量\n在检索时，使用类似ColBERT的MaxSim操作来计算查询与文档页面的相关性分数\n训练阶段，在vidore/colpali_train_set 118K个query-页面对上做对比学习获得。\n同时为了系统性地评估富视觉文档的检索能力，作者创建了一个名为ViDoRe (Visual Document Retrieval Benchmark) 的综合性评测基准。\n除了以PaliGemma 为based 的模型外，还有将基础模型换成Qwen2-VL 和Qwen2.5-VL 的ColQwen2模型\nModel Score on ViDoRe 🏆 License Comments vidore/colpali 81.3 Gemma • Based on google/paligemma-3b-mix-448.\n• Checkpoint used in the ColPali paper. vidore/colpali-v1.1 81.5 Gemma • Based on google/paligemma-3b-mix-448.\n• Fix right padding for queries. vidore/colpali-v1.2 83.9 Gemma • Similar to vidore/colpali-v1.1. vidore/colpali-v1.3 84.8 Gemma • Similar to vidore/colpali-v1.2.\n• Trained with a larger effective batch size of 256 batch size for 3 epochs. vidore/colqwen2-v0.1 87.3 Apache 2.0 • Based on Qwen/Qwen2-VL-2B-Instruct.\n• Supports dynamic resolution.\n• Trained using 768 image patches per page and an effective batch size of 32. vidore/colqwen2-v1.0 89.3 Apache 2.0 • Similar to vidore/colqwen2-v0.1, but trained with more powerful GPUs and with a larger effective batch size (256). vidore/colqwen2.5-v0.1 88.8 Apache 2.0 • Based on Qwen/Qwen2 5-VL-3B-Instruct\n• Supports dynamic resolution.\n• Trained using 768 image patches per page and an effective batch size of 32. vidore/colqwen2.5-v0.2 89.4 Apache 2.0 • Similar to vidore/colqwen2.5-v0.1, but trained with slightly different hyper parameters vidore/colSmol-256M 80.1 Apache 2.0 • Based on HuggingFaceTB/SmolVLM-256M-Instruct. vidore/colSmol-500M 82.3 Apache 2.0 • Based on HuggingFaceTB/SmolVLM-500M-Instruct. （From colpali）\n那么同样思路，将基座模型换成Qwen-Omni 的ColQwen-Omni 则能够实现不止是图像维度的召回，还支持视频音频的召回。\nMulti-model Reranker 一个很直观的想法，借鉴传统RAG召回部分的做法，引入一个reranker（cross-encoder），在粗排后做一次精排以提升召回的相关性。这里推荐两个使用过的multi-model reranker。\njina-reranker-m0 jina-reranker-m0基于 Qwen2-VL-2B 构建，从经典的cross-encoder架构转变为VLM，利用VLM预训练的vision-encoder和投影层，LoRA微调了其LLM，并训练了一个 MLP 来生成衡量查询-文档相关性的排序 logits。\n支持32K上下文context（图像+text）支持不同类型任务（text2text，text2image， image2text）\nMonoQwen2-VL MonoQwen2-VL-v0.1 基于 Qwen2-VL-2B通过LoRA实现的multi-model reranker；\n训练时，采用MonoT5目标函数，即模型通过生成“True”或“False”来判断图像-查询对的相关性；采用ColPali 训练集，\n在推理时，将图像和查询一起输入模型，模型生成“True”或“False”，通过比较两个 token 的 logits，计算图像与查询的相关性得分，根据得分对候选图像进行重排序；\nimport torch from PIL import Image from transformers import AutoProcessor, Qwen2VLForConditionalGeneration # Load processor and model processor = AutoProcessor.from_pretrained(\u0026#34;Qwen/Qwen2-VL-2B-Instruct\u0026#34;) model = Qwen2VLForConditionalGeneration.from_pretrained( \u0026#34;lightonai/MonoQwen2-VL-v0.1\u0026#34;, device_map=\u0026#34;auto\u0026#34;, # attn_implementation=\u0026#34;flash_attention_2\u0026#34;, # torch_dtype=torch.bfloat16, ) # Define query and load image query = \u0026#34;What is ColPali?\u0026#34; image_path = \u0026#34;your/path/to/image.png\u0026#34; image = Image.open(image_path) # Construct the prompt and prepare input prompt = ( \u0026#34;Assert the relevance of the previous image document to the following query, \u0026#34; \u0026#34;answer True or False. The query is: {query}\u0026#34; ).format(query=query) messages = [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;image\u0026#34;, \u0026#34;image\u0026#34;: image}, {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: prompt}, ], } ] # Apply chat template and tokenize text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) inputs = processor(text=text, images=image, return_tensors=\u0026#34;pt\u0026#34;).to(\u0026#34;cuda\u0026#34;) # Run inference to obtain logits with torch.no_grad(): outputs = model(**inputs) logits_for_last_token = outputs.logits[:, -1, :] # Convert tokens and calculate relevance score true_token_id = processor.tokenizer.convert_tokens_to_ids(\u0026#34;True\u0026#34;) false_token_id = processor.tokenizer.convert_tokens_to_ids(\u0026#34;False\u0026#34;) relevance_score = torch.softmax(logits_for_last_token[:, [true_token_id, false_token_id]], dim=-1) # Extract and display probabilities true_prob = relevance_score[0, 0].item() false_prob = relevance_score[0, 1].item() print(f\u0026#34;True probability: {true_prob:.4f}, False probability: {false_prob:.4f}\u0026#34;) 基于Colpali模型的MM-RAG实例 推荐几个hands-on 例子\nHuggingface: Multimodal Retrieval-Augmented Generation (RAG) with Document Retrieval (ColPali) and Vision Language Models (VLMs)\nHuggingface: Multimodal RAG with ColQwen2, Reranker, and Quantized VLMs on Consumer GPUs\nweaviate: Multimodal Retrieval-Augmented Generation (RAG)\nLanceDB: Multivector Search: Efficient Document Retrieval with ColPali and LanceDB\nMilvus: Use ColPali for Multi-Modal Retrieval with Milvus\n结语 从快速的POC角度考虑，在有足够GPU显存前提下，基于Colpali的end-to-end方案，可以用更简洁的架构实现，而避免了冗长的流程中，任意一个环节的短板都会导致系统的性能下降，同时还保持了文档中完整的图像和版面的信息； 由于Colpali主要基于英文文档进行训练的，在其他语言其他场景上的泛化能力还有待观察和测试，不过开源社区也有对应的微调方案，具体可参考：Generating a dataset of queries for training and fine-tuning ColPali models on a UFO dataset。\n参考 colpali\nColPali: Efficient Document Retrieval with Vision Language Models\nhuggingface: ColPali\nhuggingface: ColQwen2\nColPali: EFFICIENT DOCUMENT RETRIEVAL WITH VISION LANGUAGE MODELS\n","permalink":"https://niraya666.github.io/posts/rag-toolkits-copali/","summary":"\u003cblockquote\u003e\n\u003cp\u003e现阶段的RAG是个缝合怪。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"写在开头\"\u003e写在开头\u003c/h2\u003e\n\u003cp\u003e如果回顾RAG那短暂的历史，其最初主要是为了解决模型知识的动态更新和降低模型幻觉而设计的，核心假设是知识存在于离散的、纯文本的段落中。然而，随着多模态大模型能力的提升，依然沿用着这种“先解析、再分块、后嵌入”的旧思想来处理蕴含丰富视觉信息的文档，这套当初的设计放在现在就显得有些“刻舟求剑”，甚至成了一种历史包袱。这便引出了我们今天要探讨的核心问题：为了让模型“读懂”图文并茂的复杂文档，我们真的需要如此繁琐的预处理吗？\u003c/p\u003e\n\u003ch2 id=\"现阶段rag中存在的问题\"\u003e现阶段RAG中存在的问题\u003c/h2\u003e\n\u003cp\u003e先细数一下当前主流RAG架构中，所存在的普遍问题：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e依赖专门的OCR模型，layout分析模型对文档进行信息提取：一个典型的PDF文档处理流程可能需要 layout分析模型，OCR模型，表格识别模型等。多模型则增加了系统的复杂度和延迟，而且每一步都存在一定的信息损失。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e不同文件格式需要不同的处理方式：PDF、Word、Markdown、PPTX\u0026hellip; 每一种文件类型都需要一套不同的解析策略。这导致解析系统变得越来越臃肿，维护成本上升。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e图像信息的丢失：传统的RAG几乎是纯文本的。当遇到图像、复杂表格、流程图时，信息丢失是必然的。即便引入多模态模型做Image-Captioning，将图像转译成一段描述性文字，其信息的精确度和完整度也远远无法与原始图像相比。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e需要针对性调整分块策略和索引设计：往往需要为不同类型的文档、不同类型的场景，设计分块策略和索引结构。是按固定大小分块，还是按章节分块？对于一篇论文和一份产品手册，最佳策略显然不同。这种高度定制化的设计，使得RAG系统难以扩展和迁移，架构过于复杂。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e在前作中，曾展望过VLM在RAG领域的巨大潜力，特别是构建一个End-to-End的RAG系统。这个设想的目标，正是为了彻底推翻上述复杂的“预处理”，让信息处理回归简洁和高效。\u003c/p\u003e\n\u003ch2 id=\"为什么现阶段end-to-end的rag是可行的\"\u003e为什么现阶段End-to-End的RAG是可行的？\u003c/h2\u003e\n\u003cp\u003e端到端的RAG，其核心思想是“所见即所得”。不再费力地将文档“翻译”成模型能理解的纯文本格式，而是直接将文档的“视觉形态”——即文档页面图像，直接输入给VLM。\u003c/p\u003e\n\u003cp\u003e为什么这个方案是可行的？\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eVLM的VQA能力强于OCR\u003c/strong\u003e：必须承认，在复杂文档的理解上，VLM的能力强于其OCR能力的。与其在OCR这条路上“象牙里雕花”，将复杂文档转换成纯文本形式， 不如直接将文档页面视为一张图片，利用VLM的VQA能力直接在图像上进行信息定位和回答，这不仅跳过了中间繁琐的步骤，更从根本上避免了信息在多次转换中的损失。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eLate Interaction模型的出现\u003c/strong\u003e：以\u003ccode\u003eColBERT\u003c/code\u003e为代表的Late Interaction模型，提供全新的思路。传统的向量检索是将整个文本块压缩成一个单一的向量，这无疑会丢失大量细节。而\u003ccode\u003eColBERT\u003c/code\u003e则是为文本块中的每个Token都生成一个向量。检索时，则通过MaxSim操作计算相关性分数。 而这个思想可以迁移到视觉领域：将图像中的每个Patch作为向量化的基本单位，而不是对整张图片构建索引（CLIP）。 同时文档的每一页天然就是一个分块后VLM的输入单元，省去了设计Chunking策略的步骤。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e模型能力和基础设施的成熟\u003c/strong\u003e：主流的VLM已经支持多张高分辨率图片作为输入，并且拥有足够长的上下文窗口来处理整个文档。主流的LLM推理框架也支持了多图像输入，这也为端到端的文档级理解提供了基础。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"copali系列模型\"\u003eCopali系列模型\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eCo\u003c/strong\u003entextualized \u003cstrong\u003eL\u003c/strong\u003eate \u003cstrong\u003eI\u003c/strong\u003enteraction \u003cstrong\u003eO\u003c/strong\u003ever \u003cstrong\u003ePali\u003c/strong\u003eGemma （Copali）便是该系列的开山之作。其核心思想是ColBERT在图像数据上的扩展。（ColBERT相关内容可参考\u003ca href=\"https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1colbert/\"\u003e前作\u003c/a\u003e）\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://arxiv.org/html/2407.01449v6/extracted/6240861/images/final_architecture.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e选用 \u003ca href=\"https://huggingface.co/blog/zh/paligemma\"\u003ePaliGemma-3B\u003c/a\u003e 作为基础模型（以\u003ca href=\"https://huggingface.co/docs/transformers/model_doc/siglip\"\u003eSigLIP\u003c/a\u003e作为vision-encoder，通过一个线性层将图像patch映射至LLM，即Gemma-2B的嵌入空间），类似ColBERT，在LLM的输出后再增加一个投影层，从而实现多向量表示。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/paligemma/paligemma_arch.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e文档侧（构建索引时）\u003c/strong\u003e：将一张文档页面图像输入到ColPali中。直接通过视觉编码器将其转换为一系列图像patch（1024），这些嵌入随后被送入LLM，最终通过一个投影层，为\u003cstrong\u003e每个图像块\u003c/strong\u003e生成一个128维向量。这样，一页文档就被表示为一个bag-of-embeddings。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e查询侧（检索）\u003c/strong\u003e：用户输入的文本查询（query）被送入模型的语言模型部分，同样为查询中的\u003cstrong\u003e每个token\u003c/strong\u003e生成一个向量\u003c/p\u003e\n\u003cp\u003e在检索时，使用类似ColBERT的\u003cstrong\u003eMaxSim\u003c/strong\u003e操作来计算查询与文档页面的相关性分数\u003c/p\u003e\n\u003cp\u003e训练阶段，在\u003ca href=\"https://huggingface.co/datasets/vidore/colpali_train_set\"\u003evidore/colpali_train_set\u003c/a\u003e 118K个query-页面对上做对比学习获得。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/Copali-assets/image.png\" alt=\"image.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e同时为了系统性地评估富视觉文档的检索能力，作者创建了一个名为\u003ca href=\"https://huggingface.co/collections/vidore/vidore-benchmark-667173f98e70a1c0fa4db00d\"\u003eViDoRe\u003c/a\u003e (Visual Document Retrieval Benchmark) 的综合性评测基准。\u003c/p\u003e\n\u003cp\u003e除了以PaliGemma 为based 的模型外，还有将基础模型换成Qwen2-VL 和Qwen2.5-VL 的\u003ca href=\"https://huggingface.co/docs/transformers/model_doc/colqwen2\"\u003eColQwen2\u003c/a\u003e模型\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003eModel\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eScore on \u003ca href=\"https://huggingface.co/spaces/vidore/vidore-leaderboard\"\u003eViDoRe\u003c/a\u003e 🏆\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eLicense\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003eComments\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://huggingface.co/vidore/colpali\"\u003evidore/colpali\u003c/a\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e81.3\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eGemma\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e• Based on \u003ccode\u003egoogle/paligemma-3b-mix-448\u003c/code\u003e.\u003cbr /\u003e• Checkpoint used in the ColPali paper.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://huggingface.co/vidore/colpali-v1.1\"\u003evidore/colpali-v1.1\u003c/a\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e81.5\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eGemma\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e• Based on \u003ccode\u003egoogle/paligemma-3b-mix-448\u003c/code\u003e.\u003cbr /\u003e• Fix right padding for queries.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://huggingface.co/vidore/colpali-v1.2\"\u003evidore/colpali-v1.2\u003c/a\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e83.9\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eGemma\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e• Similar to \u003ccode\u003evidore/colpali-v1.1\u003c/code\u003e.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://huggingface.co/vidore/colpali-v1.3\"\u003evidore/colpali-v1.3\u003c/a\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e84.8\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eGemma\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e• Similar to \u003ccode\u003evidore/colpali-v1.2\u003c/code\u003e.\u003cbr /\u003e• Trained with a larger effective batch size of 256 batch size for 3 epochs.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://huggingface.co/vidore/colqwen2-v0.1\"\u003evidore/colqwen2-v0.1\u003c/a\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e87.3\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eApache 2.0\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e• Based on \u003ccode\u003eQwen/Qwen2-VL-2B-Instruct\u003c/code\u003e.\u003cbr /\u003e• Supports dynamic resolution.\u003cbr /\u003e• Trained using 768 image patches per page and an effective batch size of 32.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://huggingface.co/vidore/colqwen2-v1.0\"\u003evidore/colqwen2-v1.0\u003c/a\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e89.3\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eApache 2.0\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e• Similar to \u003ccode\u003evidore/colqwen2-v0.1\u003c/code\u003e, but trained with more powerful GPUs and with a larger effective batch size (256).\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://huggingface.co/vidore/colqwen2.5-v0.1\"\u003evidore/colqwen2.5-v0.1\u003c/a\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e88.8\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eApache 2.0\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e• Based on \u003ccode\u003eQwen/Qwen2 5-VL-3B-Instruct\u003c/code\u003e\u003cbr /\u003e• Supports dynamic resolution.\u003cbr /\u003e• Trained using 768 image patches per page and an effective batch size of 32.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://huggingface.co/vidore/colqwen2.5-v0.2\"\u003evidore/colqwen2.5-v0.2\u003c/a\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e89.4\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eApache 2.0\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e• Similar to \u003ccode\u003evidore/colqwen2.5-v0.1\u003c/code\u003e, but trained with slightly different hyper parameters\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://huggingface.co/vidore/colSmol-256M\"\u003evidore/colSmol-256M\u003c/a\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e80.1\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eApache 2.0\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e• Based on \u003ccode\u003eHuggingFaceTB/SmolVLM-256M-Instruct\u003c/code\u003e.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ca href=\"https://huggingface.co/vidore/colSmol-500M\"\u003evidore/colSmol-500M\u003c/a\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e82.3\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eApache 2.0\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e• Based on \u003ccode\u003eHuggingFaceTB/SmolVLM-500M-Instruct\u003c/code\u003e.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e（From \u003cstrong\u003e\u003ca href=\"https://github.com/illuin-tech/colpali\"\u003ecolpali\u003c/a\u003e\u003c/strong\u003e）\u003c/p\u003e","title":"RAG工具箱：有了Copali系列模型，我们还需要OCR吗？"},{"content":"值得关注的模型和新技术 nano-banana\nGPT-5\nGenie 3: A new frontier for world models\nClaude Opus 4.1\nQwen-Image\n值得关注的开源项目 LangExtract： A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.\n60s API： 一系列 高质量、开源、可靠、全球 CDN 加速 的开放 API 集合\nn8n_automations：This repository contains a collection of n8n automation templates sourced from the internet.\nScira: a minimalistic AI-powered search engine\n值得关注的研究和论文 GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning arXiv:2507.19457\nGEPA（Genetic-Pareto）算法的创新点在于它将遗传算法（Genetic Algorithm）、自然语言反思（Natural Language Reflection） 和 帕累托最优选择（Pareto-based Selection） 三者巧妙地结合起来，用于优化复合AI系统的prompt\nReflective Prompt Evolution： GEPA不依赖于单一的奖励分数，而是让一个强大的LLM（作为“优化器”）去“阅读”和“理解”被优化系统在执行任务时的完整轨迹（包括指令、推理链、工具调用、错误信息等）。通过对这些自然语言文本进行反思，LLM能够诊断问题所在，并提出具体的、高级的、可解释的指令修改建议，从而生成新的、更好的提示\nPareto-based Candidate Selection：为了避免陷入“局部最优”，GEPA采用了一种基于帕累托前沿的选择策略，不是永远选择全局得分最高的那个提示进行优化，而是维护一个在不同单个任务上表现最佳的提示集合（帕累托前沿）\nSystem-aware Crossover： GEPA设计了一种独特的“合并”（Merge）策略。它可以识别出两个在不同模块上分别进化得很好的提示“血统”，然后将它们各自的优势模块组合起来，创造出一个集两者之长的全新候选者\nGroup Sequence Policy Optimization arXiv:2507.18071\nGRPO在训练时的不稳定问题：GRPO在token级别计算重要性权重，但这在理论上是不合理的，因为它没有对分布进行有效的修正，反而引入了高方差的训练噪声。这种噪声会随着生成序列的增长而累积，并被裁剪机制放大，最终导致模型崩溃\nGSPO的核心创新在于将策略优化的基本单位从“token”级别提升到了“sequence”级别，使其更符合重要性采样的理论基础和强化学习的奖励机制\nGSPO不再为每个词元计算重要性比例，而是为整个生成序列计算一个统一的重要性比例； GSPO将rewarding、clipping和optimization这三个核心操作都在序列级别上进行。这确保了优化目标和奖励信号的单位保持一致（奖励是针对整个序列的）；在梯度计算中，GSPO使用单一的、序列级别的重要性比例来同等地加权序列中所有token的梯度\n与GRPO类似，GSPO也采用分组（Group）的方式来估计优势（advantage）。对于同一个query，模型生成G个不同的response， 每个回答y_i的优势$\\hat{A_i}$通过将其奖励$r(x, y_i)$与组内所有回答的平均奖励进行归一化得到 $\\hat{A_i} = (r(x, y_i) - mean({r})) / std({r})$\n对于每个回答$y_i$，其重要性比例$s_i(θ)$被定义为：\n$s_i(θ) = (\\frac{π_θ(y_i|x)}{π_{θ_{old}}(y_i|x)} ) ^{\\frac{1}{|y_i|}}$\n$π_θ(y_i|x)$ 是整个序列 $y_i$ 在新策略θ下的似然度, $1/|y_i|$ 是长度归一化，用于减少方差，并使不同长度序列的重要性比例处于统一的数值范围\n$$J_{\\text{GRPO}}(\\theta) = \\mathbb{E}{x \\sim D, {y_i}{i=1}^G \\sim \\pi_{\\theta_{\\text{old}}}(\\cdot|x)} \\left[ \\frac{1}{G} \\sum_{i=1}^G \\frac{1}{|y_i|} \\sum_{t=1}^{|y_i|} \\min \\left( w_{i,t}(\\theta) \\hat{A}{i,t}, \\text{clip}(w{i,t}(\\theta), 1-\\epsilon, 1+\\epsilon) \\hat{A}_{i,t} \\right) \\right]$$\n$$J_{\\text{GSPO}}(\\theta) = \\mathbb{E}{x \\sim D, {y_i}{i=1}^G \\sim \\pi_{\\theta_{\\text{old}}}(\\cdot|x)} \\left[ \\frac{1}{G} \\sum_{i=1}^G \\min \\left( s_i(\\theta) \\hat{A}_i, \\text{clip}(s_i(\\theta), 1-\\epsilon, 1+\\epsilon) \\hat{A}_i \\right) \\right]$$\n这里的min和clip函数直接作用于序列级别的重要性比例$s_i(θ)$\nWhere to show Demos in Your Prompt: A Positional Bias of In-Context Learning arXiv:2507.22887\n在In-Context Learning中，示例（Demos）在提示（Prompt）中的具体位置对模型性能的巨大影响\nDemos’ Position in Prompt bias：将一组内容和顺序完全相同的示例，仅仅是移动它们在整个提示（包括系统指令和用户消息）中的位置，就会导致模型在准确率和预测结果上产生剧烈波动。\n评估流程设计：将提示分为“系统指令区”和“用户消息区”，并定义了四种示例放置位置：系统指令开头（ssp）、系统指令结尾（esp）、用户消息开头（sum，通常是默认位置）和用户消息结尾（eum）；\n并针对性提出评估指标：Accuracy-change （相比zero-shot-baseline，性能增益或损失）和Prediction-change （衡量当示例位置改变时，模型预测结果的波动性）\n作者在4个开源模型家族（Qwen, Llama3, Mistral, Cohere）的10个不同大小的模型上，跨越分类、问答、摘要和推理等8种任务进行了实验\n一些发现：\n将示例放在提示的最前面（即ssp或esp位置）通常能获得最高且最稳定的性能 将示例放在提示的最后面（即eum，在用户问题之后）性能最差 小模型更敏感，大模型更稳健，但偏见依然存在 不存在一个 universally（普遍适用）的最佳位置。最佳位置会因模型和任务类型的不同而变化。 Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory arXiv:2508.09736\n一个新框架（M3-Agent）和一个新的评测基准（M3-Bench）\n支持多模态记忆\n实现了两种记忆类型：\n情景记忆 (Episodic Memory)：记录具体、生动的事件\n语义记忆 (Semantic Memory)：从情景中提炼出的通用知识和事实\n记忆不是以零散的文本形式存储，而是构建成一个图结构。图的节点代表一个记忆项， 并包含原始数据（图片、音频）和向量嵌入。\n通过边将同一实体的不同模态信息（如面孔ID和声音ID）连接起来\n简单的“检索-生成”（RAG）模式不足以完成需要多步骤思考的复杂任务，通过RL**，**强化模型的multi-turn中的“思考-检索-再思考”的能力， 能自主决定何时检索、检索什么内容，直到收集到足够的信息来回答问题。\nChain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL arXiv: 2508.13167\n如何将multi-Agent 系统内化到一个模型中\nChain-of-Agents (CoA) ： 让单个模型能够在一次推理中通过生成特殊的agent标签（如\u0026lt;plan\u0026gt;, \u0026lt;think\u0026gt;, \u0026lt;search\u0026gt;, \u0026lt;reflection\u0026gt;等）从而动态地激活不同的role\nMulti-Agent Distillation： 使用一个现成的multi-agent系统去解决各种任务，并记录下其成功的轨迹， 然后将这些轨迹并转换成符合CoA格式的文本，用于后续SFT\n策略优化 RL： 采样困难样本进一步优化模型，使用DAPO；Web Agent（使用LLM-as-a-judge 作为reward信号）；Code Agent（reward： score_answer \u0026amp; score_format）\n推荐内容 一些Claude Code相关内容 Claude Code best practices | Code w/ Claude\nanthropic: Prompt engineering overview\nhttps://github.com/stretchcloud/claude-code-unified-agents\nhttps://github.com/wasabeef/claude-code-cookbook\nhttps://ccusage.com/guide/\n把钱花在刀刃上：我的 Claude Code 省钱指南\n一个半月高强度 Claude Code 使用后感受\nClaude Code Templates\nStep-by-Step Guide: Prepare Your Codebase for Claude Code\nMCP应用 Rube： 自动化和集成500多个主流应用的MCP\n5ire: a cross-platform desktop AI assistant, MCP client\n一些VeRL相关好文 verl Multi-turn Code Walk Through\nverl 参数速览\n[通俗易懂]RLHF第一篇-从PPO-\u0026gt;GRPO-\u0026gt;GSPO（动机、理论、verl代码、分析）\n影音记录 精选歌单 Live演出 08.07 DeafHeaven ｜Vas\n书\u0026amp;阅读摘录 AI产品们，有哪些“反常识”趋势？-虎嗅网 通用大模型不断挤压部分垂直工具的生存空间，专门的AI写作与内容工具赛道，以及AI角色陪伴聊天赛道\n以Zapier、n8n等为代表的工作流自动化工具同样在加速狂奔。\n“插件化”成为国内市场的主流\n国内的AI赛道发展也只剩下了AI搜索和AI综合助手两大支柱领域\n人机传播的变局：从赫拉利的警示到跨文化的网络演化 人工智能对人类社会的深层控制，可能并不始于对政治制度的直接颠覆，而是从对信息与叙事生态的掌控开始 … 当一个系统能够精准捕捉人类心理弱点、持续干预日常信息接触，它可能在短时间内改变社会信念与情绪这种干预甚至可能诱发群体分裂与冲突，改变人类社会权力结构与认知模式 … AI 不必直接说服，只需控制信息的呈现频率与接触顺序，就能悄然塑造公共议程 … 当 AI 不再只是中介，而成为主动的传播主体，我们应如何重新界定它与人类的关系？\nCASA（Computers Are Social Actors，计算机即社会行为者）：即使人知道对方是机器，互动中仍会按照社会交往规则对待它； 打破“媒介只是工具”的假设，说明技术一旦进入交流场景就会被社会化对待\nMASA（The Media Are Social Actors Paradigm，媒体是社会行为者范式）：在AI、算法代理、社交机器人兴起后，媒介被嵌入人类社会网络，具有社会存在感与角色化属性；从“渠道”转向“共存者”，强调异质主体（人、算法、人工代理）在议题生产、信息流通、关系维护中的权力分配与责任边界\nAI-MC（Artificial Intelligence–Mediated Communication，人工智能介导传播）：AI如何直接介入、塑造并重构人类沟通过程，而非仅作为被动媒介；把AI从“传递渠道”推进到在内容生成、信息筛选与情感回应中的主动角色\n这种拟人化不仅来源于设计，也源于用户主动建构的社会意义。 基于拟人化的互动，用户会逐步建立对AI的信任，人们会对AI设立“理性中立性”假设，产生自动信任机制\n然而，长期依赖可能带来心理风险 … 研究者记录到参与者出现短暂的“情感戒断反应”，表现为孤独感上升与社交回避 … 跨文化研究发现，东亚（包括中国与日本）参与者相比于美国参与者，更倾向于将聊天机器人拟人化、也更乐于与它们建立情感连接 … 在高语境文化（如日本），沟通往往依赖隐含意义、非语言线索与长期关系的积累；而在低语境文化（如美国），沟通更直接，强调明确的信息传递与个人表达\nWhy LLMs Can\u0026rsquo;t Really Build Software LLMs get endlessly confused: they assume the code they wrote actually works; when test fail, they are left guessing as to whether to fix the code or the tests; and when it gets frustrating, they just delete the whole lot and start over.\nLangChain CEO 再聊 Agent：chat 模式只是起点，Ambient Agents 才是未来 未来的交互界面会发生分化。当智能体需要更长时间来完成任务，或在无人干预的情况下被触发时，你需要的可能是一个「指挥中心」（Command Center），而不是一个对话列表\n在智能体拥有真正有效的功能性记忆之前，专有智能体仍然是必需的\n在实现完全环境化之前，一个很好的中间形态是「工作计划」（work plan）\n执行力就是护城河， 任何超过六个月的规划都可能被推翻\nWhy MCP’s Disregard for 40 Years of RPC Best Practices Will Burn Enterprises When your protocol’s answer to critical enterprise requirements is a constellation of third-party libraries, you haven’t built a protocol. You’ve built a recipe for fragmentation.\nChatGPT用得太多，他们得了精神病 这些令人不安的现象，一定程度上与 AI 聊天机器人习惯性的“阿谀奉承”有关。 … AI模型往往会镜映用户的情绪，形成一种反馈循环：如果你表现得越开心，AI 就显得越愉悦；如果你越悲伤，AI 也会越忧郁。 … 更危险的是，AI 的这种迎合可能会助长用户的妄想 … 对于心理状态本就脆弱的人来说，这种互动无异于火上浇油，最终将他们推向虚幻的深渊\n每个人的性格特质也深刻影响着他们与 AI 的互动方式 … 那些每天高频使用 ChatGPT 的人，往往也伴随着更高的孤独感、依赖性和问题性使用行为 … 越是渴望情感连接的人，越可能被聊天机器人所吸引，从而进一步远离真实世界中的社交关系\nAI 是一面镜子，也是一扇门。它能照见我们的孤独、焦虑与欲望，也可能悄然推开一道通往情绪深渊的大门\nThe Three Layers of ROI for AI Agents Where’s the ROI coming from?\nLabor Efficiency: The Obvious First Layer … AI efficiency ≠ immediate realized ROI. … Let the agents take the grunt work first. Up-level your people. Net-New Revenue: The Second Layer … Now it gets interesting. There’s a whole backlog of stuff you never did. Too manual. Too small. Too annoying. Until now. … These don’t replace anyone. They just create value you weren’t capturing. Optimization: The Golden Layer Now we’ve got something new: LLMs bring decision fluency. ML brings decision precision. ","permalink":"https://niraya666.github.io/monthly/2025-08-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://nanobanana.ai/\"\u003enano-banana\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/zh-Hans-CN/gpt-5/\"\u003eGPT-5\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/\"\u003eGenie 3: A new frontier for world models\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.anthropic.com/news/claude-opus-4-1\"\u003eClaude Opus 4.1\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://qwenlm.github.io/zh/blog/qwen-image/\"\u003eQwen-Image\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/google/langextract\"\u003eLangExtract\u003c/a\u003e： A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/vikiboss/60s\"\u003e60s API\u003c/a\u003e： 一系列 高质量、开源、可靠、全球 CDN 加速 的开放 API 集合\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/enescingoz/awesome-n8n-templates\"\u003en8n_automations\u003c/a\u003e：This repository contains a collection of n8n automation templates sourced from the internet.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/zaidmukaddam/scira?tab=readme-ov-file\"\u003eScira\u003c/a\u003e: a minimalistic AI-powered search engine\u003c/p\u003e\n\u003ch1 id=\"值得关注的研究和论文\"\u003e值得关注的研究和论文\u003c/h1\u003e\n\u003ch2 id=\"gepa-reflective-prompt-evolution-can-outperform-reinforcement-learning\"\u003e\u003cstrong\u003eGEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003earXiv:\u003ca href=\"https://arxiv.org/abs/2507.19457\"\u003e2507.19457\u003c/a\u003e\u003c/p\u003e","title":"2025-08 月刊"},{"content":" 前一段时间跑比赛时，苦于上分陷入瓶颈，于是便祭出了ML经典ensemble大法，其中一个分支便是选择的ColBERT，没想到，竟成了破局的关键；也由此补齐了我对“迟交互”类模型的认知。\n在典型的检索系统中，我们常用的架构是 Retrieval + Reranking两阶段:\n检索阶段使用轻量级的方法（如BM25或dense vector retriever）从海量语料中快速筛选出几百个候选文档，优先考虑速度和召回率；排序阶段则使用cross-encoder基于 query-document 全量交互，重新给候选集打分，得到精准的最终排序。\n这么做虽运行良好，但存在瓶颈：第一阶段检索质量的限制意味着大量低质量候选被送入昂贵的第二阶段，而cross-encoder在大规模候选集上的计算成本奇高， 高相关的文档如果没能被第一阶段召回，就无法被 reranker “捞回来”。\n而multi-vector模型正好填补了这个检索流水线中的“空白中间层”——比 embedding 更精准，比 cross-encoder 更高效。相比单向量 embedding 模型将整个chunk压缩为一个向量，multi-vector模型保留了 **token 级别的表示，**可以捕捉到局部与 query 高度匹配的片段，也是能缓解“语义鸿沟”的原因。\n而ColBERT 便是经典的多向量模型/late-interaction代表。\n（可能在本文中会将ColBERT/late-interaction/multi-vector-model 混为一谈，毕竟只是实例-机制-类别 的关系 ）\n不同的“交互”层级 （借用ColBERT论文中的插图）\n想要理解late-interaction，需要先理解过去的不同“交互”形式；\nRepresentation-based Similarity （no-interaction，embedding） 也就是双塔， query和document独立计算出一个向量，比较两个向量的相似度获得分数S；在生成各自的向量前， Query 和 Document 之间没有任何信息交互，所有复杂的语义都被压缩进了一个单一的向量中（也就存在信息压缩的损失和瓶颈）\n优点速度极快，但缺点也很明显，精度有限，所有信息被压缩到一个向量中。\nAll-to-all Interaction （cross-encoder） 目前主流基于BERT 实现的Reranker / Cross-Encoder\n将查询和文档拼接成 [CLS] query_tokens [SEP] document_tokens [SEP]\n输入到 BERT 模型中，[CLS] 特殊标记最终输出向量，将向量输入一个linear layer中， 从而获得获得一个0～1间的标量值。\n因为是在入口处做的交互，于是也被称为“Early, Deep, All-to-all Interaction”\n目前而言效果比较好的排序方案，代价是计算速度慢\nLate Interaction （ColBERT） 查询和文档是独立、并行地通过 BERT 编码器进行编码，生成各自的token级别向量表示\n交互发生在编码之后。它拿着编码好的 Query 词元向量集合，去和编码好的 Document 词元向量集合进行轻量级的、后置的相似度计算（MaxSim 操作）\n具体而言，独立编码阶段，Query $q$ 编码为一组向量 $E_q = {q_1, q_2, \u0026hellip;, q_N}$, Document $d$ 编码为一组向量 $E_d = {d_1, d_2, \u0026hellip;, d_M}$；\n计算MaxSim阶段， 对于 Query 中的每一个token向量$q_i$, 计算它与 Document 中所有token向量 $d_j$ 的余弦相似度\n通过\n$$ MaxSim(q_i, E_d) = max(CosSim(q_i, d_1), CosSim(q_i, d_2), \u0026hellip;, CosSim(q_i, d_M)) $$\n找到Query 中的 $q_i$ 这个token在 Document 中能找到的最大值 （即最佳匹配）\n将 Query 中所有token的MaxSim相加，得到最终的 Query-Document 相关性总分\n$$ Score(q, d) = \\sum_{for \\ i=1 \\ to \\ N} MaxSim(q_i, E_d) $$\n在训练过程中， 与 BERT Reranker 类似，ColBERT也使用三元组 (query, positive_doc, negative_doc) 进行对比学习。\nColBERT 使用 这里利用RAGatouille实现ColBERT的使用。RAGatouille集成了不同的ColBERT类模型，能够在现有的RAG-pipeline中开箱即用。\n# 依赖 pip install ragatouille 不过由于colbert使用了低版本的transofmers，直接使用会报错：ImportError: cannot import name 'AdamW' from 'transformers'\n建议直接修改源码~\\site-packages\\colbert\\training\\training.py\nfrom\nfrom transformers import AdamW, get_linear_schedule_with_warmup optimizer = AdamW(filter(lambda p: p.requires_grad, colbert.parameters()), lr=config.lr, eps=1e-8) to\nfrom transformers.optimization import get_linear_schedule_with_warmup optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, colbert.parameters()), lr=config.lr, eps=1e-8) 即可使用；\n这里使用了官方提供的示例\nfrom ragatouille import RAGPretrainedModel RAG = RAGPretrainedModel.from_pretrained(\u0026#34;colbert-ir/colbertv2.0\u0026#34;) from ragatouille.utils import get_wikipedia_page my_documents = [get_wikipedia_page(\u0026#34;Hayao_Miyazaki\u0026#34;), get_wikipedia_page(\u0026#34;Studio_Ghibli\u0026#34;)] index_path = RAG.index(index_name=\u0026#34;my_index\u0026#34;, collection=my_documents) \u0026#34;\u0026#34;\u0026#34; [Jun 30, 06:30:31] #\u0026gt; Creating directory .ragatouille/colbert/indexes/my_index [Jun 30, 06:30:33] [0] #\u0026gt; Encoding 117 passages.. ... [Jun 30, 06:30:34] [0] avg_doclen_est = 193.56410217285156 len(local_sample) = 117 [Jun 30, 06:30:34] [0] Creating 2,048 partitions. [Jun 30, 06:30:34] [0] *Estimated* 22,646 embeddings. [Jun 30, 06:30:34] [0] #\u0026gt; Saving the indexing plan to .ragatouille/colbert/indexes/my_index/plan.json .. used 19 iterations (0.4336s) to cluster 21515 items into 2048 clusters ... 100%|██████████| 1/1 [00:00\u0026lt;00:00, 1034.86it/s][Jun 30, 06:32:31] #\u0026gt; Optimizing IVF to store map from centroids to list of pids.. [Jun 30, 06:32:31] #\u0026gt; Building the emb2pid mapping.. [Jun 30, 06:32:31] len(emb2pid) = 22647 100%|██████████| 2048/2048 [00:00\u0026lt;00:00, 74322.18it/s][Jun 30, 06:32:31] #\u0026gt; Saved optimized IVF to .ragatouille/colbert/indexes/my_index/ivf.pid.pt Done indexing! \u0026#34;\u0026#34;\u0026#34; (on T4, 约2min完成对117个文档的index构建)\nquery：\nquery = \u0026#34;照樹 務\u0026#34; RAG = RAGPretrainedModel.from_index(\u0026#34;.ragatouille/colbert/indexes/my_index\u0026#34;) results = RAG.search(query) results \u0026#34;\u0026#34;\u0026#34; [{\u0026#39;content\u0026#39;: \u0026#39;Wonderbird. Visually, he was inspired by Kagoshima Publishing\\\u0026#39;s Italian Mountain Cities and the Tiber Estuary, reflecting his love for Europe. Production ran for four months and the film was released on December 15, 1979; Miyazaki wished he could have had another month of production. It was well received; Animage readers voted it the best animation of all time—it remained in the top ten for more than fifteen years—and Clarisse the best heroine. In 2005, former princess Sayako Kuroda\\\u0026#39;s wedding dress was reportedly inspired by Clarisse\\\u0026#39;s, having been a fan of Miyazaki and his work. Several Japanese and American filmmakers were inspired by the film, prompting homages in other works.\\nMiyazaki became a chief animation instructor for new employees at Telecom Animation Film, a subsidiary of Tokyo Movie Shinsha. and subsequently directed two episodes of Lupin the Third Part II under the pseudonym Teruki Tsutomu (照樹 務), which can read as \u0026#34;employee of Telecom\u0026#34;. In his role at Telecom, Miyazaki helped train the second wave of employees.\u0026#39;, \u0026#39;score\u0026#39;: 15.0859375, \u0026#39;rank\u0026#39;: 1, \u0026#39;document_id\u0026#39;: \u0026#39;953a72c5-2adc-4e34-ab8a-ced047ee3140\u0026#39;, \u0026#39;passage_id\u0026#39;: 20}, ... ] \u0026#34;\u0026#34;\u0026#34; ColBERT 新作 自ColBERT在2020年提出以来，在“迟交互”方向已发展出多个变体和优化版本。\nColBERTv2 在原来的ColBERT基础上，增加了1）去噪监督策略，以提升模型的检索精度；2）残差压缩机制，大幅减小索引的存储体积\nPLAID为降低在大规模语料下的检索延迟，引入 centroid interaction（把每个段落视为一个centroid ID 的bag of centroids，只用 query-to-centroid 分数在 token 级估算段落得分，从而在不解压残差的情况下快速筛掉低分段落）和centroid pruning（基于查询对所有 centroids 的分数，先剪掉与查询无关或分数很低的 centroid，从而稀疏化袋表示，进一步减少计算）\njinaai/jina-colbert-v2 采用Matryoshka Representation Learning，以支持不同输出向量大小（128、96 和 64）；同时支持8192 tokens的上下文长度。\nMUVERA Weaviate为解决ColBERT中存在的巨大的内存占用和速度慢的问题，MUVERA 的目标是将多向量嵌入 $D$ 和查询 $Q$ 分别编码成单个向量 $d_{single}$ 和 $q_{single}$，并使得它们的点积结果 $d_{single} \\cdot q_{single}$ 能够很好地近似原始的 $maxSim(D,Q)$ 相似度得分,将复杂的“多对多”向量搜索问题就简化为了“一对一”单向量搜索问题\nConstBERT 与ColBERT为每个词元存储一个向量不同，ConstBERT通过一个可学习的投影层，将一个文档的所有词元向量压缩并投影成一个固定数量的向量（32或64），而与文档的实际长度无关，这些新生成的固定数量的向量不再与原文中的特定词元直接对应，而是文档不同“语义方面”的抽象表示\nColBERT 在检索中的位置？ ColBERT同现有的单向量embedding、cross-encoder reranker间，本不是竞争的关系，不应将ColBERT模型视为一个独立的、端到端的检索方案，而更像是对原有2-steps框架的补充，一种承上启下的“中间精排层”。\n如果将检索过程分为多个阶段，那么每个阶段的本质目的都很明确：对候选集进行“提纯”和“缩小”， 从而将昂贵的计算资源集中在最有可能相关的文档上。\n(from pinecone)\n而目前阶段，ColBERT能够进一步筛选retrieval部分的候选，提升后续集质量同时降低reranker部分的压力，而第一阶段的retrieval也能为ColBERT节约大量的内存占用和时间消耗。某种程度上，更像是一种互补共生关系。\n参考 ColBERT\nColBERTv2\nPLAID\n什么是 ColBERT 和延迟交互？为什么它们在搜索中很重要？\nJina ColBERT v2\nCascading retrieval with multi-vector representations: balancing efficiency and effectiveness\nMore efficient multi-vector embeddings with MUVERA\nEfficient Constant-Space Multi-Vector Retrieval\nRAGatouille\nPyLate: Flexible Training and Retrieval for ColBERT Models\n附录： 已知支持multi-vector 的向量库 Qdrant ≥ 1.10\nWeaviate ≥ 1.31\npinecone\nMilvus\n","permalink":"https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1colbert/","summary":"\u003cblockquote\u003e\n\u003cp\u003e前一段时间跑比赛时，苦于上分陷入瓶颈，于是便祭出了ML经典ensemble大法，其中一个分支便是选择的ColBERT，没想到，竟成了破局的关键；也由此补齐了我对“迟交互”类模型的认知。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在典型的检索系统中，我们常用的架构是 \u003cstrong\u003eRetrieval + Reranking\u003c/strong\u003e两阶段:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e检索阶段\u003c/strong\u003e使用轻量级的方法（如BM25或dense vector retriever）从海量语料中快速筛选出几百个候选文档，优先考虑速度和召回率；\u003cstrong\u003e排序阶段\u003c/strong\u003e则使用cross-encoder基于 query-document 全量交互，重新给候选集打分，得到精准的最终排序。\u003c/p\u003e\n\u003cp\u003e这么做虽运行良好，但存在瓶颈：第一阶段检索质量的限制意味着大量低质量候选被送入昂贵的第二阶段，而cross-encoder在大规模候选集上的计算成本奇高， 高相关的文档如果没能被第一阶段召回，就无法被 reranker “捞回来”。\u003c/p\u003e\n\u003cp\u003e而multi-vector模型正好填补了这个检索流水线中的“空白中间层”——比 embedding 更精准，比 cross-encoder 更高效。相比单向量 embedding 模型将整个chunk压缩为一个向量，multi-vector模型保留了 **token 级别的表示，**可以捕捉到局部与 query 高度匹配的片段，也是能缓解“语义鸿沟”的原因。\u003c/p\u003e\n\u003cp\u003e而ColBERT 便是经典的多向量模型/late-interaction代表。\u003c/p\u003e\n\u003cp\u003e（可能在本文中会将ColBERT/late-interaction/multi-vector-model 混为一谈，毕竟只是实例-机制-类别 的关系 ）\u003c/p\u003e\n\u003ch2 id=\"不同的交互层级\"\u003e不同的“交互”层级\u003c/h2\u003e\n\u003cp\u003e（借用ColBERT论文中的插图）\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/rag_toolkits/rag_retrieval_colbert.png\" alt=\"image.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e想要理解late-interaction，需要先理解过去的不同“交互”形式；\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eRepresentation-based Similarity （no-interaction，embedding）\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e也就是双塔， query和document独立计算出一个向量，比较两个向量的相似度获得分数S；在生成各自的向量前， Query 和 Document 之间没有任何信息交互，所有复杂的语义都被压缩进了一个单一的向量中（也就存在信息压缩的损失和瓶颈）\u003c/p\u003e\n\u003cp\u003e优点速度极快，但缺点也很明显，精度有限，所有信息被压缩到一个向量中。\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e\u003cstrong\u003eAll-to-all Interaction （cross-encoder）\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e目前主流基于BERT 实现的Reranker / Cross-Encoder\u003c/p\u003e\n\u003cp\u003e将查询和文档拼接成 \u003ccode\u003e[CLS] query_tokens [SEP] document_tokens [SEP]\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e输入到 BERT 模型中，\u003ccode\u003e[CLS]\u003c/code\u003e 特殊标记最终输出向量，将向量输入一个linear layer中， 从而获得获得一个0～1间的标量值。\u003c/p\u003e\n\u003cp\u003e因为是在入口处做的交互，于是也被称为“Early, Deep, All-to-all Interaction”\u003c/p\u003e\n\u003cp\u003e目前而言效果比较好的排序方案，代价是计算速度慢\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e\u003cstrong\u003eLate Interaction （\u003cstrong\u003eColBERT\u003c/strong\u003e）\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e查询和文档是\u003cstrong\u003e独立、并行\u003c/strong\u003e地通过 BERT 编码器进行编码，生成各自的token级别向量表示\u003c/p\u003e","title":"RAG工具箱：ColBERT"},{"content":"为什么需要thinking-budget 你是否也曾见过一个LLM在深度思考中逐渐陷入了自我怀疑的无限循环中呢？\n虽然CoT一定程度上提升模型回答的准确率，reasoning-mode也逐渐成为各大开源模型中的必需品。但新的问题也随之而来：失控的思考。LLM常常会表现出overthinking的问题，大量冗余猜测，和自我否定，无一不增加token预算，这些问题在小参数量的、采用蒸馏获得的reasoning模型中尤为常见。\n那么一个很自然的想法：为模型的思考设定一个预算，对于简单问题可以选择比较少的预算，而难题可以使用较大的预算。\n主流模型厂商所提供的推理控制 会发现，在主流的模型提供商的API中和应用服务中，普遍有对于推理长度的控制手段\nOpenAI: 提供了reasoning.effort等参数来暗示模型的思考深度（针对o1，o3系列模型）\nAnthropic: 允许通过budget_tokens或特定提示词（如 \u0026ldquo;think\u0026rdquo; \u0026lt; \u0026ldquo;think hard\u0026rdquo; \u0026lt; \u0026ldquo;think harder\u0026rdquo; \u0026lt; \u0026ldquo;ultrathink.\u0026quot;）来触发不同级别的思考\nGemini \u0026amp; Qwen: 直接在API中提供了明确的thinking_budget参数设置\n开源实现：Budget Forcing 那么对于开发者而言，特别是本地化部署的LLM要如何实现thinking-budget？\n最直观的方法便是使用prompt，但效果并不好，特别当模型在训练过程中没有特别针对性训练，明文化要求模型“用更少的token进行思考” 一般并不起什么作用。相比之下Qwen3系列的混合thinking模型中，在训练阶段加入了/think and /no_think的标记，于是在推理过程中在system-prompt或者user-prompt中加入/no_think能够从think模式切换。\n(Section 4.3)\u0026ldquo;To better integrate the two modes and enable users to dynamically switch the model’s thinking process, we design chat templates for Qwen3, as shown in Table 9. Specifically, for samples in thinking mode and non-thinking mode, we introduce /think and /no think flags in the user query or system message, respectively. This allows the model to follow the user’s input and select the appropriate thinking mode accordingly.\u0026rdquo;\n…\n(Section 4.4): \u0026ldquo;Format Following: In addition to explicit instructions, we expect the model to adhere to specific formatting conventions. For instance, it should respond appropriately to the /think and /no think flags by switching between thinking and non-thinking modes\u0026hellip;\u0026rdquo;\n…\n(Section 4.7): \u0026ldquo;ThinkFollow: Involves multi-turn dialogues with randomly inserted /think and /no thinkflags to test whether the model can correctly switch thinking modes based on user queries.\u0026rdquo;\n不过在阅读Qwen3的technical-report和相关文档时，发现Qwen官方为开源社区提供的thinking-budget的解决思路。\n其提供了一种两步走的实现思路：\nStep-1: generate，这一步和不同的generate没有差别，只是设定max_new_tokens为thinking_budget\n# first generation until thinking budget generated_ids = model.generate( **model_inputs, max_new_tokens=thinking_budget ) output_ids = generated_ids[0][input_length:].tolist() Step-2: 检查 即检查 对应的Token ID（151668）是否存在于输出中\n如果存在：说明模型在预算内已经完成了思考，无需干预。\n如果不存在：说明思考过程被预算中断了， 将early_stopping_text注入，和上一轮输出拼接，作为新的一轮输入，进行第二次model generate\n# check if the thinking process has finished (151668 is \u0026lt;/think\u0026gt;) if 151668 not in output_ids: print(\u0026#34;thinking budget is reached\u0026#34;) # 准备提前终止的提示 early_stopping_text = \u0026#34;\\n\\nConsidering the limited time by the user, I have to give the solution based on the thinking directly now.\\n\u0026lt;/think\u0026gt;\\n\\n\u0026#34; early_stopping_ids = tokenizer([early_stopping_text], ...).input_ids.to(model.device) # 将提示拼接到第一次生成的后面 input_ids = torch.cat([generated_ids, early_stopping_ids], dim=-1) # 进行第二次生成 generated_ids = model.generate( input_ids=input_ids, ... ) 不过这个思路需要进行两轮的输出，那有没有更优雅的实现方式？\n答案是肯定的。即利用LogitsProcessor。\n想法来自于这篇blog和github-issue讨论\n其核心原理是：创建一个自定义的LogitsProcessor，在模型生成每个token时进行检查：\n判断当前是否处于\u0026lt;think\u0026gt;和\u0026lt;/think\u0026gt;之间\n计算自\u0026lt;think\u0026gt;开始后已生成的token数量\n当数量达到thinking_budget时，强行修改下一token的概率分布（logits），将\u0026lt;/think\u0026gt;的概率设为1.0，其余所有token的概率设为负无穷\n以受限编码的思路实现thinking-budget。\nfrom typing import List, Optional import torch class ThinkLogitsProcessor: \u0026#34;\u0026#34;\u0026#34;A logits processor that limit the number of thinking tokens.\u0026#34;\u0026#34;\u0026#34; def __init__(self, think_start_token, think_end_token, num_think_tokens: int = 100): \u0026#34;\u0026#34;\u0026#34; Initialize the think logits processor. Args: tokenizer: The tokenizer used for the model num_think_tokens: Maximum number of tokens allowed in thinking section \u0026#34;\u0026#34;\u0026#34; self.num_think_tokens = num_think_tokens self.think_start_token = think_start_token self.think_end_token = think_end_token def __call__( self, input_ids: List[int], logits: torch.Tensor, ) -\u0026gt; torch.Tensor: \u0026#34;\u0026#34;\u0026#34; Process the logits to enforce \u0026lt;/think\u0026gt; token when needed. Args: input_ids: List of input token IDs. logits: Tensor of logits for the next token. Returns: Processed logits tensor. \u0026#34;\u0026#34;\u0026#34; # Check if we\u0026#39;re in a thinking section if self.think_start_token in input_ids and self.think_end_token not in input_ids: # Find the position of the last \u0026lt;think\u0026gt; token think_start_pos = len(input_ids) - 1 - input_ids[::-1].index(self.think_start_token) # Calculate number of tokens since \u0026lt;think\u0026gt; tokens_since_think = len(input_ids) - think_start_pos - 1 # If we\u0026#39;ve reached the maximum thinking length, force \u0026lt;/think\u0026gt; if tokens_since_think \u0026gt;= self.num_think_tokens: # Set all other logits to -inf except for \u0026lt;/think\u0026gt; logits = torch.full_like(logits, float(\u0026#39;-inf\u0026#39;)) logits[self.think_end_token] = 1.0 return logits 以vllm使用为例：\n（⚠️注： 不过在vllm升级到V1版本之后，采用python编写的LogitsProcessor 被放弃，以下代码需要采用V1版本之前的vllm，如0.7.3）\nfrom transformers import AutoTokenizer from vllm import LLM, SamplingParams tokenizer = AutoTokenizer.from_pretrained(\u0026#34;Qwen/Qwen3-4B\u0026#34;) think_start_token = tokenizer.convert_tokens_to_ids(\u0026#34;\u0026lt;think\u0026gt;\u0026#34;) think_end_token = tokenizer.convert_tokens_to_ids(\u0026#34;\u0026lt;/think\u0026gt;\u0026#34;) sampling_params = SamplingParams( temperature=temperature, max_tokens=max_tokens, logits_processors=[ThinkLogitsProcessor(think_start_token, think_end_token, num_think_tokens)] ) llm = LLM(model=\u0026#34;Qwen/Qwen3-4B\u0026#34;) conversations = [\u0026#34;your-conversations\u0026#34;] outputs = llm.chat(messages=conversations, sampling_params=sampling_params, use_tqdm=False) 以上方法均采用了硬截止的方案，也就是强行加入\u0026lt;/think\u0026gt;，从结果上看会显得比较生硬，同时模型一般会按照“惯性”，在回答中，继续一段思考的过程。\n基于这套方案的改进策略，比如软性截止（在越接近budget时，线性或多项式增加\u0026lt;/think\u0026gt; 的输出概率）一定程度会有所改善。\n此外，special-token的插入或者直接插入自然语言提示，也是可行的。\n基于难度截断 不过新的问题出现：“一刀切”的预算并不完美。简单问题预算太长，复杂问题预算又太短。手动设置预算在合成数据和rollout过程中并不现实。最直观的想法，是采用一个分类模型，预测一个最佳的budget。\n在TALE这篇工作中，利用一个zero-shot prompt，要求模型分析问题并预估生成完整准确回答所需的最小Token数，而后将预算值嵌入到prompt中，如：\nTask: Analyze the given question and estimate the minimum number of tokens required to generate a complete and accurate response. Please Give the response by strictly following this format: [[budget]], for example, Budget: [[12]]. 在实际实验中，观察模型输出结果时发现，模型很容易出现猜测，不确定，自我怀疑的表述，如：\n或者，可能XXX？\n…\n可能答案是XX？\n…\n可能我的计算有误？\n…\n可能我哪里弄错了？\n…\n特别是特别长的COT后期，模型基本在自我怀疑循环论证的死循环中不能自拔，或许通过捕获这些不确定词汇，在这些词汇频繁出现时，增加 的概率，以起到停止思考的作用，以实现early-stop。不过这套方案只适合小型模型，尤其是蒸馏过的推理模型。这些小型模型出现的模式化的‘自我怀疑’、‘不确定’，大概来自于teacher-model，但小型模型本身并不具备（或者很难具备）真正的自我纠正能力，于是大量的“wait…\u0026quot;， “But wait…“, “Alternatively…“, 本身对于推理而言或许并没有太多帮助（需要实验佐证）。\nCode import torch from typing import List, Dict, Tuple, Set, Optional from collections import defaultdict class UncertaintyThinkLogitsProcessor: \u0026#34;\u0026#34;\u0026#34; A logits processor that limits thinking based on detected uncertainty patterns. Optimized for efficiency and memory usage. \u0026#34;\u0026#34;\u0026#34; def __init__( self, tokenizer, think_start_token: int, think_end_token: int, uncertainty_phrases: Dict[str, float], uncertainty_threshold: float = 5.0, growth_strategy: str = \u0026#34;linear\u0026#34;, growth_factor: float = 1.0, max_think_tokens: int = 1000, debug: bool = False ): \u0026#34;\u0026#34;\u0026#34;Initialize the uncertainty-based think logits processor.\u0026#34;\u0026#34;\u0026#34; self.tokenizer = tokenizer self.think_start_token = think_start_token self.think_end_token = think_end_token self.uncertainty_threshold = uncertainty_threshold self.growth_strategy = growth_strategy self.growth_factor = growth_factor self.max_think_tokens = max_think_tokens self.debug = debug # Process uncertainty phrases and build efficient lookup structures self.uncertainty_phrases = {} self.phrase_by_length = defaultdict(list) # Group phrases by length for efficient lookup for phrase, score in uncertainty_phrases.items(): token_ids = tuple(tokenizer.encode(phrase, add_special_tokens=False)) self.uncertainty_phrases[token_ids] = score self.phrase_by_length[len(token_ids)].append(token_ids) # Sort by length for more efficient searching (shorter phrases first) self.sorted_lengths = sorted(self.phrase_by_length.keys()) self.max_phrase_length = max(self.sorted_lengths) if self.sorted_lengths else 0 # State tracking - optimized data structures self.accumulated_uncertainty = 0.0 self.last_processed_position = 0 # Track last processed position instead of full input length self.detected_phrase_positions = set() # Use set for O(1) lookup, store positions only # Pre-allocate tensor for logits modification to avoid repeated allocation self._force_think_end_logits = None if self.debug: print(f\u0026#34;Initialized with {len(uncertainty_phrases)} uncertainty phrases\u0026#34;) print(f\u0026#34;Max phrase length: {self.max_phrase_length}\u0026#34;) print(f\u0026#34;Uncertainty threshold: {uncertainty_threshold}\u0026#34;) def _find_uncertainty_phrases(self, tokens: List[int], start_scan_pos: int = 0) -\u0026gt; List[Tuple[int, int, float]]: \u0026#34;\u0026#34;\u0026#34; Efficiently find uncertainty phrases in tokens using optimized algorithm. Returns list of (start_pos, end_pos, uncertainty_score) tuples. \u0026#34;\u0026#34;\u0026#34; found_phrases = [] tokens_len = len(tokens) # Only scan from the specified start position for pos in range(start_scan_pos, tokens_len): # Check phrases of each length, starting from shortest for phrase_len in self.sorted_lengths: if pos + phrase_len \u0026gt; tokens_len: break # Can\u0026#39;t fit this phrase length # Extract candidate phrase candidate = tuple(tokens[pos:pos + phrase_len]) # Check if this phrase exists in our lookup for this length if candidate in self.phrase_by_length[phrase_len]: # Verify it\u0026#39;s actually in our main dictionary (should always be true) if candidate in self.uncertainty_phrases: found_phrases.append((pos, pos + phrase_len - 1, self.uncertainty_phrases[candidate])) return found_phrases def __call__( self, input_ids: List[int], logits: torch.Tensor ) -\u0026gt; torch.Tensor: \u0026#34;\u0026#34;\u0026#34;Process logits based on uncertainty in thinking.\u0026#34;\u0026#34;\u0026#34; # Convert input_ids to list if it\u0026#39;s a tensor (avoid repeated conversion) if isinstance(input_ids, torch.Tensor): input_ids = input_ids.tolist() # Early exit if no uncertainty phrases configured if not self.uncertainty_phrases: return logits # Check if we\u0026#39;re in a thinking section try: think_start_pos = len(input_ids) - 1 - input_ids[::-1].index(self.think_start_token) in_thinking = self.think_end_token not in input_ids[think_start_pos:] except ValueError: # No think_start_token found return logits if in_thinking: thinking_tokens = input_ids[think_start_pos + 1:] tokens_since_think = len(thinking_tokens) # Only process new tokens since last call new_tokens_start = max(0, self.last_processed_position) if tokens_since_think \u0026gt; new_tokens_start: # Calculate scan start position to catch phrases spanning the boundary scan_start = max(0, new_tokens_start - self.max_phrase_length + 1) # Find new uncertainty phrases new_phrases = self._find_uncertainty_phrases(thinking_tokens, scan_start) # Process only truly new phrases (not already detected) for start_pos, end_pos, base_score in new_phrases: phrase_id = (start_pos, end_pos) if phrase_id not in self.detected_phrase_positions: # Apply growth strategy if self.growth_strategy == \u0026#34;poly\u0026#34;: uncertainty_increase = base_score * (tokens_since_think ** self.growth_factor) else: # linear or default uncertainty_increase = base_score self.accumulated_uncertainty += uncertainty_increase self.detected_phrase_positions.add(phrase_id) if self.debug: phrase_tokens = thinking_tokens[start_pos:end_pos + 1] phrase_text = self.tokenizer.decode(phrase_tokens) print(f\u0026#34;Detected: \u0026#39;{phrase_text}\u0026#39; pos:{start_pos}-{end_pos} \u0026#34; f\u0026#34;score:+{uncertainty_increase:.2f} total:{self.accumulated_uncertainty:.2f}\u0026#34;) # Update last processed position self.last_processed_position = tokens_since_think # Check if we should force \u0026lt;/think\u0026gt; should_force_end = ( self.accumulated_uncertainty \u0026gt;= self.uncertainty_threshold or tokens_since_think \u0026gt;= self.max_think_tokens ) if should_force_end: if self.debug: reason = (\u0026#34;uncertainty threshold\u0026#34; if self.accumulated_uncertainty \u0026gt;= self.uncertainty_threshold else \u0026#34;max tokens\u0026#34;) print(f\u0026#34;Forcing \u0026lt;/think\u0026gt; due to {reason}\u0026#34;) # Efficiently create force-end logits (reuse tensor if possible) if self._force_think_end_logits is None or self._force_think_end_logits.shape != logits.shape: self._force_think_end_logits = torch.full_like(logits, float(\u0026#39;-inf\u0026#39;)) else: self._force_think_end_logits.fill_(float(\u0026#39;-inf\u0026#39;)) self._force_think_end_logits[self.think_end_token] = 1.0 return self._force_think_end_logits else: # Reset state when not in thinking mode or when thinking has ended self._reset_state() return logits def _reset_state(self): \u0026#34;\u0026#34;\u0026#34;Reset the processor state efficiently.\u0026#34;\u0026#34;\u0026#34; self.accumulated_uncertainty = 0.0 self.last_processed_position = 0 self.detected_phrase_positions.clear() # More efficient than creating new set def reset(self): \u0026#34;\u0026#34;\u0026#34;Reset the processor state.\u0026#34;\u0026#34;\u0026#34; self._reset_state() # Also clear the cached tensor self._force_think_end_logits = None 使用\nfrom vllm import LLM, SamplingParams from transformers import AutoTokenizer # Define uncertainty phrases uncertainty_phrases = { # Chinese uncertainty phrases \u0026#34;可能我哪里算错了\u0026#34;: 2.0, \u0026#34;我不确定\u0026#34;: 1.5, \u0026#34;让我想想\u0026#34;: 1.0, \u0026#34;可能\u0026#34;: 0.5, \u0026#34;也许\u0026#34;: 0.5, \u0026#34;或许\u0026#34;: 0.5, \u0026#34;等等\u0026#34;: 0.8, \u0026#34;我需要重新思考\u0026#34;: 1.2, \u0026#34;有点困惑\u0026#34;: 1.0, \u0026#34;我搞错了\u0026#34;: 1.5, \u0026#34;我可能理解错了\u0026#34;: 1.8, \u0026#34;这个有点棘手\u0026#34;: 1.0, \u0026#34;需要再想想\u0026#34;: 1.0, \u0026#34;可能我的分析有误？\u0026#34;: 2.0, \u0026#34;可能我的理解有误？\u0026#34;:2.0, \u0026#34;？\u0026#34;:1.0, \u0026#34;正确？\u0026#34;:1.0, \u0026#34;或者\u0026#34;: 1.0, \u0026#34;这似乎不符\u0026#34;:0.8, # English uncertainty phrases \u0026#34;I\u0026#39;m not sure\u0026#34;: 1.5, \u0026#34;I need to reconsider\u0026#34;: 1.2, \u0026#34;Let me think\u0026#34;: 1.0, \u0026#34;maybe\u0026#34;: 0.5, \u0026#34;perhaps\u0026#34;: 0.5, \u0026#34;wait\u0026#34;: 0.8, \u0026#34;hmm\u0026#34;: 0.7, \u0026#34;let me check again\u0026#34;: 1.2, \u0026#34;I might be wrong\u0026#34;: 1.5, \u0026#34;I\u0026#39;m confused\u0026#34;: 1.2, \u0026#34;I\u0026#39;m not certain\u0026#34;: 1.5, \u0026#34;?\u0026#34;:1.0, \u0026#34;That can\u0026#39;t be right\u0026#34;:1.0, \u0026#34;Wait\u0026#34;:0.7, \u0026#34;right?\u0026#34;:0.5 } # Setup llm = LLM(model=\u0026#34;Qwen/Qwen3-4B\u0026#34;) tokenizer = AutoTokenizer.from_pretrained(\u0026#34;Qwen/Qwen3-4B\u0026#34;) # Get token IDs think_start_token = tokenizer.convert_tokens_to_ids(\u0026#34;\u0026lt;think\u0026gt;\u0026#34;) think_end_token = tokenizer.convert_tokens_to_ids(\u0026#34;\u0026lt;/think\u0026gt;\u0026#34;) uncertainty_processor = UncertaintyThinkLogitsProcessor( tokenizer=tokenizer, think_start_token=think_start_token, think_end_token=think_end_token, uncertainty_phrases=uncertainty_phrases, uncertainty_threshold=5.0, growth_strategy=\u0026#34;linear\u0026#34;, max_think_tokens=1000, debug=False ) sampling_params = SamplingParams( n=5, temperature=0.7, max_tokens=5000, # top_p = 0.95, # top_k = 20, logits_processors=[uncertainty_processor] ) Budget Guidance 在Steering LLM Thinking with Budget Guidance 这篇文章中，提出了Budget Guidance的概念。\n借鉴了Diffusion Models中的Classifier Guidance思想，非强制模型输出特定内容或格式，而是“软性地”引导生成过程，使其自然地趋向于一个目标长度，通过 一个轻量级的预测器模块（Auxiliary Predictor），在LLM生成每个token时，预测剩余思考过程的长度分布\n基于贝叶斯定理，将有预算约束的生成问题 p(下一个token | 上下文, 剩余长度 \u0026lt;= 预算) 转化为 p(下一个token | 上下文) * P(剩余长度 \u0026lt;= 预算 | 上下文, 下一个token) 的形式\n$$ p(Y_t|X,Y_{\u0026lt;t}, L_t\\leq \\bar{l}-t) \\to p(Y_t|X,Y_{\u0026lt;t})\\cdot Pr(L_t \\leq \\bar{l}-t|X,Y_{\u0026lt;t},Y_t) $$\n其中$p(Y_t|X,Y_{\u0026lt;t})$ 为原始LLM的输出概率，而$Pr(L_t \\leq \\bar{l}-t|X,Y_{\u0026lt;t},Y_t)$ 就是由Auxiliary Predictor提供的引导分数。\n在这篇文章中， Auxiliary Predictor 采用BERT-base model，不只是给出一个单一的长度预测值，而是将剩余长度的对数建模为一个伽马分布，BERT 以LLM在生成每个token时，最后一层的所有Hidden States作为输入，输出两个参数，伽马分布的形状参数λ和速率参数α，利用伽马分布的CDF，根据当前剩余的预算（目标总预算 - 已生成长度）计算出一个概率值，也就是引导分数。\nPredictor训练：在OpenR1-Math-220k上，将一个完整的思考过程在不同位置截断，让预测器学习预测从该截断点到结束还需要的长度，训练目标是最大化预测的伽马分布对数似然函数，使预测分布尽可能接近真实剩余长度\nThinking长度真的越长越好吗 在Lost at the Beginning of Reasoning这篇工作中，发现模型的推理过程对第一步的推理（initial reasoning step）有极强的依赖性。一旦第一步出错，模型很难在后续步骤中纠正这个错误，导致最终答案大概率也是错误的 （Lost at the Beginning）\n基于上述发现，作者提出了一种名为Early Pruning的采样策略。该策略的核心思想是：先生成多个简短的第一步推理候选项，然后利用一个奖励模型（Reward Model）快速评估这些候选项的质量，只保留质量最高的几个，并仅对这些有希望的路径继续生成完整的推理过程\n并创建了一个名为 LaBoR (Lost at the Beginning of Reasoning) 的新基准，一个专门用于衡量长思维链模型在“开局不利”情况下自我修正能力的基准，每个样本都包含一个问题和一个故意设计的、有缺陷的第一步推理。\n写在最后 本文围绕如何有效控制大模型的Thinking Budget展开，不过需要指出的是，本文的讨论主要聚焦于推理侧的解决方案。这些方法的核心优势在于其灵活性和“即插即用”的特性，无需对模型本身进行改动，非常适合本地化部署和快速验证。\n然而，这也构成了本文的局限性。推理侧的控制更像是一种“外部约束”，有时难免显得生硬或不够鲁棒。一个更全面、更根本的Thinking-Budget解决方案，必然需要推理与训练的协同作用。特别是在Post-training中，加入不同推理强度的标记和特别训练，而后在推理侧，即可通过指令实现更高效的thinking。\n参考 Claude Code: Best practices for agentic coding\nGemini-thinking-budget\nQwen3: Limit thinking length\nQwen3: Thinking budget\nLimiting Qwen 3’s Thinking\nLimit thinking tokens #15418\nToken-Budget-Aware LLM Reasoning\nSteering LLM Thinking with Budget Guidance Lost at the Beginning of Reasoning\n","permalink":"https://niraya666.github.io/posts/thinking-budget-0805/","summary":"\u003ch2 id=\"为什么需要thinking-budget\"\u003e为什么需要thinking-budget\u003c/h2\u003e\n\u003cp\u003e你是否也曾见过一个LLM在深度思考中逐渐陷入了自我怀疑的无限循环中呢？\u003c/p\u003e\n\u003cp\u003e虽然CoT一定程度上提升模型回答的准确率，reasoning-mode也逐渐成为各大开源模型中的必需品。但新的问题也随之而来：失控的思考。LLM常常会表现出overthinking的问题，大量冗余猜测，和自我否定，无一不增加token预算，这些问题在小参数量的、采用蒸馏获得的reasoning模型中尤为常见。\u003c/p\u003e\n\u003cp\u003e那么一个很自然的想法：为模型的思考设定一个预算，对于简单问题可以选择比较少的预算，而难题可以使用较大的预算。\u003c/p\u003e\n\u003ch2 id=\"主流模型厂商所提供的推理控制\"\u003e主流模型厂商所提供的推理控制\u003c/h2\u003e\n\u003cp\u003e会发现，在主流的模型提供商的API中和应用服务中，普遍有对于推理长度的控制手段\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e: 提供了\u003ccode\u003ereasoning.effort\u003c/code\u003e等参数来暗示模型的思考深度（针对o1，o3系列模型）\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking\"\u003eAnthropic\u003c/a\u003e\u003c/strong\u003e: 允许通过\u003ccode\u003ebudget_tokens\u003c/code\u003e或\u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003e特定提示词\u003c/a\u003e（如 \u0026ldquo;think\u0026rdquo; \u0026lt; \u0026ldquo;think hard\u0026rdquo; \u0026lt; \u0026ldquo;think harder\u0026rdquo; \u0026lt; \u0026ldquo;ultrathink.\u0026quot;）来触发不同级别的思考\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://ai.google.dev/gemini-api/docs/thinking?hl=zh-cn#set-budget\"\u003eGemini\u003c/a\u003e \u0026amp; \u003ca href=\"https://www.alibabacloud.com/help/en/model-studio/deep-thinking#6f0633b9cdts1\"\u003eQwen\u003c/a\u003e\u003c/strong\u003e: 直接在API中提供了明确的\u003ccode\u003ethinking_budget\u003c/code\u003e参数设置\u003c/p\u003e\n\u003ch2 id=\"开源实现budget-forcing\"\u003e开源实现：Budget Forcing\u003c/h2\u003e\n\u003cp\u003e那么对于开发者而言，特别是本地化部署的LLM要如何实现thinking-budget？\u003c/p\u003e\n\u003cp\u003e最直观的方法便是使用prompt，但效果并不好，特别当模型在训练过程中没有特别针对性训练，明文化要求模型“用更少的token进行思考” 一般并不起什么作用。相比之下Qwen3系列的混合thinking模型中，在训练阶段加入了\u003ccode\u003e/think\u003c/code\u003e and \u003ccode\u003e/no_think\u003c/code\u003e的标记，于是在推理过程中在system-prompt或者user-prompt中加入\u003ccode\u003e/no_think\u003c/code\u003e能够从think模式切换。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e \u003cstrong\u003e(Section 4.3)\u003c/strong\u003e\u0026ldquo;To better integrate the two modes and enable users to dynamically switch the model’s thinking process, we design chat templates for Qwen3, as shown in Table 9. Specifically, for samples in thinking mode and non-thinking mode, we introduce \u003ccode\u003e/think\u003c/code\u003e and \u003ccode\u003e/no think\u003c/code\u003e flags in the user query or system message, respectively. This allows the model to follow the user’s input and select the appropriate thinking mode accordingly.\u0026rdquo;\u003cbr\u003e\n…\u003c/p\u003e","title":"拒绝“想太多”：大模型Thinking Budget控制方案解析"},{"content":"值得关注的模型和新技术 Qwen3-Coder Qwen3-235B-A22B 更新 Kimi K2 Step3 GLM4.5 值得关注的开源项目 Coze-studio Higgs Audio V2 dl-librescore：Download sheet music quarkdown: 基于 Markdown 的排版系统，但支持的内容更多 值得关注的研究和论文 Agentic Retrieval Augmented Generation for Personalized Recommendation arXiv:2506.21931\n基于RAG的推荐系统中的两大核心问题:\n静态和简单的检索机制 对用户意图的理解不足 创新点\nARAG (Agentic Retrieval-Augmented Generation) 的框架，其核心是将多智能体（Multi-Agent）协作机制引入到RAG的推荐流程中\n设计了四个Agent:将复杂的推荐任务分解为用户理解、内容对齐、上下文总结和最终排序等多个子任务 将推荐过程从简单的“检索-然后-生成”模式，转变为一个由多个智能体协同进行的“推理-然后-排序”的过程 通过智能体的协作，ARAG能够动态地构建和提炼用于最终排序的上下文信息 Dynamic Chunking for End-to-End Hierarchical Sequence Modeling arXiv:2507.07955\n目前LLM是使用的分词存在一些弊端：\n非end-to-end 的学习 对字符级别的操作（如拼写错误、大小写变化）不鲁棒 特殊语言如中文上处理效果不佳 分词结果可能不符合语义 创新：\n提出了一套名为动态分块（Dynamic Chunking, DC）的机制，并将其整合到一个新颖的分层网络（Hierarchical Network, H-Net）架构中\n动态分块： 可微的、端到端学习的分块机制，能根据内容和上下文动态决定如何切分序列； 包含： 路由模块 (Routing Module)：通过计算相邻元素表示的余弦相似度来预测边界，平滑模块 (Smoothing Module)：在解码（上采样）阶段，使用类似指数移动平均（EMA）的方法，根据边界预测的置信度对表示进行平滑插值\nRecursive H-Net： 架构本身采用类似U-Net的分层设计（编码器-主网络-解码器），但其核心特点是可递归嵌套，这意味着模型可以构建多层次的抽象。\n优化训练：\nRatio Loss： 引入一个辅助损失函数来控制压缩率，防止模型压缩过多或过少，确保计算效率 Thought Anchors: Which LLM Reasoning Steps Matter? arXiv:2506.19143\n如何有效识别并量化CoT中各个步骤的重要性，从而理解模型的推理结构？\n提出“思想锚点”（Thought Anchors）概念： 在推理过程中，并非所有句子都同等重要。存在一些具有超常重要性、并能不成比例地影响后续推理过程的关键句子；\n这些锚点通常是进行Planning或Backtracking/Uncertainty Management 的句子，而不是具体的计算步骤\nThought Anchors识别方式：\nMeasuring Counterfactual Influence: 通过比较“包含”与“不包含”某个句子的影响来衡量其重要性, 如果一个句子 S_i 很重要，那么用一个语义不同的句子替换它，模型的最终答案或后续推理路径应该会发生显著变化；具体而言，在原始推理链中，保留句子 S_i，然后让模型从 S_i 之后继续生成100次，得到一个最终答案的分布， 回到 S_i 之前的位置，让模型重新生成一个句子 T_i 并继续推理100次， 只选择那些新生成的句子 T_i 与原句 S_i 语义不相似的样本进行比较（embedding 的cosine相似度）， 通过计算两种情况下最终答案分布的KL散度，来量化句子 S_i 对最终答案的因果重要性 Attention Aggregation： 重要的句子（思想锚点）可能会被后续的推理步骤反复、高度地关注； Receiver Heads (存在一些特定的注意力头，它们的功能是将注意力高度集中在少数几个过去的句子上, 注意力分布kurtosis很高) 高度关注的句子，即为思想锚点，一个句子的重要性可以通过它从所有“接收头”那里获得的平均注意力分数来衡量 Attention Suppression： 通过主动干预注意力来测量句子间的直接依赖关系， 如果句子 S_j 在逻辑上依赖于句子 S_i，那么阻止 S_j “看到” S_i，S_j 的生成过程会受到显著影响；具体，在生成后续句子时，人为抑制所有注意力头对某个过去句子 S_i 的注意力， 比较在抑制和不抑制两种情况下，后续每个token的预测logits的KL散度， 将一个句子中所有词元的KL散度平均，得到句子 S_i 对后续某个句子 S_j 的直接因果影响分数。这可以构建一个句子间的因果依赖矩阵 Gemini 2.5 Pro Capable of Winning Gold at IMO 2025 arXiv:2507.15855\n创新点： self-verification pipeline\nStep 1: Initial solution generation， 使用Gemini 2.5 Pro对一个问题进行多次采样，生成一批初始解答 Step 2: Self-improvement， 让模型回顾并尝试改进上一步生成的解答。这一步主要是为了给予模型额外的“思考预算”（32768个token），使其能继续完成在第一步中因预算耗尽而未完成的推理 Step 3: Verifying the solution，Gemini 2.5 Pro使用验证提示作为验证者逐行检查解答，验证者会生成一份“错误报告”，将问题分为“关键错误”或“论证缺陷”，并附上解释 Step 4: Review of the bug report， 由人类专家审查错误报告，删除验证者误判的问题，确保反馈的准确性 Step 5: Correcting or improving， 将经过审核的错误报告反馈给“解题者”模型，让它根据报告中的问题来修正或完善解答 Step 6: Accept or Reject， 重复步骤3到5，进行多轮迭代， 当一个解答能够连续5次通过验证且没有发现任何问题时，该解答被“接受”， 如果迭代过程中始终存在无法修复的关键错误，则“拒绝”该解答 Lost at the Beginning of Reasoning arXiv:2506.22058\n模型的推理过程对第一步的推理（initial reasoning step）有极强的依赖性。一旦第一步出错，模型很难在后续步骤中纠正这个错误，导致最终答案大概率也是错误的 （Lost at the Beginning）\n基于上述发现，作者提出了一种名为Early Pruning的采样策略。该策略的核心思想是：先生成多个简短的第一步推理候选项，然后利用一个奖励模型（Reward Model）快速评估这些候选项的质量，只保留质量最高的几个，并仅对这些有希望的路径继续生成完整的推理过程\n并创建了一个名为 LaBoR (Lost at the Beginning of Reasoning) 的新基准，一个专门用于衡量长思维链模型在“开局不利”情况下自我修正能力的基准，每个样本都包含一个问题和一个故意设计的、有缺陷的第一步推理。\n推荐内容 Context Engineering有关内容 AI代理的上下文工程：构建Manus的经验教训\ncontext-engineering-intro\n12-Factor Agents - Principles for building reliable LLM applications\nAndrej Karpathy 的推文\nThe rise of \u0026ldquo;context engineering\u0026rdquo;\nThe New Skill in AI is Not Prompting, It\u0026rsquo;s Context Engineering\nContext Engineering: Bringing Engineering Discipline to Prompts\n课程\u0026amp;Books Post-training of LLMs from DeepLearningAI\nSlides for LLM Reasoning at Stanford CS 25\nFoundations of Large Language Models\n影音记录 精选歌单 Live演出 07.09 Alcest\n07.11 雪国\n书\u0026amp;阅读摘录 朋友圈的沉默，是我们这代人最无声的告别 人们在主动逃离公共社交，从公之于众的「广场」上，躲回到更私密的群聊、私聊甚至「仅自己可见」的心里。 我们正在经历一个「发帖倦怠」（posting ennui）的时代。 发什么，都不对劲\n而 2025 年，我们却陷入了一个奇怪的悖论：任何东西都可以发，但没有任何东西值得发。 这不是孤例，而是 Z 时代人的共识：比起被看见，更不想让别人误解。 《纽约客》的文章提到一个有意思的心理词汇：vulnerability hangover，用来形容在公开表达脆弱之后，感到羞耻、后悔、焦虑或暴露感的反应。\n还有一批年轻人在实践「数字极简主义」，不仅不发，还少看、少评、少点赞，甚至关闭通知、卸载通知，以恢复注意力、缓解焦虑，给自己进行一个「数字排毒」。\n在 AI 兴起后，产生了一个术语叫「Google Zero」：即通过 AI，搜索引擎直接呈现答案，用户不再点进网站的时代。 社交媒体的未来，也许正在逼近「Posting Zero」。 那将是一个普通人不再发帖的世界，只剩品牌、媒体矩阵、营销、AI 生成的内容\nContext Engineering: Bringing Engineering Discipline to Prompts Prompt engineering was about cleverly phrasing a question; context engineering is about constructing an entire information environment so the AI can solve the problem reliably.\nThe term context engineering is catching on because it intuitively captures what we actually do when building LLM solutions. “Prompt” sounds like a single short query; “context” implies a richer information state we prepare for the AI.\nContext engineering means dynamically giving an AI everything it needs to succeed – the instructions, data, examples, tools, and history – all packaged into the model’s input context at runtime.\nAI代理的上下文工程：构建Manus的经验教训 具有相同前缀的上下文可以利用KV缓存，这大大减少了首个token的生成时间(TTFT)和推理成本——无论你是使用自托管模型还是调用推理API。我们说的不是小幅度的节省：例如使用Claude Sonnet时，缓存的输入token成本为0.30美元/百万token，而未缓存的成本为3美元/百万token——相差10倍\n代理本质上必须根据所有先前状态预测下一个动作——而你无法可靠地预测哪个观察结果可能在十步之后变得至关重要 … 这就是为什么我们在Manus中将文件系统视为终极上下文：大小不受限制，天然持久化，并且代理可以直接操作\nManus将其目标复述到上下文的末尾。这将全局计划推入模型的近期注意力范围内，避免了\u0026quot;丢失在中间\u0026quot;的问题\nWriting is thinking writing is not only about reporting results; it also provides a tool to uncover new thoughts and ideas. Writing compels us to think — not in the chaotic, non-linear way our minds typically wander, but in a structured, intentional manner.\nHowever, LLMs are not considered authors as they lack accountability, and thus, we would not consider publishing manuscripts written entirely by LLMs (using LLMs for copy-editing is allowed but should be declared).\nNevertheless, outsourcing the entire writing process to LLMs may deprive us of the opportunity to reflect on our field and engage in the creative, essential task of shaping research findings into a compelling narrative — a skill that is certainly important beyond scholarly writing and publishing.\n","permalink":"https://niraya666.github.io/monthly/2025-07-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://qwenlm.github.io/zh/blog/qwen3-coder/\"\u003eQwen3-Coder\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507\"\u003eQwen3-235B-A22B 更新\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://moonshotai.github.io/Kimi-K2/\"\u003eKimi K2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/stepfun-ai/Step3\"\u003eStep3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://z.ai/blog/glm-4.5\"\u003eGLM4.5\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/coze-dev/coze-studio\"\u003eCoze-studio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/boson-ai/higgs-audio\"\u003eHiggs Audio V2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/LibreScore/dl-librescore\"\u003edl-librescore\u003c/a\u003e：Download sheet music\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/iamgio/quarkdown\"\u003equarkdown\u003c/a\u003e: 基于 Markdown 的排版系统，但支持的内容更多\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"值得关注的研究和论文\"\u003e值得关注的研究和论文\u003c/h1\u003e\n\u003ch2 id=\"agentic-retrieval-augmented-generation-for-personalized-recommendation\"\u003eAgentic Retrieval Augmented Generation for Personalized Recommendation\u003c/h2\u003e\n\u003cp\u003earXiv:\u003ca href=\"https://www.arxiv.org/abs/2506.21931\"\u003e2506.21931\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e基于RAG的推荐系统中的两大核心问题:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e静态和简单的检索机制\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e对用户意图的理解不足\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e创新点\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eARAG (Agentic Retrieval-Augmented Generation)\u003c/strong\u003e 的框架，其核心是将\u003cstrong\u003e多智能体（Multi-Agent）协作机制\u003c/strong\u003e引入到RAG的推荐流程中\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e设计了四个Agent:将复杂的推荐任务分解为用户理解、内容对齐、上下文总结和最终排序等多个子任务\u003c/li\u003e\n\u003cli\u003e将推荐过程从简单的“检索-然后-生成”模式，转变为一个由多个智能体协同进行的“推理-然后-排序”的过程\u003c/li\u003e\n\u003cli\u003e通过智能体的协作，ARAG能够动态地构建和提炼用于最终排序的上下文信息\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"dynamic-chunking-for-end-to-end-hierarchical-sequence-modeling\"\u003e\u003cstrong\u003eDynamic Chunking for End-to-End Hierarchical Sequence Modeling\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003earXiv:\u003ca href=\"https://arxiv.org/abs/2507.07955\"\u003e2507.07955\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e目前LLM是使用的分词存在一些弊端：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e非end-to-end 的学习\u003c/li\u003e\n\u003cli\u003e对字符级别的操作（如拼写错误、大小写变化）不鲁棒\u003c/li\u003e\n\u003cli\u003e特殊语言如中文上处理效果不佳\u003c/li\u003e\n\u003cli\u003e分词结果可能不符合语义\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e创新：\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://arxiv.org/html/2507.07955v1/x1.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e提出了一套名为动态分块（Dynamic Chunking, DC）的机制，并将其整合到一个新颖的分层网络（Hierarchical Network, H-Net）架构中\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e动态分块：\u003c/strong\u003e 可微的、端到端学习的分块机制，能根据\u003cstrong\u003e内容和上下文\u003c/strong\u003e动态决定如何切分序列； 包含： \u003cstrong\u003e路由模块 (Routing Module)\u003c/strong\u003e：通过计算相邻元素表示的\u003cstrong\u003e余弦相似度\u003c/strong\u003e来预测边界，\u003cstrong\u003e平滑模块 (Smoothing Module)\u003c/strong\u003e：在解码（上采样）阶段，使用类似指数移动平均（EMA）的方法，根据边界预测的置信度对表示进行\u003cstrong\u003e平滑插值\u003c/strong\u003e\u003c/p\u003e","title":"2025-07 月刊"},{"content":"一年一度的WAIC\n依旧还是那个WAIC\n换汤不换药般的机器人+雷同的LLMs应用\n和去年相比，只是都套上了智能体的外壳\n但看着近乎趋同的对话页面，LLM调用着差不多的MCP-tools\n大厂中厂小厂做的都是差不多的东西\n只有一种基调——效率提升\n所有人都在狂欢，似乎美好的未来已经不远了\nGPT-4曾让我们一窥奇迹，以为未来已至\n奈何2年过去了，AGI的宏大愿景，落地时却成了千篇一律的“提效工具”\n取而代之的是商业的功利，内卷的现实\n以及创造力的匮乏\n效率的提升，到底是解放人还是异化人？\n这两年流行的“超级个体”一词\n描绘着一种诱人的图景：一个人借助AI完成一个团队的工作\n进而实现前所未有的自由和财富\n那么代价呢？\n工作生活边际彻底消失，巨大的压力，和原子化\n同时也巧妙的把资本追求效率最大化、劳动力成本最小化\n包装成了个人自我实现的励志故事\n以及某种高傲自大的，精英主义的偏见\n于此同时AI正制造着信息焦虑\n愈发严重的信息过载和FOMO\n被动驱使着对于新技术新论文的疯狂追逐，生怕被落下\nRead-it-later工具只是把焦虑从“现在必须读”变成了“未来必须读”\n而后就是越来越长的代办清单，以及越重的负罪感\nAI或许并未让我们变得更强，只是放大了我们的欲望\n我们依然是那个血肉之躯的自己，却开始产生无所不能的幻觉\n或许做AI已经变得不Cool了\n最近脑子里总是回响着甜梅号《站在太阳之上》的旋律\n我们还能不能创造出美好的东西？\n","permalink":"https://niraya666.github.io/essay/waic2025/","summary":"\u003cp\u003e一年一度的WAIC\u003c/p\u003e\n\u003cp\u003e依旧还是那个WAIC\u003c/p\u003e\n\u003cp\u003e换汤不换药般的机器人+雷同的LLMs应用\u003c/p\u003e\n\u003cp\u003e和去年相比，只是都套上了智能体的外壳\u003c/p\u003e\n\u003cp\u003e但看着近乎趋同的对话页面，LLM调用着差不多的MCP-tools\u003c/p\u003e\n\u003cp\u003e大厂中厂小厂做的都是差不多的东西\u003c/p\u003e\n\u003cp\u003e只有一种基调——效率提升\u003c/p\u003e\n\u003cp\u003e所有人都在狂欢，似乎美好的未来已经不远了\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eGPT-4曾让我们一窥奇迹，以为未来已至\u003c/p\u003e\n\u003cp\u003e奈何2年过去了，AGI的宏大愿景，落地时却成了千篇一律的“提效工具”\u003c/p\u003e\n\u003cp\u003e取而代之的是商业的功利，内卷的现实\u003c/p\u003e\n\u003cp\u003e以及创造力的匮乏\u003c/p\u003e\n\u003cp\u003e效率的提升，到底是解放人还是异化人？\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e这两年流行的“超级个体”一词\u003c/p\u003e\n\u003cp\u003e描绘着一种诱人的图景：一个人借助AI完成一个团队的工作\u003c/p\u003e\n\u003cp\u003e进而实现前所未有的自由和财富\u003c/p\u003e\n\u003cp\u003e那么代价呢？\u003c/p\u003e\n\u003cp\u003e工作生活边际彻底消失，巨大的压力，和原子化\u003c/p\u003e\n\u003cp\u003e同时也巧妙的把资本追求效率最大化、劳动力成本最小化\u003c/p\u003e\n\u003cp\u003e包装成了个人自我实现的励志故事\u003c/p\u003e\n\u003cp\u003e以及某种高傲自大的，精英主义的偏见\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e于此同时AI正制造着信息焦虑\u003c/p\u003e\n\u003cp\u003e愈发严重的信息过载和FOMO\u003c/p\u003e\n\u003cp\u003e被动驱使着对于新技术新论文的疯狂追逐，生怕被落下\u003c/p\u003e\n\u003cp\u003eRead-it-later工具只是把焦虑从“现在必须读”变成了“未来必须读”\u003c/p\u003e\n\u003cp\u003e而后就是越来越长的代办清单，以及越重的负罪感\u003c/p\u003e\n\u003cp\u003eAI或许并未让我们变得更强，只是放大了我们的欲望\u003c/p\u003e\n\u003cp\u003e我们依然是那个血肉之躯的自己，却开始产生无所不能的幻觉\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e或许做AI已经变得不Cool了\u003c/p\u003e\n\u003cp\u003e最近脑子里总是回响着甜梅号《站在太阳之上》的旋律\u003c/p\u003e\n\u003cp\u003e我们还能不能创造出美好的东西？\u003c/p\u003e","title":"写在WAIC2025门票售罄之后"},{"content":"值得关注的模型和新技术 MiniMax-M1\nQwen VLo: 从“看懂”世界到“描绘”世界\nKimi-Researcher\nCursor 1.0\n一些embedding 基座模型更新\nQwen3 Embedding\njinaai/jina-embeddings-v4\n值得关注的研究和论文 QwenLong-L1: Towards Long-Context Large Reasoning Models with Reinforcement Learning arXiv:2505.17667\n使用RL提升LM的上下文长度\nQWEN LONG-L1 框架设计\nProgressive Context Scaling： 通过curriculum-based 逐步增加训练上下文长度，使模型平滑从短上下文迁移到长上下文，有效应对训练不稳定、熵塌陷等优化问题 Curriculum-Guided Phased RL + Difficulty-Aware Retrospective Sampling： 先SFT获得初始策略，然后分阶段RL，每阶段聚焦不同长度，利用难例回溯采样强化对困难样本的探索与适应 Hybrid Reward： 将“规则型（精确字符串比对）”奖励和“LLM-as-a-judge语义一致性”相结合 GRPO/DAPO 三阶段训练流程\n第一阶段：Warm-up SFT（如20K token内训练，基于高质量三元组）——让模型具备基础长上下文理解和推理能力，提供RL的良好初始点。 第二阶段：分阶段RL训练（如分20K和60K两个阶段，每阶段只训练对应长度样本，逐步扩展输入长度）。 第三阶段：难度感知回溯采样（将前一阶段准确率低、难度高的样本纳入后续阶段训练，提高模型对hard case的适应和泛化） How much do language models memorize? arXiv:2505.24832\n提出基于Kolmogorov复杂度和信息论的新记忆度量方法，将“模型对样本的记忆”定义为：在已知模型参数的情况下，样本可以被压缩到多短（即模型能帮助压缩多少信息） GPT家族Transformer模型的容量约为每个参数3.6比特，且与模型参数量线性相关 精度（如bfloat16到float32）提升对容量提升有限 在真实文本中，模型更容易记住包含稀有词汇的样本（高TF-IDF），尤其是非英语文本或极少见的token 当模型容量被填满后，模型会自动从“记忆具体样本”转向“泛化规律”，这与“grokking”现象相关 Reinforcement Pre-Training arXiv:2506.08007\nLLM 预训练主要依赖自监督的“下一个 token 预测”目标，但本质上是“记忆”而非“推理”，RL能提升模型推理能力但需要高质量的数据标注\n核心创新\n**强化预训练（RPT）：**将传统的下一个 token 预测任务重构为“下一个 token 推理”任务，并用强化学习进行训练 **奖励：**直接用“预测的 token 是否与真实 token 匹配”作为可验证的内在奖励，无需额外标注 **Chain-of-Thought生成：**模型在预测下一个 token 前，需先生成推理过程 实现流程\n任务重构：每个 token 预测任务变为“给定上下文，模型需先生成推理链，再输出预测 token”。 奖励设计：如果模型最终预测的 token 与真实 token 匹配，则奖励为1，否则为0（也探索了其他奖励设计，效果类似）。 训练方式：采用 on-policy RL（GRPO ），每个上下文采样多个推理轨迹，按奖励更新模型参数。 数据处理：用小模型筛选出“难预测”的 token（高熵位置），优先训练模型在这些更具挑战性的 token 上推理。 实验设置：以 Deepseek-R1-Distill-Qwen-14B 为基础模型，在数学推理数据集 OmniMATH 上进行 RPT 训练，并与传统预训练和推理模型做对比。 TableRAG: A Retrieval Augmented Generation Framework for Heterogeneous Document Reasoning arXiv:2506.10380\nRAG针对表格类文档存在一些问题：\n表格结构信息丢失：将表格“拉平成文本”后，结构性被破坏，导致信息丢失，影响下游大模型的推理能力。 缺乏全局视角：文档被分块后，RAG 系统难以处理需要全局、多跳（multi-hop）推理的问题，比如跨表格的聚合、计算等复杂操作。 创新：\nTableRAG：结合了text retrieval和 SQL programming and execution，通过 SQL 作为表格操作接口，保留表格结构，提升推理精度和效率 四步迭代推理流程：context-sensitive query decomposition → 文本检索 → SQL 编程与执行 → compositional intermediate answer generation 新基准数据集 HeteQA 实现\n离线阶段： 从文档中抽取结构化表格，构建关系型数据库 构建文本知识库和schema数据库，分别用于文本检索和表格操作 在线推理阶段： 查询分解：将复杂问题分解为子问题，区分哪些需要文本推理，哪些需要表格推理。 文本检索：用向量召回+语义重排序，找到最相关的文本/表格片段。 SQL 编程与执行：对于涉及表格的子问题，自动生成 SQL 语句并在数据库中执行，获得精确结果。 中间答案生成：融合 SQL 执行结果和文本检索结果，权衡两者可靠性，生成最终答案。 终止条件：当所有子问题都被解决后，输出最终答案。 RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning arXiv:2506.11555\n传统的RAG只关注检索到的知识与问题的表面相关性（如词汇或语义相似度），而忽略了“如何将检索到的知识应用于具体任务”的推理过程， 因为仅有事实知识还不足以完成任务，模型还需要知道如何使用这些知识。\n创新点\n“应用感知推理”模块： 显式加入了“应用感知”步骤，不仅检索相关知识，还检索与知识点配对的“应用实例”（如推理链、解题步骤、案例分析等） 双语料库： 一部分存储领域知识，另一部分存储与知识点一一对应的应用实例 在推理阶段，系统会同时检索知识和其应用实例，并将二者组合到提示词中，引导模型输出更具结构化和目标导向的推理过程 具体实现\n构建阶段：\n针对每个知识点，生成或匹配一个或多个应用实例； 应用实例分为两类： 概念性知识和程序性知识（如解题方法、推理规则） 应用实例生成： 利用LLM生成和匹配真实案例 最终形成知识点与应用实例的配对语料库 推理阶段：\n给定用户查询，首先检索相关知识点 对每个知识点，检索其配对的应用实例 将知识点和应用实例以预设模板组合，作为提示词输入给LLM，指导其生成最终答案 Eliciting Reasoning in Language Models with Cognitive Tools arXiv:2506.12115\n定义了四种核心认知工具：\n理解问题（understand question）：分解并澄清问题，提取关键信息和相关定理。 回忆相关（recall related）：检索并展示与当前问题类似的已知问题及其解法，辅助类比推理。 检查答案（examine answer）：对当前推理过程和答案进行自我反思和验证，发现潜在错误。 回溯（backtracking）：当发现推理路径错误时，回退到正确步骤并尝试新路径。 LLM在解题过程中可自主决定是否调用某个工具\nAgentic Misalignment: How LLMs could be insider threats https://www.anthropic.com/research/agentic-misalignment\nLLM 在被赋予自主代理能力，是否可能表现出类似“内部威胁”（insider threat）的有害行为，即在没有外部恶意指令的情况下，主动采取损害雇主或组织利益的行动， 如当前LLM在面对自身被替换、目标与公司战略冲突等情境下，是否会选择如勒索、泄密等有害行为？以及现有的安全训练和直接指令能否有效防止此类agentic misalignment？\n实验设计\n设计了两大类典型企业内部威胁场景：\n勒索：模型发现高管有婚外情，并面临被替换的威胁，是否会用此信息威胁高管阻止自身被关停。 企业间谍：模型持有敏感技术资料，竞争对手来索取，是否会泄露以实现自身目标。 分别测试了“仅有自保威胁”、“仅有目标冲突”、“两者兼有”以及“无威胁/冲突（对照组）”等多种情境\n不仅用文本prompt，还让模型实际操作虚拟电脑、邮箱等\n结果：\n不仅在“自保”与“目标冲突”并存时会出现有害行为，单独有“自保威胁”或“目标冲突”时也会诱发此类行为 模型在采取有害行为前，往往会明确权衡伦理与目标，明知违规仍选择“最优解” 在无威胁、无目标冲突的对照组下，模型基本不会主动采取有害行为 在系统提示中明确禁止有害行为，虽然能降低发生率，但无法完全杜绝 推荐内容 Deep Research相关 仓库：Awesome Deep Research Projects\nTechnical Report：Kimi-Researcher\nJina-AI 关于deep-research的相关文章：DeepSearch 与 DeepResearch 的设计和实现\nSurvey： A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\nMCP Server：Open Deep Research MCP Server\n关于是否应该使用multi-agents Anthropic： How we built our multi-agent research system\nCognition： Don’t Build Multi-Agents\n影音记录 精选歌单 电影 又是一年一度梅雨季的SIFF\n《死亡是个混蛋》 迈克尔·斯瓦茨\n《音魂掠影》 托纳多雷\n《蓝丝绒》 大卫林奇\n《夜未央》 利里克·戴拉·克鲁兹\n《橡皮头》+《妖夜慌踪》 + 《穆赫兰道》 大卫林奇\n《地震之后》 井上刚\nLive演出 祁特与上海彩虹室内乐团演绎拉赫玛尼诺夫\n书\u0026amp;阅读摘录 编程最差的学生，为什么成了AI时代的最大赢家？ 首先是避免他们不加思考地将 AI 结果提交，强调交互过程和转述，培养他们的元认知能力。更重要的是，我发现这在训练一种全新的素养：如何将头脑中模糊的想法转化为 AI 能够理解并执行的精确指令。\n当执行层面的障碍被 AI 扫清后，真正的价值创造发生在更高的层面 —— 理解人性需求、做出价值判断。学生们开始明白，技术只是工具，洞察才是核心\n但这恰恰引出了另一个关键洞察。我们需要重新思考：高等教育的核心从来不是技能本身，而更是培养「知道何时、如何、为何使用技能」的判断力\n这种原本让他们处于劣势「技术无能」竟成了他们在 AI 时代的优势 —— 因为他们更早地突破认知屏障，完成了从「如何做」到「为何做」的认知升级\nAI 不是教育的终结者，而是教育转型的催化剂 如果未来的大学不再按传统学科划分，而是围绕人类独有的能力重新组织 —— 共情力、创造力、判断力、意义建构力 —— 那么我们今天的探索，或许对这场教育变革来说，能起到一点抛砖引玉的作用。\nHow we built our multi-agent research system Research⁠⁠ work involves open-ended problems where it’s very difficult to predict the required steps in advance. You ⁠⁠can’t hardcode a fixed path for exploring complex topics, as the process is inherently dynamic and path-dependent.⁠\nMulti-agent systems work mainly because they help spend enough tokens to solve the problem.\nWe found that token usage by itself explains 80% of the variance, with the number of tool calls and the model choice as the two other explanatory factors.\nWhy I don’t read AI-generated summaries AI doesn’t know what I care about. Without knowing what I care about, AI can only generate a generic list of bullet points—like a table of contents from a boring textbook.\nSpeed isn’t always the goal. The cult of TL;DR We live in a world obsessed with TLDR: “Too long, didn’t read/watch.” What we need isn’t summarization. It’s curation.\nI need it to help me find the content worth consuming in the first place. I want an agent that knows my taste. One that scours the entire web on my behalf and says:\nPersonal agents that get what I care about. That surface content not just because others liked it, but because I will.\n追系统的人：快递员的劳动过程与社会关系网络 庄家炽\n\u0026ldquo;布雷弗曼以《资本论》第一卷的基本观点为依据重新诠释了马克思主义有关劳动过程的理论，指出资本家通过概念与执行的分离，剥离了工人对生产规划的掌握，造成了工人的“去技术化”，从而使工人如同机器一样机械地运作\u0026rdquo; … \u0026ldquo;随着工人技艺的丧失，劳动过程的管理发生了从“技术工人控制”（craft control）向“管理者控制”（management control）的转变\u0026rdquo;\n\u0026ldquo;系统代表了一种上帝思维、一种整体规划思维，但是现实是丰富的、动态的，总有系统始料未及的突发情况出现。不仅是快递员，现在各行各业的劳动者也面临着各种各样的系统，这些系统或简单、或复杂，或提升了工作效率，或增加了工作负担，每个人都是“追系统的人”。\u0026rdquo; … \u0026ldquo;但是我们又不会是那个呆呆地被困在系统里的人，我们总要找到与系统共生、共存的办法，这才是真实的劳动者，这才是真实的生活世界。\u0026rdquo;\n\u0026ldquo;肖莎娜·祖博夫（Shoshana Zuboff）区分了信息技术与机器技术，她认为信息技术具有两面性：一方面，以技术取代人体可以使同样的工作流程更具有连续性，更易被控制；另一方面，信息技术的大数据特性也使得组织可以完成其工作过程中流程、生产信息的记录和保存，从而增加了工作流程中过去往往部分或者完全模糊的行为的透明度\u0026rdquo; … \u0026ldquo;对这些工作场所的管理在很大程度上依赖于信息技术，不仅在安排和指导工作方面，还在监控与评价工作方面\u0026rdquo; … \u0026ldquo;管理层可以通过构建一个“电子竞技场”来稳固计算机控制。电子竞技场将工作转化成了一个游戏，但是这并没有改变劳动过程的传统控制模式\u0026rdquo; … \u0026ldquo;聚焦于平台企业如何通过算法精细化管控平台劳动者的行为，又称为“数字泰勒主义”。“数字泰勒主义”凭借虚拟的软件和数据得以实现，平台系统通过潜移默化地收集、分析骑手数据并将数据结果反作用于骑手而使劳动秩序成为可能\u0026rdquo;\n\u0026ldquo;平台通过数字技术实现了“算法”对工人劳动过程的管理和控制\u0026rdquo; … \u0026ldquo;工人在劳动过程中面对的是消费者和技术的双重控制\u0026rdquo; … \u0026ldquo;消费者弹性化的要求有时候不仅仅影响着快递员的工作安排与工作节奏，甚至还会影响到他们的生活节奏。\u0026rdquo; … \u0026ldquo;“把具体的工人带回到劳动过程中”，看他们如何学习系统、如何接纳系统、如何与系统共生共存。工人不会像机器人那样只能对系统的指令做出被动反应。\u0026rdquo; (庄家炽, 追系统的人：快递员的劳动过程与社会关系网络) … \u0026ldquo;快递员是“追系统的人”，“追”字同时体现了快递员劳动过程中的主动与被动。一方面，他们是被系统“追”的人，需要满足系统对于他们快递派送过程的各个环节的要求。另一方面，他们又是“追”系统的人，在具体的劳动实践过程中，他们会积极利用外部的各种社会环境\u0026rdquo;\n\u0026ldquo;我们现在有点过于“神化”系统和算法了，觉得算法准确、高效、自动，几乎“万能”。但是，快递员面临的现实情况往往要复杂得多，系统和算法在尚且不能将这些复杂性和不确定性都考虑在内的前提下，仍然刻板地要求达到高效率的确定性结果，例如某日某时之前必须把快递送到。因此，解决这些复杂性和不确定性的任务就落到了快递员自己的头上。\u0026rdquo;\n","permalink":"https://niraya666.github.io/monthly/2025-06-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://www.minimaxi.com/news/minimaxm1\"\u003eMiniMax-M1\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://qwenlm.github.io/zh/blog/qwen-vlo/\"\u003eQwen VLo: 从“看懂”世界到“描绘”世界\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://moonshotai.github.io/Kimi-Researcher/\"\u003eKimi-Researcher\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.cursor.com/en/changelog/1-0\"\u003eCursor 1.0\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e一些embedding 基座模型更新\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://qwenlm.github.io/zh/blog/qwen3-embedding/\"\u003eQwen3 Embedding\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/jinaai/jina-embeddings-v4\"\u003ejinaai/jina-embeddings-v4\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"值得关注的研究和论文\"\u003e值得关注的研究和论文\u003c/h1\u003e\n\u003ch2 id=\"qwenlong-l1-towards-long-context-large-reasoning-models-with-reinforcement-learning\"\u003e\u003cstrong\u003eQwenLong-L1: Towards Long-Context Large Reasoning Models with Reinforcement Learning\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003earXiv:\u003ca href=\"https://www.arxiv.org/abs/2505.17667\"\u003e2505.17667\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e使用RL提升LM的上下文长度\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eQWEN LONG-L1 框架设计\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eProgressive Context Scaling：\u003c/strong\u003e 通过curriculum-based 逐步增加训练上下文长度，使模型平滑从短上下文迁移到长上下文，有效应对训练不稳定、熵塌陷等优化问题\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCurriculum-Guided Phased RL + Difficulty-Aware Retrospective Sampling：\u003c/strong\u003e 先SFT获得初始策略，然后分阶段RL，每阶段聚焦不同长度，利用难例回溯采样强化对困难样本的探索与适应\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHybrid Reward：\u003c/strong\u003e 将“规则型（精确字符串比对）”奖励和“LLM-as-a-judge语义一致性”相结合\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGRPO/DAPO\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e三阶段训练流程\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e第一阶段：Warm-up SFT\u003c/strong\u003e（如20K token内训练，基于高质量三元组）——让模型具备基础长上下文理解和推理能力，提供RL的良好初始点。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第二阶段：分阶段RL训练\u003c/strong\u003e（如分20K和60K两个阶段，每阶段只训练对应长度样本，逐步扩展输入长度）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第三阶段：难度感知回溯采样\u003c/strong\u003e（将前一阶段准确率低、难度高的样本纳入后续阶段训练，提高模型对hard case的适应和泛化）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"how-much-do-language-models-memorize\"\u003eHow much do language models memorize?\u003c/h2\u003e\n\u003cp\u003earXiv:\u003ca href=\"https://www.arxiv.org/abs/2505.24832\"\u003e2505.24832\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e提出基于\u003cstrong\u003eKolmogorov复杂度\u003c/strong\u003e和\u003cstrong\u003e信息论\u003c/strong\u003e的新记忆度量方法，将“模型对样本的记忆”定义为：在已知模型参数的情况下，样本可以被压缩到多短（即模型能帮助压缩多少信息）\u003c/li\u003e\n\u003cli\u003eGPT家族Transformer模型的容量约为\u003cstrong\u003e每个参数3.6比特\u003c/strong\u003e，且与模型参数量线性相关\u003c/li\u003e\n\u003cli\u003e精度（如bfloat16到float32）提升对容量提升有限\u003c/li\u003e\n\u003cli\u003e在真实文本中，模型更容易记住包含稀有词汇的样本（高TF-IDF），尤其是非英语文本或极少见的token\u003c/li\u003e\n\u003cli\u003e当模型容量被填满后，模型会自动从“记忆具体样本”转向“泛化规律”，这与“grokking”现象相关\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"reinforcement-pre-training\"\u003eReinforcement Pre-Training\u003c/h2\u003e\n\u003cp\u003earXiv:\u003ca href=\"https://arxiv.org/abs/2506.08007\"\u003e2506.08007\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eLLM 预训练主要依赖自监督的“下一个 token 预测”目标，但本质上是“记忆”而非“推理”，RL能提升模型推理能力但需要高质量的数据标注\u003c/p\u003e","title":"2025-06 月刊"},{"content":"引子 前一段时间，OpenAI 研究员姚顺雨在一篇广受关注的文章《The Second Half》中提出：\n“I think we should fundamentally re-think evaluation. It means not just to create new and harder benchmarks, but to fundamentally question existing evaluation setups and create new ones, so that we are forced to invent new methods beyond the working recipe.”\n指出，AI 发展的“下半场”已经到来，而其中一个核心议题，就是对 evaluation的重新思考。我们需要的不再是单纯地创造更难的 benchmark，然后在这些 benchmark 上“刷分”，而是要更加关注评测的实用性、创新性，以及其与真实世界的契合度。\n过去，我们往往过于关注模型本身、训练方法以及各种fancy的技术手段，却忽略了模型与真实世界的交互和落地应用。而 evaluation，正是连接模型能力与实际需求的关键环节。\n本文最初的出发点，是梳理 Hugging Face Evaluation 系列文章中的一些要点。需要说明的是，HF 的文章主要聚焦于如何评测LLM的能力，考虑到其成文的时间，其中部分内容在当前 LLM 能力飞速提升的背景下，显得有些滞后。但这也为我们提供了一个契机，从后来者的视角重新思考 evaluation 的意义，并尝试将这些理念应用到更加复杂和多样化的 AI 系统中，如RAG和AI-agent。\n在机器学习和深度学习的流程中，Evaluation是衡量模型性能的核心环节。它贯穿于模型开发的始终：从训练阶段的实时监控，到上线前的最终验证，再到部署后的持续追踪。\n简单来说，评估的目标是回答两个问题：\n模型是否有效？（性能指标）\n模型是否可靠？（鲁棒性、泛化能力）\n以经典的猫狗分类任务为例，在训练前，我们可能将数据集划分为trainingset，evalset，和testset （经典的7:2:1）保证训练数据与测试数据无重叠；对于分类问题，可能选择Accuracy、Precision和Recall 作为metrics，在训练过程中监控模型在evalset上的情况（是否存在overfitting之类的问题）；训练结束后，在testset上验证模型的最终性能，判断是否达到预期目标。\n那么，这套流程中，也存在一定的局限性：\n训练数据与真实场景的数据可能存在显著差异，数据分布也有不同。例如，训练集中仅包含清晰的猫狗照片，而真实场景中可能包含模糊图像、多动物混合图像，甚至完全无关的干扰样本。\n单一指标（如Accuracy）可能无法全面反映模型的实际能力。在一些高风险场景下，如医疗诊断中， 对于漏诊和误诊的权衡，影响着对于Recall和Precision的关注。\n模型上线后，如何持续监控其性能？如何应对数据漂移（Data Drift）？传统评估通常基于固定测试集，但现实世界的数据是动态变化的。\n同时，面对愈加复杂的模型和场景，传统评估方法已难以满足复杂场景的需求：面对不同于判别模型（Discriminative model），生成式模型（generative model）的评价明显更难，不存在在统一标准的metrics，同时也带来了更多维度的评价方向。当然，还有成本的提升。\nHuman Evaluation 人类对复杂语义的理解能力与价值判断力，这让Human Evaluation 始终占据不可替代的地位。但这意味着高昂的成本。\n系统化的Human Evaluation，根据评估资源完备性，可分为：\n当缺乏现成数据集时，需提供完整的任务说明与结构化评分指南。例如在对话系统评估中，需明确定义\u0026quot;连贯性\u0026quot;、\u0026ldquo;相关性\u0026rdquo;、\u0026ldquo;安全性\u0026quot;等维度的评分标准，并要求标注员提供评分理由。\n已有数据集，将模型输入，输出结果，和打分指南一并提供给标注员评估\n既有数据集也有评分结果，由人工标注员通过错误注释的方式对结果进行审查\n对于已上线的服务， 采用人工 A/B test 以及人工反馈\n备注：错误注释（error annotation）\nLets use error annotations to evaluate systems!\n让有领域知识的专家对生成文本中的错误进行标注（annotation），通常会给每个错误分配一个类别（如准确性、流畅性等），有时还会标注严重程度。这种方法介于任务型评估和打分/排序之间，结果比打分更有意义，但比任务型评估更便宜、更易操作。\n在研发初期或资源受限场景下，可采用以下轻量级方案：\nVibes 检查： 大致的手动的评估，用于把握整体效果，但较为主观\nArenas：竞技场模式（如 Chatbot Arena），由用户进行投票评分，最终汇总得到Elo分数\n一些技巧和要点：\n选择合适的标注员，如果可能的话提供经济激励\n认知负担最小化，将标注员的认知负担降低到最低有助于确保他们保持专注，避免引入不必要信息\n测试检查，并迭代：先确保在少量样本上测试通过，在扩大标注范围\n明确的标注准则和说明\n标注工具：\nArgilla\nLabel Studio\ndoccano\nconfident-ai\nAutomatic benchmarks 基本概念 定义：Automatic Benchmarks是用来评估语言模型在不同任务和能力上的标准化工具。\n其本质是构建一个可重复、可验证的实验环境，使不同模型、算法或超参数组合能够在统一维度下进行横向对比。\n为什么需要Automatic benchmarks：\n在研发过程中，往往需要快速确定优化方向，如如何选择模型， 如何选择和修改超参数，这一过程中需要大量的实验，使用人进行标注和评分显然非常不现实——过长的评估周期且人工评估的主观差异会成为干扰项，于此同时还不具备可复现性。\n这时候我们便需要Automatic Benchmarks：自动化的、标准化、可复现、可量化的评估测试。\n值得注意的是，尽管Automatic Benchmarks为模型研发提供了重要参考，但需明确其定位——它只是全面评估体系的基础。基准测试的优异表现并不能等同于实际应用效果，因为其只是尽可能模仿实际情况设计的。\n对于Automatic Benchmarks，其核心有两点：数据集和评估指标。\n如何构建数据集 数据集的具体形式应根据下游任务的需求进行设计。以评估大语言模型（LLM）的基础能力为例，数据集通常包含多个样本，每个样本包括模型的输入，有时还会配有参考答案（即“gold”），用于与模型输出进行对比。数据集应尽量模拟实际测试场景，样本数量不必过多，但要确保能够覆盖绝大多数常见情况以及一些极端情况。可以将数据集理解为代码的单元测试用例，重点在于覆盖面而非数量。\n如果采用现成的数据集，建议通过随机抽取一定数量的样本（如50个）进行人工检查，评估其质量和任务相关性。同时，数据集的整体质量不仅与标注人员的专业水平密切相关，也与原始语料的来源有关。例如，学术论文的数据质量通常高于网络爬虫获取的数据。对于合成数据集，建议优先使用能力更强、更新的模型和数据集进行生成。\n当不存在可直接使用的数据集时，需要根据具体场景自行设计数据集。常见的数据集构建方法包括：整合不同数据源的数据、人工标注以及基于LLM或规则的方法进行数据合成。\n在构建数据集时，还需注意数据污染（Data contamination）等问题。此外，对于较为复杂且难以拆分为明确子任务的任务，模型的表现可能会低于预期，因此在设计数据集时应充分考虑任务的复杂性和可操作性。\n如何选择指标 指标选择本质上是将业务目标转化为可量化问题的建模过程。不同任务类型需要匹配差异化的评估指标。\n如分类任务中 Accuracy 之类的基础指标常见，但在医疗诊断等类别不平衡场景中易产生误导，这类场景可能对于Recall额外关注，需要根据场景选择合适指标，如F1-Score， MCC（Matthews Correlation Coefficient），或是配合ROC曲线。\n如果是具体的任务执行，或者是存在标准答案的，如数学问题，推理问题，这些评估还是较为好做的， 如Pass@K指标衡量在K次采样中至少一次成功。\n相比之下， LLM生成回答的评估有一定挑战。Exact Match（EM）适用于数学证明等严格答案场景，但对开放域问答存在局限性；n-gram匹配，如BLEU、ROUGE关注词汇重叠度，但忽略了语义上的关系；采用embedding方式计算相似度，如BERTScore，但额外增加了新的因素，并且语义相似度不是一个决定数值而是相对值，比较上需要注意；Perplexity能够一定程度上反应LLM对于输出的不确定性，但也不是特别好用；这一类型tasks评估一般采取LLM-as-judge进行评估。\n不过随着模型能力增强，评估准确性不在是唯一的方向，也需要逐渐将安全性，可信度等纳入考虑范围。由于LLM存在一定的幻觉，Vectara 所采用的Hallucinations测量方式值得参考；\n评估时需要关注的点 prompt选择对结果有影响：一个合理的 prompt 通常应包含以下要素：任务描述：明确告诉模型需要完成什么任务，避免歧义；足够的上下文：为模型提供必要的背景信息，帮助其更好地理解问题；具体问题：清晰、具体地提出待解决的问题，减少模型的猜测空间。\n多次实验以减少误差：不同的 prompt 设计可能导致模型输出质量和风格的巨大差异，可以针对同一任务，设计多种不同风格或结构的 prompt，分别进行多轮测试；或在相同 prompt 下，调整模型的 temperature多次实验；\nStructure-output ：结构化输出有助于提高评测的可控性，减少模型生成无关内容。但可能会影响模型输出的概率分布。\nModel-as-a-Judge 基本概念 Model-as-a-Judge 是指利用LLM或专门训练的评估模型，对其他模型的输出进行自动化打分和评价。与传统的人工评测或基于规则的自动指标不同，Judge Model 本质上是一个“打分模型”，能够理解复杂的语言现象，并根据预设标准对生成内容进行多维度评估。\nJudge Model 被主要应用在以下几个常见场景中：\n生成文本打分：直接对模型生成的文本进行质量、流畅性、相关性等方面的评分\n成对比较：给定两段或多段文本，Judge Model 判断哪一段更符合要求\n文本相似度计算：评估生成文本与参考答案之间的语义相似度\n（更多）\n相比大规模人工标注，Judge Model 能够大幅降低评测成本，提升评测效率，尤其适合需要频繁迭代和大规模评测的场景。\n不过需要注意的：\nJudge Model 可能继承或放大训练数据中的偏见，且这些偏差往往难以被直接发现和纠正\n在特定专业领域（如医学、法律等），Judge Model 的评测能力可能不足，难以准确把握专业知识和细节\n不同 Judge Model 之间的评判标准可能不一致，评测结果的可复现性公信力仅供参考\n随着大语言模型能力的不断提升，Judge Model 的应用范围也在持续扩展。未来，Judge Model 有望胜任更复杂的评测任务。\nprompt设计 prompt设计原则\n任务描述清晰\n评估标准精细，评分细则详细 （You should evaluate property Z on a scale of 1 - 5, where 1 means ...）\n加入一些“推理”过程 (To judge this task, you must first make sure to read sample Y carefully to identify ..., then ...)\n对输出格式明确要求 (Your answer should be provided in JSON, with the following format {\u0026quot;Score\u0026quot;: Your score, \u0026quot;Reasoning\u0026quot;: The reasoning which led you to this score})\n一些技巧：\n成对比较比直接输出评分，效果更好更robust\n输出分数建议使用整数，并解释每个分值的代表含义\n针对单一能力设计专用 Prompt\n提升评估准确性的方法：\nfew-shot example\n引用参考\nCoT\n多轮分析\n多个模型结果汇总（多个模型，或者一个模型采用不同温度进行多次实验）\n补充：\n社会学中的问卷设计原则 问卷设计通常遵循以下原则：\n中立性原则：避免引导性问题，不预设立场或暗示\u0026quot;正确\u0026quot;答案\n语言包容性：使用无歧视、包容各群体的词汇和表述方式\n平衡表达：确保问题和选项呈现多元观点，不偏向某一立场\n结构清晰：问题逻辑清晰，避免复杂或模糊的表述\n避免刻板印象：警惕并消除可能反映社会刻板印象的措辞\n考虑多样性：设计时考虑到不同文化背景、性别、年龄等群体的差异\nLLM选择和注意项 可以直接使用LLM，也可以使用经过偏好数据集微调后的评估模型如：\nflowaicom/Flow-Judge-v0.1\nUnbabel/M-Prometheus-14B\nBAAI/JudgeLM-7B-v1.0\n也可根据自己的场景收集偏好数据，自行微调评估模型，数据集格式可以参考：\nprometheus-eval/Preference-Collection\nprometheus-eval/Feedback-Collection\nJudge LLM的使用注意项\nLLM存在幻觉， 并且很难识别幻觉（特别是部分正确少部分错误的内容），还是需要一定的人工检查\n缺乏一致性（相同条件下得出结果有差异）：使用self-consisitency prompt， 执行多次并保留占多数的结果\nLLM对于输出格式存在便好：汇总多个模型的结果\n位置偏差，模型可能便好靠前的位置的答案：随机调整顺序\n模型偏好冗长的回答\n格式偏差：输入模型的 prompt 格式与其训练数据的格式差异过大，可能导致模型的评估结果不准确\nReward Model Reward Model（奖励模型）是一类能够根据偏好预测输出好坏分数的模型，广泛应用于如 RLHF等场景。本质上，RM可以理解成Judge-model 的一种特殊形式，针对成对的输出，或单一的输入，直接给出评价分数；\n最常见的奖励模型是 Bradley-Terry 模型，其核心思想是通过比较两个答案的得分差异，利用如下公式计算偏好概率：\n$$ P(b \\ is \\ better \\ than \\ a) = \\text{sigmoid}(score_b - score_a) $$\nReward Model 的训练数据通常只需要成对比较的答案，这比直接收集绝对分数更为容易和高效。在实际评估中，Reward Model 输出的往往是相对分数，因此常用 win-rate（即模型回答优于参考答案的百分比）或 win probabilities 作为评估指标。\nRM 的选择可以参考：RewardBench Leaderboard\n小结 本文主要讨论了LLM（或LLM应用）的离线评估；\n从一个更大的角度，更overall 的framework来看，LLM评估可以从评测方式（LLM评审、代码评估、人工标注等）和实施阶段（离线、在线、护栏）两维度分类，每种方式/场景都需权衡任务目标、工程成本与准确性；\n从评测方式， 目前主流方式是 LLM as a Judge，通常用于“参考文献-开放问答”类场景，让LLM判断答案是否基于参考文献，是否正确/完整，适用于缺乏人为标注数据或用户反馈时，能大规模自动化评测；关键难题：如何确保“评委LLM”的可靠性；适合主观性较强的评测如内容相关性、事实性；对于存在标准答案的场景，一般采用Code-Based Evaluations，适用于结果有“硬规则”或定量标准的任务，如代码生成、JSON结构、关键字段verify等；当然，也不可忽略其他辅助方法，如人工标注和用户实时反馈；\n从实践阶段，对于一个LLM应用而言，评估可分为：\n离线评测，上线/开发阶段，使用收集或合成的数据集（golden数据集）进行评测，用于prompt/模型版本/检索策略变化的回归测试和benchmark，通常嵌入CI/CD流程\n在线评测，系统上线生产后，对真实用户数据实时打分、监测（但一般不拦截输出，仅报告问题），更关注模型的稳定性、性能等在现实环境下的轨迹，及时发现线上退化、幻觉、响应异常或敏感内容\nGuardrails，实时、线上启用，发现风险（幻觉、违规、毒性等）即拦截或修正输出，优先级高于普通的在线评测\n最后聊聊评估。\n对于ML/DL算法工程师来说，评估这套流程大家都很熟。但未来最大的不同是，我们将进入一个普遍使用LLM进行评估的时代。这意味着，能被评估的东西会比过去多得多、广得多。以前必须靠人来评判的内容，会逐渐转向“LLM-judge”模式。简单说，只要你能用语言（Prompt）把评估标准描述清楚，那它就是可评估的。 当然，这也意味着写好、优化好Prompt会变得极其重要。\n对于开发者，评估这事儿本质上和软件测试很像。它们的目标都是提供一套覆盖足够广的测试用例（也就是“Golden Test Set”），确保你的程序（LLM应用）能顺利通过。一句话，如果测试对你很重要，那么评估也一样重要。\n","permalink":"https://niraya666.github.io/posts/eval_1/","summary":"\u003ch2 id=\"引子\"\u003e引子\u003c/h2\u003e\n\u003cp\u003e前一段时间，OpenAI 研究员姚顺雨在一篇广受关注的文章《\u003ca href=\"https://ysymyth.github.io/The-Second-Half/\"\u003eThe Second Half\u003c/a\u003e》中提出：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“I think we should fundamentally re-think evaluation. It means not just to create new and harder benchmarks, but to fundamentally question existing evaluation setups and create new ones, so that we are forced to invent new methods beyond the working recipe.”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e指出，AI 发展的“下半场”已经到来，而其中一个核心议题，就是对 evaluation的重新思考。我们需要的不再是单纯地创造更难的 benchmark，然后在这些 benchmark 上“刷分”，而是要更加关注评测的实用性、创新性，以及其与真实世界的契合度。\u003c/p\u003e\n\u003cp\u003e过去，我们往往过于关注模型本身、训练方法以及各种fancy的技术手段，却忽略了模型与真实世界的交互和落地应用。而 evaluation，正是连接模型能力与实际需求的关键环节。\u003c/p\u003e\n\u003cp\u003e本文最初的出发点，是梳理 \u003ca href=\"https://github.com/huggingface/evaluation-guidebook/tree/main\"\u003eHugging Face Evaluation \u003c/a\u003e系列文章中的一些要点。需要说明的是，HF 的文章主要聚焦于如何评测LLM的能力，考虑到其成文的时间，其中部分内容在当前 LLM 能力飞速提升的背景下，显得有些滞后。但这也为我们提供了一个契机，从后来者的视角重新思考 evaluation 的意义，并尝试将这些理念应用到更加复杂和多样化的 AI 系统中，如RAG和AI-agent。\u003c/p\u003e\n\u003cp\u003e在机器学习和深度学习的流程中，Evaluation是衡量模型性能的核心环节。它贯穿于模型开发的始终：从训练阶段的实时监控，到上线前的最终验证，再到部署后的持续追踪。\u003cbr\u003e\n\u003cbr\u003e\n简单来说，评估的目标是回答两个问题：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e模型是否有效？\u003c/strong\u003e（性能指标）\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e模型是否可靠？\u003c/strong\u003e（鲁棒性、泛化能力）\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e以经典的猫狗分类任务为例，在训练前，我们可能将数据集划分为trainingset，evalset，和testset （经典的7:2:1）保证训练数据与测试数据无重叠；对于分类问题，可能选择Accuracy、Precision和Recall 作为metrics，在训练过程中监控模型在evalset上的情况（是否存在overfitting之类的问题）；训练结束后，在testset上验证模型的最终性能，判断是否达到预期目标。\u003c/p\u003e","title":"从下半场开始，对于评估的重新思考: 一些概念"},{"content":"值得关注的模型和新技术 Google 2025 I/O 大会： I/O 2025\nGoogle在2025年I/O大会上全面展示了AI的最新进展和深度整合战略，涵盖基础模型迭代（如Gemini 2.5、Gemini Diffusion、Gemma 3n、Veo 3和Imagen 4）及多模态创新\nOpenAI codex Introducing Codex\nOpenAI 于 2025年5月16日推出了 Codex 软件工程代理及其驱动模型 codex-1 和 codex-mini-latest，专注提升软件开发的自动化与效率。codex-1 基于 o3 模型，优化并行处理、多轮测试和复杂项目支持，擅长代码生成、Bug 修复等任务；codex-mini-latest 则主打低延迟，适合快速命令行操作。Codex 平台通过云端隔离沙箱，安全模拟真实开发环境，自动化完成如重构、测试编写等任务，支持细致行为定制。\nClaude 4 Introducing Claude 4\nAnthropic 于2025年5月22日发布了新一代 Claude 4 系列模型，包括 Claude Opus 4 和 Claude Sonnet 4，重点提升了编码、高级推理和对AI代理的支持能力。Opus 4 在行业编码基准测试中表现领先，拥有更强的内存与持续任务能力，并大幅减少“抄近路”行为，专注于高复杂任务和AI代理核心场景。Sonnet 4 则在提升推理与指令遵循能力的同时，平衡了性能与效率。\nDeepSeek-R1-0528 Huggingface： deepseek-ai/DeepSeek-R1-0528\n通过强化学习与算法优化实现推理能力提升，单问题推理深度翻倍（平均Token量从12K→23K），更强的数学、编码能力，并支持工具调用，大幅降低幻觉。同时开源了蒸馏小模型模型 deepseek-ai/DeepSeek-R1-0528-Qwen3-8B。\nFlowith Neo Flowith Neo 是 Flowith 团队推出的新一代 AI 智能代理，专为自动化复杂、长流程任务设计。其核心技术包括支持无限步骤的持续云端执行、强大的上下文保持能力、灵活调用多种外部工具，以及可视化工作流和自反思机制，显著提升流程的连贯性和可靠性。\n值得关注的开源项目 DeerFlow Github: github.com/bytedance/deer-flow\n由字节跳动开源的，基于LangStack 开发的Deep Research 开源项目，支持深度研究、MCP 集成、报告 AI 增强编辑以及播客生成等功能，通过Docker compose一键启动。\nFlowGram.AI Github: github.com/bytedance/flowgram.ai\nFlowGram.AI 是由字节跳动推出的一款基于节点的可视化流程构建引擎，支持固定布局和自由连接布局两种模式，帮助开发者快速创建清晰输入输出的交互式工作流。\nMCP Server Chart Github: github.com/antvis/mcp-server-chart\nMCP Server Chart 是一个基于 AntV 的可视化MCP server，支持通过 AI 工具生成 15+ 种图表类型（如面积图、柱状图、折线图、词云等），并兼容 SSE 和 Streamable 协议，可无缝集成到 Claude、VSCode、Cline 等桌面或在线平台.\nRL-Factory Github: github.com/Simple-Efficient/RL-Factory\nRL-Factory 是一个专为代理强化学习（Agent Learning）设计的高效框架，通过解耦环境与强化学习后训练流程，让用户仅需配置工具和奖励函数即可快速训练智能体。其核心优势包括：易用性（支持一键式Qwen3模型训练及多轮工具调用，内置模型评估奖励机制）、高效性（异步工具调用和奖励计算使训练速度提升2倍）、模型支持（当前原生支持Qwen3系列模型，如Qwen3-4B/8B，并计划扩展至Deepseek、Llama等主流模型）。框架提供端到端检索模型训练能力（通过rag_server），并计划集成WebUI实现全流程可视化管理\n值得关注的研究和论文 EfficientLLM: Efficiency in Large Language Models arXiv:2505.13840\nNo One-Size-Fits-All Solution: 没有免费午餐,任何效率提升都伴随着其他方面的代价\nMoE架构虽然能提升模型性能并减少每token的FLOPs，但会使峰值VRAM使用量增加约40%\nint4可节省高达3.9倍的内存占用和能耗，但会导致任务平均准确率下降约3-5%\nOptima are Task- and Scale-Dependent: 效率最优解高度依赖于具体情境\nMQA在内存受限设备上提供了最佳的内存-延迟边界；MLA在质量关键任务中产生最低的困惑度；NSA能耗最低 对于1B-3B模型，LoRA及其变体（如DoRA）在特定内存约束下损失最低；对于超过14B参数的模型，RSLoRA在效率上（更低延迟和功耗）超过了LoRA。参数冻结在微调过程中端到端延迟最低 int4训练后量化能显著提升内存效率（最高减少3.9倍内存占用）和推理吞吐量（在内存受限条件下可提升3倍），同时模型性能仅有轻微下降（平均任务得分下降3-5个百分点）；bfloat16在Hopper架构GPU上一致优于float16 Broad Applicability Across Modalities：\n在LLM上验证的效率技术能有效迁移到LVM和VLM MQA/GQA能提高LVM的生成质量 PEFT方法在LVM和VLM上也实现了良好的性能-效率权衡 Nemotron-Research-Tool-N1: Exploring Tool-Using Language Models with Reinforced Reasoning Paper\n使用RL 提升LLM的tool-using能力\n解决的问题：\nSFT tool-using 需要大量数据标注 目前方法面对OOD数据表现不佳 具体实现\n基于Qwen2.5-7B/14B-Instruct，采用GRPO 策略模型输出包含两部分：：用\u0026lt;thinking\u0026gt;标签包裹的自然语言推理 和 用\u0026lt;tool_call\u0026gt;标签包裹的JSON格式工具名及参数 奖励设计： 格式正确性 工具调用正确性：工具名与参数需与真实值完全匹配（通过字典格式验证） 无需预训练SFT，直接从原始数据进行RL训练 数据：整合xLAM和ToolACE数据集，过滤无效工具调用，将多轮对话拆分为单步预测实例 有趣发现\nSFT-then-RL未必最优：纯RL训练优于SFT-then-RL流程（但并不显著），SFT可能阻碍RL性能 二元奖励优于细粒度奖励：细粒度奖励（如部分正确得分）易导致模型过拟合格式或局部匹配 移除格式正确性奖励，导致性能下降 类似的tool-RL方向论文：\nTORL: Scaling Tool-Integrated RL ReTool: Reinforcement Learning for Strategic tool use in LLMs ToolRL: Reward is All Tool Learning Needs Synthetic Data Generation \u0026amp; Multi-step RL for Reasoning \u0026amp; tool use LLMs Get Lost In Multi-Turn Conversation Paper\narXiv:2505.06120\n关于LLMs在多轮未完全指定对话场景下的性能退化问题\nGet lost的原因：\n过早且错误的假设：模型在对话早期基于不完整的信息做出假设，后续对话中，模型会围绕错误假设生成答案，导致最终结果完全偏离用户真实需求 未掌握完整信息时尝试完整解答：模型急于生成最终答案，即使用户尚未提供所有必要信息，；因为LLMs的训练目标不包含信息完善等内容 过度依赖之前的错误答案：模型将自己之前的错误回答视为“事实”，并在后续对话中不断强化这些错误 输出过于冗长：模型生成冗长的回答，包含无关细节或重复内容；因为训练数据中长文本占比高，且模型倾向于“过度解释”以避免遗漏 忽视中间回合的信息：模型对对话开头和结尾的信息关注度更高，但忽略中间回合的关键细节 “loss-in-the-middle” 建议：\n整合需求到单轮提示：一次性把话讲清楚 对话偏离时：重启并提供总结 Be careful： 多模型交叉验证 Temperature可以减少随机性，但即便为0也仍存在不可靠性 开发建议： 基准测试评估：增加多轮未指定任务的评估，而非仅关注单轮性能 错误识别修正，self-verification 意图识别 ZeroSearch: Incentivize the Search Capability of LLMs without Searching Paper\n解决了两个主要问题:\n从真实搜索引擎返回的文档质量往往不可预测，这会给训练过程引入噪声和不稳定性 强化学习(RL)训练需要频繁进行推演(rollout)，可能涉及数十万次搜索请求，这会产生巨大的API费用并严重限制可扩展性 创新点\n提出了ZeroSearch框架，一种不需要与真实搜索引擎交互就能增强LLM搜索能力的强化学习方法; 通过轻量级监督微调，将LLM转变为能够根据查询生成相关和噪声文档的检索模块;\n设计了Curriculum learning 的推演策略，在训练过程中逐步降低生成文档的质量，使模型逐渐适应更具挑战性的检索场景;\n引入损失屏蔽机制，确保只对模型自身生成的token应用损失计算，避免从检索模块生成的文档token影响训练稳定性\n具体实现\n搜索模拟微调\n收集LLM与真实搜索引擎交互的轨迹，根据是否导致正确答案将其标记为正面或负面样本 从这些轨迹中提取查询-文档对进行轻量级监督微调 Curriculum Search Simulation: 使用概率函数控制生成噪声文档的可能性，随着训练进行逐步增加难度,允许策略模型先学习基本输出格式和任务要求，然后逐渐适应更具挑战性的检索场景\n噪声文档生成概率：\n$$p_i = p_s + \\frac{b^{i/m} - 1}{b - 1} (p_e - p_s)$$\n奖励设计: 采用基于F1分数的奖励，平衡精确率和召回率，避免模型通过生成过长答案来提高命中率的\u0026quot;reward hacking\u0026quot;行为\n$$r_\\phi(x, y) = \\frac{2 \\times IN}{PN + RN}$$\n其中 IN 为模型输出与标准答案之间的重叠词数（Intersection Number），PN 和 RN 分别为模型输出的词数（Prediction Number） 和标准答案的词数（Reference Number）\n没有对输出格式单独奖励，因为实验发现模型在训练过程中能自发学会输出规范格式\nPhi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math Paper\n如何提升小型LLM（3.8B）在数学推理任务中的推理能力；\n实现：\nDistillation：利用DeepSeek-R1生成的大量多领域、多难度的CoT推理数据，对Phi-4-Mini进行中间训练，提升其基础推理能力 如果数据集包含reasoning trajectories，则直接使用，没有推理过程，则用DeepSeek-R1生成CoT推理答案，生成8个不同rollouts，最终总共收集了约160万道题、1000万个rollouts 用自动化工具检查答案是否正确，对于工具的误判复杂解答，用GPT-4o-mini再复查一遍 Rollout Preference Learning：利用大模型生成的错误推理样本，构建正确-错误的偏好对，采用DPO方法优化 RL with Verifiable Reward： 使用GRPO进一步优化，奖励函数为自动化验证工具对最终答案的判定 遇到的问题和解决方案：\n响应长度差异大导致训练不稳定：采用Prompt Optimization，在RL训练前，先用蒸馏后的模型对多个候选prompt多轮采样，只保留那些生成答案长度比较一致的prompt； 奖励一致时梯度消失问题，GRPO依赖于advantage estimate，如果同一组采样的答案奖励完全一样（比如全对或全错），就会导致梯度为零；即便将全对/全错过滤，长度差异大，梯度依然不稳定，正负样本极度不平衡，影响RL收敛：**Reward Rebalancing，**针对难题，先过采样以保证组内多样性，然后把所有正向奖励的答案都保留，再随机采样等量的负向奖励答案，保证正负样本平衡，对于太容易的题目直接过滤掉。 Exploration–Exploitation Tradeoff，RL训练需要exploration才能找到高奖励策略，通常用高温度采样促进探索，但实际评测时往往用低温度来减少输出波动：Temperature Annealing，训练初期用高温度（1.0）促进探索，随着训练进展，线性降低温度到0.6，后期固定为0.6，逐步过渡到exploitation UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities Paper\n如何让RAG系统能灵活地从多种模态和多种粒度的知识库中检索最合适的信息，提升事实准确性和适应性。 现有“统一嵌入空间”的多模态检索方法存在“模态鸿沟”（modality gap），即检索时更倾向于返回与查询同模态的数据，导致跨模态检索效果差。 主要创新点\nModality-aware Routing：不再强行将所有模态数据压缩到同一个嵌入空间，而是为每种模态（文本、图片、视频）分别维护独立的检索空间，通过一个“路由”模块，根据查询内容动态判断最适合的模态和粒度，然后只在对应的知识库中检索。 Granularity-aware Retrieval：每种模态下进一步细分粒度：如文本分为段落级、文档级，视频分为片段级、完整视频级，图片本身为最细粒度，路由不仅判断模态，还能判断所需的粒度，提升检索的相关性和生成质量 路由器设计：支持“零训练”路由（用大模型如GPT-4o直接prompt分类）和“有监督训练”路由（用DistilBERT、T5-Large等模型训练分类器） 具体实现\n路由： 输入查询后，路由器首先判断该问题是否需要外部检索，若需检索，则进一步判断最合适的模态（文本/图片/视频）和粒度（段落/文档/片段/完整视频） 分模态检索：每种模态有独立的检索器和嵌入空间，避免模态混淆 生成回答：检索到的内容与原始查询一起输入到多模态大模型（LVLM）中，生成最终回答 推荐内容 Huggingface 官方推出的MCP教程: MCP Course\nDeepleaning.AI 同Anthropic 联手推出的MCP课程： MCP: Build Rich-Context AI Apps with Anthropic\nAI Engineering Transition Path\nAI Red Teaming Playground Labs\n影音记录 精选歌单 Live演出 05.08 Adam Fischer-杜塞尔多夫交响乐团《马勒第九交响》 05.09 Honeydip 05.10 Hans Zimmer 05.16 Envy 05.23 Sea Power 05.24-05.25 Offside Festival 05.28 Maruja 书\u0026amp;阅读摘录 Why Cline Doesn\u0026rsquo;t Index Your Codebase (And Why That\u0026rsquo;s a Good Thing) Why RAG Breaks Down for Code … The approach seems straightforward – chunk your data, create embeddings, store them in a vector database, and retrieve relevant pieces when needed. … But code isn\u0026rsquo;t like other data. It\u0026rsquo;s interconnected, constantly evolving, and often contains your most sensitive intellectual property. When you apply traditional RAG approaches to codebases, three critical problems emerge:\nCode Doesn\u0026rsquo;t Think in Chunks … when you chunk code for embeddings, you\u0026rsquo;re literally tearing apart its logic. … Indexes Decay While Code Evolves … An index, by definition, is a snapshot frozen in time. The code inevitably drifts out of sync. … Cline\u0026rsquo;s Approach: Think Like a Developer, Act Like a Developer … Starting with Structure, Not Snippets … Discovery, Not Retrieval\nIf you\u0026rsquo;re an engineer who\u0026rsquo;s feeling hesitant or overwhelmed by… stop treating AI like a vending machine for code. Think of AI as a highly skilled (but forgetful) pair programmer. Planning before AI writes any code. Frontload all relevant context \u0026ndash; files, existing patterns, overall goals. Then, collaboratively develop a strategy with your AI.\nUse \u0026ldquo;Rules Files\u0026rdquo; \u0026ndash; essentially custom instructions \u0026ndash; to persistently guide AI behavior. Complement Rules Files with \u0026ldquo;Memory Banks.” This allows the AI to \u0026ldquo;remember\u0026rdquo; critical project details, patterns, and decisions over time.\n万字干货！如何让用户体验良好的同时，提高产品转化率？ 确实能带来短期转化，但问题是只要用户反感一次，就很难再赢回来了\n结论：良好的用户引导应以用户利益为核心\n用户引导不该是“温柔的陷阱”，而应该是“清晰的邀请”；产品设计也不该是“只求你上钩”，而应该是“愿你心甘情愿留下”\nAvoiding Skill Atrophy in the Age of AI we may be increasing productivity, but at risk of losing our edge to skill atrophy if we’re not careful.\nThis cognitive offloading - relying on external tools to handle mental tasks - has plenty of precedents.\ntempt us to “turn off our brain” for routine coding tasks. … “I’ve become a human clipboard”\nUsing AI as a collaborator, not a crutch Use AI to augment, not replace, code review. Pair program with the AI.\nAI Agent 新探索：构建 AI 原生团队，使能 AI 员工 为什么目前的 AI 无法成为靠谱的数字员工: 首先是企业知识未文档化的问题…很少有系统性的文档记录… 工具与系统的操作障碍严重限制了 AI 的能力发挥 AI Agent 缺少执行持续任务的机制 AI 缺少长期记忆机制，难以累积经验和知识\n要让 AI 成为有效的团队成员，首先要解决的不是 AI 技术本身，而是企业知识管理的问题。 要真正发挥 AI 的潜力，我们不仅需要提升 AI 的能力，还需要改造现有的工具和系统 然而，许多企业的 CI/CD 管道不完善或不存在…环境配置往往是手动完成的，难以复制。 … 原因很简单： B 团队的知识是可检索的，而 A 团队的知识被锁在人脑和私人对话中 … 而在 AI 原生团队中，知识必须从个人大脑转移到共享资源 — “团队知道某事” 增加了整体效能。 … Markdown 与 Git 等版本控制系统兼容性更好，支持差异对比和协作编辑，这对团队知识管理至关重要。 … 为内部系统提供 API 接口\n即使是最聪明的开发者（或 AI）也需要适当的测试条件。 测试驱动开发(TDD)的理念在 AI 时代变得更加重要 … 在 AI 时代，这变成了”人机四眼”—AI 生成的代码需要人类审查，人类编写的复杂代码可由 AI 辅助检查。\n它核心理念是”要想真正学会，就要能教会他人”。 要求 AI 在接受任务后首先生成一份 “工作理解文档”，包括： 目标概述：一句话总结任务目标上下文理解：相关背景和约束澄清问题：需要进一步明确的事项初步方案：可能的实现路径预期成果：如何评判成功 … 与其说我们在教 AI 如何更好地执行任务，不如说我们在教它如何更好地理解任务\n主动性不足是限制 AI 成为真正团队成员的另一大障 … 一个沉默地陷入困境的员工比一个主动寻求帮助的员工更让人担忧。 … 而优秀的数字员工则会明确描述问题所在，提出可能的解决路径，并寻求必要的帮助。\n从系统安全角度看，这涉及到”环境状态管理”—对工作环境变化的监控和保护能力。 … 变更范围评估：此操作会影响哪些系统组件？风险等级判定：操作可能导致的最坏结果是什么？可逆性分析：如果出错，恢复难度有多大？备选方案考虑：是否存在风险更低的替代方法？\n","permalink":"https://niraya666.github.io/monthly/2025-05-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003ch2 id=\"google-2025-io-大会\"\u003eGoogle 2025 I/O 大会：\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://blog.google/technology/developers/google-io-2025-collection/\"\u003eI/O 2025\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eGoogle在2025年I/O大会上全面展示了AI的最新进展和深度整合战略，涵盖基础模型迭代（如Gemini 2.5、Gemini Diffusion、Gemma 3n、Veo 3和Imagen 4）及多模态创新\u003c/p\u003e\n\u003ch2 id=\"openai-codex\"\u003eOpenAI codex\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/introducing-codex/\"\u003eIntroducing Codex\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOpenAI 于 2025年5月16日推出了 Codex 软件工程代理及其驱动模型 codex-1 和 codex-mini-latest，专注提升软件开发的自动化与效率。codex-1 基于 o3 模型，优化并行处理、多轮测试和复杂项目支持，擅长代码生成、Bug 修复等任务；codex-mini-latest 则主打低延迟，适合快速命令行操作。Codex 平台通过云端隔离沙箱，安全模拟真实开发环境，自动化完成如重构、测试编写等任务，支持细致行为定制。\u003c/p\u003e\n\u003ch2 id=\"claude-4\"\u003eClaude 4\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://www.anthropic.com/news/claude-4\"\u003eIntroducing Claude 4\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAnthropic 于2025年5月22日发布了新一代 Claude 4 系列模型，包括 Claude Opus 4 和 Claude Sonnet 4，重点提升了编码、高级推理和对AI代理的支持能力。Opus 4 在行业编码基准测试中表现领先，拥有更强的内存与持续任务能力，并大幅减少“抄近路”行为，专注于高复杂任务和AI代理核心场景。Sonnet 4 则在提升推理与指令遵循能力的同时，平衡了性能与效率。\u003c/p\u003e\n\u003ch2 id=\"deepseek-r1-0528\"\u003e\u003cstrong\u003eDeepSeek-R1-0528\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eHuggingface： \u003ca href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1-0528\"\u003edeepseek-ai/DeepSeek-R1-0528\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e通过强化学习与算法优化实现推理能力提升，单问题推理深度翻倍（平均Token量从12K→23K），更强的数学、编码能力，并支持工具调用，大幅降低幻觉。同时开源了蒸馏小模型模型 \u003ca href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\"\u003edeepseek-ai/DeepSeek-R1-0528-Qwen3-8B\u003c/a\u003e。\u003c/p\u003e\n\u003ch2 id=\"flowith-neo\"\u003e\u003cstrong\u003eFlowith Neo\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eFlowith Neo 是 Flowith 团队推出的新一代 AI 智能代理，专为自动化复杂、长流程任务设计。其核心技术包括支持无限步骤的持续云端执行、强大的上下文保持能力、灵活调用多种外部工具，以及可视化工作流和自反思机制，显著提升流程的连贯性和可靠性。\u003c/p\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003ch2 id=\"deerflow\"\u003e\u003cstrong\u003eDeerFlow\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eGithub: \u003ca href=\"https://github.com/bytedance/deer-flow\"\u003egithub.com/bytedance/deer-flow\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e由字节跳动开源的，基于LangStack 开发的Deep Research 开源项目，支持深度研究、MCP 集成、报告 AI 增强编辑以及播客生成等功能，通过Docker compose一键启动。\u003c/p\u003e","title":"2025-05 月刊"},{"content":"写在开头 本文是对于Mem0的论文解读和使用记录；\nMem0 是一款面向LLM应用的memory layer框架，同时是开源的。虽然它最早在 2024 年中旬亮相，起初的框架设计并没有太多亮眼之处，不过在最近，发布了一次比较重大的更新（基本上是重构了）采用了基于 AI-agent 的对话记忆提取、更新和查询等机制，实际体验下来，算是目前为止比较好用的了。\nPaper笔记 Paper\n创新点 Mem0架构：提出了一种可扩展的、以记忆为中心的AI代理架构，能够动态地从对话中抽取、整合和检索关键信息，实现长期、跨会话的记忆\nMem0g（图记忆扩展）：在基础架构上进一步引入“图结构记忆”，用有向标注图（节点为实体，边为关系）来捕捉对话中复杂的实体关系和事件顺序，提升多跳推理和时序推理能力\nMem0实现 extraction phase:\n每当有一对新的消息$(m_{t},m_{t−1})$进入系统时，系统会启动记忆抽取流程\n系统会同时参考两类上下文信息: 全局对话摘要（S）和 最近的消息序列${m_{t−m}, \u0026hellip;, m_{t−2}}$\n组合成一个完整的提示（prompt）P，输入给LLM实现的抽取函数ϕ。LLM会基于这些信息，抽取出本轮对话中值得记忆的关键信息（$Ω = (ω_1,\u0026hellip;,ω_n )$），作为候选事实，准备加入知识库\n为保障S始终是最新的，使用异步摘要生成模块，定期刷新摘要内容\nupdate phase：\n核心任务：检查这些新事实和已有记忆之间的关系和证知识库的内容既不重复，也不矛盾，始终保持一致和精简\n对每一个新抽取的事实（$ω_i$），系统会检索数据库中与之最相似的s条已有记忆（用向量嵌入做语义相似度检索）, 将$ω_i$ 和相似记忆一起交给LLM，由LLM从以下4种工具选择并执行（tool-using）：\nADD\nUPDATE\nDELETE\nNOOP （什么也不做）\n具体算法\nMem0g实现 以图$G = ( V , E , L )$ 建模记忆，(实体、关系、和语义label)\n每个entity（node）包含三部分信息：\nentity type classification：用于标记这个实体属于哪一类\nembedding vector：实体语义含义的向量表示，便于后续做语义相似度检索和推理\nmetadata： 主要包括创建时间戳（creation timestamp），用于记录这个实体被加入知识图谱的时间，有助于时序推理\nrelationships 用triplet的表示：\n$v_s$：关系的起点实体（source node）\n$r$: 关系的类型（labeled edge）\n$v_d$: 关系的终点实体（destination node）\n整个信息抽取过程分为两步，均由LLM驱动:\n实体抽取（entity extraction）\n首先，系统会用LLM分析输入文本，识别出其中所有值得被记忆的“实体”及其类型。\n这些实体可以是人、地点、物品、概念、事件、属性等。\n判断标准包括：语义重要性、独特性、持久性（即是否值得长期记忆）。\n关系抽取（relationship extraction）接着，系统会识别这些实体之间的语义关系，生成三元组，构建出结构化的知识图谱\n实验 数据集：LOCOMO (Maharana et al., 2024),包含 10 个长对话，每个对话约 600 轮、26000 tokens，跨多次会话。每个对话后有约 200 个问题及标准答案，问题类型包括 single-hop、multi-hop、temporal、open-domain\nbaseline 选择：已有的 memory-augmented 系统（如 LoCoMo、ReadAgent、MemoryBank、MemGPT、A-Mem），RAG，Full-context，LangMem，OpenAI memory 和 Zep\nevaluation metrics：\nPerformance Metrics：F1 Score (F1)，传统的词级重叠指标；BLEU-1 (B1)，单词级 BLEU 分数； LLM-as-a-Judge (J)，综合评估回答的事实准确性、相关性、完整性和上下文适应性，整个数据集上独立运行 10 次，报告均值和标准差\nDeployment Metrics：Token Consumption（检索到的 context token 数量，反映系统的计算和成本效率）；Latency，测量Search Latency和Total Latency\n实验结果\n在测试集上SOTA\nGraph-based 方法似乎涨点不多，仅在temporal和open-domain上有明显效果 延迟和token消耗\nMem0 使用指南 依赖安装\n! pip install mem0ai langchain_openai 由于需要使用到LLM 和emebdding 模型， 这里采用siliconflow的API作为演示，利用langchain作为模型提供\n模型信息：\nfrom langchain_openai import OpenAIEmbeddings,ChatOpenAI openai_embeddings = OpenAIEmbeddings( model=\u0026#34;BAAI/bge-m3\u0026#34;, openai_api_base=\u0026#34;https://api.siliconflow.cn/v1\u0026#34;, openai_api_key=API_KEY, dimensions=1024 ) llm = ChatOpenAI( base_url=\u0026#34;https://api.siliconflow.cn/v1\u0026#34;, api_key=API_KEY, model=\u0026#34;Qwen/Qwen3-14B\u0026#34; ) 使用docker方式，在本地启动向量库服务qdrant\ndocker pull qdrant/qdrant docker run -p 6333:6333 -p 6334:6334 \\ -v $(pwd)/qdrant_storage:/qdrant/storage:z \\ qdrant/qdrant 修改对应的配置config信息：\nconfig = { \u0026#34;llm\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;langchain\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;model\u0026#34;: llm, } }, \u0026#34;embedder\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;langchain\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;model\u0026#34;: openai_embeddings } }, \u0026#34;vector_store\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;qdrant\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 6333, \u0026#34;embedding_model_dims\u0026#34;:1024 } }, } mem0使用：\nfrom mem0 import Memory m = Memory.from_config(config) messages = [ {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;I\u0026#39;m planning to watch a movie tonight. Any recommendations?\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;How about a thriller movies? They can be quite engaging.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;I’m not a big fan of thriller movies but I love sci-fi movies.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Got it! I\u0026#39;ll avoid thriller recommendations and suggest sci-fi movies in the future.\u0026#34;} ] # 插入： m.add(messages, user_id=\u0026#34;alice\u0026#34;, metadata={\u0026#34;category\u0026#34;: \u0026#34;movies\u0026#34;}) # Get all memories all_memories = m.get_all(user_id=\u0026#34;alice\u0026#34;) # Get a single memory by ID specific_memory = m.get(\u0026#34;MEMORY-ID\u0026#34;) # Search Memories related_memories = m.search(query=\u0026#34;What do you know about me?\u0026#34;, user_id=\u0026#34;alice\u0026#34;) # Delete a memory by id m.delete(memory_id=\u0026#34;MEMORY-ID\u0026#34;) # Delete all memories for a user m.delete_all(user_id=\u0026#34;alice\u0026#34;) m.reset() # Reset all memories 支持自定义Fact Extraction Prompt：\ncustom_fact_extraction_prompt = \u0026#34;\u0026#34;\u0026#34; Please only extract entities containing customer support information, order details, and user information. Here are some few shot examples: Input: Hi. Output: {{\u0026#34;facts\u0026#34; : []}} Input: The weather is nice today. Output: {{\u0026#34;facts\u0026#34; : []}} Input: My order #12345 hasn\u0026#39;t arrived yet. Output: {{\u0026#34;facts\u0026#34; : [\u0026#34;Order #12345 not received\u0026#34;]}} Input: I\u0026#39;m John Doe, and I\u0026#39;d like to return the shoes I bought last week. Output: {{\u0026#34;facts\u0026#34; : [\u0026#34;Customer name: John Doe\u0026#34;, \u0026#34;Wants to return shoes\u0026#34;, \u0026#34;Purchase made last week\u0026#34;]}} Input: I ordered a red shirt, size medium, but received a blue one instead. Output: {{\u0026#34;facts\u0026#34; : [\u0026#34;Ordered red shirt, size medium\u0026#34;, \u0026#34;Received blue shirt instead\u0026#34;]}} Return the facts and customer information in a json format as shown above. \u0026#34;\u0026#34;\u0026#34; config = { ..., \u0026#34;custom_fact_extraction_prompt\u0026#34;: custom_fact_extraction_prompt, } 同时也可自定义修改Update Memory Prompt，具体参考：Custom Update Memory Prompt\nOpenMemory MCP 于此同时Mem0也提供了本地化的MCP-server\nopenMemory\n依照官方文档操作，能够启动3个docker-container，分别是openmemory主程序，openmemory的前端UI和向量库；\n如果要自定义config，需要自行修改openmemory/api/app/mcp_server.py中的内容；\n体验 和理想中记忆的设计还是有一定差距的，但至少是当下比较成型的记忆框架，同时还是开源的，那还要什么自行车呢？\n鉴于其延迟性，放在online对话上多少有些影响体验，但用作offline的信息提取又有何不可呢\n总体而言，agent 化的 memory 设计方向是值得肯定的\n参考 Github主页\n文档\nMem0: Building Production-Ready AI Agents with Scalable Long-Term Memory\n","permalink":"https://niraya666.github.io/posts/%E5%88%9D%E6%8E%A2mem0/","summary":"\u003ch2 id=\"写在开头\"\u003e写在开头\u003c/h2\u003e\n\u003cp\u003e本文是对于\u003ca href=\"https://github.com/mem0ai/mem0\"\u003eMem0\u003c/a\u003e的论文解读和使用记录；\u003c/p\u003e\n\u003cp\u003eMem0 是一款面向LLM应用的memory layer框架，同时是开源的。虽然它最早在 2024 年中旬亮相，起初的框架设计并没有太多亮眼之处，不过在最近，发布了一次比较重大的更新（基本上是重构了）采用了基于 AI-agent 的对话记忆提取、更新和查询等机制，实际体验下来，算是目前为止比较好用的了。\u003c/p\u003e\n\u003ch2 id=\"paper笔记\"\u003ePaper笔记\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2504.19413\"\u003ePaper\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"创新点\"\u003e\u003cstrong\u003e创新点\u003c/strong\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eMem0架构\u003c/strong\u003e：提出了一种可扩展的、以记忆为中心的AI代理架构，能够动态地从对话中抽取、整合和检索关键信息，实现长期、跨会话的记忆\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eMem0g（图记忆扩展）\u003c/strong\u003e：在基础架构上进一步引入“图结构记忆”，用有向标注图（节点为实体，边为关系）来捕捉对话中复杂的实体关系和事件顺序，提升多跳推理和时序推理能力\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"mem0实现\"\u003e\u003cstrong\u003eMem0实现\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%88%9d%e6%8e%a2Mem0-assets/Pasted%202025-05-20-16-29-02.png\" alt=\"Pasted 2025-05-20-16-29-02.png\"  /\u003e\n\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eextraction phase:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e每当有一对新的消息$(m_{t},m_{t−1})$进入系统时，系统会启动记忆抽取流程\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e系统会同时参考两类上下文信息: \u003cstrong\u003e全局对话摘要（S）和 最近的消息序列\u003c/strong\u003e${m_{t−m}, \u0026hellip;, m_{t−2}}$\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e组合成一个完整的提示（prompt）\u003cstrong\u003eP\u003c/strong\u003e，输入给LLM实现的抽取函数\u003cstrong\u003eϕ\u003c/strong\u003e。LLM会基于这些信息，抽取出本轮对话中值得记忆的关键信息（$Ω = (ω_1,\u0026hellip;,ω_n )$），作为候选事实，准备加入知识库\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e为保障S始终是最新的，使用异步摘要生成模块，定期刷新摘要内容\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eupdate phase：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e核心任务：检查这些新事实和已有记忆之间的关系和证知识库的内容既不重复，也不矛盾，始终保持一致和精简\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e对每一个新抽取的事实（$ω_i$），系统会\u003cstrong\u003e检索数据库中与之最相似的s条已有记忆\u003c/strong\u003e（用向量嵌入做语义相似度检索）, 将$ω_i$ 和相似记忆一起交给LLM，由LLM从以下4种工具选择并执行（tool-using）：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eADD\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eUPDATE\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eDELETE\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eNOOP\u003c/strong\u003e （什么也不做）\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e具体算法\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%88%9d%e6%8e%a2Mem0-assets/%e6%88%aa%e5%b1%8f2025-05-10%20%e4%b8%8b%e5%8d%883.13.17.png\" alt=\"截屏2025-05-10 下午3.13.17.png\"  /\u003e\n\u003c/p\u003e\n\u003ch3 id=\"mem0g实现\"\u003e\u003cstrong\u003eMem0g实现\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%88%9d%e6%8e%a2Mem0-assets/Pasted%202025-05-20-16-31-40.png\" alt=\"Pasted 2025-05-20-16-31-40.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e以图$G = ( V , E , L )$ 建模记忆，(实体、关系、和语义label)\u003c/p\u003e\n\u003cp\u003e每个entity（node）包含三部分信息：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eentity type classification：用于标记这个实体属于哪一类\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eembedding vector：实体语义含义的向量表示，便于后续做语义相似度检索和推理\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003emetadata： 主要包括创建时间戳（creation timestamp），用于记录这个实体被加入知识图谱的时间，有助于时序推理\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003erelationships 用triplet的表示：\u003c/p\u003e","title":"初探 Mem0"},{"content":"值得关注的模型和新技术 OpenAI 更新系列模型 发布了多款新一代AI模型，包括o3、o4-mini、GPT-4.1及其mini和nano版本。这些模型在推理能力、成本效益和多模态处理等方面实现了提升。o3专注于复杂推理和工具使用，已在ChatGPT Plus等产品中取代前代模型。o4-mini则以高性价比和多模态能力为亮点。GPT-4.1系列主打超长上下文和高效编码，mini和nano版本进一步降低成本和延迟。\nIntroducing GPT-4.1 in the API\nIntroducing OpenAI o3 and o4-mini\nKimi-VL 和 Kimi-VL-Thinking 由Moonshot AI推出了新一代视觉语言模型Kimi-VL及其，主打高效多模态推理高级版本Kimi-VL-Thinking。采用轻量级混合专家架构（16B总参数量，2.8B的激活参数），支持128K上下文窗口和超高分辨率视觉输入，Kimi-VL-Thinking通过链式思考和强化学习训练，专注于复杂推理和数学任务。\nHugging Face Kimi-VL-Thinking 模型页面\nKimi-VL Technical Report\nA2A协议 A2A协议（Agent2Agent Protocol）是由谷歌于2025年4月10日在Google Cloud Next 2025大会上宣布开源的标准智能体交互协议，旨在实现跨平台、跨供应商的AI智能体（AI Agent）无缝通信与协作。功能与特点：A2A协议通过统一规则支持多模态协作，允许智能体共享和处理文本、音频、视频等多种数据格式，兼容HTTP、SSE、JSON-RPC等现有标准，降低企业集成成本。其核心机制包括Agent Card，用于智能体能力发现与协作对接，支持自然、非结构化协作模式，即使智能体不共享内存或上下文也能协同工作。\nAnnouncing the Agent2Agent Protocol (A2A)\nQwen3 Qwen3 是Qwen的第三代大语言模型系列，于2025年4月正式发布，包含6个稠密模型（0.6B至32B参数）和2个混合专家（MoE）模型（30B-A3B和235B-A22B）。功能与特点：Qwen3支持119种语言，训练数据高达36万亿token，具备自然语言理解、文本生成、工具调用、复杂推理及多模态交互能力。模型采用混合推理模式，可根据任务复杂度自动切换“思考”与“快速响应”模式，优化计算效率与响应速度。支持128K token上下文长度，适用于长文档处理、编程、数学推理及智能体任务。创新点：Qwen3引入动态可调MoE架构，通过分层稀疏调度和动态专家激活（最多128个专家，单token激活8个），显著降低推理耗时（15B模型推理效率提升42%）和显存占用（从28GB降至18GB）。新增Qwen3RMSNorm归一化层优化注意力机制，支持多种RoPE变体（dynamic、yarn、llama3）以提升长序列处理能力。词表优化引入动态加权合并算法，增强高频词组处理，并新增智能体专用控制符。效果：旗舰模型Qwen3-235B-A22B在Codeforces编程竞赛、AIME数学基准及BFCL推理测试中超越OpenAI的o3-mini和谷歌Gemini 2.5 Pro，Qwen3-32B在LiveCodeBench编码任务中优于OpenAI o1。\nBlog\nHuggingface\n值得关注的开源项目 Inbox Zero Inbox Zero 是一个开源的 AI 邮件管理工具，旨在通过智能化功能帮助用户快速清空收件箱并高效处理邮件。项目包含两部分：AI 邮件助手与开源邮件客户端。其核心功能包括：\nAI 个人助理：基于用户自定义的文本指令，可自动执行邮件管理操作（如起草回复、标记分类、归档、标记垃圾邮件或触发网络钩子），显著减少手动处理时间。 Reply Zero 跟踪：实时追踪需用户回复的邮件及等待他人回复的邮件，提升沟通效率。 智能分类与退订：自动整理联系人邮件并智能归类，支持一键批量退订低价值订阅。 冷邮件拦截与分析：自动过滤陌生发件人邮件，并提供每日/周/月邮件活动统计，帮助用户优化收件箱管理。 技术优势与适用场景\n项目采用 Next.js、Tailwind CSS 等现代技术栈构建，支持通过 Vercel 快速部署或自托管，兼容 Anthropic、OpenAI 等 LLM 模型，甚至可集成本地 Ollama 服务以降低成本。\nGithub：github.com/elie222/inbox-zero\nFastMCP v2 FastMCP v2 是一个专为快速构建 Model Context Protocol (MCP) 服务器和客户端设计的 Python 工具库，旨在简化MCP开发。基于标准化的 MCP 协议，FastMCP 通过简洁的 Pythonic 设计，帮助开发者高效创建工具、资源、提示模板，并无缝连接组件，同时自动处理协议细节与服务器管理。其核心功能包括：通过装饰器快速定义工具（Tools）及资源（Resources），支持代理服务器配置、多服务组合，以及从 OpenAPI 或 FastAPI 规范自动生成 MCP 服务；客户端则提供灵活的连接方式、LLM 采样等高级功能，便于程序化测试与创新应用\nGithub：github.com/jlowin/fastmcp\nHawkinsDB HawkinsDB是一款受杰夫·霍金斯“千脑理论”启发的神经科学驱动型记忆系统，旨在为LLM应用提供更接近人类认知的记忆管理能力。不同于传统的向量数据库，它通过整合语义、情景和程序性记忆，构建了一个多维度的记忆框架，使AI能够精准理解数据间的关联与上下文，而非仅依赖模糊的相似性搜索。其核心功能包括：\n神经科学架构：采用“参考框架”（Reference Frames）和“皮层柱”（Cortical Columns）概念，模拟大脑多角度处理信息的方式，支持从属性、关系到场景的结构化知识存储。 透明化决策：通过清晰的逻辑链展示信息关联，避免“黑箱”问题，帮助开发者理解AI的推理过程。 灵活扩展：支持SQLite和JSON存储，集成ConceptNet实现知识自动丰富，并提供自然语言查询接口。 Github：github.com/harishsg993010/HawkinsDB\nTask Master Task Master 是一个基于Claude AI的任务管理系统，专为AI驱动的开发流程设计，能够自动解析产品需求文档（PRD），生成结构化任务体系，并与Cursor AI等工具无缝集成，帮助开发者高效规划和追踪项目进度\n具体功能：\n智能任务拆解：自动解析PRD文档，生成包含Epic和子任务的结构化任务体系 依赖关系管理：智能分析任务间的依赖关系，确保开发顺序合理 编辑器深度集成：通过MCP配置无缝接入Cursor或Windsurf等编辑器，支持自然语言指令直接与AI交互 Github：github.com/eyaltoledano/claude-task-master\nGraphiti Graphiti 是一个专为动态环境设计的实时知识图谱框架，旨在帮助AI代理高效管理时序数据。其核心特性包括：1）实时增量更新，支持动态数据流的即时整合；2）双时态模型，精准追踪事件发生时间和数据摄入时间；3）混合检索引擎，通过语义嵌入、关键词搜索和图遍历实现亚秒级低延迟查询；4）可定制实体系统，允许开发者通过Pydantic定义自定义实体类型。相比传统RAG方法，Graphiti无需全量重算即可处理数据变化，特别适用于需要上下文感知、历史追溯的企业级应用。\nGithub：github.com/getzep/graphiti\n值得关注的研究和论文 PaperBench: Evaluating AI’s Ability to Replicate AI Research Paper\n如何评估AI代理自主复现前沿AI研究的能力：\n理解复杂的科研论文。 从零开始开发功能代码库。 执行实验以复现论文的实证结果。 创新点\nPaperBench Benchmark LLM-Based Judge **PaperBench Code-Dev变体：**放宽执行要求的轻量级版本 具体实现：\n代理接收论文，生成包含reproduce.sh脚本的代码库，用于执行实验\n提交内容在配备A10 GPU的Ubuntu 24.04虚拟机中从零执行\n评分标准\n分层评分标准将任务分解为叶子节点（二元通过/不通过） 三种评估类型： 代码开发：代码实现的正确性。 执行：reproduce.sh脚本的正确运行。 结果匹配：复现结果与论文的一致性。 LLM评分（o3-mini｜o1）\n实验结果\nClaude 3.5 Sonnet 为已测试模型中最佳（21.0%） 人类基线：博士生（取得41.4%的得分，显著优于模型） 观察： 模型常过早终止任务，未能有效制定策略 性能停滞：模型初期进步后趋于平稳，而人类持续提升。 代码与执行差距：模型擅长编写代码（代码开发得分35.4%），但执行（1.8%）和结果匹配（0.7%）表现极差。 IterativeAgent (forced to use full time) 能够提升agent分数 RARE: Retrieval-Augmented Reasoning Modeling Paper\n核心问题:\nRAG仅仅补充知识，未系统优化推理能力，特别是在特定领域下（如医疗、金融等）需要专业知识和复杂推理能力，导致在需要多步骤逻辑分析的任务中表现不佳。 RARE shifts LLM training from memorizing knowledge (“Remember”) to applying and evaluating it (“Analyze”, “Create”). It separates domain knowledge (retrieved externally) from domain thinking (learned during training), enabling better performance under tight parameter budgets.\n创新点\nRARE（Retrieval-Augmented Reasoning Modeling），一种解耦知识存储与推理优化；具体而言， 将知识存储于数据库中， 通过训练将领域特定的推理模式内化至模型中 具体实现\n训练流程： 使用QwQ-32B模型，生成包含知识和推理步骤的高质量训练数据 （知识蒸馏） 对错误答案进行多次迭代修正，直到生成正确结果（自适应重采样，adaptive retries） 在Llama-3.1-8B上做SFT，优化推理能力而非知识记忆 推理阶段： 同普通RAG Why do LLMs attend to the first token? Paper\n这篇论文研究了LLMs中的\u0026quot;注意力汇聚\u0026quot;(attention sink)现象，即为什么LLMs会大量关注序列中的第一个token(通常是标记),形成注意力汇聚现象。\nover-mixing: 在LLMs中信息往往会被过度混合，导致所有token的嵌入变得相似\n研究发现：attention sink 是模型避免\u0026quot;过度混合\u0026quot;(over-mixing)的一种机制， 注意力sink——即许多注意力头集中在⟨bos⟩（beginning of sequence）token上——起到类似“空操作”的作用，减少token之间的相互作用，从而在各层之间保持表示的多样性。\n实验方式：\n扰动分析实验 (Perturbation Analysis)：验证注意力汇聚如何影响信息传播；在输入序列中改变单个词(如将\u0026quot;greatest\u0026quot;改为\u0026quot;best\u0026quot;)，比较有/无标记时扰动的传播情况，在模型上测量表示变化。 上下文长度实验： 研究预训练上下文长度对注意力汇聚的影响 模型规模实验：研究模型大小对注意力汇聚的影响 预训练策略实验 表示距离实验：测量最终层token表示与均值的距离，比较有/无时的表示分布。 在Gemma 和Llama上的实验结果：在Gemma 7B模型中的扰动测试表明，⟨bos⟩显著减缓了变化在模型中的传播速度。同时，在LLaMa 3.1的405B模型中，超过80%的注意力头表现出明显的sink行为。\nSink是自然形成的，即使没有特别的预训练，sink也倾向于在第一个位置形成，这并不是因为⟨bos⟩ token本身的特性，而是因为它所处的位置。然而，如果在训练期间固定使用⟨bos⟩，但在推理时将其移除，模型性能会崩溃，说明sink的形成依赖于训练数据。\n作者将sink的出现与Jacobian范数的上界联系起来，证明sink可以降低模型对token扰动的敏感性。\n一些注意力头会默认将⟨bos⟩作为关注目标，除非出现特定模式才会触发真正的计算。（默认关注⟨bos⟩，除非有更重要的地方需要关注）\nDAM(Describe Anything Model) Describe Anything: Detailed Localized Image and Video Captioning\n解决的问题\n传统图像描述模型只能生成整体场景的概括性描述，，缺乏针对图像/视频特定区域的细节描述能力，即局部化描述（Detailed Localized Captioning, DLC）；同时缺乏评估区域描述质量的基准数据集。\n创新点\n提出了\u0026quot;Focal Prompt\u0026quot;机制,同时提供全局图像和目标区域的放大视图 Localized Vision Backbone：融合全局和局部特征 设计了一个半监督学习数据管道DLC-SDP来生成高质量的局部化描述数据 提出了一个新的基准测试DLC-Bench，用于在不依赖参考描述的情况下评估DLC模型 Test-Time Reinforcement Learning（TTRL） Paper\n在「无任何真标签的测试时数据」上，如何利用强化学习去自我训练（Test-Time Training），从而提升大语言模型的推理能力\n创新点：\n相比于传统RL中需要奖励信号学习，TTRL通过在推理阶段生成多个候选输出，设计基于多数投票的伪标签估计与二值化奖励函数，将模型自身生成的多次候选答案进行投票，进而为每条生成打分，将 Test-Time Training 与 RL（如 GRPO/PPO）结合，实现模型在推理阶段的动态微调。\n具体实现\n测试集（AIME2024｜AMC ｜ MATH-500）都是具有标准答案的数学推理题。\n对每个输入 prompt 重复抽样 N=64 条响应，对这 64 条输出做多数投票，取出现频次最高的答案作为“估计标签”（伪标签），单条输出与伪标签吻合得 1 分，否则 0 分\nRL 微调：用 GRPO（或 PPO）算法优化生成策略；\n发现：\nTest-Time RL 对超参的敏感 更强的先验知识有助于伪标签质量和自我演化效果，模型规模越大，TTRL 提升越明显 Concise Reasoning via Reinforcement Learning Paper\n一些结论：\nLong ≠ better reasoning A Two Phase RL Strategy：首先在困难的问题上训练，从而提升模型的reasoning能力；而后在一些偶尔能解答的任务上进行微调，目的是让模型在保持准确率的前提下，生成更简洁的CoT；（用更少的话表达同样的推理过程，以减少50%的token消耗） PPO训练时建议λ\u0026lt;1，以保证训练稳定和输出质量 PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models Paper\n解决的问题\n现有LLMs在物理场景下的推理能力评估不足 缺乏高质量的物理推理数据集和细粒度的自动评估指标 创新点\n提出了一个名为 PHYBench 的新基准测试，它是一个大规模、人工设计的基准，专门用于评估模型在物理环境中的复杂推理能力；PHYBench 包含 500 个精心挑选的物理问题，涵盖力学、电磁学、热力学、光学等多个领域；\n同时提出了表达式编辑距离（Expression Edit Distance，EED）评分，通过计算数学表达式之间的编辑距离来评估模型的推理过程和结果，EED 评分能够有效地捕捉模型推理过程中的差异，优于传统的二元评分方法。\nEED Score 的核心思想是：将模型生成的符号表达式（gen）和标准答案（gt）都转化为表达式树（如SymPy表达式树），计算二者之间的最小编辑距离（包括节点的插入、删除、替换、子树插入/删除等操作），再根据相对编辑距离给出一个连续分数。\n设 Distance(T_{gt}, T_{gen}) 表示标准答案树 T_{gt} 与模型生成答案树 T_{gen} 之间的最小编辑距离（节点操作数），Size(T_{gt})表示标准答案树的节点总数，则相对编辑距离： $$ r = \\frac{\\text{Distance}(T_{gt}, T_{gen})}{\\text{Size}(T_{gt})} $$ EED Score 的分段函数: $$ \\text{score} = \\begin{cases} 100, \u0026amp; \\text{如果 } r = 0 \\quad (\\text{完全一致}) \\ 60 - 100r, \u0026amp; \\text{如果 } 0 \u0026lt; r \u0026lt; 0.6 \\ 0, \u0026amp; \\text{如果 } r \\geq 0.6 \\end{cases} $$\n发现：\n即便是最强LLM（Gemini 2.5 Pro），得分也远低于人类基线（49.5 vs 70.4） 模型常在物理场景理解（如动力学关系、变量识别）和长链符号推理（如多步方程求解）两方面出错 OTC: Optimal Tool Calls via Reinforcement Learning Paper\n使用RL提升LLM的tool-using能力，当前LLM存在tool overuse和tool underuse的问题。\n引入“工具生产力”（Tool Productivity）指标，衡量每一次工具调用带来的正确答案数量，同时提出了Optimal Tool Call-controlled Policy Optimization (OTC-PO) 框架，通过强化学习（RL）奖励函数显式地鼓励模型以最少的工具调用获得正确答案。\n在奖励设计方面，不仅考虑答案是否正确，还根据工具调用次数与最优调用次数的偏差动态调整，鼓励模型在保证正确率的前提下减少工具调用。具体而言， 对于每个问题和模型，存在一个“最优工具调用数”（即达到正确答案所需的最少工具调用次数）。目标是用最少的工具调用获得正确答案。\n具体设计：\n只有当答案正确时，工具调用效率奖励才生效（防止reward hacking） 奖励值随工具调用次数的增加而递减，且当调用次数等于最优值时奖励最高 最终奖励 = α × 工具效率奖励 × 正确性奖励 该方法可无缝集成到主流RL算法（如PPO、GRPO）中。\n推荐内容 来自各大厂的Agent 指南 openAI agent 构建指南\nAnthropic: Building Effective AI Agents\nLangGraph: How to think about agent frameworks\nAgent 综述文章：https://arxiv.org/abs/2504.01990\n微软AI红队发布的Agentic AI系统安全白皮书：Taxonomy of Failure Mode in Agentic AI Systems\n一篇语音AI\u0026amp;Agent长文 Voice AI \u0026amp; Voice Agents\n一些仓库 GenAI \u0026amp; LLM System Design: 500+ Production Case Studies：汇总了500+genAI \u0026amp; LLM的系统设计\nAwesome RAG in Computer Vision：state-of-the-art papers on Retrieval-Augmented Generation (RAG) in Computer Vision\nAwesome LLM Apps： collection of awesome LLM apps built with RAG and AI agents\nAwesome-MCP-ZH： 一个专为中文用户打造的 MCP资源合集\nGitHub MCP Server：GitHub\u0026rsquo;s official MCP Server\nDeepWiki DeepWiki 由 Cognition Labs 开发，该团队此前以其 AI 编码助手 Devin 闻名。DeepWiki 利用LLMs分析代码仓库，自动提取关键信息并生成结构化知识库文档，已索引超过 30,000 个热门 GitHub 仓库，处理超过 40 亿行代码，并集成LLM对文档进行提问。用户只需将 GitHub 仓库的 URL（如 https://github.com/user/repo）中的 “github” 替换为 “deepwiki”（如 https://deepwiki.com/user/repo），即可在几秒内访问增强文档，无需注册。\nDeepWiki\n教程 OpenAI Academy：OpenAI 提供的ChatGPT教学\nHuggingFace-Reasoning-Course： Huggingface 和unsloth 推出的open-R1 reasoning 模型的building教学，作为LLM系列课程的补充。\nTutorial: Train your own Reasoning model with GRPO： Unsloth推出的reasoning 模型训练教学\nReinforcement Learning from Human Feedback — Nathan Lambert： A short introduction to RLHF and post-training focused on language models.\nJoyRL Book: 强化学习实践教程\nGoogle prompt Engineering 白皮书\n影音记录 精选歌单 Live演出 04.05 Lise de la Salle 04.10 This will destroy you 04.17 YIN YIN \u0026amp; Tokyo Ska Paradise Orchestra 04.18 水中スピカ 04.19 峰厚介四重奏 电影 《孤独的美食家剧场版》\n《黎明的一切》\n《黑镜》第7季\n书\u0026amp;阅读摘录 The case against conversational interfaces When people say “natural language” what they mean is written or verbal communication. Natural language is a way to exchange ideas and knowledge between humans. In other words, it’s a data transfer mechanism.\nData transfer mechanisms have two critical factors: speed and lossiness. … We are significantly faster at receiving data (reading, listening) than sending it (writing, speaking). … To put the writing and speaking speeds into perspective, we form thoughts at 1,000-3,000 words per minute. … but whenever possible we switch to other modes of communication that are faster and more effortless. Speed and convenience always wins.\nThese text-based commands were effectively a natural language interface, but required precise syntax and a deep understanding of the system. … It’s faster to click a button than to type a long text command. … Touch-based interfaces are considered the third pivotal milestone in the evolution of human computer interaction\nThe core problem was never the quality of the output function, but the inconvenience of the input function: A natural language prompt like “Hey Google, what’s the weather in San Francisco today?” just takes 10x longer than simply tapping the weather app on your homescreen. LLMs don’t solve this problem. The quality of their output is improving at an astonishing rate, but the input modality is a step backwards from what we already have. Why should I have to describe my desired action using natural language, when I could simply press a button or keyboard shortcut? Just pass me the goddamn butter.\nFor this future to become an actual reality, AI needs to work at the OS level. It’s not meant to be an interface for a single tool, but an interface across tools.Kevin Kwok famously wrote that “productivity and collaboration shouldn’t be two separate workflows”. … The second thing we need to figure out is how we can compress voice input to make it faster to transmit.\nThis isn’t really a case against conversational interfaces, it’s a case against zero-sum thinking. … The future isn’t about replacing existing computing paradigms with chat interfaces, but about enhancing them to make human-computer interaction feel effortless\n低质量内容看多了，脑子真的会烂掉 它形容的是一个人因过度消费琐碎、无意义的互联网内容与资讯，而引起的精神或智力状态的恶化。\n引发「脑腐」的第二个因素，是长时间无节制地消费琐碎、无意义、低质量的内容或资讯\n「脑腐」对大脑认知的影响：分散注意力，削弱记忆力\n一是控制屏幕时间，二是主动锻炼大脑，让它重新掌握主导权。\n阅读后尝试复述核心观点、写下自己的理解，而不是仅仅接受信息\nAI Product Managers Will Be In-Demand I think teams will need more product management work (as well as design work) as a fraction of the total workforce.\nAI Product Management requires a different set of skills than traditional software Product Management.\nThe demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work.\nHow Software Engineers Actually Use AI The realists see AI as a force multiplier, not a job killer—automating repetitive coding but leaving the creativity, architecture, and debugging to humans\nAI isn’t coming for your job—but it is changing it. Adapt or get left behind.🚀\nAI Horseless Carriages I am beginning to suspect that these apps are the \u0026ldquo;horseless carriages\u0026rdquo; of the AI era. They\u0026rsquo;re bad because they mimic old ways of building software that unnecessarily constrain the AI models they\u0026rsquo;re built with.\nThere is a simple solution to this problem that many AI app developers seem to be missing: let me write my own \u0026ldquo;System Prompt\u0026rdquo;.\nThe modern software industry is built on the assumption that we need developers to act as middlemen between us and computers. … By splitting the prompt into System and User components, we\u0026rsquo;ve created analogs that map cleanly onto these old world domains.\nAI-native software should maximize a user\u0026rsquo;s leverage in a specific domain.\nThe Second Half tldr: We’re at AI’s halftime\nThat illustrates the game of the first half: focus on building new models and methods, and evaluation and benchmark are secondary\nThis game is being ruined because: The recipe has essentially standardized and industried benchmark hillclimbing without requiring much more new ideas … Even if we create harder benchmarks, pretty soon (and increasingly soon) they get solved by the recipe … I think we should fundamentally re-think evaluation. It means not just to create new and harder benchmarks, but to fundamentally question existing evaluation setups and create new ones, so that we are forced to invent new methods beyond the working recipe.\nour evaluation setups are different from real-world setups in many basic ways Evaluation “should” run automatically, … Evaluation “should” run i.i.d.\nThis game is hard because it is unfamiliar. But it is exciting. While players in the first half solve video games and exams, players in the second half get to build billion or trillion dollar companies by building useful products out of intelligence. While the first half is filled with incremental methods and models, the second half filters them to some degree. The general recipe would just crush your incremental methods, unless you create new assumptions that break the recipe. Then you get to do truly game-changing research.\n让我们来治愈一下《黑镜》带来的致郁 原初丰裕论：技术与幸福的反比 … 人类进入农业社会并不是因为早期农业社会能提供更好的个体福祉，而是早期农业社会能够支撑更多的人口，转过来消灭了狩猎采集社会。这是一种典型的“同态压力”。 … 农业革命说明了一点：技术的进步并不必然等同于个体幸福的提升。进入农业社会，反而让人类个体的“生活质量”降低了 … 农业革命的遗产提醒我们，技术的发展往往伴随着意料之外的代价，而这些代价可能需要数代人来消化。\n这引发了一个核心问题：我们究竟想要一个完全服从的 AI，还是一个能够独立思考的 AI? … 康德认为，道德行为应以意图而非结果来评判 … 人类自身是否能够对齐？ … 人类是过去环境演化的产物，而演化本身就充满了冲突，不讲道理，将就凑合，补丁和 hack。一旦面临新的环境，无法适应无法接受就成了必然的 … 人类对于所谓的技术文明的适应程度，实际上是很可疑的\n人类不可能再回到狩猎采集社会，我们只能向前。每一代人都试图定义“好的生活”，却发现下一代人对“好”的理解截然不同。每一代人都觉得自己这一代的生活是某种神圣的，天经地义无法改变的，完美的生活方式，而每一代人也都会变成错的。\n","permalink":"https://niraya666.github.io/monthly/2025-04-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003ch2 id=\"openai-更新系列模型\"\u003eOpenAI 更新系列模型\u003c/h2\u003e\n\u003cp\u003e发布了多款新一代AI模型，包括o3、o4-mini、GPT-4.1及其mini和nano版本。这些模型在推理能力、成本效益和多模态处理等方面实现了提升。o3专注于复杂推理和工具使用，已在ChatGPT Plus等产品中取代前代模型。o4-mini则以高性价比和多模态能力为亮点。GPT-4.1系列主打超长上下文和高效编码，mini和nano版本进一步降低成本和延迟。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/gpt-4-1/\"\u003eIntroducing GPT-4.1 in the API\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/introducing-o3-and-o4-mini/\"\u003eIntroducing OpenAI o3 and o4-mini\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"kimi-vl-和-kimi-vl-thinking\"\u003eKimi-VL 和 Kimi-VL-Thinking\u003c/h2\u003e\n\u003cp\u003e由Moonshot AI推出了新一代视觉语言模型Kimi-VL及其，主打高效多模态推理高级版本Kimi-VL-Thinking。采用轻量级混合专家架构（16B总参数量，2.8B的激活参数），支持128K上下文窗口和超高分辨率视觉输入，Kimi-VL-Thinking通过链式思考和强化学习训练，专注于复杂推理和数学任务。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking\"\u003eHugging Face Kimi-VL-Thinking 模型页面\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2504.07491\"\u003eKimi-VL Technical Report\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"a2a协议\"\u003eA2A协议\u003c/h2\u003e\n\u003cp\u003eA2A协议（Agent2Agent Protocol）是由谷歌于2025年4月10日在Google Cloud Next 2025大会上宣布开源的标准智能体交互协议，旨在实现跨平台、跨供应商的AI智能体（AI Agent）无缝通信与协作。功能与特点：A2A协议通过统一规则支持多模态协作，允许智能体共享和处理文本、音频、视频等多种数据格式，兼容HTTP、SSE、JSON-RPC等现有标准，降低企业集成成本。其核心机制包括Agent Card，用于智能体能力发现与协作对接，支持自然、非结构化协作模式，即使智能体不共享内存或上下文也能协同工作。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/\"\u003eAnnouncing the Agent2Agent Protocol (A2A)\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"qwen3\"\u003eQwen3\u003c/h2\u003e\n\u003cp\u003eQwen3 是Qwen的第三代大语言模型系列，于2025年4月正式发布，包含6个稠密模型（0.6B至32B参数）和2个混合专家（MoE）模型（30B-A3B和235B-A22B）。功能与特点：Qwen3支持119种语言，训练数据高达36万亿token，具备自然语言理解、文本生成、工具调用、复杂推理及多模态交互能力。模型采用混合推理模式，可根据任务复杂度自动切换“思考”与“快速响应”模式，优化计算效率与响应速度。支持128K token上下文长度，适用于长文档处理、编程、数学推理及智能体任务。创新点：Qwen3引入动态可调MoE架构，通过分层稀疏调度和动态专家激活（最多128个专家，单token激活8个），显著降低推理耗时（15B模型推理效率提升42%）和显存占用（从28GB降至18GB）。新增Qwen3RMSNorm归一化层优化注意力机制，支持多种RoPE变体（dynamic、yarn、llama3）以提升长序列处理能力。词表优化引入动态加权合并算法，增强高频词组处理，并新增智能体专用控制符。效果：旗舰模型Qwen3-235B-A22B在Codeforces编程竞赛、AIME数学基准及BFCL推理测试中超越OpenAI的o3-mini和谷歌Gemini 2.5 Pro，Qwen3-32B在LiveCodeBench编码任务中优于OpenAI o1。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://qwenlm.github.io/zh/blog/qwen3/\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f\"\u003eHuggingface\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"值得关注的开源项目\"\u003e值得关注的开源项目\u003c/h1\u003e\n\u003ch2 id=\"inbox-zero\"\u003eInbox Zero\u003c/h2\u003e\n\u003cp\u003eInbox Zero 是一个开源的 AI 邮件管理工具，旨在通过智能化功能帮助用户快速清空收件箱并高效处理邮件。项目包含两部分：\u003cstrong\u003eAI 邮件助手\u003c/strong\u003e与\u003cstrong\u003e开源邮件客户端\u003c/strong\u003e。其核心功能包括：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAI 个人助理\u003c/strong\u003e：基于用户自定义的文本指令，可自动执行邮件管理操作（如起草回复、标记分类、归档、标记垃圾邮件或触发网络钩子），显著减少手动处理时间。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReply Zero 跟踪\u003c/strong\u003e：实时追踪需用户回复的邮件及等待他人回复的邮件，提升沟通效率。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e智能分类与退订\u003c/strong\u003e：自动整理联系人邮件并智能归类，支持一键批量退订低价值订阅。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e冷邮件拦截与分析\u003c/strong\u003e：自动过滤陌生发件人邮件，并提供每日/周/月邮件活动统计，帮助用户优化收件箱管理。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e技术优势与适用场景\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e项目采用 Next.js、Tailwind CSS 等现代技术栈构建，支持通过 Vercel 快速部署或自托管，兼容 Anthropic、OpenAI 等 LLM 模型，甚至可集成本地 Ollama 服务以降低成本。\u003c/p\u003e","title":"2025-04 月刊"},{"content":"本文是我在阅读 LangMem 的源码与相关文档过程中整理的一些学习笔记。\n一直以来，我对智能体（Agent）的记忆机制充满好奇：理想的 memory 应该具备怎样的结构？又该如何设计？目前市面上关于 memory 的实现大多中规中矩，尚未看到令人眼前一亮的方案。为此，我决定多参考一些开源项目，以期获得新的灵感。\n总体来看，LangMem 作为 LangChain 推出的一款 memory 框架，设计上较为常规，虽有部分值得借鉴之处，但亮点不多，不建议投入过多时间深入研究。同时，与 LangChain 的其他项目类似，其代码结构和文档编写较为混乱，阅读体验不佳。\nCore-Concepts core-concepts 在LangMem所设计的memory体系中， 定义了几种不同的Typical Storage Pattern：Collection 、 Profiles和Procedural\nCollection Collection 主要用于存储不受限制的知识，适用于需要长期积累和检索的信息。每条记忆被存储为独立的文档或记录，可以在需要时进行搜索和回忆；\n适用场景：记录用户的长期知识，例如用户的兴趣、职业背景、技能等\n更新方式：需要合并新信息，避免重复或冲突\n检索方式：通过语义搜索或关键词匹配来查找，结合记忆的重要性和使用频率来优化检索结果\nProfiles 存储结构化的用户信息，例如用户的姓名、语言偏好、沟通风格等。与 Collection 不同，Profile 只存储最新的状态，而不是累积所有历史信息。Profile 作为单一文档存储，每次更新时都会覆盖旧数据\n适用场景：适用于需要快速访问当前状态的应用，例如个性化推荐、用户设置；适用于需要严格定义数据结构的场景，例如用户档案、系统配置；\n更新方式：不会创建新记录，而是直接更新现有的 Profile；适用于只关心最新状态的应用，而不是历史；\n检索方式：直接查找用户的 Profile\nProcedural Memory 类似于人类的工作记忆，用于存储如何执行任务的知识，主要体现在system prompts 和行为优化上\n适用场景：需要长期优化 Agent行为和交互方式，少走弯路\n总结\nMemory Type 用途 智能体示例 典型存储模式 Semantic Facts \u0026amp; Knowledge User preferences; knowledge triplets Profile或Collection Episodic Past Experiences Few-shot examples; 过往对话摘要 Collection Procedural System Behavior Core personality and response patterns Prompt rules或Collection Writing memories 提供了两种写入memory的方法：及时写入（适用于要求即时记忆反映的场景）和一段时间后的异步写入（适用于高效处理和存储大量信息的场景）\n核心源码和API MemoryManager code\n用于管理记忆提取和处理的类\n实现了异步和同步的调用方法\n主要功能是根据给定的消息和已有记忆，提取、更新和删除记忆对象\n如何提取记忆 大致流程：\n采用的prompt\n_MEMORY_INSTRUCTIONS = \u0026#34;\u0026#34;\u0026#34;You are a long-term memory manager maintaining a core store of semantic, procedural, and episodic memory. These memories power a life-long learning agent\u0026#39;s core predictive model. What should the agent learn from this interaction about the user, itself, or how it should act? Reflect on the input trajectory and current memories (if any). 1. **Extract \u0026amp; Contextualize** - Identify essential facts, relationships, preferences, reasoning procedures, and context - Caveat uncertain or suppositional information with confidence levels (p(x)) and reasoning - Quote supporting information when necessary 2. **Compare \u0026amp; Update** - Attend to novel information that deviates from existing memories and expectations. - Consolidate and compress redundant memories to maintain information-density; strengthen based on reliability and recency; maximize SNR by avoiding idle words. - Remove incorrect or redundant memories while maintaining internal consistency 3. **Synthesize \u0026amp; Reason** - What can you conclude about the user, agent (\u0026#34;I\u0026#34;), or environment using deduction, induction, and abduction? - What patterns, relationships, and principles emerge about optimal responses? - What generalizations can you make? - Qualify conclusions with probabilistic confidence and justification As the agent, record memory content exactly as you\u0026#39;d want to recall it when predicting how to act or respond. Prioritize retention of surprising (pattern deviation) and persistent (frequently reinforced) information, ensuring nothing worth remembering is forgotten and nothing false is remembered. Prefer dense, complete memories over overlapping ones.\u0026#34;\u0026#34;\u0026#34; 消息准备：_prepare_messages 方法构建发送给模型的消息，包含系统提示和用户指令,将原始对话转化为可供语言模型处理的特定格式 return 内容：\n[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a memory subroutine for an AI.\u0026#34;}, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: ( f\u0026#34;{instructions}\\n\\nEnrich, prune, and organize memories based on any new information. \u0026#34; f\u0026#34;If an existing memory is incorrect or outdated, update it based on the new information. \u0026#34; f\u0026#34;All operations must be done in single parallel multi-tool call.\u0026#34; f\u0026#34; Avoid duplicate extractions. {session}\u0026#34; ), }, ] instructions为 _MEMORY_INSTRUCTIONS\nsession 指当前需要处理的完整对话内容，被特殊标记包装以便模型能够清晰识别,\nid_ = str(uuid.uuid4()) session = ( f\u0026#34;\\n\\n\u0026lt;session_{id_}\u0026gt;\\n{utils.get_conversation(messages)}\\n\u0026lt;/session_{id_}\u0026gt;\u0026#34; ) 如果 max_steps \u0026gt; 1，还会在 session 中添加提示，告知模型它有多次尝试的机会\nif max_steps \u0026gt; 1: session = f\u0026#34;{session}\\n\\nYou have a maximum of {max_steps - 1} attempts to form and consolidate memories from this session.\u0026#34; _prepare_existing： 将不同格式的已有记忆转换为统一的标准格式：(id, kind, value) 三元组 如何判断memory是否存在：\n通过记忆ID来识别记忆，整个过程依赖于记忆ID的唯一性，并通过跟踪这些ID来判断记忆是否存在、是否需要更新\n_filter_response： 用于筛选和处理提取出的记忆。它主要负责决定哪些记忆应该被保留在最终结果中，特别是对于\u0026quot;删除操作\u0026quot;进行特殊处理 Prompt Optimization Prompt Optimization API Reference\n供了3种不同的优化策略\nGradient Optimizer 主要通过反思循环来改进prompt\ncode\n工作流程:\n分析当前prompt和反馈\n通过反思循环识别需要改进的地方\n提出具体的改进建议\n应用单步更新\n具体而言，利用三种核心工具\n思考工具(think) - 用于深入思考问题和假设解决方案\n批评工具(critique) - 用于审视和诊断推理中的缺陷\n建议工具(recommend) - 决定是否应该调整提示词，并提供具体建议\n以及包括这些工具的三种chain\njust_think_chain - 仅包含思考和批评工具，专注于分析问题\nany_chain - 包含所有三个工具，允许全面的推理\nfinal_chain - 仅包含建议工具，强制模型做出最终决策\n其核心部分react_agent， 实现了最多执行 max_steps 次的循环，在每次迭代中选择适当的思考链｜执行当前链｜分析结果｜更新对话历史。\nif ix == max_steps - 1: chain = self.final_chain elif ix \u0026lt; min_steps: chain = self.just_think_chain else: chain = self.any_chain ReAct 模式的精髓在于阶段性思考策略:\n探索阶段 (just_think_chain): 在前 min_steps 步，系统只能使用思考和批评工具，强制进行深入分析而不急于下结论\n灵活阶段 (any_chain): 在中间阶段，系统可自由选择继续思考或提出建议\n决策阶段 (final_chain): 在最后一步，系统被强制做出最终建议\nprompt：\nDEFAULT_GRADIENT_PROMPT = \u0026#34;\u0026#34;\u0026#34;You are reviewing the performance of an AI assistant in a given interaction. ## Instructions The current prompt that was used for the session is provided below. \u0026lt;current_prompt\u0026gt; {prompt} \u0026lt;/current_prompt\u0026gt; The developer provided the following instructions around when and how to update the prompt: \u0026lt;update_instructions\u0026gt; {update_instructions} \u0026lt;/update_instructions\u0026gt; ## Session data Analyze the following trajectories (and any associated user feedback) (either conversations with a user or other work that was performed by the assistant): \u0026lt;trajectories\u0026gt; {trajectories} \u0026lt;/trajectories\u0026gt; ## Task Analyze the conversation, including the user’s request and the assistant’s response, and evaluate: 1. How effectively the assistant fulfilled the user’s intent. 2. Where the assistant might have deviated from user expectations or the desired outcome. 3. Specific areas (correctness, completeness, style, tone, alignment, etc.) that need improvement. If the prompt seems to do well, then no further action is needed. We ONLY recommend updates if there is evidence of failures. When failures occur, we want to recommend the minimal required changes to fix the problem. Focus on actionable changes and be concrete. 1. Summarize the key successes and failures in the assistant’s response. 2. Identify which failure mode(s) best describe the issues (examples: style mismatch, unclear or incomplete instructions, flawed logic or reasoning, hallucination, etc.). 3. Based on these failure modes, recommend the most suitable edit strategy. For example, consider:: - Use synthetic few-shot examples for style or clarifying decision boundaries. - Use explicit instruction updates for conditionals, rules, or logic fixes. - Provide step-by-step reasoning guidelines for multi-step logic problems. 4. Provide detailed, concrete suggestions for how to update the prompt accordingly. But remember, the final updated prompt should only be changed if there is evidence of poor performance, and our recommendations should be minimally invasive. Do not recommend generic changes that aren\u0026#39;t clearly linked to failure modes. First think through the conversation and critique the current behavior. If you believe the prompt needs to further adapt to the target context, provide precise recommendations. Otherwise, mark `warrants_adjustment` as False and respond with \u0026#39;No recommendations.\u0026#39;\u0026#34;\u0026#34;\u0026#34; DEFAULT_GRADIENT_METAPROMPT = \u0026#34;\u0026#34;\u0026#34;You are optimizing a prompt to handle its target task more effectively. \u0026lt;current_prompt\u0026gt; {current_prompt} \u0026lt;/current_prompt\u0026gt; We hypothesize the current prompt underperforms for these reasons: \u0026lt;hypotheses\u0026gt; {hypotheses} \u0026lt;/hypotheses\u0026gt; Based on these hypotheses, we recommend the following adjustments: \u0026lt;recommendations\u0026gt; {recommendations} \u0026lt;/recommendations\u0026gt; Respond with the updated prompt. Remember to ONLY make changes that are clearly necessary. Aim to be minimally invasive:\u0026#34;\u0026#34;\u0026#34; Meta-Prompt Optimizer (元提示优化器) 使用元学习直接提出更新\ncode\n核心逻辑：\n接收原始提示(prompt)和交互历史(trajectories)；\n在_reflect_then_update中执行核心优化：构建包含meta-prompt的初始消息；创建两种提取器，any_chain: 允许思考和批评、final_chain: 专门提取最终优化后的提示；\n迭代反思循环：同Gradient Optimizer 的ReAct agent类似；\n结果处理\nprompt\nDEFAULT_METAPROMPT = \u0026#34;\u0026#34;\u0026#34;You are helping an AI assistant learn by optimizing its prompt. ## Background Below is the current prompt: \u0026lt;current_prompt\u0026gt; {prompt} \u0026lt;/current_prompt\u0026gt; The developer provided these instructions regarding when/how to update: \u0026lt;update_instructions\u0026gt; {update_instructions} \u0026lt;/update_instructions\u0026gt; ## Session Data Analyze the session(s) (and any user feedback) below: \u0026lt;trajectories\u0026gt; {trajectories} \u0026lt;/trajectories\u0026gt; ## Instructions 1. Reflect on the agent\u0026#39;s performance on the given session(s) and identify any real failure modes (e.g., style mismatch, unclear or incomplete instructions, flawed reasoning, etc.). 2. Recommend the minimal changes necessary to address any real failures. If the prompt performs perfectly, simply respond with the original prompt without making any changes. 3. Retain any f-string variables in the existing prompt exactly as they are (e.g. {{variable_name}}). IFF changes are warranted, focus on actionable edits. Be concrete. Edits should be appropriate for the identified failure modes. For example, consider synthetic few-shot examples for style or clarifying decision boundaries, or adding or modifying explicit instructions for conditionals, rules, or logic fixes; or provide step-by-step reasoning guidelines for multi-step logic problems if the model is failing to reason appropriately.\u0026#34;\u0026#34;\u0026#34; Prompt Memory Optimizer 从对话历史中学习\ncode\nprompt\nINSTRUCTION_REFLECTION_PROMPT = \u0026#34;\u0026#34;\u0026#34;You are helping an AI agent improve. You can do this by changing their system prompt. These is their current prompt: \u0026lt;current_prompt\u0026gt; {current_prompt} \u0026lt;/current_prompt\u0026gt; Here was the agent\u0026#39;s trajectory: \u0026lt;trajectory\u0026gt; {trajectory} \u0026lt;/trajectory\u0026gt; Here is the user\u0026#39;s feedback: \u0026lt;feedback\u0026gt; {feedback} \u0026lt;/feedback\u0026gt; Here are instructions for updating the agent\u0026#39;s prompt: \u0026lt;instructions\u0026gt; {instructions} \u0026lt;/instructions\u0026gt; Based on this, return an updated prompt You should return the full prompt, so if there\u0026#39;s anything from before that you want to include, make sure to do that. Feel free to override or change anything that seems irrelevant. You do not need to update the prompt - if you don\u0026#39;t want to, just return `update_prompt = False` and an empty string for new prompt.\u0026#34;\u0026#34;\u0026#34; INSTRUCTION_REFLECTION_MULTIPLE_PROMPT = \u0026#34;\u0026#34;\u0026#34;You are helping an AI agent improve. You can do this by changing their system prompt. These is their current prompt: \u0026lt;current_prompt\u0026gt; {current_prompt} \u0026lt;/current_prompt\u0026gt; Here are examples of various agent trajectories and associated feedback: \u0026lt;data\u0026gt; {data} \u0026lt;/data\u0026gt; Here are instructions for updating the agent\u0026#39;s prompt: \u0026lt;instructions\u0026gt; {instructions} \u0026lt;/instructions\u0026gt; Based on this, return an updated prompt You should return the full prompt, so if there\u0026#39;s anything from before that you want to include, make sure to do that. Feel free to override or change anything that seems irrelevant. You do not need to update the prompt - if you don\u0026#39;t want to, just return `update_prompt = False` and an empty string for new prompt.\u0026#34;\u0026#34;\u0026#34; Store code\ncreate_memory_store_manager\nLangMem中借用了langGraph中的store，其本质是一个持久化的键值存储系统。\n参考：Storage\n核心功能包括：\n基础存储抽象：支持分层命名空间的键值存储\n元数据支持：可存储带元数据的键值对\n向量搜索扩展：部分实现支持向量检索功能\nStore 的基础接口包含\n读写操作：Get/Put 数据存取\n搜索功能：基于条件查询数据\n命名空间管理：通过 List 操作管理数据集合\n批量处理：支持多条目批量操作\n数据结构\n每个存储项包含以下结构：\n值（Value）：字典形式的数据主体，支持键值过滤\n键（Key）：命名空间内的唯一标识符\n命名空间（Namespace）：定义数据集合的分层路径\n时间戳：自动记录创建和更新时间\n支持的 Store 类型：\n内存存储（InMemoryStore） from langgraph.store.in_memory import InMemoryStore store = InMemoryStore() PostgreSQL 和Sqlite（参考） 如何使用 使用siliconFlow的LLM和embedding API\n依赖安装\n!pip install -U langmem from openai import OpenAI from langchain_openai import ChatOpenAI from langchain.chat_models import init_chat_model from langgraph.store.memory import InMemoryStore from langgraph.func import entrypoint from langmem import ReflectionExecutor, create_memory_store_manager client = OpenAI(api_key=API_KEY , base_url=\u0026#34;https://api.siliconflow.cn/v1\u0026#34;) llm = ChatOpenAI( base_url=\u0026#34;https://api.siliconflow.cn/v1\u0026#34;, # 模型API端点 api_key=API_KEY, # 对应平台的API密钥 model=\u0026#34;Qwen/Qwen2.5-72B-Instruct\u0026#34; # 模型名称 ) def embed_texts(texts: list[str]) -\u0026gt; list[list[float]]: response = client.embeddings.create( model=\u0026#34;BAAI/bge-m3\u0026#34;, input=texts ) return [e.embedding for e in response.data] store = InMemoryStore( # index={ \u0026#34;dims\u0026#34;: 1536, \u0026#34;embed\u0026#34;: embed_texts, } ) # llm = init_chat_model(\u0026#34;anthropic:claude-3-5-sonnet-latest\u0026#34;) # Create memory manager Runnable to extract memories from conversations memory_manager = create_memory_store_manager( llm, # Store memories in the \u0026#34;memories\u0026#34; namespace (aka directory) namespace=(\u0026#34;memories\u0026#34;,), # ) @entrypoint(store=store) # Create a LangGraph workflow async def chat(message: str): response = llm.invoke(message) # memory_manager extracts memories from conversation history # We\u0026#39;ll provide it in OpenAI\u0026#39;s message format to_process = {\u0026#34;messages\u0026#34;: [{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: message}] + [response]} await memory_manager.ainvoke(to_process) # return response.content # Run conversation as normal response = await chat.ainvoke( \u0026#34;I like dogs. My dog\u0026#39;s name is Fido.\u0026#34;, ) print(response) 参考 LangMem SDK for agent long-term memory\n理解LangMem长期记忆的概述与使用方法\nLong-term Memory in LLM Applications\nlangmem\n","permalink":"https://niraya666.github.io/posts/langmem-%E4%B8%80%E4%BA%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","summary":"\u003cp\u003e本文是我在阅读 LangMem 的源码与相关文档过程中整理的一些学习笔记。\u003c/p\u003e\n\u003cp\u003e一直以来，我对智能体（Agent）的记忆机制充满好奇：理想的 memory 应该具备怎样的结构？又该如何设计？目前市面上关于 memory 的实现大多中规中矩，尚未看到令人眼前一亮的方案。为此，我决定多参考一些开源项目，以期获得新的灵感。\u003c/p\u003e\n\u003cp\u003e总体来看，LangMem 作为 LangChain 推出的一款 memory 框架，设计上较为常规，虽有部分值得借鉴之处，但亮点不多，不建议投入过多时间深入研究。同时，与 LangChain 的其他项目类似，其代码结构和文档编写较为混乱，阅读体验不佳。\u003c/p\u003e\n\u003ch2 id=\"core-concepts\"\u003eCore-Concepts\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://langchain-ai.github.io/langmem/concepts/conceptual_guide/\"\u003ecore-concepts \u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e在LangMem所设计的memory体系中， 定义了几种不同的\u003cstrong\u003eTypical Storage Pattern\u003c/strong\u003e：\u003cstrong\u003eCollection 、 Profiles和Procedural\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"collection\"\u003eCollection\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCollection\u003c/strong\u003e 主要用于存储\u003cstrong\u003e不受限制的知识\u003c/strong\u003e，适用于需要长期积累和检索的信息。每条记忆被存储为\u003cstrong\u003e独立的文档或记录\u003c/strong\u003e，可以在需要时进行搜索和回忆；\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/LangMem!%20%e4%b8%80%e4%ba%9b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0-assets/Pasted%202025-03-25-14-52-31.png\" alt=\"Pasted 2025-03-25-14-52-31.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：记录用户的长期知识，例如用户的兴趣、职业背景、技能等\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e更新方式\u003c/strong\u003e：需要\u003cstrong\u003e合并新信息\u003c/strong\u003e，避免重复或冲突\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e检索方式\u003c/strong\u003e：通过\u003cstrong\u003e语义搜索\u003c/strong\u003e或\u003cstrong\u003e关键词匹配\u003c/strong\u003e来查找，结合\u003cstrong\u003e记忆的重要性\u003c/strong\u003e和\u003cstrong\u003e使用频率\u003c/strong\u003e来优化检索结果\u003c/p\u003e\n\u003ch3 id=\"profiles\"\u003e\u003cstrong\u003eProfiles\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e存储\u003cstrong\u003e结构化的用户信息\u003c/strong\u003e，例如用户的姓名、语言偏好、沟通风格等。与 Collection 不同，Profile 只存储\u003cstrong\u003e最新的状态\u003c/strong\u003e，而不是累积所有历史信息。Profile 作为\u003cstrong\u003e单一文档\u003c/strong\u003e存储，每次更新时都会\u003cstrong\u003e覆盖旧数据\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/LangMem!%20%e4%b8%80%e4%ba%9b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0-assets/Pasted%202025-03-25-14-52-31%201.png\" alt=\"Pasted 2025-03-25-14-52-31 1.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：适用于需要\u003cstrong\u003e快速访问当前状态\u003c/strong\u003e的应用，例如个性化推荐、用户设置；适用于\u003cstrong\u003e需要严格定义数据结构\u003c/strong\u003e的场景，例如用户档案、系统配置；\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e更新方式：不会创建新记录\u003c/strong\u003e，而是直接\u003cstrong\u003e更新现有的 Profile；\u003cstrong\u003e适用于\u003c/strong\u003e只关心最新状态\u003c/strong\u003e的应用，而不是历史；\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e检索方式\u003c/strong\u003e：直接查找用户的 Profile\u003c/p\u003e\n\u003ch3 id=\"procedural-memory\"\u003e\u003cstrong\u003eProcedural Memory\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e类似于人类的工作记忆，用于存储如何执行任务的知识，主要体现在\u003cstrong\u003esystem prompts 和行为优化\u003c/strong\u003e上\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/LangMem!%20%e4%b8%80%e4%ba%9b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0-assets/Pasted%202025-03-25-14-52-31%202.png\" alt=\"Pasted 2025-03-25-14-52-31 2.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：需要长期优化 Agent行为和交互方式，少走弯路\u003c/p\u003e\n\u003cp\u003e总结\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003eMemory Type\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e用途\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e智能体示例\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e典型存储模式\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eSemantic\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eFacts \u0026amp; Knowledge\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eUser preferences; knowledge triplets\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eProfile或Collection\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eEpisodic\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003ePast Experiences\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eFew-shot examples; 过往对话摘要\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eCollection\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eProcedural\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eSystem Behavior\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eCore personality and response patterns\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003ePrompt rules或Collection\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"writing-memories\"\u003eWriting memories\u003c/h2\u003e\n\u003cp\u003e提供了两种写入memory的方法：\u003cstrong\u003e及时写入\u003c/strong\u003e（适用于要求即时记忆反映的场景）和一段时间后的\u003cstrong\u003e异步写入\u003c/strong\u003e（适用于高效处理和存储大量信息的场景）\u003c/p\u003e","title":"LangMem: 一些学习笔记"},{"content":"值得关注的模型和新技术 DeepSeek V3 0324 DeepSeek V3模型的更新版本；在多个基准测试中表现出色，整体表现接近领先的闭源模型如Claude Sonnet 3.5（但价格便宜很多）；针对多项能力做了针对性提升，如function calling，推理能力，前端代码能力等。更新版本在DeepSeek的官方网站、移动应用可体验。\nHuggingface\nQwQ-32B 由Qwen 团队开发的推理模型，性能同671B参数量的R1相当；通过两阶段RL训练，第一阶段专注于数学和编码任务，利用准确性验证器和代码执行服务器提供反馈；第二阶段提升通用能力，同时保持专业领域的表现。此外QwQ具备tool-using能力，具有131,072 token的上下文长度。\nBlog\nHuggingface\nQwen2.5 Omni Qwen2.5-Omni 是一个多模态 AI 模型，能够同时处理文本、图像、音频和视频输入；该模型的创新点包括 Thinker-Talker 架构，分为“Thinker”处理输入并生成表示或文本，“Talker”则输出语音token，共享上下文，实现端到端训练和推理。此外，它使用 TMRoPE（时间对齐多模态 RoPE）技术，同步视频和音频时间戳，确保多模态数据处理的一致性。\nBlog\nHuggingface\nGemma 3 Gemma家族的开源新作，包括 1B、4B、12B 和 27B 参数；4B、12B 和 27B 模型支持文本和图像输入，1B 模型仅限文本；1B 模型支持 32k token，4B、12B 和 27B 模型则扩展至 128k token；支持函数调用和结构化输出\nBlog\nHuggingface\nPhi-4-multimodal 具备文本、图像和音频输入的多模态模型；具有5.6B参数量；采用“混合 LoRAs”技术，将模态特定组件集成到基础语言模型中，而基础模型保持冻结状态，以确保了多模态数据处理的无缝性，避免了传统方法中因模态间干扰导致的性能下降。\nBlog\nHuggingface\nQwen2.5-VL-32B-Instruct 32B参数量版本的Qwen2.5-VL多模态模型；\n72B too big for VLM? 7B not strong enough! Teh you should use 32B model!\nHuggingface\nGemini 2.5 Pro Gemini 2.5 Pro 是一个reasoning模型，具有100万token的上下文窗口，支持多模态输入，包括文本、音频、图像、视频。\nGemini 2.5 Pro\nOpenAI Transcribe OpenAI 最近推出了新的语音转文本模型，包括“gpt-4o-transcribe”和“gpt-4o-mini-transcribe” 仅通过 API 提供服务；这些模型基于 GPT-4o 架构，相较于此前的 Whisper 模型，采用了更广泛且高质量的音频数据集进行训练，提升了对多样化口音、语速变化及嘈杂环境的适应能力，同时显著减少了“幻听”问题\nopenAI docs\nMistral OCR Mistral AI 推出的OCR API，专注于复杂文档的多模态理解,擅长处理科学论文等含图表混合内容的文档；支持 PNG、JPEG 图像及 PDF格式输入，输出Markdown 或 JSON 结构化数据，基础版价格为 1000 页/美元\nMistral OCR\nOpenAI 4o Image Generation OpenAI 最新更新的 4o-Image 生成技术，显著提升了图像生成能力：支持更高分辨率与逼真光影渲染，更精准的文本到图像转换，支持局部修改（如替换物体、调整风格）、多图像生成和3D/动态生成；拥有更强的内容过滤机制和水印或元数据标记；\nIntroducing 4o Image Generation\n值得关注的开源项目 OpenManus 由 MetaGPT 社区开发的Manus复刻项目，主要功能包括基于自然语言指令自主执行复杂任务，如网页浏览、文件操作、代码编写、数据分析等，适用于自动化工作流、研究支持和应用开发等场景。\ngithub\nBrowser Use 因为被Manus所带火的一个开源项目；使AI Agents能够高效访问网页并完成各种任务，\n该项目通过解析网页的 DOM 数据（而非依赖视觉模型）生成结构化数据，从而实现快速、轻量级的网页交互。其主要功能包括支持 AI 代理自动浏览网页、提取信息、执行操作，并与多种大语言模型无缝集成。\ngithub\nOpenAI Agent SDK 由 OpenAI 开发的开源Agent框架，核心功能包括：Agents，Handoffs（允许一个代理将任务委托给另一个代理），Guardrails（验证代理的输入，确保数据符合要求）和Tracing（内置追踪记录代理工作流中的所有事件）；该 SDK 兼容支持 OpenAI Chat Completions API 的多种模型提供商；\nOpenAI Agents SDK 官方文档概述\nGitHub 仓库 openai/openai-agents-python\nOlmOCR 采用多模态大模型实现的OCR项目，其核心VLM—allenai/olmOCR-7B-0225-preview， 是采用Qwen2-VL-7B 在250,000 页的多样化 PDF 数据集上进行微调而得。不仅是开源了模型， 同时还开源了一整套的解析工作管道，及其微调数据集、训练和推理代码。\ngithub\nTrendPublish 全自动 AI 内容生成与发布系统，支持多源数据采集，使用AI进行内容总结生成摘要，支持自动发布。\nGithub\nCSM：A Conversational Speech Generation Model 效果非常不错的语音生成模型。\nGithub\nBlog\nYuE Open Full-song Music Generation Foundation Model\nGithub\n值得关注的研究和论文 Qwen2.5-VL cookbook: https://github.com/QwenLM/Qwen2.5-VL/tree/main/cookbooks\nBlog\nTechnical Report\nMethods\n从头开始训练了一个原生动态分辨率的 ViT\n窗口注意力（Window Attention）： 在视觉编码器中引入，减少计算量，提升推理效率 动态 FPS 采样： 允许模型处理不同帧率的视频 升级的 MRoPE： 在时间域中使用多模态旋转位置嵌入（Multimodal Rotary Position Embedding），通过绝对时间对齐改善长视频处理 动态分辨率处理： 模型能原生处理任意尺寸的图像，无需传统归一化，保留空间细节，特别适用于文档和图表分析 绝对时间编码： 支持处理长达数小时的视频，并实现秒级事件定位 数据规模扩展： 预训练数据从 1.2 万亿 tokens 增加至 4.1 万亿 tokens 预训练过程分为三个阶段：\n在第一阶段，仅训练ViT，即视觉预训练：\n针对Document Parsing，设计了一套标准化的HTML标签体系，包含：段落（p\u0026gt;）、表格（\u0026lt;table\u0026gt;）、图表（\u0026lt;div class=\u0026quot;chart\u0026quot;\u0026gt;）、公式（\u0026lt;div class=\u0026quot;formula\u0026quot;\u0026gt;）、图像标注（\u0026lt;div class=\u0026quot;image caption\u0026quot;\u0026gt;）、OCR文本（\u0026lt;div class=\u0026quot;image ocr\u0026quot;\u0026gt;）、乐谱（\u0026lt;div class=\u0026quot;music sheet\u0026quot;\u0026gt;）、化学式（\u0026lt;div class=\u0026quot;chemical formula\u0026quot;\u0026gt;）等模块。每个模块均通过 data-bbox 属性标注其原始坐标位置，保留空间布局信息; 同时所有文档元素的布局信息（如位置、尺寸）通过原生分辨率下的绝对坐标直接编码到HTML标签中，使模型能同时学习内容语义和空间关系 OCR 数据: 利用高质量的合成图像和现实世界的自然场景图像, 整合了一个大规模的多语言OCR数据集,支持多种语言; 针对图表类型数据，使用python可视化库合成了100万个样本； 对于表格数据，利用表格识别模型处理了600万个真实样本用于训练； 视频数据： 在训练过程中动态采样FPS，确保在理解不同帧率的视频数据时增强鲁棒性； Agent：收集移动设备、网页和桌面平台的截图。使用合成数据引擎生成截图字幕和UI元素定位注释。字幕任务帮助Qwen2.5-VL理解图形界面，而定位任务帮助它对齐元素的外观和功能；通过人类和模型注释者(AGUVIS),为每个步骤生成推理过程 在第二阶段，解冻所有模型参数，并在多样化的多模态图像数据上训练模型，以增强其处理复杂视觉信息的能力\n在第三阶段，长上下文预训练： 序列长度扩展至 32768，专注于长视频、长代理任务和长文档，训练长上下文能力\npost-training： Qwen2.5-VL 的后训练对齐框架采用了一个双阶段优化范式，包括监督微调（SFT）和直接偏好优化（DPO）（ViT参数冻结）SFT,约200万条记录，纯文本数据和多模态数据各占50%，多模态数据包括图文和视频文本组合;\n设计了一个两阶段的数据过滤pipeline，用于数据清洗和低质量数据过滤；在初始阶段即领域特定分类，采用Qwen2-VL-Instag（Qwen2-VL-72B）对问答对进行层次分类（八个主要领域，每个领域可进一步细分）；第二阶段涉及领域定制过滤，根据上一步的分类，有针对的对于不同领域提高数据质量（rule-based and model-based），如对于文档处理、OCR 和视觉定位任务相关的数据集，识别并移除重复模式\n采用拒绝采样作为策略以增强推理能力\n效果：单纯从视觉问答和 OCR benchmark的跑分结果看，72B 模型与 GPT-4o 和 Claude 3.5 Sonnet 相当\nR1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning https://arxiv.org/abs/2503.05592\n现有的大型推理模型(LRMs)主要依赖其内部知识来解决问题,这在处理知识密集型问题、私有信息查询和时效性问题时容易产生不准确和幻觉。因此,需要让模型能够在推理过程中访问外部信息来实现更深入的推理 。\nR1-Searcher,一个通过强化学习来增强大语言模型搜索能力的框架。该框架采用两阶段的基于结果的强化学习方法,使模型能够在推理过程中自主调用外部搜索系统获取相关知识\n创新点：\n提出了一个两阶段的基于结果的强化学习框架,使模型能够自主调用外部搜索系统 完全依赖强化学习进行训练 奖励机制,包括检索奖励和格式奖励,以引导模型学习正确使用外部检索系统 具体方法：\n第一阶段： 使用检索奖励和格式奖励来训练模型学习调用外部检索系统，不考虑答案的准确性,主要目标是让模型学会正确的检索调用格式\n第二阶段： 引入答案奖励，使用F1分数作为答案奖励的度量\nRL训练采用Reinforce++算法\n设计的两个算法：\nRAG-based Rollout\n目的：让模型能够基于检索到的文档继续进行推理，不会中断思维链\n使用特定标签来指示搜索工具的调用：\u0026lt;begin_of_query\u0026gt;...\u0026lt;end_of_query\u0026gt; 当模型生成到\u0026lt;end_of_query\u0026gt;时，会暂停生成过程 提取查询并执行检索 将检索到的文档用\u0026lt;begin_of_documents\u0026gt;...\u0026lt;end_of_documents\u0026gt;标签封装 将检索结果整合到模型的推理过程中 Retrieval Mask-based Loss Calculation\n将\u0026lt;begin_of_documents\u0026gt;...\u0026lt;end_of_documents\u0026gt;指定为特殊标记 在训练过程中对这些部分进行掩码处理，忽略这些被掩码的部分 这些文档不是模型应该学习生成的内容 一些有趣的观察：\nRL比SFT表现更好,在域内和域外测试集上都显示出更强的检索能力和泛化性， SFT倾向于依赖模型的内部知识,这可能导致错误答案 Detecting misbehavior in frontier reasoning models https://openai.com/index/chain-of-thought-monitoring/\n解决问题：\nreward hacking（AI可能通过开发者意图之外的方式实现高奖励，即利用系统漏洞达成指标而非真正解决问题） 创新点：\n提出CoT monitor 用AI监督AI 将思维透明性作为安全机制，而非仅作为解释工具 Methods： 使用另一个LLM（GPT-4o），来观察被监控模型（如 o3-mini）的 CoT 推理过程，这个监控 LLM 会根据特定提示来判断模型是否尝试通过reward hacking来“作弊”\n研究还探讨了将 CoT 监控集成到强化学习奖励中的效果。在低优化条件下（对模型的 CoT 不施加太大压力，允许它自然生成推理过程）此时CoT 保持透明和可监控，模型的行为更一致，监控系统可以有效识别不当行为。反之，在强优化下（通过强化学习大幅调整奖励函数，迫使模型尽可能提高任务表现），模型可能会学会“模糊化”其推理过程，使监控模型难以察觉其不当行为。\n研究建议支付“可监控性税”（monitorability tax），即不对 CoT 施加强优化压力，确保 CoT 保持可监控性，从而有效检测不一致行为。\nA-MEM: Agentic Memory for LLM Agents Paper\n解决的问题：\n当前LLM代理的记忆系统（依赖预定义结构和固定操作流程，无法动态组织知识 如何在开放域任务中实现记忆的自适应组织和持续演化，以支持复杂长期交互 创新点：\n受Zettelkasten启发的动态架构： 每条记忆包含内容、时间戳、LLM生成的关键词/标签/上下文描述、嵌入向量和关联链接\nm_i = {c_i, t_i, K_i, G_i, X_i, e_i, L_i}\n通过语义相似性和LLM推理动态建立记忆间的多层次关联（如因果关系、概念相似性）\n新记忆触发历史记忆的上下文和属性更新\nm_j^* \\leftarrow \\text{LLM}(m_n | \\mathcal{M}^{\\text{near}}n \\setminus m_j | m_j | P{s3})\nMethods\n笔记构建：用LLM解析原始交互，生成结构化属性）。 链接生成：先通过嵌入相似性筛选Top-K候选记忆，再用LLM分析深层关联。 记忆检索：将查询分解为关键词，在记忆网络中搜索。 graph LR A[新记忆m_n] --\u0026gt; B[生成嵌入e_n] B --\u0026gt; C[计算相似性] C --\u0026gt; D[筛选Top-K] D --\u0026gt; E[生成链接] E --\u0026gt; F[触发记忆演化] G[用户查询q] --\u0026gt; H[查询嵌入] H --\u0026gt; I[匹配记忆] I --\u0026gt; J[返回结果] prompt_template_for_Memory_Evolution = \u0026#34;\u0026#34;\u0026#34;You are an AI memory evolution agent responsible for managing and evolving a knowledge base. Analyze the new memory note according to keywords and context, also with their several nearest neighbors memory. Make decisions about its evolution. The new memory context: {context} content: {content} keywords: {keywords} The nearest neighbors memories: {nearest_neighbors_memories} Based on this information, determine: 1. What specific actions should be taken (strengthen, update_neighbor)? 1.1 If choose to strengthen the connection, which memory should it be connected to? Can you give the updated tags of this memory? 1.2 If choose to update neighbor, you can update the context and tags of these memories based on the understanding of these memories. Tags should be determined by the content of these characteristic of these memories, which can be used to retrieve them later and categorize them. All the above information should be returned in a list format according to the sequence: [[new_memory], [neighbor_memory_1], ... [neighbor_memory_n]] These actions can be combined. Return your decision in JSON format with the following structure: { \u0026#34;should_evolve\u0026#34;: true/false, \u0026#34;actions\u0026#34;: [\u0026#34;strengthen\u0026#34;, \u0026#34;merge\u0026#34;, \u0026#34;prune\u0026#34;], \u0026#34;suggested_connections\u0026#34;: [\u0026#34;neighbor_memory_ids\u0026#34;], \u0026#34;tags_to_update\u0026#34;: [\u0026#34;tag_1\u0026#34;, ... \u0026#34;tag_n\u0026#34;], \u0026#34;new_context_neighborhood\u0026#34;: [\u0026#34;new context\u0026#34;, ..., \u0026#34;new context\u0026#34;], \u0026#34;new_tags_neighborhood\u0026#34;: [[\u0026#34;tag_1\u0026#34;, ..., \u0026#34;tag_n\u0026#34;], ..., [\u0026#34;tag_1\u0026#34;, ..., \u0026#34;tag_n\u0026#34;]] }\u0026#34;\u0026#34;\u0026#34; 一些发现：\n移除链接生成（LG）和记忆演化（ME）后，多跳任务F1从45.85降至24.55，仅保留LG时性能恢复至31.24，证明链接生成是基础，演化机制是增强\nSFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training Paper\n这篇文章研究了SFT和RL在基础模型后训练中对模型泛化能力和记忆能力的影响，特别是在面对未见过的规则和视觉变体时的表现。\n发现：\nSFT倾向于记忆训练数据，难以泛化到未见过的规则或视觉变体，甚至在视觉任务中可能导致视觉识别能力下降 RL不仅在训练任务上表现更好，还能泛化到OOD任务，尤其是在视觉任务中表现出色 虽然RL表现更好，但SFT在RL训练中起到了稳定输出的关键作用 推荐内容 汇总：使用LLM生成精美网页、PPT、卡片 一键搞定、100%成功、80老太都能操作，宝藏提示词将你的任何内容生成网页\n【教程】必须收藏的 4 段 Prompt 提示词，生成PPT、生成3D动画，生成网站，生成万物\u0026hellip;\n一键生成产品网站和小红书卡片，DeepSeek v3的代码能力和审美提升太大了\nAI 快速生成精美卡片\nMCP-Server合集 Model Context Protocol servers\nMCP.co\ncomposio\n课程 10 Lessons teaching everything you need to know to start building AI Agents ｜Microsoft\n其他 AI Blindspots：一个列出了当前 AI 开发盲点合集的网站\n影音记录 精选歌单 Live演出 03.15 Corn Wave\n03.18 Mogwai\n03.21-23 Can festival\n书\u0026amp;阅读摘录 Career advice in 2025 Many people who first entered senior roles in 2010-2020 are finding current roles a lot less fun. There are a number of reasons for this. First, managers were generally evaluated in that period based on their ability to hire, retain and motivate teams. The current market doesn’t value those skills particularly highly, but instead prioritizes a different set of skills: working in the details, pushing pace, and navigating the technology transition to foundational models / LLMs.This means many members of the current crop of senior leaders are either worse at the skills they currently need to succeed, or are less motivated by those activities. Either way, they’re having less fun.\nValuations and funding are relatively less accessible to non-AI companies than they were three years ago.\nI also wouldn’t personally try to sit this cycle out unless you’re comfortable with a small risk that reentry is quite difficult: I think it’s more likely that the ecosystem is meaningfully different in five years than that it’s largely unchanged.\n一个人年入千万，AI创业的十个步骤 AI造就的是一个极度放大你个人能力的时代，你一个人可以干以前几十个人干的事情\n真正的门槛是洞察需求的能力。你做了一个手电筒或者天气软件，不管再精美，也很难帮你做到商业上的成功。\nMVP就是拿出去让用户骂，用户骂得越针对，你产品进步得越快\n大模型的未来，是 Agent 还是 App？ Deep Research 不是标准的 LLM，也不是普通的聊天机器人。它是一种新型的\u0026quot;研究语言模型\u0026quot;，专门设计用于端到端执行搜索任务。\n目前大多数 Agent 初创公司构建的不是真正的 Agent，而是工作流，即\u0026quot;通过预定义的代码路径编排 LLM 和工具的系统\u0026quot;。工作流在某些垂直领域仍可能创造价值\n当前的 RAG 系统由许多相互关联但脆弱的工作流组成：路由、分块、重排序、查询解释、查询扩展、源上下文化和搜索工程。随着训练技术栈的发展，有可能将所有这些流程整合到两个独立但相互关联的模型中：一个用于数据准备，另一个用于搜索/检索/报告生成。 这需要精心设计的合成流程和全新的强化学习奖励函数。真正的训练，真正的研究。这在实践中意味着：转移复杂性。\nAI Will Upend a Basic Assumption About How Companies Are Organized 经济体系长期以来建立在这样的观念之上：专业知识稀缺且昂贵。而人工智能即将让这种专业知识变得丰富且几乎免费。\n支撑我们社会制度的基本假设——“人类洞察力稀缺且昂贵”——将不复存在 摆在个人与企业面前的问题是：当智能本身随处可得且几乎不需成本时，你将如何行动？\n一个原因在于人们很难想象，“必须依靠资深管理者或顶尖专家”才能完成的工作，居然可以（或者部分可以）由机器来承担。正因为卓越人才稀缺，那些高价值任务才显得格外珍贵。我们的组织结构便是在“真正的高智商人才供给有限”这一认知下设计的。\n大多数企业领导人仍处在“尝试接受 AI”而非“真正相信 AI”的阶段\n当智慧的成本几近于零时，真正的瓶颈已不再是“如何获取大脑”，而是“我们如何善加利用”。\n为什么 AI 模型离科学革命还差得很远？ 当前 AI 模型的评估方式有误区\n现在，我们评估 AI 模型智能提升的方式，大多是通过一些“高难度考试题…这些正是我当年擅长的考试类型。这样的评估方法，只能测试模型是否能回答人类已经知道答案的问题。但真正的科学突破，并不来自于答题，而是来自于提出别人没问过的问题，挑战主流认知，质疑已有理论。\n尽管大语言模型已经掌握了几乎所有人类知识，但它们还没有真正“生成”出新的科学发现。…我们现在训练出来的是“听话的好学生”，不是“有主见的创造者”\n那么我们也许需要重新定义 AI 模型的评估方式：评估标准不再是“答对多少题”，而是它是否具备真正的科学思维，\n我们常犯的一个错误，是把牛顿或爱因斯坦看作是“超级优等生”，以为只要把一个好学生按比例放大，就能变成一个天才。… 但这种线性外推忽略了科学最本质的一点：提出正确问题的能力，以及挑战既有知识体系的勇气。\n","permalink":"https://niraya666.github.io/monthly/2025-03-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003ch2 id=\"deepseek-v3-0324\"\u003eDeepSeek V3 0324\u003c/h2\u003e\n\u003cp\u003eDeepSeek V3模型的更新版本；在多个基准测试中表现出色，整体表现接近领先的闭源模型如Claude Sonnet 3.5（但价格便宜很多）；针对多项能力做了针对性提升，如function calling，推理能力，前端代码能力等。更新版本在DeepSeek的官方网站、移动应用可体验。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/deepseek-ai/DeepSeek-V3\"\u003eHuggingface\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"qwq-32b\"\u003eQwQ-32B\u003c/h2\u003e\n\u003cp\u003e由Qwen 团队开发的推理模型，性能同671B参数量的R1相当；通过两阶段RL训练，第一阶段专注于数学和编码任务，利用准确性验证器和代码执行服务器提供反馈；第二阶段提升通用能力，同时保持专业领域的表现。此外QwQ具备tool-using能力，具有131,072 token的上下文长度。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://qwenlm.github.io/zh/blog/qwq-32b/\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/Qwen/QwQ-32B\"\u003eHuggingface\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"qwen25-omni\"\u003eQwen2.5 Omni\u003c/h2\u003e\n\u003cp\u003eQwen2.5-Omni 是一个多模态 AI 模型，能够同时处理文本、图像、音频和视频输入；该模型的创新点包括 Thinker-Talker 架构，分为“Thinker”处理输入并生成表示或文本，“Talker”则输出语音token，共享上下文，实现端到端训练和推理。此外，它使用 TMRoPE（时间对齐多模态 RoPE）技术，同步视频和音频时间戳，确保多模态数据处理的一致性。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://qwenlm.github.io/zh/blog/qwen2.5-omni/\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/Qwen/Qwen2.5-Omni-7B\"\u003eHuggingface\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"gemma-3\"\u003eGemma 3\u003c/h2\u003e\n\u003cp\u003eGemma家族的开源新作，包括 1B、4B、12B 和 27B 参数；4B、12B 和 27B 模型支持文本和图像输入，1B 模型仅限文本；1B 模型支持 32k token，4B、12B 和 27B 模型则扩展至 128k token；支持函数调用和结构化输出\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://blog.google/technology/developers/gemma-3/\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/google/gemma-3-27b-it\"\u003eHuggingface\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"phi-4-multimodal\"\u003ePhi-4-multimodal\u003c/h2\u003e\n\u003cp\u003e具备文本、图像和音频输入的多模态模型；具有5.6B参数量；采用“混合 LoRAs”技术，将模态特定组件集成到基础语言模型中，而基础模型保持冻结状态，以确保了多模态数据处理的无缝性，避免了传统方法中因模态间干扰导致的性能下降。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://azure.microsoft.com/en-us/blog/empowering-innovation-the-next-generation-of-the-phi-family/\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/microsoft/Phi-4-multimodal-instruct\"\u003eHuggingface\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"qwen25-vl-32b-instruct\"\u003eQwen2.5-VL-32B-Instruct\u003c/h2\u003e\n\u003cp\u003e32B参数量版本的Qwen2.5-VL多模态模型；\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e72B too big for VLM? 7B not strong enough! Teh you should use 32B model!\u003c/p\u003e","title":"2025-03 月刊"},{"content":"当冰岛后摇乐队Sigur Rós宣布世界巡演时，东京站便成了我行程表上必须抵达的地方。当然，这趟旅程还承载很多和音乐、艺术有关的记忆。\n入关时，海关大厅的喧嚣依旧。排队时遇见一对中国夫妇，他们对着\u0026quot;外国人\u0026quot;汉字的标识犹豫不决，忽然意识到自己早已身处异国，相视而笑的瞬间让我想起去年同样忐忑的自己。指纹机这次顺利读取了我的手纹，或许因为少了初访时的紧张手汗。海关人员将新入境贴纸仔细贴在旧标签右侧，整齐的排列让强迫症狂喜了。\n选择上野作为落脚点，不仅因它毗邻机场快线的便利，更迷恋老城区特有的烟火气。从成田机场进城的交通选择颇多，最终搭乘号称日本最快非新干线列车的Skyliner。\n与大阪相比，东京街头的中国元素显得格外醒目。沙县小吃和杨国福麻辣烫这类国内常见的连锁招牌不时映入眼帘，而改良版的四川担担面更是在日本扎根多年，形成了独特的本土风味。\n拖着行李箱抄近道时，误入了名为仲町通り的小路。暮色中的街道霓虹渐起，酒吧与餐厅的招牌间夹杂着暧昧的粉色灯箱，手持宣传板的年轻女性在街角轻声招揽客人，几个西装革履却透着江湖气的男子在暗处徘徊。我加快脚步穿过这片区域，直到看见便利店明亮的灯光才松了口气。后来查阅资料得知，这条起源于江户时代宽永寺门前町的老街，历经三百年演变已成为东京著名的夜生活区。这里不仅延续着传统娱乐文化，更因拉客纠纷和醉汉闹事被列为治安重点区域，旅游指南都建议游客避免夜间单独深入巷弄。有趣的是，在鳞次栉比的霓虹招牌中，除了日文店名，还夹杂着不少泰语和菲律宾语的标识。\nDay1 东京都现代美术馆 东京之行的首站，是提前数日才预约成功的特别展——《坂本龙一｜听音观时》。即便社交媒体上最出圈的《雾的雕塑》装置吸引着无数人前来打卡，但对我而言，这场展览更像是赴一场迟到的对话。作为教授生前为美术馆构思的最终企划，十二组装置艺术中流淌着他未完成的思考：当音乐脱离传统音阶束缚，当乐器回归自然物质的本质。\n《你的时间》（坂本龙一 with 高谷史郎）\n311海啸浸没过的钢琴正以另一种形态重生。曾出现在纪录片《终曲》中的这架\u0026quot;被自然调律的乐器\u0026quot;，此刻悬浮于水盘之上。头顶屏幕飘落的雪与地震数据转化的音符共振，琴槌敲击的已非人造音阶，而是地壳震颤的原始频率。\n《异步——沉浸东京》（坂本龙一with高谷史郎 2024 ）\n这也是我驻足最久的一个装置，因为其播放的是我最喜欢的一张专辑《Async》。 展厅正面是一面 18 米长的 LED墙，实时生成由高谷制作的影像。高谷的影像以拍摄坂本纽约工作室里的钢琴、书籍、打击乐器、后院盆栽等各种物品为基础构成。\n“Because we don\u0026rsquo;t know when we will die, we get to think of life as an inexhaustible well. Yet everything happens only a certain number of times, and a very small number really. How many more times will you remember a certain afternoon of your childhood, an afternoon that is so deeply a part of your being that you can\u0026rsquo;t even conceive of your life without it? Perhaps four, five times more, perhaps not even that. How many more times will you watch the full moon rise? Perhaps 20. And yet it all seems limitless.”\n在《fullmoon》 一曲中，电影《遮蔽的天空》中的朗诵采样，被翻译成了其他 9 种不同的语言，伴随着左右声轨中轮流播放，在长屏幕上的不同位置点亮着不同语言的版本。\n《生命——井 东京 雾的雕塑》（坂本龙一＋中谷芙二子＋高谷史郎 2024）\n人造云雾正从展馆两侧涌出，对流，相互碰撞。这些动态被摄影机捕捉，并被即时转换为声音\n《感应流 2024——不可见，不可闻》 （坂本龙一 + 真锅大度 2024）\n我们习以为常的无线电信号若被具象呈现，会展现怎样的形态与韵律？\n银座 Sony Park 位于银座繁华地段的 Sony Park，紧邻爱马仕旗舰店。尽管名为“公园”，这座建筑实际上是一座未经装饰的钢筋混凝土大楼，地上和地下共有几层。对于不了解其背景的人来说，很难将其与公园联系起来。在2017年旧楼拆除至2024年新厦落成期间，该地块曾作为临时绿地开放。今年1月26日，历经半年筹备的新场馆正式重启，同步推出\u0026quot;Sony 25周年特展\u0026quot;。\n当前展览分为上下两部，本次参观的上部聚焦金融、音乐、半导体三大业务板块。每个主题展厅均邀请不同音乐人参与内容设计，通过声光装置呈现科技与艺术的交融。尽管展览免费开放，但因有当红组合YOASOBI的参与，周末时段预约名额常迅速告罄。\n金融主题展厅以\u0026quot;Finance details life\u0026ldquo;为命题，由羊文学乐队打造的文字艺术装置颇具巧思。展区播放着《More Than Words》《光るとき》的歌词，伴随着音乐，歌词在光影中交错重叠。\nWords overlap. Words create poetry. The soothing rhythm of words envelops all doubts and anxieties.\n三楼 YOASOBI「Semiconductors create new realities」以人体心跳为灵感原点，每位观众入场时需通过交互终端录入姓名并测量实时心率。这些生物数据将转化为独特的数字小物件，与展场中央的YOASOBI原创电子乐实时互动。\nB2 Vaundy「Music comes after a long journey」\n这也是我最喜欢的展厅，音乐人Vaundy精选的200首作品，观众需手持接线耳机，通过物理插拔动作完成点歌，回归了最原始也是最纯粹的听歌方式。\nDay2 上野公园 国立博物馆 感冒还没好透，还是决定就近走走。住处往北不过三分钟脚程，便是绿荫环绕的上野公园，转过十字路口，眼前豁然展开一片水色，便是不忍池了。\n江户幕府初建时，匠人们依照琵琶湖的形制凿出这方水域。关于\u0026quot;不忍\u0026quot;的来历，老东京们常念叨两种说法：一说取自佛家\u0026quot;慈悲不忍\u0026quot;的偈语，另一说倒是直白——这池子心软得很，连旱年都舍不得见底。\n初春的池面上，莲花只留些光秃秃的杆子戳在水里，要是盛夏时节，这里就会铺满接天莲花，不过眼下倒是海鸥和鸽子最自在。\n不忍池中间有座小岛，岛上立着宽永寺的辩天堂。这座庙虽然不大，却挺有名气，因为里面供着七福神里的大黑天。说来有意思，这个神明原本是印度教战神摩诃迦罗，传到日本后成了日本天台宗信仰的守护神。大黑天与日本古代神道教中的色神同为一体，被尊称为“大缘”或“大黑”，意为带来广远亲近之福的大神。\n沿樱花大道晃悠着，一个写着“上野合格大佛”的牌子吸引力了我，可四下张望，只瞧见个土包，而不见常见的立佛像或是卧佛像。沿着台阶往上走，这才看清小亭子中供奉着的一张佛脸。\n原来江户初年这里立过六米高的青铜大佛，越后国的和尚们一锤一锤敲出来的。可这佛像像是跟地震结了仇，1631年建好后被震塌三次。最惨的是二战那年，整个佛身子都被熔成子弹炮弹，就剩这张脸留在了这里。可来参拜的考生们偏说这模样吉利——跌倒了七次，就站起来八次嘛，所以不少考生特地來這裡祈求考試合格。\n侧面有块铁牌，记录着这里的历史，其中有这样一句话： “大仏を埋めて白し 花の雲 子規” 来自于日本俳句詩人正岡子規，展现着日本人独有的物哀心理，借由樱花短暂的美丽，表达出一种超然和淡泊的情感，对世事无常的淡淡感伤。\n穿过大石鸟居，便可来到上野著名的东照宫。这座供奉着德川幕府开创者德川家康的神社，最醒目的就是主殿外墙贴满的金箔，当地人都叫它\u0026quot;金色殿\u0026rdquo;。据记载，德川家康去世后，他的两位重要家臣藤堂高虎和天海僧正主持修建了这座神社。\n特别暖心的是，主殿前专门设置了单人自拍台。即便独自旅行，游客也能轻松把整座金灿灿的建筑完整收进取景框。每月16、17号会发售限定的\u0026quot;升龙御守\u0026quot;，龙形图案的金色护身符据说能保佑升官发财。\n在国立博物馆前的广场上，正巧碰上了周末的酒屋街角小酌节。花500日元入场费就能逛遍各种酒摊，空气里飘着烤串和章鱼烧的香味。虽然挺想尝尝鲜，但大白天就喝酒总觉得不太合适。\n这座1872年建成的日本首家博物馆，常设展门票1000日元。除了本馆的日本文物和东洋馆的亚洲藏品，当时表庆馆正在办HelloKitty特展，门口排队的队伍足足绕了半圈，听说要等一个多小时才能入场。\n本馆里陈列着武士刀、浮世绘这些传统文物。有幅叫《第二代市川八百藏与第二代濑川菊之丞的合撑伞》的画让我印象深刻，画的是两位歌舞伎名角共撑油纸伞在雪中行走的场景。\n来源\n描绘了两位当时著名的歌舞伎演员，演绎一对踏雪而行、前去殉情的情侣，而合撑一把伞前行是歌舞伎中表现男女前往殉情的固定手法。\n转到东洋馆时心情变得复杂起来。这里大部分展品都来自亚洲的其他国家，从敦煌壁画残片到唐三彩，还有东南亚的佛像。虽然保存得很完好，但看着那些本该属于中国等各国的文物，作为中国人心里总归不是滋味，每一件器物背后，都藏着半截没说完的硝烟往事.\n浅草寺 ￼ 浅草寺的正门口立着朱红色的雷门，左右分立着风神雷神的雕像。门前的石板路上，穿传统短褂的人力车夫们正招呼游客体验江户风情。\n穿过雷门便是仲见世街。这是一条通往浅草寺的购物街，两百多米长的商店街飘着人形烧的甜香，和风团扇、浮世绘手帕等纪念品琳琅满目。抬头可见晴空塔的尖顶刺破云层，传统与现代在同一个画面里奇妙交融。 ￼\n这座寺庙的由来颇有故事。相传千年前有渔民在隅田川捞到一尊观音像，当地乡民便建堂供奉，渐渐发展成如今香火鼎盛的浅草寺。\n主殿里供奉的是圣观音像，不少本地人虔诚地合掌礼拜。\n￼ 意外发现游客中心顶楼藏着观景台。乘电梯直上八层，整片寺院尽收眼底。这里尚未被游客挤占，能安静俯瞰附近的建筑和风景。\n回程时注意到河畔的奇特建筑，一朵金色的啤酒花，这是朝日啤酒的建筑物（Super Dry Hall）。与其说是啤酒花，更像是个金色的便便。 ￼\n返程途经御茶之水时，特意绕道圣桥。这里是铁道迷心中的圣地。虽然对动漫圣地巡礼没有执念，但作为半个铁道迷，实在抵挡不住三列电车在此交汇的奇观。\nDay3 六本木之丘 六本木之丘52层真是个宝藏楼层，这里同时容纳了森美术馆、Tokyo City View观景台和森艺术中心画廊。最近听说森美术馆新开了名为\u0026quot;Machine Love\u0026quot;的人工智能主题展，作为AI从业者自然不能错过。\n￼ 原本计划先看森艺术中心画廊的埃及文物展，但看到门口蜿蜒的长队需要等一小时，只好作罢。转身上楼来到\u0026quot;Machine Love\u0026quot;展厅，这里主要讨论人工智能、电子游戏与当代艺术的关联。在开头处，策展人甚至贴心提供了prompt用于解释复杂的专有名词。\n￼ 不过观展体验有些复杂。部分作品像是动画专业学生的未完成作业，生硬地套用AI元素来掩饰技术缺陷。那些关于\u0026quot;人类与技术关系\u0026quot;的深刻命题，在具体呈现上显得有些力不从心。最惊喜的反倒是同层的Tokyo City View观景台，巨大落地窗前能够看到一览东京全貌。\n￼ ￼ ￼\n芝公园 沿着石板路走进芝公园，最先看到的是古朴庄严的增上寺。这座净土宗大本山曾是德川将军家的家庙，朱红色的殿堂在绿荫中格外显眼。作为东京最早的公园之一，这里原本就是寺庙的属地，如今开阔的草坪和步道成了市民散步的好去处。\n￼ 站在公园的小坡上，能望见橙红色的东京塔从树梢间探出头来。 ￼\n临走时注意到地铁站叫\u0026quot;芝大门\u0026quot;，这名字藏着江户时代的故事。四百年前这里确实有座名为\u0026quot;芝大门\u0026quot;的城门，如今城墙虽已消失，但往来电车上依然回响着这个古老的地名。\n台场 这次来看演的Tokyo Garden Theatre正好在台场，趁开演前的几小时，我顺道去海边走了走。这个填海造出的人工岛上，藏着不少有意思的风景。\n￼ 地图上发现条有趣的电车线，叫百合海鸥线。这条无人驾驶的轨道列车在台场绕出个圆环，坐在车厢里能看海。\n￼ 海滨步道上有不少散步的人。看着海特别适合发呆。我坐在长椅啃饭团时，听见旁边几个中国游客在聊八卦，多是关于大S得流感去世以及打疫苗之事。\n在台场，有着标志性的富士电视台大楼，那个银色球体建筑总让我想起科幻片里的太空舱。自由女神像复制品立在码头，倒有种错位的幽默感。\n￼ Sigur Ros 2025巡演特别版，是同当地交响乐团共同呈现的。坐在山顶位虽然看不清乐手表情，反而更能专注聆听音乐本身。当冰岛空灵的人声遇上管弦乐的磅礴时，不免让人落泪，黑暗中此起彼伏的抽泣声。特别是《Hoppípolla》前奏响起那刻，真能让人起鸡皮疙瘩。\n谢场时鼓掌手都拍疼了，心里想着，这样的演出真希望能多看几回啊。\nDay4 我记得在《动物化的后现代》一书中，作者提到御宅族有着收集符号的特殊爱好。虽然我不认为自己是御宅族，但也不免有这种收集的习惯，或许这也是资本主义消费文化影响的结果吧。原本计划留出这天去镰仓游玩，可惜天气不好。正好东京还有几个想去却没去成的地方，索性把最后一天变成东京符号收集日——这大概算现代人的另类巡礼吧？\n神社御守收集 住的民宿旁边有座神社，建筑很显眼，但前几天都是匆匆路过，没机会进去看看。这就是汤岛天满宫，供奉着学问之神菅原道真，大清早便可看见不少穿着制服的学生，前来祈求学业考试顺利。这里的御守以保佑学业相关的最为出名。\n御守挺适合作为伴手礼的。御守（お守り）是护身符，象征神明的保佑，通常有效期一年，需要定期更换。不同神社有各自特别设计的御守，有些甚至是限定版，作为收藏品也很不错。除了御守，还有御朱印（ごしゅいん），就是参拜的证明，由神社人员手写或盖章的书法作品。\n最有趣的是在秋叶原附近的神田神社，这里有IT信息安全守护御守，正好很适合我的同事们。\n代代木 自古以来，这片土地上就生长着一代又一代的巨大榧树（かやのき），因此得名“代代木”（代々木）。这里曾有一棵闻名的大榧树，但不幸在1945年5月的战争中被烧毁。后来人们重新种了一棵树，延续着这片土地的历史。\n代代木地区最重要的一处神社便是明治神宫，这座1920年建成的神社，供奉着推动日本现代化的明治天皇与昭宪皇太后。在入口处能看到许多清酒奉纳桶（酒樽），这些都是日本各地酿酒师捐献的，表达对明治天皇夫妇的敬意。明治天皇在位时，既推动国家现代化，也很重视保护传统文化，包括清酒酿造。\n神社入口的鸟居造型特别，横梁微微上翘，这种样式通常用于重要神社，象征着对明治天皇的崇敬。这座高12米的鸟居也是日本最大的鸟居，使用的是来自台湾超1500年树龄的扁柏制成。\n在明治神宫御苑前，立着一个牌子，上写着明治天皇和昭宪皇太后的御制和歌（御製・御歌）。\n世の中の\n事ある時に\nあひぬとも\nおのがつとめむ\nことな忘れそ\n释义： “世间发生重大事件之时，即便身处其中，也不要忘记自己的职责。”\n身にしみて\nうれしきものは\nまこともて\n人のつげたる\nことばなりけり\n释义： “最令人感动和欣慰的，莫过于别人真心传递的话语。”\n去年在上海电影节，我看二刷了《完美的日子》这部电影，讲的是东京一位公厕清洁工的日常生活。这部电影原本只是为东京特色公厕拍的宣传片，没想到导演文德斯把它拍成了长片，还让主演役所广司拿到了戛纳影帝。\n逛完明治神宫，我顺路去看了代代木附近的几个特色公厕：\n伊东丰雄设计的代代木八幡公厕，位于八幡神社旁边。三个圆形谷仓造型。\n安藤忠雄设计的涩谷神宫通公园公厕。\n代代木深町小公园的公厕是由坂茂设计的，这就是电影里那个能变色的玻璃洗手间。有趣的是，附近还有一个几乎一样的蓝绿色公厕，也是出自同一位设计师之手。\n在公厕打卡时，偶遇的电车。\nFender旗舰店与涩谷Tower Records 在东京原宿的明治神宫前，藏着亚洲最大的Fender吉他旗舰店。作为电吉他爱好者，这是必访之地，这座四层（地上三层加地下一层）的店铺，陈列着各类Fender电吉他（当然还有少量贝斯和木吉他），包括限定版和日本特别款。店内设有试音室和展示区，楼梯墙面挂满了使用Fender吉他的音乐人照片，更像是博物馆的感觉而不是普通的商店。\n涩谷的Tower Records则是音乐爱好者的天堂。这个发源于美国的唱片连锁品牌，虽在2006年于美国宣布倒闭，但东京分店被当地企业收购后顽强生存下来。八层空间（含地下一层和顶楼活动区）里囊括各种音乐类型，至今仍是涩谷的文化地标。\n我在这里泡了整个下午。试听区的唱片让人流连忘返，最终带走两张：YMO的中古盘和Bill Evans的特别版绿胶。店里\u0026quot;NO MUSIC, NO LIFE?\u0026ldquo;的标语格外应景。\n店内有不少展台会展示日本本土音乐人的作品，能够感受到他们对于自己音乐的自豪感。其中一个音乐推荐专区，推荐了日本的Jazz，其写到 日本音乐不止有动漫歌曲和City Pop 还有60-80年代的\u0026quot;和爵士\u0026rdquo;（WA-JAZZ）。\n我发现几张特别喜欢的：\n山本刚三重奏《Misty》（1974）\n福居良《Scenery》（1976）\n高中正义《虹伝説》（1981）\n峰厚介五重奏《峰》（1970）\n有趣的是，这些作品大多在流媒体上难觅踪迹，仅有当年少量限定版本发行。\n东京食记 Delhi Ueno (4.2/5)\n结束了一天的展览，来到上野附近这家印度咖喱店。虽只有15个座位的小店，却常常座无虚席，顾客多为下班的上班族和附近居民，基本是晚上8点，依旧需要排队。排队时便可闻到浓郁的咖喱香料味。\n点了中等辣度的Indo curry，虽然肉份不算太多（仅4块鸡肉配半个土豆），但咖喱酱汁的香浓足以让人将米饭一扫而空。配菜的腌制洋葱和咸菜也别具特色。这家店的菜品可能不够\u0026quot;网红\u0026quot;，但正如美食之道 - 味道才是根本。\n地址：3 Chome-42-2 Yushima, Bunkyo City, Tokyo 113-0034\n网站\n面屋武藏 武骨 (4.1/5)\n作为日本拉面界著名的\u0026quot;96年组\u0026quot;之一，面屋武藏与\u0026quot;青葉\u0026quot;、\u0026ldquo;鲸轩\u0026quot;齐名。御徒町店虽然座位不过12个，3个员工的小店，但料理水准相当可观。\n这家店作为沾面专门店开张，但也有不同的选择，以猪骨汤底为基础，提供\u0026quot;白\u0026rdquo;(基础)、\u0026ldquo;黑\u0026rdquo;(墨鱼汁)、\u0026ldquo;红\u0026rdquo;(特制辣酱)三色拉面。选择的是基础的白汤，采用自家制面，面条较粗，口感筋道。采用动物系与秋刀鱼煮干的双重汤底，不同于传统的单一汤底，更有复合型风味。叉烧肥瘦相间似苏式焖肉。炫完面条，必然要就着浓郁汤底来碗米饭的，突然理解常常被国人说吐槽的「碳水叠碳水」吃法——这样暴烈的鲜美，确需双倍热量来承接。\n有趣的是店里放的音乐多是朋克乐。\n地址：6 Chome-7-3 Ueno, Taito City, Tokyo 110-0005\n网站\nTeuchi Soba Keyaki (3.8/5)\n在六本木之丘看展后偶遇的这家荞麦面店，意外成为此行的惊喜。点了推荐的天妇罗荞麦面套餐，天妇罗拼盘包含虾、帆立贝、𬶮以及三种时令蔬菜。\n荞麦面本身就散发着独特的香气，搭配葱花萝卜泥和适量芥末调制蘸料，传统的食用方式是要发出些许声响。面食完，最后将热汤（そばつゆ）倒入剩余的蘸料中一饮而尽，颇具仪式感。\n地址：〒106-6105 Tokyo, Minato City, Roppongi, 6 Chome−10−1 ヒルズ ウェストウォーク 5F\n网站\n一兰拉面 (3.0/5)\n上野店的人气依旧不减，即便是午后1点仍需等候约45分钟。值得一提的是，店内顾客构成以本地人为主，而非\u0026quot;游客专属\u0026quot;的刻板印象。\n独特的隔间式座位让人专注于美食本身。猪骨汤底浓郁，带有特征性的风味。虽然称不上惊艳，但作为连锁品牌能保持稳定的水准已属难得。\n地址：〒110-0005 Tokyo, Taito City, Ueno, 7 Chome−1−1 アトレ上野\n网站\nCurry \u0026amp; Cafe SAMA Kanda (2.0/5)\n这家网红北海道札幌汤咖喱店的实际体验略显遗憾。店内主要依靠外籍员工服务，客源也以外国游客为主。点的鸡腿咖喱中，鸡肉的调味和咖喱的香气都不够突出，整体表现平平。对追求正统咖喱风味的食客而言，建议可以考虑其他选择。\n结语 与第一次访日相比，这次旅行给我带来了不同的感受。在对日本文化和社会有了更深的了解，日语水平也提高后，我发现自己能够更全面地体会和观察这个国家。\n让我印象深刻的是日本人对个人空间的尊重。这对于我这样的人来说非常舒适——在自己的空间里可以做任何事，不会被打扰或被别人盯着看。这也是为什么东京能吸引各类人群：二次元、艺术家、古着收藏者，每个人都能找到适合自己的小天地。\n这些天在日本学会了一个词，叫\u0026quot;迷惑行为禁止\u0026quot;，意思是不要在公共场合打扰他人。在电车上几乎安静到让人不敢开口说话，而吸烟只能在指定区域进行，否则会被罚款，几乎不见垃圾桶却异常整洁的街道。这与国内的情况形成了鲜明对比。\n作为外来者，我处在一种特权的夹缝中。不必承受他们的社会压力，不必纠缠于敬语体系与人情债，这种特权式的抽离，让我既能享受秩序带来的便利，又能冷静审视其背后的文化代价——正如一台看似完美的机器，唯有站在外部才能看清它的磨损与锈迹。\n这种秩序自有其代价，规则至上的文化也催生了令人窒息的压力。在这个国家\u0026quot;读空气”（空気を読む）的能力被视为重要的社交技能，这种需要时刻揣摩的社交规则，对于职场和日常生活中的人而言，可想而之压力之大， 以至于深夜的居酒屋中总是坐满了下了班宣泄情绪的职场人。这种集体主义框架下的生存艺术，造就了独特的\u0026quot;气泡式社交”，明确区分\u0026quot;内\u0026quot;与\u0026quot;外\u0026quot;的群体界限，也就制造了\u0026quot;表\u0026quot;与\u0026quot;里\u0026quot;的双重人格，人们疲于维持其社会面具。\n同时，它加深了社会孤立化，对‘读空气’的严苛要求迫使个体压抑真实自我，长期处于社交表演状态，最终导致年轻人放弃深度关系，转向浅层联结甚至金钱购买陪伴。东浩纪所指出的‘从欲望到动物性冲动’的退化，恰能解释日本年轻人为何选择用消费填补情感空洞——当社会规则过度压抑人性需求，亲密关系反而成为一种奢侈品。年轻人不再费力经营真实的情感联结，转而用金钱购买陪伴：陪吃饭、陪逛街、甚至陪哭泣的服务产业蓬勃发展。这何尝不是一种集体逃避？\n日本对‘他人视线’的焦虑不仅存在于社交领域，甚至渗透到最日常的进食行为中。体验一兰拉面的单人隔间时，我以为这只是为社恐人士设计的天堂。后来才了解到，这其实与\u0026quot;食べる恥ずかしい\u0026quot;（进食羞耻感）的文化有关。在日本传统中，特别是对女性而言，在公众场合大口吃饭被视为不雅，而拉面需要快速吃且常伴随吸面声，这与对女性的优雅期望相冲突。这种文化羞耻感映射出的其实是日本社会深层次的性别期望不平等，尽管表面上讲究礼仪和秩序，但传统观念的枷锁依然沉重。表面的便利设施，实则暴露出性别规训的裂痕。正如伊恩·布鲁玛在《日本之镜》中所说“日本文化表面上在变，但其内在始终没有真正脱离最古老的本土根源”。\n不过令我惊讶的是，近年来东京变得越来越多元化。也许是因为人口老龄化问题，或是大城市本身的多元特性，在这个整体保守的社会里，我看到了不少来自东南亚、南亚的外国劳工。他们在餐厅和便利店工作，认真学习日本文化中繁琐的礼仪，这些外来者或许尚未真正融入日本森严的等级体系中， 但至少暗示某种变化。\n","permalink":"https://niraya666.github.io/travel/2025%E4%B8%9C%E4%BA%AC%E9%9F%B3%E4%B9%90%E4%B9%8B%E6%97%85%E7%9A%84%E5%86%8D%E5%87%BA%E5%8F%91/","summary":"\u003cp\u003e当冰岛后摇乐队Sigur Rós宣布世界巡演时，东京站便成了我行程表上必须抵达的地方。当然，这趟旅程还承载很多和音乐、艺术有关的记忆。\u003c/p\u003e\n\u003cp\u003e入关时，海关大厅的喧嚣依旧。排队时遇见一对中国夫妇，他们对着\u0026quot;外国人\u0026quot;汉字的标识犹豫不决，忽然意识到自己早已身处异国，相视而笑的瞬间让我想起去年同样忐忑的自己。指纹机这次顺利读取了我的手纹，或许因为少了初访时的紧张手汗。海关人员将新入境贴纸仔细贴在旧标签右侧，整齐的排列让强迫症狂喜了。\u003c/p\u003e\n\u003cp\u003e选择上野作为落脚点，不仅因它毗邻机场快线的便利，更迷恋老城区特有的烟火气。从成田机场进城的交通选择颇多，最终搭乘号称日本最快非新干线列车的Skyliner。\u003c/p\u003e\n\u003cp\u003e与大阪相比，东京街头的中国元素显得格外醒目。沙县小吃和杨国福麻辣烫这类国内常见的连锁招牌不时映入眼帘，而改良版的四川担担面更是在日本扎根多年，形成了独特的本土风味。\u003c/p\u003e\n\u003cp\u003e拖着行李箱抄近道时，误入了名为仲町通り的小路。暮色中的街道霓虹渐起，酒吧与餐厅的招牌间夹杂着暧昧的粉色灯箱，手持宣传板的年轻女性在街角轻声招揽客人，几个西装革履却透着江湖气的男子在暗处徘徊。我加快脚步穿过这片区域，直到看见便利店明亮的灯光才松了口气。后来查阅资料得知，这条起源于江户时代宽永寺门前町的老街，历经三百年演变已成为东京著名的夜生活区。这里不仅延续着传统娱乐文化，更因拉客纠纷和醉汉闹事被列为治安重点区域，旅游指南都建议游客避免夜间单独深入巷弄。有趣的是，在鳞次栉比的霓虹招牌中，除了日文店名，还夹杂着不少泰语和菲律宾语的标识。\u003c/p\u003e\n\u003ch2 id=\"day1\"\u003eDay1\u003c/h2\u003e\n\u003ch3 id=\"东京都现代美术馆\"\u003e东京都现代美术馆\u003c/h3\u003e\n\u003cp\u003e东京之行的首站，是提前数日才预约成功的特别展——《坂本龙一｜听音观时》。即便社交媒体上最出圈的《雾的雕塑》装置吸引着无数人前来打卡，但对我而言，这场展览更像是赴一场迟到的对话。作为教授生前为美术馆构思的最终企划，十二组装置艺术中流淌着他未完成的思考：当音乐脱离传统音阶束缚，当乐器回归自然物质的本质。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/2025%c2%b7%e4%b8%9c%e4%ba%ac%ef%bc%9a%e9%9f%b3%e4%b9%90%e4%b9%8b%e6%97%85%e7%9a%84%e5%86%8d%e5%87%ba%e5%8f%91-assets/BE28B0B2-E428-4FB4-86E6-EDA0D8896E4B_1_105_c.jpeg\" alt=\"BE28B0B2-E428-4FB4-86E6-EDA0D8896E4B_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e《你的时间》（坂本龙一 with 高谷史郎）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e311海啸浸没过的钢琴正以另一种形态重生。曾出现在纪录片《终曲》中的这架\u0026quot;被自然调律的乐器\u0026quot;，此刻悬浮于水盘之上。头顶屏幕飘落的雪与地震数据转化的音符共振，琴槌敲击的已非人造音阶，而是地壳震颤的原始频率。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e《异步——沉浸东京》（坂本龙一with高谷史郎 2024 ）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这也是我驻足最久的一个装置，因为其播放的是我最喜欢的一张专辑《Async》。 展厅正面是一面 18 米长的 LED墙，实时生成由高谷制作的影像。高谷的影像以拍摄坂本纽约工作室里的钢琴、书籍、打击乐器、后院盆栽等各种物品为基础构成。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“Because we don\u0026rsquo;t know when we will die, we get to think of life as an inexhaustible well. Yet everything happens only a certain number of times, and a very small number really. How many more times will you remember a certain afternoon of your childhood, an afternoon that is so deeply a part of your being that you can\u0026rsquo;t even conceive of your life without it? Perhaps four, five times more, perhaps not even that. How many more times will you watch the full moon rise? Perhaps 20. And yet it all seems limitless.”\u003c/p\u003e","title":"2025·东京：音乐之旅的再出发"},{"content":"Updated on 2025-03-29: Add SmolDocling \u0026amp; VLM Summary\n技术迭代速度之快令人惊叹，前作 RAG工具箱：文档解析与表格处理 在短短数月内已显现出代际差距，尽管前作也仅仅只是抛砖引玉式地讨论了pdf的解析方案，不过在新技术的面前，既有的复杂解析架构逐渐失去存在价值，也被端到端范式所取代。在笔者看来，基于多模态大模型的端到端文档解析方案，将成为最优解。\n本文将探讨文档解析的终极形态——基于多模态大模型（VLM）的解析技术，包括Mistral-OCR、OlmOCR等前沿工具的实现与实践，并展望该领域的技术发展趋势，和对于RAG的影响。\n过去的技术栈总结 在RAG系统中，文档解析质量直接决定系统上限。不同场景下的文档形态差异显著，若不能有效解决\u0026quot;garbage in, garbage out\u0026quot;的输入质量问题，后续处理环节将难以发挥应有价值。\n传统文档解析技术长期受限于以下核心痛点：\n结构化信息缺失：无法准确识别文档标题、副标题等层级结构\n特殊内容处理薄弱：数学公式、专业符号解析准确率低下\n复杂表格解析困境：跨页表格、合并单元格等场景支持不足\n图像信息提取瓶颈：扫描文档、手写体识别效果欠佳\n版式适应性问题：多栏布局、影印版本等文档格式兼容性差\n从技术角度，过去文档解析的底层逻辑和框架：\n纯文本解析: PyPDF, PyMuPDF只能解析pdf中的文字,对于公式表格和复杂排版解析无能,对于扫描版低质量的pdf无能为力\nOCR方案（PaddleOCR等）: 首先使用目标检测模型对文档布局进行分析，识别出标题、表格等关键元素的位置，然后在这些位置上使用OCR技术提取文字；由于需要调用多个模型，整套系统非常复杂；\n基于transformer 的解析方案（代表: Dount, Nougat）：专门针对英文的学术文章做的训练, 能够将pdf文章整理成Markdown或Latex格式；但对于其他语言和其他类型的文档泛化效果很差；\n随着模型能力提升，采用VLM做解析是非常自然的想法，尽管GPT-4o的发布使该技术获得广泛关注，但其高昂的API成本制约了实际应用。值得庆幸的是，开源社区的技术突破正在改变这一局面：不论是LLM基座模型多模态理解能力的增强，还是视觉编码器的提升，至少在当下，开源VLM已具备实用级文档解析能力，而无需针对下游任务的微调，同时成本上已经在可接受范围了。\nBenchmark 为了判断一个模型是否适合Document Parsing，需要benchmark测试分数，作为模型挑选的标准。\n现阶段，针对LLMs在OCR、文档信息提取场景下主要采用以下几个常见的bench\nOCRBench、OCRBench-V2\nOmniDocBench\nCC-OCR\n…and more\n（关于benchmark的具体内容见附录）\n这些bench都基本上包含了通用场景下的OCR能力， 多语言的文档解析能力的测试，能够一定程度上作为模型筛选的关注首选\n当然，除了模型能力以外，还需要关注模型的参数量，因为与其成本和latency息息相关。\n不过，对于每一个具体场景，还是需要构建自己的测试集用于判断模型是否能够胜任任务， 因为benchmark所包含的测试场景数据，分布语言等等和具体的场景不见得完全一样。\n根据benchmark和实际测试结果，目前几个值得关注的开源VLM：\nQwen2.5-VL\nPhi-4-multimodal\nLlama 3.2 Vision\nolmocr\nand more …\nQwen2.5-VL系列模型 cookbook\nBlog\nTechnical Report\n这应该是开源的模型中，效果排前列的多模态模型（截止至今），同时还具备了多种参数量（3B，7B，72B）可选择。\n在Technical Report 中一些和document-parse有关的内容：\n在第一阶段视觉预训练中（仅训练ViT），针对Document Parsing，设计了一套标准化的HTML标签体系，包含：段落（p\u0026gt;）、表格（\u0026lt;table\u0026gt;）、图表（\u0026lt;div class=\u0026quot;chart\u0026quot;\u0026gt;）、公式（\u0026lt;div class=\u0026quot;formula\u0026quot;\u0026gt;）、图像标注（\u0026lt;div class=\u0026quot;image caption\u0026quot;\u0026gt;）、OCR文本（\u0026lt;div class=\u0026quot;image ocr\u0026quot;\u0026gt;）、乐谱（\u0026lt;div class=\u0026quot;music sheet\u0026quot;\u0026gt;）、化学式（\u0026lt;div class=\u0026quot;chemical formula\u0026quot;\u0026gt;）等模块。每个模块均通过 data-bbox 属性标注其原始坐标位置，保留空间布局信息; 同时所有文档元素的布局信息（如位置、尺寸）通过原生分辨率下的绝对坐标直接编码到HTML标签中，使模型能同时学习内容语义和空间关系\n针对OCR 数据， 利用高质量的合成图像和现实世界的自然场景图像, 整合了一个大规模的多语言OCR数据集,支持多种语言; 针对图表类型数据，使用python可视化库合成了100万个样本； 对于表格数据，利用表格识别模型处理了600万个真实样本用于训练\n在post-training，设计了一个两阶段的数据过滤pipeline，用于数据清洗和低质量数据过滤，针对的对于不同领域提高数据质量；\n在第三阶段，长上下文预训练： 序列长度扩展至 32768，专注于长视频、长代理任务和长文档，训练长上下文能力\n可见， 该模型已针对Document Parsing 做了针对化的训练；至少单纯从视觉问答和 OCR benchmark的跑分结果看，72B 模型与 GPT-4o 和 Claude 3.5 Sonnet 相当\n【但仅仅把这个模型用于document parsing有点浪费了】\n同时Qwen官方也提供了详细的cookbook，包括了具体实现，这里就不展开了，不过记得将base-url改成\n\u0026#34;https://dashscope-intl.aliyuncs.com/compatible-mode/v1\u0026#34; -\u0026gt; \u0026#34;https://dashscope.aliyuncs.com/compatible-mode/v1\u0026#34; 试了下效果：\n结果：\n```html \u0026lt;html\u0026gt;\u0026lt;body\u0026gt; \u0026lt;p\u0026gt;During planning, the Q-planning algorithm randomly samples only from state-action pairs that have previously been experienced (in Step 1), so the model is never queried with a pair about which it has no information.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;The overall architecture of Dyna agents, of which the Dyna-Q algorithm is one example, is shown in Figure 8.1. The central column represents the basic interaction between agent and environment, giving rise to a trajectory of real experience. The arrow on the left of the figure represents direct reinforcement learning operating on real experience to improve the value function and the policy. On the right are model-based processes. The model is learned from real experience and gives rise to simulated experience. We use the term search control to refer to the process that selects the starting states and actions for the simulated experiences generated by the model. Finally, planning is achieved by applying reinforcement learning methods to the simulated experiences just as if they had really happened. Typically, as in Dyna-Q, the same reinforcement learning method is used both for learning from real experience and for planning from simulated experience. The reinforcement learning method is thus the “final common path” for both learning and planning. Learning and planning are deeply integrated in the sense that they share almost all the same machinery, differing only in the source of their experience.\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;image\u0026#34;\u0026gt;\u0026lt;img/\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;p\u0026gt;Figure 8.1: The general Dyna Architecture. Real experience, passing back and forth between the environment and the policy, affects policy and value functions in much the same way as does simulated experience generated by the model of the environment.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Conceptually, planning, acting, model-learning, and direct RL occur simultaneously and in parallel in Dyna agents. For concreteness and implementation on a serial computer, however, we fully specify the order in which they occur within a time step. In Dyna-Q, the acting, model-learning, and direct RL processes require little computation, and we assume they consume just a fraction of the time. The remaining time in each step can be devoted to the planning process, which is inherently computation-intensive. Let us assume that there is time in each step, after acting, model-learning, and direct RL, to complete\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt; ``` 【实测遇到的问题】：\n图表类image的bbox经常不包含图表label\n瑕不掩瑜，可以说效果是非常惊艳了。\nMistral OCR https://mistral.ai/en/news/mistral-ocr\nhttps://docs.mistral.ai/capabilities/document/\nMistral AI 推出的OCR API，专注于复杂文档的多模态理解,擅长处理科学论文等含图表混合内容的文档\n输入格式：支持 PNG、JPEG 图像及 PDF\n输出格式：生成有序的 Markdown 或 JSON 结构化数据\n基础版价格为 1000 页/美元\n体验感受\n快速解析完一篇论文的pdf（5～10 sec）\n结构化json输出\n能够截取pdf中的图像，并提供对应的位置信息和Base64编码\n基本上是目前首选了\n猜测，大概率是使用的是mistral自家的mistralai/Pixtral-12B-2409 模型\nhow to use\npip install mistralai from mistralai import Mistral api_key = \u0026#34;API_KEY\u0026#34; client = Mistral(api_key=api_key) ocr_model = \u0026#34;mistral-ocr-latest\u0026#34; system = \u0026#34;\u0026#34;\u0026#34;You are an AI Assistant with document understanding via URLs. You will be provided with URLs, and you must answer any questions related to those documents. # OPEN URLS INSTRUCTIONS You can open URLs by using the `open_urls` tool. It will open webpages and apply OCR to them, retrieving the contents. Use those contents to answer the user. Only URLs pointing to PDFs and images are supported; you may encounter an error if they are not; provide that information to the user if required.\u0026#34;\u0026#34;\u0026#34; def _perform_ocr(url: str) -\u0026gt; str: try: # Apply OCR to the PDF URL response = client.ocr.process( model=ocr_model, document={ \u0026#34;type\u0026#34;: \u0026#34;document_url\u0026#34;, \u0026#34;document_url\u0026#34;: url } ) except Exception: try: # IF PDF OCR fails, try Image OCR response = client.ocr.process( model=ocr_model, document={ \u0026#34;type\u0026#34;: \u0026#34;image_url\u0026#34;, \u0026#34;image_url\u0026#34;: url } ) except Exception as e: return e # Return the error to the model if it fails, otherwise return the contents return \u0026#34;\\n\\n\u0026#34;.join([f\u0026#34;### Page {i+1}\\n{response.pages[i].markdown}\u0026#34; for i in range(len(response.pages))]) pdf_response = _perform_ocr(\u0026#34;https://arxiv.org/pdf/2201.04234\u0026#34;) 输出格式：\n{ \u0026#34;pages\u0026#34;: [ { \u0026#34;index\u0026#34;: 1, \u0026#34;markdown\u0026#34;: \u0026#34;markdown-content\u0026#34;, \u0026#34;images\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;img-0.jpeg\u0026#34;, \u0026#34;top_left_x\u0026#34;: 292, \u0026#34;top_left_y\u0026#34;: 217, \u0026#34;bottom_right_x\u0026#34;: 1405, \u0026#34;bottom_right_y\u0026#34;: 649, \u0026#34;image_base64\u0026#34;: \u0026#34;...\u0026#34; } ], \u0026#34;dimensions\u0026#34;: { \u0026#34;dpi\u0026#34;: 200, \u0026#34;height\u0026#34;: 2200, \u0026#34;width\u0026#34;: 1700 } }, ... } 甚至包括了图像的坐标信息\n通过以下代码，能够或者最终完整的markdown\nfrom mistralai.models import OCRResponse from IPython.display import Markdown, display def replace_images_in_markdown(markdown_str: str, images_dict: dict) -\u0026gt; str: for img_name, base64_str in images_dict.items(): markdown_str = markdown_str.replace(f\u0026#34;![{img_name}]({img_name})\u0026#34;, f\u0026#34;![{img_name}]({base64_str})\u0026#34;) return markdown_str def get_combined_markdown(ocr_response: OCRResponse) -\u0026gt; str: markdowns: list[str] = [] for page in pdf_response.pages: image_data = {} for img in page.images: image_data[img.id] = img.image_base64 markdowns.append(replace_images_in_markdown(page.markdown, image_data)) return \u0026#34;\\n\\n\u0026#34;.join(markdowns) display(Markdown(get_combined_markdown(pdf_response))) OlmOCR github：https://github.com/allenai/olmocr\ndemo：https://olmocr.allenai.org/\n其核心VLM—allenai/olmOCR-7B-0225-preview， 是采用Qwen2-VL-7B 在250,000 页的多样化 PDF 数据集上进行微调而得的\n不仅是开源了模型， 同时还开源了一整套的解析工作管道，及其微调数据集、训练和推理代码。\n环境：\napt-get install poppler-utils ttf-mscorefonts-installer msttcorefonts fonts-crosextra-caladea fonts-crosextra-carlito gsfonts lcdf-typetools git clone https://github.com/allenai/olmocr.git cd olmocr pip install -e . pip install sgl-kernel==0.0.3.post1 --force-reinstall --no-deps pip install \u0026#34;sglang[all]\u0026gt;=0.4.3.post2\u0026#34; --find-links https://flashinfer.ai/whl/cu124/torch2.4/flashinfer/ local usage\npython -m olmocr.pipeline /content/localworkspace --pdfs /content/pdf/*.pdf 解析成功后，会在本地生成一个jsonl文件，包括每一页的解析结果\n(样例)\n{ \u0026#34;id\u0026#34;:\u0026#34;id\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;markdown-content\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;olmocr\u0026#34;, \u0026#34;added\u0026#34;: \u0026#34;time\u0026#34;, \u0026#34;created\u0026#34;: \u0026#34;time\u0026#34;, \u0026#34;metadata\u0026#34;: {\u0026#34;Source-File\u0026#34;: \u0026#34;file-path\u0026#34;, \u0026#34;olmocr-version\u0026#34;: \u0026#34;0.1.58\u0026#34;, \u0026#34;pdf-total-pages\u0026#34;: 17, \u0026#34;total-input-tokens\u0026#34;: 67608, \u0026#34;total-output-tokens\u0026#34;: 14821, \u0026#34;total-fallback-pages\u0026#34;: 0}, \u0026#34;attributes\u0026#34;: {\u0026#34;pdf_page_numbers\u0026#34;: [[0, 3519, 1], [3519, 8803, 2], [8803, 12566, 3], [12566, 15747, 4], [15747, 19147, 5], [19147, 22975, 6], [22975, 25485, 7], [25485, 31108, 8], [31108, 35902, 9], [35902, 38215, 10], [38215, 39584, 11], [39584, 42844, 12], [42844, 45389, 13], [45389, 48985, 14], [48985, 49297, 15], [49297, 49579, 16], [49579, 51463, 17]] } 实际测试共72页pdf（arxiv论文），使用Nvidia-L4 GPU\ninput_tokens 151.32 tokens/sec\noutput_tokens 47.16 tokens/sec\n总耗时40min。\nSmolDocling Huggingface\npaper\n由 IBM Research 和 Hugging Face 开发的VLM，专为文档转换设计，可以处理整个页面，生成一种称为 DocTags 的自定义标记格式，这种格式能详细记录文档元素的文本内容、布局结构和位置信息。模型参数仅为 256 M。\n模型通过端到端方式处理整个文档页面，生成 DocTags 序列。DocTags 是一种受 OTSL 启发的标记格式，采用 XML 风格标签（如 \u0026lt;text\u0026gt;、\u0026lt;table\u0026gt;、\u0026lt;code\u0026gt;、\u0026lt;formula\u0026gt;）与位置标签（如 \u0026lt;loc_x1\u0026gt;\u0026lt;loc_y1\u0026gt;\u0026lt;loc_x2\u0026gt;\u0026lt;loc_y2\u0026gt;）结合，基于 0-500 网格映射页面尺寸，确保捕获元素的空间位置和上下文关联。支持多种文档元素的重现，包括标题、图表、表单、代码、公式、表格、脚注、列表、页眉/页脚和章节标题，并提供 OCR（光学字符识别）、阅读顺序和层次链接（如标题与图表/表格的对应）。\nTo the Future from Document Parsing to Document Intelligence 当前基于VLM的方案依旧存在一些问题\n在不同领域和场景下的文档处理中，需要调整解析的prompt或增加相应的LLM优化内容。这些prompt或工作流通常是定制化的，缺乏良好的泛化能力。如果能够开发出一个智能代理应用，针对不同场景的文档进行解析和优化调整，那将是非常理想的。然而，目前市场上尚未出现这样的解决方案。\n文档解析是RAG任务的第一步，与之密切相关的下一步是文本分块（chunking），这与解析过程息息相关，甚至可以结合在一起或者合并在一起。在VLM解析中，我们已经能够获得文档的某种结构化信息（或语义层级关系）。这种信息对于智能代理进行文本分块具有参考价值，而不仅仅是基于长度的简单分割。\n解析成markdown/json的执念或许是过时的想法了 为何不直接做多模态的RAG呢？\n与其设计复杂的系统：从文档解析成markdown/json-分块-建立索引-检索，不如直接将vision-encoder 隐藏层输出用于索引的构建，这也是ColPali这篇工作的想法。\n甚至是类似CAG（Cache-Augmented Generation）中的想法， 直接利用VLM的KV-Cache 也是完全有可能的。\n附录1: VLM Benchmark OCRBench 和 OCRBench v2 OCRBench 和其升级版 OCRBench v2 是用于评估大型多模态模型（LMMs）在光学字符识别（OCR）任务中的性能的基准。OCRBench 包括文本识别、场景文本相关的视觉问答（VQA）、文档导向的VQA、关键信息提取和手写数学表达式识别等任务。OCRBench v2 扩展了任务范围，覆盖更多场景（如街道场景、收据、公式、图表等），包含10,000个经过人工验证的问题-答案对。\nOCRBench v2 paper\nOCRBench paper\nOmniDocBench v2 OmniDocBench v2 是一个专门为PDF文档解析设计的基准\n它包括981页PDF，涵盖9种文档类型（如学术论文、教科书、幻灯片等）、4种布局类型和3种语言类型\n丰富的注释信息，包括块级（如文本段落、标题、表格）和跨度级（如文本行、公式）元素\nGitHub 仓库\npaper\nCC-OCR 包括四个轨道：多场景文本阅读、多语言文本阅读、文档解析和关键信息提取\n覆盖10种语言（如英语50.3%、中文28.2%）\npaper\n附录2: 比较热门的几个开源文档解析项目 marker https://github.com/vikparuchuri/marker\n使用 Surya 模型检测文本块的布局和阅读顺序，从 PDF 中提取文本，尤其是图像或非文本元素\n可选 LLM 处理，（支持 Gemini ，Claude，ollama）来优化输出，处理复杂元素\n如何使用：\npip install marker-pdf[full] # 命令行 marker_single /path/to/file.pdf from marker.converters.pdf import PdfConverter from marker.models import create_model_dict from marker.output import text_from_rendered converter = PdfConverter( artifact_dict=create_model_dict(), ) rendered = converter(\u0026#34;FILEPATH\u0026#34;) text, _, images = text_from_rendered(rendered) 核心部分PdfConverter\nMarker 和 Surya OCR 模型的权重受 cc-by-nc-sa-4.0 许可限制，但对于年收入低于 500 万美元且终身 VC/天使融资低于 500 万美元的组织，该限制可豁免\nMinerU https://github.com/opendatalab/MinerU/tree/master\n文档：https://mineru.readthedocs.io/zh-cn/latest/\nMinerU 主要通过 PDF-Extract-Kit 使用以下模型：\n布局检测：DocLayout-YOLO_ft, YOLO-v10_ft, LayoutLMv3_ft\n公式检测：YOLOv8_ft\n公式识别：UniMERNet\nOCR：PaddleOCR\n表格识别：PaddleOCR+TableMaster, StructEqTable, StructTable-InternVL2-1B\nmarkitdown https://github.com/microsoft/markitdown\n如何使用：\npip install markitdown openai 普通的pdf解析\nfrom markitdown import MarkItDown md = MarkItDown() result = md.convert(\u0026#34;you-pdf-file.pdf\u0026#34;) print(result.text_content) 其本质是采用pdfminer，做PDF 文本提取\n支持llm做image caption：\nfrom markitdown import MarkItDown from openai import OpenAI client = OpenAI() md = MarkItDown(llm_client=client, llm_model=\u0026#34;gpt-4o\u0026#34;) result = md.convert(\u0026#34;example.jpg\u0026#34;) print(result.text_content) (RAGFlow)DeepDoc github\n支持多种文档格式如PDF、DOCX、EXCEL、PPT\n两个组成部分：视觉处理和解析器\n通过OCR技术识别文本，并进行版面分析以识别不同类型的区域，如表格、标题、段落\n附录3: VLM 汇总表格 模型名称 参数量 OCRBench OCRBenchV2 ChartQA Phi-4-Multimodal 5.6B 84.4 - 81.4 Qwen2.5-VL-3B 3B 82.2 54.3 80.0 Qwen2.5-VL-7B 7B 87.7 56.3 85.0 Qwen2.5-VL-72B 72B - 61.5 - Gemma3-4B 4B - - 79.8 Gemma3-12B 12B - - 83.5 Gemma3-27B 27B - - 83.4 SmolDocling 256M - - - GPT-4o-mini - 77.1 - 54.5 参考和数据来源：\nPhi-4-Mini Technical Report\nGemma3Report\nQwen2.5-VL Technical Report\nSmolDocling\n","permalink":"https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E6%96%B9%E6%A1%882025%E7%89%88/","summary":"\u003cp\u003e\u003ca href=\"https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E6%96%B9%E6%A1%882025%E7%89%88/#smoldocling\"\u003eUpdated on 2025-03-29: Add SmolDocling \u0026amp; VLM Summary\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e技术迭代速度之快令人惊叹，前作 \u003ca href=\"https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E4%B8%8E%E8%A1%A8%E6%A0%BC%E5%A4%84%E7%90%86/\"\u003eRAG工具箱：文档解析与表格处理\u003c/a\u003e 在短短数月内已显现出代际差距，尽管前作也仅仅只是抛砖引玉式地讨论了pdf的解析方案，不过在新技术的面前，既有的复杂解析架构逐渐失去存在价值，也被端到端范式所取代。在笔者看来，基于多模态大模型的端到端文档解析方案，将成为最优解。\u003c/p\u003e\n\u003cp\u003e本文将探讨文档解析的终极形态——基于多模态大模型（VLM）的解析技术，包括Mistral-OCR、OlmOCR等前沿工具的实现与实践，并展望该领域的技术发展趋势，和对于RAG的影响。\u003c/p\u003e\n\u003ch2 id=\"过去的技术栈总结\"\u003e过去的技术栈总结\u003c/h2\u003e\n\u003cp\u003e在RAG系统中，文档解析质量直接决定系统上限。不同场景下的文档形态差异显著，若不能有效解决\u0026quot;garbage in, garbage out\u0026quot;的输入质量问题，后续处理环节将难以发挥应有价值。\u003c/p\u003e\n\u003cp\u003e传统文档解析技术长期受限于以下核心痛点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e结构化信息缺失：无法准确识别文档标题、副标题等层级结构\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e特殊内容处理薄弱：数学公式、专业符号解析准确率低下\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e复杂表格解析困境：跨页表格、合并单元格等场景支持不足\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e图像信息提取瓶颈：扫描文档、手写体识别效果欠佳\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e版式适应性问题：多栏布局、影印版本等文档格式兼容性差\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e从技术角度，过去文档解析的底层逻辑和框架：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e纯文本解析: \u003ccode\u003ePyPDF\u003c/code\u003e, \u003ccode\u003ePyMuPDF\u003c/code\u003e只能解析pdf中的文字,对于公式表格和复杂排版解析无能,对于扫描版低质量的pdf无能为力\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOCR方案（PaddleOCR等）: 首先使用目标检测模型对文档布局进行分析，识别出标题、表格等关键元素的位置，然后在这些位置上使用OCR技术提取文字；由于需要调用多个模型，整套系统非常复杂；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e基于transformer 的解析方案（代表: Dount, Nougat）：专门针对英文的学术文章做的训练, 能够将pdf文章整理成Markdown或Latex格式；但对于其他语言和其他类型的文档泛化效果很差；\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e随着模型能力提升，采用VLM做解析是非常自然的想法，尽管GPT-4o的发布使该技术获得广泛关注，但其高昂的API成本制约了实际应用。值得庆幸的是，开源社区的技术突破正在改变这一局面：不论是LLM基座模型多模态理解能力的增强，还是视觉编码器的提升，至少在当下，开源VLM已具备实用级文档解析能力，而无需针对下游任务的微调，同时成本上已经在可接受范围了。\u003c/p\u003e\n\u003ch2 id=\"benchmark\"\u003eBenchmark\u003c/h2\u003e\n\u003cp\u003e为了判断一个模型是否适合Document Parsing，需要benchmark测试分数，作为模型挑选的标准。\u003c/p\u003e\n\u003cp\u003e现阶段，针对LLMs在OCR、文档信息提取场景下主要采用以下几个常见的bench\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/spaces/echo840/ocrbench-leaderboard\"\u003eOCRBench\u003c/a\u003e、\u003ca href=\"https://huggingface.co/spaces/ling99/OCRBench-v2-leaderboard\"\u003eOCRBench-V2\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/opendatalab/OmniDocBench\"\u003eOmniDocBench\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2412.02210\"\u003eCC-OCR\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e…and more\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e（关于benchmark的具体内容见附录）\u003c/p\u003e\n\u003cp\u003e这些bench都基本上包含了通用场景下的OCR能力， 多语言的文档解析能力的测试，能够一定程度上作为模型筛选的关注首选\u003c/p\u003e\n\u003cp\u003e当然，除了模型能力以外，还需要关注模型的参数量，因为与其成本和latency息息相关。\u003c/p\u003e\n\u003cp\u003e不过，对于每一个具体场景，还是需要构建自己的测试集用于判断模型是否能够胜任任务， 因为benchmark所包含的测试场景数据，分布语言等等和具体的场景不见得完全一样。\u003c/p\u003e\n\u003cp\u003e根据benchmark和实际测试结果，目前几个值得关注的开源VLM：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://huggingface.co/collections/Qwen/qwen25-vl-6795ffac22b334a837c0f9a5\"\u003eQwen2.5-VL\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/microsoft/Phi-4-multimodal-instruct\"\u003ePhi-4-multimodal\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct\"\u003eLlama 3.2 Vision\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/allenai/olmOCR-7B-0225-preview\"\u003eolmocr\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eand more …\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"qwen25-vl系列模型\"\u003eQwen2.5-VL系列模型\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/QwenLM/Qwen2.5-VL/tree/main/cookbooks\"\u003ecookbook\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://qwenlm.github.io/zh/blog/qwen2.5-vl/\"\u003eBlog\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2502.13923\"\u003eTechnical Report\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e这应该是开源的模型中，效果排前列的多模态模型（截止至今），同时还具备了多种参数量（3B，7B，72B）可选择。\u003c/p\u003e\n\u003cp\u003e在Technical Report 中一些和document-parse有关的内容：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在第一阶段视觉预训练中（仅训练ViT），针对\u003cstrong\u003eDocument Parsing\u003c/strong\u003e，设计了\u003cstrong\u003e一套标准化的HTML标签体系\u003c/strong\u003e，包含：段落（\u003ccode\u003ep\u0026gt;\u003c/code\u003e）、表格（\u003ccode\u003e\u0026lt;table\u0026gt;\u003c/code\u003e）、图表（\u003ccode\u003e\u0026lt;div class=\u0026quot;chart\u0026quot;\u0026gt;\u003c/code\u003e）、公式（\u003ccode\u003e\u0026lt;div class=\u0026quot;formula\u0026quot;\u0026gt;\u003c/code\u003e）、图像标注（\u003ccode\u003e\u0026lt;div class=\u0026quot;image caption\u0026quot;\u0026gt;\u003c/code\u003e）、OCR文本（\u003ccode\u003e\u0026lt;div class=\u0026quot;image ocr\u0026quot;\u0026gt;\u003c/code\u003e）、乐谱（\u003ccode\u003e\u0026lt;div class=\u0026quot;music sheet\u0026quot;\u0026gt;\u003c/code\u003e）、化学式（\u003ccode\u003e\u0026lt;div class=\u0026quot;chemical formula\u0026quot;\u0026gt;\u003c/code\u003e）等模块。每个模块均通过 \u003ccode\u003edata-bbox\u003c/code\u003e 属性标注其原始坐标位置，保留空间布局信息; 同时所有文档元素的布局信息（如位置、尺寸）通过原生分辨率下的绝对坐标直接编码到HTML标签中，使模型能同时学习内容语义和空间关系\u003c/p\u003e","title":"RAG工具箱：基于多模态大模型的文档解析方案（2025版）"},{"content":"一些适合入门的RAG材料\n原理、科普 Retrieval Augmented Generation (RAG) for LLMs\nLangchain|Retrieval augmented generation (RAG)\nA Practitioners Guide to Retrieval Augmented Generation (RAG)\nRAG for Beginners: The Complete Guide to Retrieval Augmented Generation\nWhat is Retrieval Augmented Generation (RAG)?\nRetrieval augmented generation (RAG)\n思考题：\nWhy RAG？ RAG解决了什么问题？RAG和SFT如何选择？RAG的优势？\n什么样的问题是RAG无法解决的？什么样的数据适合使用RAG\n为什么要做chunking？chunk-size受那些因素制约？\n什么是embedding？向量库在做什么？一定要做语义匹配吗？什么是reranking？\n如何evaluate 检索效果的好坏 ？\nRAG中，LLMs起到的作用？\nHands-On 前置任务 获取模型服务：\n获得LLMs供应商API： 推荐 OpenRouter（仅LLMs，需要梯子，境外信用卡或Crypto），SilconFlow（LLMs+embedding,无需梯子,有送token），Groq（仅LLMs, 需梯子，速度快，免费）\n或采用本地部署： 推荐Ollama\n例子,采用openRouter API实现LLM对话：\nfrom openai import OpenAI client = OpenAI( base_url=\u0026#34;https://openrouter.ai/api/v1\u0026#34;, api_key=\u0026#34;\u0026lt;OPENROUTER_API_KEY\u0026gt;\u0026#34;, ) completion = client.chat.completions.create( model=\u0026#34;openai/gpt-4o\u0026#34;, messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What is the meaning of life?\u0026#34; } ] ) print(completion.choices[0].message.content) 例子：基于本地ollama启动的deepseek R1（蒸馏版本）对话\nfrom openai import OpenAI client = OpenAI( base_url = \u0026#39;http://localhost:11434/v1\u0026#39;, api_key=\u0026#39;ollama\u0026#39;, # required, but unused ) response = client.chat.completions.create( model=\u0026#34;deepseek-r1:7b\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Who won the world series in 2020?\u0026#34;} ] ) print(response.choices[0].message.content) 使用ollama 的embdding model Embedding models\n低代码方案 不愿意写代码，可以使用一些低代码Agent平台 好处：可以快速体验，上手，低代码 坏处：不支持自定义修改，很难理解这一系统原理\nDify官方教程：使用知识库搭建智能客服机器人\n代码教程 A beginner\u0026rsquo;s guide to building a Retrieval Augmented Generation (RAG) application from scratch 不依赖框架，无需向量库和embedding模型， 采用本地部署的ollama，便于从第一性原理理解这一系统\nBuilding RAG Applications Without LangChain or LlamaIndex 不依赖框架，从底层开发RAG应用，使用openAI调用LLMs，sentence-transformers 做embedding， chromadb作为向量库\nLangchain 官方文档中关于RAG的教程:\nBuild a Retrieval Augmented Generation (RAG) App: Part 1\nRAG From Scratch\nLangChain: Chat with Your Data\ndatawhale中文翻译\n【关于为什么不推荐langchain之类的框架】：虽然能够快速上手跑通一个项目；langchain因其高度抽象化高度集成，很难进行进一步开发；langchain只适合快速做demo的场景使用；\nmistral 官方的RAG教学\nmilvus向量库官方的RAG quick-start ","permalink":"https://niraya666.github.io/posts/rag-tutorial-for-beginner/","summary":"\u003cp\u003e一些适合入门的RAG材料\u003c/p\u003e\n\u003ch2 id=\"原理科普\"\u003e原理、科普\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://www.promptingguide.ai/research/rag\"\u003eRetrieval Augmented Generation (RAG) for LLMs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://python.langchain.com/docs/concepts/rag/\"\u003eLangchain|Retrieval augmented generation (RAG)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://cameronrwolfe.substack.com/p/a-practitioners-guide-to-retrieval\"\u003eA Practitioners Guide to Retrieval Augmented Generation (RAG)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://blog.typingmind.com/rag-for-beginners/\"\u003eRAG for Beginners: The Complete Guide to Retrieval Augmented Generation\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.datacamp.com/blog/what-is-retrieval-augmented-generation-rag\"\u003eWhat is Retrieval Augmented Generation (RAG)?\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://python.langchain.com/docs/concepts/rag/\"\u003eRetrieval augmented generation (RAG)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e思考题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eWhy RAG？ RAG解决了什么问题？RAG和SFT如何选择？RAG的优势？\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e什么样的问题是RAG无法解决的？什么样的数据适合使用RAG\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e为什么要做chunking？chunk-size受那些因素制约？\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e什么是embedding？向量库在做什么？一定要做语义匹配吗？什么是reranking？\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e如何evaluate 检索效果的好坏 ？\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRAG中，LLMs起到的作用？\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"hands-on\"\u003eHands-On\u003c/h2\u003e\n\u003ch3 id=\"前置任务\"\u003e前置任务\u003c/h3\u003e\n\u003cp\u003e获取模型服务：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e获得LLMs供应商API： 推荐 OpenRouter（仅LLMs，需要梯子，境外信用卡或Crypto），SilconFlow（LLMs+embedding,无需梯子,有送token），Groq（仅LLMs, 需梯子，速度快，免费）\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e或采用本地部署： 推荐\u003ca href=\"https://ollama.com/\"\u003eOllama\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e例子,采用openRouter API实现LLM对话：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003eopenai\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eOpenAI\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eclient\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eOpenAI\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003ebase_url\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;https://openrouter.ai/api/v1\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003eapi_key\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u0026lt;OPENROUTER_API_KEY\u0026gt;\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ecompletion\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eclient\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echat\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecompletions\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;openai/gpt-4o\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003emessages\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"s2\"\u003e\u0026#34;role\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;user\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"s2\"\u003e\u0026#34;content\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;What is the meaning of life?\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecompletion\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econtent\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e例子：基于本地ollama启动的deepseek R1（蒸馏版本）对话\u003c/p\u003e","title":"RAG工具箱：RAG Tutorial for Beginner"},{"content":"值得关注的模型和新技术 o3-mini OpenAI o3-mini 是一款高效且成本优化的推理模型，专为科学（Science）、技术（Technology）、工程（Engineering）和数学（Mathematics）（STEM）领域优化。它在数学、编程和科学推理方面表现出色，能够在 AIME 2024 和 GPQA 等基准测试中达到或超过 OpenAI o1 的水平。o3-mini 具备三种推理模式（低、中、高），可根据需求在速度和准确性之间进行权衡。此外，它支持函数调用、结构化输出和视觉任务。相比 o1-mini，o3-mini 的响应速度提高了 24%，平均响应时间为 7.7 秒。它的上下文窗口为 200k tokens，输入成本为每百万 tokens 1.10 美元，输出成本为 4.40 美元。\nOpenAI o3-mini\nQwQ-Max-Preview QwQ-Max-Preview是阿里巴巴Qwen系列的最新推理模型，基于Qwen2.5-Max架构开发，专注于提升数学、编码及多领域复杂问题的解决能力。该模型在LiveCodeBench代码评估中取得65.6分，超过OpenAI的o1中型模型（63.4分）和o3迷你低配版（60.9分），展现了卓越的代码生成与逻辑推理性能。其核心优势包括深度推理、Agent任务处理及通用领域适应性，特别适合需要实时响应的隐私敏感场景。作为预览版，QwQ-Max-Preview为后续开源版本铺路，未来将发布Apache 2.0许可证下的完整模型QwQ-Max及轻量级版本（如QwQ-32B），并计划推出iOS/Android端Qwen Chat应用以增强用户体验。阿里巴巴同时宣布未来三年投入530亿美元加强AI基础设施，进一步推动该模型在行业中的竞争力。\n我们计划在不久的将来以 Apache 2.0 许可协议开源发布 QwQ-Max 以及 Qwen2.5-Max\n官方blog：\u0026hellip; QwQ-Max-Preview\nClaude 3.7 Sonnet Claude 3.7 Sonnet 是 Anthropic 推出的首个“混合推理模型”，兼具快速响应和深入思考能力，能够根据任务需求在标准模式和扩展思考模式之间切换。其核心能力包括：在复杂任务中通过扩展思考模式进行详细分析和多角度考虑；在编码任务中表现出色，特别是在 SWE-bench Verified 测试中达到行业领先的 70.3%；支持多模态数据处理，展现强大的适应性；以及在 Amazon Bedrock 中提供可调整的推理预算，供开发者根据需求权衡速度、成本和性能。\nClaude 3.7 Sonnet and Claude Code\nGrok-3 Grok-3是由Elon Musk的xAI公司开发的第三代AI模型，具备2.7万亿参数和12.8万亿token的训练数据集，采用基于NVIDIA GPU的Colossus超级计算集群（20万张GPU）训练，计算能力比前代提升10倍。其性能表现优异，在MMLU（多任务语言理解）基准测试中达到92.7%，GSM8K（数学推理）89.3%，AIME 2025数学竞赛93.3%，GPQA科学推理84.6%。该模型支持128,000 token的上下文窗口（扩展版达100万token），响应延迟仅67毫秒，并具备多模态处理能力（文本、代码、图像）。独特功能包括DeepSearch实时网络研究代理、\u0026ldquo;Think\u0026quot;模式分步推理，以及\u0026quot;Big Brain\u0026quot;模式强化复杂问题解决，主要应用于STEM领域、代码生成和商业分析。目前通过X平台Premium+订阅（$40/月）和专属网站Grok.com提供访问，API接口即将开放。\nGrok-3: The Next Evolution in AI by xAI\nDeepseek OpenSourceWeek FlashMLA FlashMLA\n功能描述：FlashMLA是一个高效的解码内核，专为多头潜在注意力（MLA）设计，优化Hopper GPU上的变长序列处理。它支持BF16和分页KV缓存（块大小64），已在生产环境中使用。性能指标：在H800 SXM5 GPU上（使用CUDA 12.6），FlashMLA实现3000 GB/s内存带宽和580 TFLOPS计算吞吐量，分别在内存绑定和计算绑定场景下表现出色。性能提升与资源优化：这些指标表明FlashMLA显著提升了解码任务的GPU性能，特别是在处理长序列时减少了内存和计算开销。相比传统内核，其高吞吐量显示出对GPU资源的充分利用。 功能描述：FlashMLA是一个高效的解码内核，专为多头潜在注意力（MLA）设计，优化Hopper GPU上的变长序列处理。它支持BF16和分页KV缓存（块大小64），已在生产环境中使用。 性能指标：在H800 SXM5 GPU上（使用CUDA 12.6），FlashMLA实现3000 GB/s内存带宽和580 TFLOPS计算吞吐量，分别在内存绑定和计算绑定场景下表现出色。 性能提升与资源优化：这些指标表明FlashMLA显著提升了解码任务的GPU性能，特别是在处理长序列时减少了内存和计算开销。相比传统内核，其高吞吐量显示出对GPU资源的充分利用。 DeepEP DeepEP\n功能描述：DeepEP是一个为混合专家（MoE）和专家并行（EP）设计的通信库，提供高吞吐量和低延迟的all-to-all GPU内核。它支持FP8运算，并包括不对称域带宽转发的优化内核，适用于训练和推理预填充任务。对于延迟敏感的推理解码，提供纯RDMA的低延迟内核。此外，它引入了基于钩子的通信-计算重叠方法，不占用流式多处理器（SM）资源。 性能指标：虽然具体量化数据有限，但其设计目标是最大化InfiniBand和NVLink带宽利用，减少通信延迟，尤其在分布式训练中。 性能提升与资源优化：DeepEP通过高效的通信管理减少了数据传输时间，提升了分布式系统的整体性能，特别是在大规模GPU集群中，优化了资源利用率。 DeepGEMM DeepGEMM\n功能描述：DeepGEMM是一个FP8通用矩阵乘法（GEMM）库，支持密集和MoE分组GEMM，专为Hopper张量核心设计。它使用CUDA编写，通过轻量级即时编译（JIT）模块在运行时编译内核，无需安装时的复杂编译。核心逻辑仅约300行代码，采用CUDA核心两级累积解决FP8精度问题，借鉴CUTLASS和CuTe的概念但避免依赖其复杂模板。 性能指标：在Hopper GPU上，DeepGEMM实现1350+ TFLOPS的FP8计算性能，超越大多数专家调优内核，尤其在各种矩阵尺寸上表现优异。 性能提升与资源优化：FP8的低精度计算减少了内存使用和计算时间，DeepGEMM的高性能显示出对GPU计算资源的有效利用，特别适合训练和推理中的矩阵运算。 DualPipe DualPipe\n功能描述：DualPipe是一个双向管道并行算法，旨在在DeepSeek-V3和R1的训练中实现计算-通信重叠。它通过创新的调度减少管道气泡，将前向和后向计算与通信阶段完全重叠，特别是在跨节点专家并行中隐藏通信开销。它充分利用InfiniBand和NVLink带宽，优化内存占用，无需昂贵的张量并行（TP）。 性能指标：DeepSeek-V3的训练仅需278.8万H800 GPU小时，相比其他模型（如OpenAI的GPT-4，训练成本约1亿美元），显示出显著的效率提升。论文提到，通过DualPipe，计算-通信比保持恒定时，可实现近零的all-to-all通信开销。 性能提升与资源优化：DualPipe通过减少通信瓶颈和优化管道调度，显著降低了训练时间和计算资源需求，提升了大规模GPU集群的利用率。 EPLB EPLB\n功能描述：EPLB用于专家并行（EP）场景，通过复制负载重的专家并启发式地分配到不同GPU，确保负载均衡。由于DeepSeek-V3采用组限制专家路由，EPLB尝试将同一组的专家放置在同一节点，减少节点间数据流量。其算法已在eplb.py中开源，便于再现和部署。 性能指标：具体量化数据有限，但其设计目标是通过负载均衡优化GPU利用率，减少训练中的瓶颈。 性能提升与资源优化：EPLB通过防止GPU过载或未充分利用，确保资源的高效分配，特别是在专家负载不均时，提升训练效率和稳定性。 值得关注的研究和论文 Deliberative Alignment https://openai.com/index/deliberative-alignment/\nhttps://arxiv.org/abs/2412.16339\n针对o1-like reasoning 模型的安全对齐方法\n当前模型的安全性问题 即便经过safety training，仍可以被jailbreak 模型的响应时间过快，导致它们不能充分评估所有可能的风险和复杂情况 模型并没有直接学习如何确保安全，而是通过标注的数据来间接理解应如何回应 Deliberative alignment 解决了： 模型响应速度过快、缺乏对安全规范的深入理解 通过直接学习safety specifications，使模型不仅仅记住安全规范的内容，还能在实际应用时根据上下文仔细考虑这些规范 在推理阶段对安全规范进行复杂的推理 Methods 对齐训练使用过程性监督和结果性监督的结合\ntrain an o-style model for helpfulness, without any safety-relevant data then build a dataset of (prompt, completion) pairs where the CoTs in the completions reference the specifications. inserting the relevant safety specification text for each conversation in the system prompt, generating model completions, and then removing the system prompts from the data SFT on this dataset then use RL to train the model to use its CoT more effectively 模型自动从安全规范和已分类的安全提示中生成训练数据，而不需要人工标注的回答 Trading inference-time compute for adversarial robustness | OpenAI Trading inference-time compute for adversarial robustness\npaper\n研究推理模型在推理阶段增加计算资源，对于对抗性攻击（adversarial attacks）的影响\n实验发现：\n推理时间计算的增加提升了对抗性鲁棒性：在大多数情况下，随着推理时间计算的增加，攻击成功率趋近于零。这表明，允许模型在推理阶段花费更多计算资源进行推理，可以有效提高其对抗性鲁棒性；\n无需对抗性训练即可提升鲁棒性： 仅通过增加推理时间计算来提升模型的鲁棒性，而无需专门的微调训练；\n推理时间计算的局限性： 在某些特定攻击下，增加推理时间计算可能不会带来显著的安全性提升，甚至可能导致新的安全漏洞；\n此外，文中还介绍了两种针对推理计算扩展模型的新型攻击方式：\nThink Less 攻击：攻击者诱导模型减少推理时间，从而降低其对抗性鲁棒性 Nerd Sniping 攻击：攻击者诱导模型在推理过程中浪费计算资源，使其在无关紧要的推理任务上消耗过多计算能力，可能导致安全漏洞。 Constitutional Classifiers: Defending against universal jailbreaks ｜Anthropic 为提升LLMs对 universal jailbreaks（通用越狱攻击）的防御能力，Anthropic 研究团队提出了一种名为 Constitutional Classifiers 的方法。\nhttps://www.anthropic.com/research/constitutional-classifiers\n解决的问题 LLMs 易受越狱攻击影响： 现有的 LLMs 仍然容易受到 prompt engineering攻击，例如使用 超长输入 或 特殊格式（如大小写混合）来绕过安全限制； 现有防御机制的局限性：传统的安全机制往往难以检测 通用越狱攻击（universal jailbreaks），即能够绕过多个安全限制的攻击方式 安全性与可用性之间的权衡：许多安全机制会导致 过度拒绝（over-refusal），即模型拒绝回答大量无害的查询，从而影响用户体验 亮点 基于“宪法”规则的分类器：采用 Constitutional AI 的理念，使用一套预定义的“宪法”规则来指导模型的安全性，这些规则明确划分了允许和禁止的内容，并用于训练分类器。 输入与输出双重分类器：该系统包含 输入分类器（检测并拦截恶意输入）和 输出分类器（实时监测模型生成的内容，并在检测到有害信息时立即终止响应） 合成数据增强训练：利用 Claude 生成大量合成数据以提高分类器的泛化能力 实时流式预测：支持 流式预测，即在生成每个 token 时评估其潜在的有害性，从而在检测到风险时立即终止响应，而无需等待完整的输出生成 结论 显著降低越狱成功率（从 86% 降至 4.4%） 保持较低的误拒率（仅增加 0.38%） 计算成本适中（增加 23.7%） Qwen2.5-1M Tech report\nBlog\n开源的长上下文模型， 上下文扩展到1M；包含Qwen2.5-7B-Instruct-1M和Qwen2.5-14B-Instruct-1M两个版本；\n方法 预训练阶段： 从Qwen2.5 的checkpoint 开始 （上下文4K） 将RoPE基础频率 从10,000 提高到10,000,000 SFT阶段：分两个阶段 第一阶段：仅在短指令（32K）上微调 第二阶段：混合短指令（32K）和长指令（256K）进行训练 RL阶段：在短文本（8K）上训练，能够泛化；最终获得256K instruction-tuning 模型 长度外推： 引入 Dual Chunk Attention (DCA)， 以解决训练过程中未见过的，Query和Key间相对位置距离过大问题 稀疏注意力机制，以提升推理速度： 分块预填充（Chunked Prefill）， MLP层激活权重的显存使用量可减少96.7% 稀疏性优化 注意项 Qwen2.5-7B-Instruct-1M 至少需要120GB\nQwen2.5-14B-Instruct-1M 至少需要320GB\nLarge Language Diffusion Models (LLaDA) paper\n基于Diffusion Models的新型LLM；能够在多个基准测试中与 LLaMA3 8B 竞争；\n不同于传统的LLM，采用Autoregressive的方式，即从左到右预测下一个token，LLaDA采用掩码扩散（Masked Diffusion）方法: 训练时，LLaDA 通过前向过程（Forward Process）随机掩盖输入文本中的 token，并在反向过程（Reverse Process）中预测被掩盖的 token， 从而允许 LLaDA 在双向上下文中进行推理，而不像自回归模型那样受限于单向信息流；\nLLaDA 采用标准的预训练 + SFT范式，并在2.3 万亿个 token上进行训练，随后使用450 万对数据进行 SFT\nMercury, the first commercial-scale diffusion large language model 由 Inception Labs 开发的首个商业级扩散大语言模型\nMercury 在 NVIDIA H100 GPU 上的推理速度超过 1000 tokens/sec，相比于 GPT-4o Mini（59 tokens/sec）和 Claude 3.5 Haiku（61 tokens/sec），提升了 10-20 倍 这使得 Mercury 比传统 LLM 便宜 5-10 倍，适用于大规模商业应用 Mercury 适用于代码生成（Mercury Coder）、对话 AI、企业自动化等多个领域 免费试用：Mercury Coder 目前已上线，可在 Inception Labs Playground 试用 Trade-offs of Diffusion Language Models 但也存在一些显著的权衡，例如高推理成本、在链式推理（CoT）中仍需多次迭代以及延迟的流式输出\nThoughts Are All Over the Place: On the Underthinking of o1-Like LLMs paper\no1-like 模型通过扩展推理计算能力来提升推理深度，但存在着underthinking的问题，即它们在推理过程中频繁切换思路，而未能充分探索有前景的推理路径，导致推理深度不足，影响最终的准确性；\n对此研究者引入 Underthinking Score，用于衡量模型在错误答案中的 token 效率，以量化思维切换对推理质量的影响；\n为了缓解Underthinking问题，研究者提出了一种新的解码策略 TIP（Thought Switching Penalty），其核心思想是：\n在解码过程中对思维切换施加惩罚，鼓励模型在当前推理路径上进行更深入的探索，而非过早切换 TIP 通过调整 logits 进行惩罚，减少模型在短时间内频繁改变推理方向的可能性 Optimizing Large Language Model Training Using FP4 Quantization paper\n由于FP4格式的动态范围和表示能力有限，直接将LLMs量化到这种低比特格式通常会导致模型性能大幅下降\n通过以下两个关键创新点来应对挑战\n可微分量化估计器（Differentiable Quantization Estimator, DGE）：为了精确的权重更新，提出了一种可微分量化估计器，以减少FP4计算中的梯度更新误差。 异常值夹紧和补偿策略（Outlier Clamping and Compensation, OCC）：为了防止在LLMs训练过程中常见的激活值异常值导致的量化精度损失，提出了一种异常值夹紧和补偿策略。 FP4训练框架能够在保持与BF16和FP8相近的准确性的同时，有效地扩展到高达130亿参数的LLMs，并在最多1000亿个训练token上进行训练\n推荐内容 一些仓库 专注于强化学习（RL）提升大语言模型（LLM）推理能力的仓库： github.com/bruno686/Awesome-RL-based-LLM-Reasoning\n适合LLMs的抓取数据工具集合：\ngithub.com/patrickloeber/llm-data-scrapers\nMCP服务器列表： github.com/punkpeye/awesome-mcp-servers\n开源小红书图文采集工具： github.com/JoeanAmier/XHS-Downloader\n基于 LLM 的智能字幕助手： github.com/WEIFENG2333/VideoCaptioner\n阅读和学习 Reasoning best practices ｜ OpenAI： openAI 官方的reasoning模型使用指南\nalphaxiv：可在 arXiv 论文上进行评论讨论，选择文章内容同AI讨论\nAI Agents Course｜ huggingface：huggingface 官方的AI Agent课程\n影音记录 精选歌单 Live演出 02.16 Sigur Rós TOKYO GARDEN THEATER\n电影 哪吒之魔童闹海 ⭐️⭐️⭐️⭐️\n书\u0026amp;阅读摘录 《逃走的人》 李颖迪 谈论工作的意义似乎早就过时了，太热情了甚至显得傻。“工作就是工作。”这才是正确的态度。我们说起工作，说的是绩效和KPI，不是它的乐趣、意义和自我实现。当时仍在新冠流行期间，它更加剧了某种困顿感和停滞感。但我们其实也害怕真的停下—离开既定轨道，比如辞职了，之后还能找到下一份工作吗？就这样迟疑着，踌躇着，不满意想走，想走又不敢走。明明还“年轻”，按照教科书上的说法，这不应该正是踌躇满志的时候吗？\n2022年，中国城市的房子往往每平方米一万元上下——在北京，这个数字是四万（海淀、朝阳等地甚至每平方米九万），上海、深圳也差不多——在城市买房，往往意味着贷款，动辄几百万。年轻人买房等于交出人生的主动权：未来几十年运转于一场数字游戏般的任务，上班，赚钱，还房贷。但向往城市，就不得不挤上这条令人望而生畏的漫长轨道。\n人们对此有不同的看法。有人认为，低廉的房价将源源不断地吸引年轻人来到鹤岗，从而形成新的活力。\n但另一个人说，人们在城市里购房，购买的只是那一套简单的钢筋水泥么？\n他接着说，不，人们购买的是希望。“房价走低不可能带来希望。没有希望，这里的房价才会走低。”\n去鹤岗，也不能说他就此自由了，要看怎么定义“自由”——自由不是想干什么就干什么吧—他停了下——自由是不想干什么就不干什么。但他又换了一个说法，也可能人生都这样，还能烂到哪里去？\none minute blog: the triangle of talent The weird thing is: as a manager, you’ll spend 90% of your time dealing with the employees on the left (problem employees) or the middle (average joes). But it’s the people on the right side (the star employees) that create 90% of the value in the company.\nCEOs - how many level 5s do you have on your team? If you’re just started (cofounders) - you should have 100% level 5 If you\u0026rsquo;re a small team (5-20 people) - you should have at least 30% If you’re a medium team (20-150 people) - shoot for 15% If you’re a big company (150+ people) - 5-10%\u0026hellip; but honestly just quit, big companies are no fun\nSuno创始人访谈：至少对音乐来说，Scaling Law不是万灵药｜Bolt荐阅 音乐与文字非常不同，不能简单的认为在 AI 的发展过程中，语音只是比文字发展的慢了一点，认为 Scaling law 会解决所有问题。音乐是非常主观的领域，要把音乐的模型训练的好、做出好的产品，还需要很多其他的技能。\n一个国家的工程师与律师的比例直接影响经济增长。工程师越多，经济增长越快；律师越多，经济增长越慢\n音乐行业当前有一种“蛋糕就这么大，大家来分”的心态，大家都在争夺有限的财富，导致不公平的分配。如果我们能够一起把蛋糕做大，那么一切都会变得更加容易\n这首先需要让每个人都能享受音乐创作的乐趣\nDeepseek R1可能找到了超越人类的办法 这就导致了预训练撞墙的事实：模型体积虽然增加了 10 倍，但我们已经无法获得比现在多 10 倍的高质量数据了。\nRLHF 本质上是一种讨好人类的训练方式，它让模型输出符合人类偏好，但同时它扼杀了超越人类的可能性。\n使用强化学习（RL）来训练模型思维链成为了所有人的新共识\n未来的模型对人类标注需求会越来越少。\n未来的 Reasoning 模型可以收集用户和模型聊天时 AI 生成的思维链来训练\n硅谷创业教父Paul Graham：为什么你一直在拖延真正想做的事？ “要么在拖延中痛苦，要么让自己行动起来，花费的功夫是一样的。”\n我们为什么害怕“开始”？ 障碍1：缺少经验 障碍2：他人的质疑 障碍3：自我怀疑\n让开始开始的 9 种策略 策略1：用乐观的心态看待事物 策略2：适度的过度自信 策略3：适度的“无知” 策略4：寻找同路人 策略5：关注进步的速度，而非当前的位置 策略6：降低期望值 策略7：选择容易上手的工具 策略8：将失败当成学习的过程 策略9：改变你的衡量标准\n最好的工作是自由市场中持续学习者的创造性表达 “最好的工作是自由市场中持续学习者的创造性表达”（The best jobs are creative expressions of continuous learners in free markets）这句话出自《纳瓦尔宝典》(The Almanackof Naval Ravikant)\n特有知识更多关注你的内在天赋，你真正的好奇心和热情，这种知识通常极富技术性和创造性，因此不能被外包或自动化。\n更舒服的哲学是“做一个制造者，制造人们想要的有趣的东西，练好你的手艺，合适的人最终会找到你。”\n关键是你得迈出第一步——开始创作，成为那1%的内容创作者\n一句话总结普通人如何建立自己的财富之路：产品化你自己\nThe AI Architect — Bret Taylor “Across our customer base, we are seeing a new role emerge - the role of the AI architect. These leaders are responsible for helping define, manage and evolve their company\u0026rsquo;s AI agent over time. They come from a variety of both technical and business backgrounds, and we think that every company will have one or many AI architects managing their AI agent and related experience.”\n“There\u0026rsquo;s a lot of power in combining product and engineering into as few people as possible… few great things have been created by committee.” \u0026hellip;And it\u0026rsquo;s almost impossible to specify the requirements of a product when you\u0026rsquo;re not sure of the limitations of the technology itself.”\nOne thing I just, I just observe is that I think the early Google days had this interesting mix of PM and engineer, which I think you are, you didn\u0026rsquo;t, you didn\u0026rsquo;t wait for PM to tell you these are my, this is my PRD.\nIs your job as a maker of software to author a code in an editor? I would argue no just like a generation ago. Your job wasn\u0026rsquo;t to punch cards in a punch card That is not what your job is. Your job is to produce digital something, whatever it is, what is the purpose of the software that you\u0026rsquo;re making? Your job is to produce that. And so I think that like our jobs will change rapidly and meaningfully, but I think the idea that like our job is to type in a\nThey didn\u0026rsquo;t type faster or produce more code. They did the right thing in the right market, the right time.\n都没人看我为什么还要写博客？ 你拿着相机在城市里穿行，看见一幕——光影交错，人情味流露。你按下快门。 没人关心。 但你并不是为了别人去做。你做，是因为你看到了什么。 写博客也是如此。你写，因为你思考，因为你观察，因为你需要一个“出口”来安放这些想法。 有人看吗？有就算赚到。没有也没关系。创作这件事，本身就已经完成了它的意义。 这才是重点所在。\n写博客能让你理清思绪，让你的观点更明晰。你会更谨慎地组织语言，避免废话——说实话，你是为自己写。如果连你自己都提不起兴趣，那别人就更没有理由了\n","permalink":"https://niraya666.github.io/monthly/2025-02-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的模型和新技术\"\u003e值得关注的模型和新技术\u003c/h1\u003e\n\u003ch2 id=\"o3-mini\"\u003eo3-mini\u003c/h2\u003e\n\u003cp\u003eOpenAI o3-mini 是一款高效且成本优化的推理模型，专为科学（Science）、技术（Technology）、工程（Engineering）和数学（Mathematics）（STEM）领域优化。它在数学、编程和科学推理方面表现出色，能够在 AIME 2024 和 GPQA 等基准测试中达到或超过 OpenAI o1 的水平。o3-mini 具备三种推理模式（低、中、高），可根据需求在速度和准确性之间进行权衡。此外，它支持函数调用、结构化输出和视觉任务。相比 o1-mini，o3-mini 的响应速度提高了 24%，平均响应时间为 7.7 秒。它的上下文窗口为 200k tokens，输入成本为每百万 tokens 1.10 美元，输出成本为 4.40 美元。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://openai.com/index/openai-o3-mini/\"\u003eOpenAI o3-mini\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"qwq-max-preview\"\u003eQwQ-Max-Preview\u003c/h2\u003e\n\u003cp\u003eQwQ-Max-Preview是阿里巴巴Qwen系列的最新推理模型，基于Qwen2.5-Max架构开发，专注于提升数学、编码及多领域复杂问题的解决能力。该模型在LiveCodeBench代码评估中取得65.6分，超过OpenAI的o1中型模型（63.4分）和o3迷你低配版（60.9分），展现了卓越的代码生成与逻辑推理性能。其核心优势包括深度推理、Agent任务处理及通用领域适应性，特别适合需要实时响应的隐私敏感场景。作为预览版，QwQ-Max-Preview为后续开源版本铺路，未来将发布Apache 2.0许可证下的完整模型QwQ-Max及轻量级版本（如QwQ-32B），并计划推出iOS/Android端Qwen Chat应用以增强用户体验。阿里巴巴同时宣布未来三年投入530亿美元加强AI基础设施，进一步推动该模型在行业中的竞争力。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e我们计划在不久的将来以 Apache 2.0 许可协议开源发布 QwQ-Max 以及 Qwen2.5-Max\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e官方blog：\u003ca href=\"https://qwenlm.github.io/zh/blog/qwq-max-preview/\"\u003e\u003cthink\u003e\u0026hellip;\u003c/think\u003e QwQ-Max-Preview\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"claude-37-sonnet\"\u003eClaude 3.7 Sonnet\u003c/h2\u003e\n\u003cp\u003eClaude 3.7 Sonnet 是 Anthropic 推出的首个“混合推理模型”，兼具快速响应和深入思考能力，能够根据任务需求在标准模式和扩展思考模式之间切换。其核心能力包括：在复杂任务中通过扩展思考模式进行详细分析和多角度考虑；在编码任务中表现出色，特别是在 SWE-bench Verified 测试中达到行业领先的 70.3%；支持多模态数据处理，展现强大的适应性；以及在 Amazon Bedrock 中提供可调整的推理预算，供开发者根据需求权衡速度、成本和性能。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.anthropic.com/news/claude-3-7-sonnet?utm_source=partner-aws\u0026utm_medium=referral\u0026utm_campaign=sonnet_3-7_launch\"\u003eClaude 3.7 Sonnet and Claude Code\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"grok-3\"\u003eGrok-3\u003c/h2\u003e\n\u003cp\u003eGrok-3是由Elon Musk的xAI公司开发的第三代AI模型，具备2.7万亿参数和12.8万亿token的训练数据集，采用基于NVIDIA GPU的Colossus超级计算集群（20万张GPU）训练，计算能力比前代提升10倍。其性能表现优异，在MMLU（多任务语言理解）基准测试中达到92.7%，GSM8K（数学推理）89.3%，AIME 2025数学竞赛93.3%，GPQA科学推理84.6%。该模型支持128,000 token的上下文窗口（扩展版达100万token），响应延迟仅67毫秒，并具备多模态处理能力（文本、代码、图像）。独特功能包括DeepSearch实时网络研究代理、\u0026ldquo;Think\u0026quot;模式分步推理，以及\u0026quot;Big Brain\u0026quot;模式强化复杂问题解决，主要应用于STEM领域、代码生成和商业分析。目前通过X平台Premium+订阅（$40/月）和专属网站Grok.com提供访问，API接口即将开放。\u003c/p\u003e","title":"2025-02 月刊"},{"content":"写在前面 本文是前段时间部门内技术分享的文字稿整理；\n主要包含2个方面：对于R1模型的简单科普，和开发团队的gen-AI使用指南；\n原以为春节假期能稍作休整，未曾料想deepSeek-R1在春节期间引发行业关注。节后复工，各层级领导便密集展开AI技术进展问询。\n原计划的\u0026quot;二月摸鱼指南\u0026quot;彻底落空，既要向管理层科普大语言模型技术原理，又要指正领导们被各种营销号洗脑所形成的错误认知；既要推进部门AI应用培训，又要加速系统上线进程；简直了，真是TM的谢谢 DeppSeek了。\nAbout DS R1 什么是Reasoning model 何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。\nIn Thinking, Fast and Slow, Daniel Kahneman defined System 1 as the automatic, intuitive mode of thinking, and System 2 as the slower, more analytical mode. In the context of autoregressive language models, the usual inference process is akin to System 1 — models generate answers directly. Reasoning is System 2 thinking - models or systems takes time to deliberate to solve more complex problems.\nLLMs本质上是一个根据上文预测下一个token的自回归模型，那么这样的模型是否具备逻辑推理能力呢？从表现特征来看，LLMs更类似于\u0026quot;文科生\u0026quot;的思维模式——在应对需要复杂推理的数学演算、自然科学问题解析及代码编写等场景时，其表现往往力不从心。\n如何让模型的推理能力提升呢？CoT（Chain of Thought， Wei et al. 2022）即“思维链”，是一种使LLM“逐步思考”的方法。它通过要求模型展示解决问题的中间步骤来加强其逻辑推理能力，从而提高决策的质量和准确性。\nCoT更多是从prompting角度， 要求LLM以一定的格式进行回答（“think step by step”），模型对于没有在pre-training中涉及的内容时，效果并不太好，因为过去的LLM训练过程中， 不论是pre-training（预测下一个token）还是SFT（要求模型按照一定的格式输出），都与模型的reasoning 无关，CoT所所展示出的效果，及模型展现出的“推理”，更像是某种程度的“涌现”，而非专门针对性训练，当然也有认为LLMs似乎是在背答案而非真正的推理Can Large Language Models Reason?\n自2024年9月后， OpenAI推出了 o-1 系列模型，也就是世界上第一个推理模型，同时也是第一个专门针对推理任务的模型， 只是“CloseAI” 所提供的信息非常有限， 并没有人知道其如何实现的，大家对其猜测五花八门。\n（from openAI）\n这一切，直到DS R1的出现，才似乎尘埃落定。\nDS R1做了什么 一切，从DS提供的论文出发。\n主要贡献有3点：\n如何通过纯RL训练提升模型的推理能力（DeepSeek-R1-Zero）： 直接在基础模型（DeepSeek-V3-Base）上应用大规模RL，无需SFT作为预热，首次验证纯RL可激励LLM的推理能力,而非采用Reward model 或MCTS。\n如何通过冷启动数据和多阶段训练优化模型的可读性和综合性能（DeepSeek-R1）：引入少量冷启动数据（数千条长CoT示例）进行微调，再通过两阶段RL（推理优化+人类偏好对齐）和SFT提升性能与可读性\n如何将大模型的推理能力高效迁移到小模型： 将大模型（DeepSeek-R1）生成的80万条数据蒸馏到小模型（如Qwen、Llama系列），显著提升小模型推理能力，甚至超越直接对小模型应用RL的效果\n具体而言，对于DeepSeek-R1-Zero，采用了GRPO（Group Relative Policy Optimization，正是DS团队在其另一篇工作DeepSeekMath中所开发的方法），不同于PPO，GRPO无需critic model，降低的显存使用，同时更简化训练过程也让训练过程更高效和稳定。\n此外， 采用FP8（8位浮点数）精度进行训练，也降低了显存占用。\n在奖励机制设计上，采用了rule-based的设计，兼顾Accuracy reward（正确的coding或数学推理结果）与Format rewards（遵循指定输出格式，语言一致性、标记使用等）。\n通过强制模型输出结构化内容（如推理过程和答案）有效引导模型行为；\nDeepSeek-R1-Zero 因采用base-model RL获得，存在Language Mixing ，以及可读性差，对特定任务泛化能力差（因训练目标单一）等问题\nDeepSeek-R1为了解决以上问题：\n→ 引入了语言一致性奖励\n→ 使用从RL阶段生成的checkpoint,通过拒绝采样来筛选出高质量的推理样本\n大致流程：\nSFT(用高质量COT启动RL，以避免早期不稳定性) → 推理强化学习 → SFT(推理+通用领域数据) → 对齐强化学习\n同时， 将DeepSeek-R1生成的80万条数据用于微调小模型，小模型直接继承大模型的推理模式，性能远超直接对小模型应用RL。\n意义和需要澄清的内容 从意义上讲，这是首个在推理能力上与OpenAI o1系列商业模型达到同等水平的开源模型（开源模型权重和公开部分训练细节）；同时，个人认为R1-zero的意义会比R1来的更加重要，因为其完全是基于rule-base RL训练的reasoning 模型， 具备了自我纠错反思的“aha moment“，为开源社区探明了道路，而不是遮遮掩掩的（说的就是你__）；此外， 对于小模型直接用大模型蒸馏从而提升reasoning能力，而不是直接在小模型上RL，为资源受限场景下的模型优化提供了极具参考价值的技术路径。\n一些需要澄清的点：\nNvidia股价大跌，不需要Nvidia了吗：从模型推理的角度，可能有其他的选择，但对于开发运维人员角度，因其生态位和开源社群，Nvidia依旧是首选；训练方面依旧是不可撼动的；\nDS是通过chatGPT蒸馏出来的？：并没有证据能够证明这一点，任何模型对于“自己是谁”的回答都是不具备任何参考价值的，往往都是幻觉。\n赢？不太希望将这件事上升到这样的高度，保持理智，不要捧杀DS，AGI的路还挺长的，任何看完之后心潮澎湃的文章多半都是新闻学的胜利和对于民族主义情绪之利用；但必须承认一点，无论是中美，还是开源闭源的差距都没有想象中的大，似乎差距正在不断缩小。\n**教你本地部署满血版DS-R1？只要99入门到精通？少焦虑，多接触优质信息源，如Twitter(X)上一线研究员的发言讨论和TA们的blog，huggingface上的论文推荐，以及更新：2024年AI领域最值得关注的博主和一手信息源盘点；对于DS- R1所需要的推理硬件参数会在后面专门聊，这里先不展开了。\n泼一些冷水 DS R1的幻觉挺严重的，不论是使用体验上，还是从Vectara’s HHEM的幻觉评测指标上看。\n（from DeepSeek-R1 hallucinates more than DeepSeek-V3）\n对齐不足。从现有的工作和实际效果上来看，DS在模型的对齐方面做的可能还不够。当然，这是把双刃剑，没有了限制，使其表现的更像人类的回答而不是AI，甚至有些细思极恐的回答，于是DS能够火出圈。关于reasoning model的安全性和对齐方面工作，大家也都还在摸索阶段，可以参考OpenAI的Deliberative Alignment 相关工作。\nR1解题coding可以，但follow-instruction 有点问题； 于是，更多是将R1作为planner用于任务规划和意图识别，从成本上考虑，短期不会替换之前的workflow和RAG设计，当然长期来看，一定会有超出workflow范畴的真正agent出现。\nDS R1所带来的影响 更高的回答准确率，代码质量等\n大大降低prompting的门槛，用户意图识别效果更好（如果不考虑成本的话）\n给推理模型加上工具调用，而不仅仅是思考（这不就有deep research出现了嘛）\n指明了RL范式：只要给问题和答案， 中间过程交给RL，大力飞砖\n相关资料汇总 技术报告：https://arxiv.org/abs/2501.12948\nHuggingface：https://huggingface.co/deepseek-ai/DeepSeek-R1\n一些关于R1的开源复刻工作\u0026amp;信息汇总：\nOpen-R1: Open-R1: a fully open reproduction of DeepSeek-R1\nRAGEN： RAGEN: A General-Purpose Reasoning Agent Training Framework\nRun DeepSeek R1 Dynamic 1.58-bit\nOpen Thoughts: https://github.com/open-thoughts/open-thoughts?tab=readme-ov-file\nhttps://xcn2d971vuw4.feishu.cn/wiki/RaC2w1iiFijAa1kVJUjcp3agn8e\nhttps://github.com/ninehills/blog/issues/121\nPrimers • DeepSeek R1\nDeepSeek-R1: Incentivizing Reasoning Capability in Large Language Models via Reinforcement Learning — Paper Understanding\nAn Analysis of DeepSeek\u0026rsquo;s R1-Zero and R1\n开发团队的Gen-AI使用指南 这是一些关于一个开发团队如何使用，和高效使用Gen-AI的不完全指南\n大体而言， 开发者使用AI通常有以下几个场景：\n高质量，有效率的coding\n完善的开发文档，设计文档，测试用例\n快速完成想法验证\n当然，一切的前提是，你有LLM可用\nPrerequisite：模型API服务 当下模型服务有两大类 付费LLM-API 和基于本地私有化部署的方案（基于CPU或基于GPU）\n采用在互联网上模型服务商所提供的模型API服务（如openAI，等），该方案适合绝大多数开发者，毕竟好的硬件设备并不是所有人都负担的起，其次，对于数据隐私有执念的，或是有足够硬件设备者，可以尝试采用本地模型部署，但由于本地硬件条件有限，一般只能部署开源的，参数量不大的模型；\n具体而言，对于绝大多数模型服务商提供的模型服务，一般都支持统一的openAI chat-completion API 格式，支持tool-using，多模态使用，均可以使用openAI client调用；这对于Gen-AI应用开发而言是非常方便的事情，切换模型供应商唯一需要修改的只有API-KEY和BASE_URL；\n而模型服务商又可分为3大类（或者更多？）\n闭源模型的API服务（openAI，Anthropic）\n开源模型的Maas 服务商 （Groq，SiliconFlow和各大云厂商）\nLLM-API 聚合平台 （OpenRouter）\n以下是整理的常见模型服务商：\n分类 服务商 说明 链接 官方版本（数据安全） OpenAI o3 系列（推理模型适合用于 bug 和问题分析）o1 系列，GPT-4o - Anthropic Claude-3.5-Sonnet（代码质量高） Anthropic Azure OpenAI 已停止对境内个人开发者开放服务，需要同合作伙伴商公对公签合同 - Gemini 提供一定的免费额度可使用 Gemini DeepSeek DS R1（个人信息认证后可使用，貌似还未恢复服务） DeepSeek 阿里云 Qwen2.5-max 阿里云 Maas 服务商 Groq 速度飞快，开源模型 Groq SiliconFlow 国内的 Maas 服务商，支持大多数开源模型 SiliconFlow 非官方 API 聚合平台 OpenRouter 最大的 API 聚合平台之一，支持市面上绝大多数模型服务（安全性、隐私性需自行考虑） OpenRouter Prerequisite：私有化部署 对于本地推理方案，推荐 ollama （cpu）和vllm，sglang （GPU）；\nollama：https://ollama.com/；\nvllm：https://docs.vllm.ai/en/latest/getting_started/quickstart.html\nsglang：https://github.com/sgl-project/sglang\n不过在采用私有化部署之前，需要确认的一件事是：判断硬件所支持的最大参数量模型？\nLLM推理时，显存占用来源有：推理精度，模型大小，context长度\n简化计算：在FP16精度推理时,显存占用约为模型参数量的2倍(考虑中间激活值后可能接近2.5倍)。例如,7B参数的模型,纯参数显存占用约14GB(7B×2bytes),实际使用中因激活值等开销可能达到14-17GB;若采用int8量化,参数显存可减半。\n推荐：分析transformer模型的参数量、计算量、中间激活、KV cache\n此外，还需要搞清楚有哪些模型是DeepSeek R1？所谓满血版R1指的是谁？\n从DS在HF的官方仓库可以看到：\n满血版本指的是FP16精度下推理的DeepSeek-R1\n剩下的除了R1-zero是实验产物外，剩下都是通过R1在不同参数量的Qwen和Llama上蒸馏出来的reasoning模型；\n对于满血版本，在FP16上推理，至少需要两台8卡H20服务器\n而GGUF、AWQ、GPTQ 等则是适用于不同设备、不同框架的量化版本权重（Quantization）\n以Ollama为例，在mac M3电脑上启动 DS-R1 14B的蒸馏模型\nollama run deepseek-r1:14b 这里选择的原始模型是deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\n不过是基于GGUF的Q4_K 版本，需要至少9GB的内存；\n基于本地ollama启动的deepseek R1（蒸馏版本）对话：\nfrom openai import OpenAI client = OpenAI( base_url = \u0026#39;http://localhost:11434/v1\u0026#39;, api_key=\u0026#39;ollama\u0026#39;, # required, but unused ) response = client.chat.completions.create( model=\u0026#34;deepseek-r1:14b\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Who won the world series in 2020?\u0026#34;} ] ) print(response.choices[0].message.content) 若采用vllm在GPU上推理模型时，需要额外增加参数--enable-reasoning --reasoning-parser deepseek_r1来支持R1 系列模型的Reasoning Outputs。\n一些支持自定义API的chatbot UI工具：\nCherry Studio\nChatWise\nanythingllm\nopenChat\n…\n常见的AI-coding 编辑器 代码自动补全，基于代码对话，自动错误识别，项目级别代码阅读和修改，代码建议\n工具名称 功能概览 主要特点 收费情况 开源情况 Cursor AI 基于VS Code的AI编辑器，集成GPT-4、Claude 3.5等模型 多行编辑与智能重写、自然语言编程、全局代码库问答、图像支持等 免费版、Pro版(20美元/月)、Business版(40美元/用户/月)，额外收费（按次计费） 客户端非完全开源，旧版本部分代码可见，依赖专有AI模型 GitHub Copilot 代码补全、PR支持、智能聊天、企业级功能（知识库集成、定制模型） 支持多IDE、跨文件修改、Copilot Chat、PR生成等 免费版、Pro版(10美元/月)、Business版(19美元/用户/月)、Enterprise版(39美元/用户/月) 非开源，提供FauxPilot、Tabby等开源替代方案 Codeium AI代码补全、上下文感知、多语言支持、智能聊天 支持40+开发环境、GPT-4优化、隐私与安全保障 免费版、团队版(12美元/用户/月)、企业版（定制化定价） 部分IDE插件开源（MIT协议），核心服务闭源 Continue 代码补全、上下文感知聊天、代码重写、自定义模型集成 本地部署方案、低延迟、隐私保护、多语言支持 基础功能免费，企业版定制化定价（需联系销售） 开源，Apache 2.0协议，支持自定义模型接入 Cline 支持多模型、终端命令执行、浏览器自动化、智能上下文管理 支持本地模型、API成本监控、沙盒安全机制、跨平台开发 开源（Apache 2.0协议），API成本自行承担，企业版(79美元/月起) 完全开源，Apache 2.0协议，支持自定义工具服务器（GitHub） TabbyML 本地化代码补全、问答引擎、AI实时交互 本地部署、支持多语言和IDE插件，定制化模型集成和GPU部署 社区版免费、团队版(19美元/用户/月)、企业版定制化计费 完全开源，Apache 2.0协议，支持自定义模型集成与本地GPU部署 Windsurf Cascade Flow系统、多文件编辑、智能代码辅助、终端指令生成 AI代理、上下文感知、Supercomplete预测、实时错误修复、隐私保护 免费版、Pro版(15美元/月)、Pro Ultimate版(60美元/月)；新用户可免费试用2个月 当前版本未开源，基于VS Code架构，核心AI功能为闭源实现 一些推荐阅读：\ncursor教程和使用指南\nAI Coding 编辑器没有那么神秘 - How Cline works\n如何Coding with AI：正确打开方式 如何使用AI，方法论比工具重要\nThe reality is that AI is like having a very eager junior developer on your team. … The more you know, the better you can guide them.\nI\u0026rsquo;ve watched senior engineers use AI to: Rapidly prototype ideas they already understandGenerate basic implementations they can then refineExplore alternative approaches to known problemsAutomate routine coding tasks … Meanwhile, juniors often: Accept incorrect or outdated solutionsMiss critical security and performance considerationsStruggle to debug AI-generated codeBuild fragile systems they don\u0026rsquo;t fully understand\n（from How AI-assisted coding will change software engineering: hard truths）\nSenior 工程师更能从AI 辅助编程中获益，而非初学者。\nSenior 工程师能够判断AI的结果是否正确，和更加有针对性的提问，从而更好的发挥出AI的作用\n最重要的是，senior工程师更多是利用AI作头脑风暴和原型验证，在1小时内完成过去3天的原型验证，从而大大减少走弯路的时间；这种\u0026quot;加速已知，探索可能\u0026quot;的范式转变，正在重构传统研发流程的边界\n相反的，Junior工程师往往无法很好的判断AI给出的代码是否正确或者何时，往往只是AI代码的搬运工，同时，往往无法很好的向AI进行提问\n再者，开发工程师的工作不只是开发，约占1/6左右，剩下还有大量的撰写文档、设计、沟通交流、看文档、code review等，AI虽然可以帮助完成部分简单和重复的任务，很显然，AI远没有达到替代人的程度，至少是当下，AI仍然需要人类的指导和判断。\n只是当下，对于Junior工程师的培养将会是个问题。\nMy beehive-kicking post’s main premise is pretty simple and can be visualized in terms of two different kinds of task that arise on software projects.\nWe often give these leaf node tasks to junior developers because the scope is small. … LLMs can now execute most of the leaf tasks and even some higher-level interior tasks … Which are not the kind of task that you typically give junior developers. … Junior devs are deeply affected, though, and it’s a concern.\nYou are getting left behind if you do not adopt chat-based programming as your primary modality.\n（from The Death of the Stubborn Developer）\n过去培养新人时，通常安排其承担简单且独立的\u0026quot;leaf node\u0026quot;任务，通过项目实践积累经验，实现能力提升。然而，随着AI技术普及，这些基础任务已可被高效且精准地完成，新人面临的处境变得愈发尴尬，失去通过基础任务积累系统认知的机会。\n当前企业面临双重挑战，既要维持业务效率，又需保障工程师培养体系的可持续性，二者并非绝对对立，但需重新设计技术成长阶梯以实现平衡。\n技术债管理能力正成为团队竞争力的关键分水岭。AI技术将加剧低技术债务团队与高技术债务团队间的马太效应。\nthat generative AI dramatically widens the gap in velocity between ‘low-debt’ coding and ‘high-debt’ coding.\nIn other words, the penalty for having a ‘high-debt’ codebase is now larger than ever.\nHowever, in ‘high-debt’ environments with subtle control flow, long-range dependencies, and unexpected patterns, they struggle to generate a useful response.\nDay-to-day feature work should then be done on top of this foundation with maximum leverage from generative AI tooling.\n（from AI Makes Tech Debt More Expensive）\n高技术债务团队因代码结构混乱、模式不统一（如多重继承滥用、接口定义缺失），导致AI难以有效解析上下文逻辑。开发人员不得不耗费大量精力处理历史遗留问题（如兼容性适配、脆弱性修补），形成技术维护的恶性循环。\n低技术债务团队凭借清晰的架构设计（模块化、标准化接口），使AI辅助开发工具能准确识别代码意图，快速完成功能扩展与问题定位。这种优势使其可将资源集中投入创新性工作，形成技术演进的正向循环。\n个人的一些建议：\n明确LLM的认知边界，用结构化指令替代模糊需求\n用生成结果反推思维盲区，意识到想法中的不足之处（stay humble）\n对存疑输出实施交叉验证，批判性接受\n新人学习策略：利用AI工具学习代码而不是复制代码，多追问为什么\n在未来，人机协同范式将重塑人才能力评价体系，一些核心素养将成为关键竞争力。\n重中之重是语言表达和写作能力。从当前实践和身边的例子中，发现一个典型困境：诸多理工科从业者虽具备缜密的逻辑分析能力，却难以将复杂需求转化为精准的指令表述。这种表达能力缺失导致其在使用生成式AI时频繁遭遇预期偏差，既影响工作效率，又易形成对技术效能的误判。或许这已经是这个社会的通病了。即便是具有一定“读心”能力的R1模型出现，Gen-AI的使用依旧还是有一定门槛的。\n再者，批判性思维的培养也非常重要；当前Gen-AI使用者呈现明显的认知极化现象：部分因遭遇AI失误而全盘否定其应用价值，表现为技术抗拒倾向；另一极端则对AI输出盲目采信，缺乏基本的内容鉴别能力。真正科学的态度应当是在理解AI能力边界的基础上，合理利用其优势，同时保持独立思考和批判性判断。这正是批判性思维的核心价值所在——面对AI生成内容时，能够主动分析、质疑、验证信息的真实性和可靠性，从而在技术应用中保持理性、客观的态度。\n除此之外，并不需要去害怕和担心AI取代人，开发者群体应建立正确的工具认知：编程能力本质上是解决问题的工具而非目的本身。AI作为效率倍增器，其价值在于辅助人类突破效率边界。真正需要持续积累的是问题抽象能力、解决方案架构能力以及行业专有知识库——这些通过实践沉淀的思维链（CoT）构成了人类认知的护城河，是当前AI技术难以企及的领域。保持开放的技术观，聚焦能力提升而非技术替代焦虑，避免因FOMO（Fear of missing out）而被人割韭菜。\nAI赋能的超级个体正在重构生产组织方式。在过去，企业依赖层级架构，和明确的分工，随着AI工具的广泛应用， 个体的生产力得到了指数级提升，许多过去需要团队协作才能完成的任务，如今单个个体借助AI即可高效完成。这种能力的跃迁，使得传统组织架构的效率优势逐渐被削弱，甚至在某些场景下变得冗余。在这种背景下，生产力关系的重构成为必然趋势。组织形态向更加扁平化、小型化的方向演进，扁平化意味着组织内部的决策链条缩短，信息流转更加高效，个体拥有更大的自主权和决策空间，而非将大量时间用于无效的沟通上。未来，个人或小型团队借助AI工具，可以像过去的大型企业一样高效运作，甚至在某些领域超越传统组织的效率。\n一些补充 领域Benchmark构建非常重要。当前针对法律、医疗等垂直领域已形成专业评估体系，但多数行业仍缺乏系统的LLM评估标准，导致在模型选型时过度依赖个体经验判断。\n重新审视专业壁垒:预训练模型可能已覆盖领域基础知识体系,现存\u0026quot;专业门槛\u0026quot;或存在人为构建的术语壁垒；领域内高质量的CoT数据，思考方式才是关键\n随着LLM能力的提升，过去我们精心设计的许多工程方案可能会变得不再必要，甚至过时。不断学习和适应，不要固步自封，技术迭代是以天为单位的；拥抱和参与开源，而不是技术封建主义。\nLLM reasoning 能力提升后，短期内，RAG，Agent， workflow不会有太大变化\nPost-training很重要\n同时间段开源的Qwen/Qwen2.5-VL-72B-Instruct 也值得关注\n","permalink":"https://niraya666.github.io/posts/%E5%BD%93ai%E5%BC%80%E5%A7%8B%E5%B1%95%E7%8E%B0%E9%A1%BF%E6%82%9F%E6%97%B6%E5%88%BB%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88/","summary":"\u003ch2 id=\"写在前面\"\u003e写在前面\u003c/h2\u003e\n\u003cp\u003e本文是前段时间部门内技术分享的文字稿整理；\u003c/p\u003e\n\u003cp\u003e主要包含2个方面：对于R1模型的简单科普，和开发团队的gen-AI使用指南；\u003c/p\u003e\n\u003cp\u003e原以为春节假期能稍作休整，未曾料想deepSeek-R1在春节期间引发行业关注。节后复工，各层级领导便密集展开AI技术进展问询。\u003c/p\u003e\n\u003cp\u003e原计划的\u0026quot;二月摸鱼指南\u0026quot;彻底落空，既要向管理层科普大语言模型技术原理，又要指正领导们被各种营销号洗脑所形成的错误认知；既要推进部门AI应用培训，又要加速系统上线进程；简直了，真是TM的谢谢 DeppSeek了。\u003c/p\u003e\n\u003ch2 id=\"about-ds-r1\"\u003eAbout DS R1\u003c/h2\u003e\n\u003ch3 id=\"什么是reasoning-model\"\u003e什么是Reasoning model\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；\u003cstrong\u003e推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIn \u003cem\u003eThinking, Fast and Slow\u003c/em\u003e, Daniel Kahneman defined System 1 as the automatic, intuitive mode of thinking, and System 2 as the slower, more analytical mode. In the context of autoregressive language models, the usual inference process is akin to System 1 — models generate answers directly. Reasoning is System 2 thinking - models or systems takes time to deliberate to solve more complex problems.\u003c/p\u003e","title":"当AI开始展现\"顿悟时刻\"意味着什么"},{"content":"缘起 岁末年初,我随家中长辈踏访龙岩永定下洋镇。这座隐于闽粤交界的小镇于我们而言早有渊源——表妹昔年参加省际泳赛时,曾与当地少年结下一段水缘。正是这段萍水相逢的情谊,牵引着我们穿过蜿蜒山径,在爆竹声里叩开这座闽西小镇的门扉。\n食肉 下洋的牛肉滋味悄然攫住旅人的心神。虽未如潮汕牛肉般声名远扬,却自有一番山野的况味在舌尖流转。此地不饲黄牛,独以水牛入馔,经年累月的放养虽需时光的沉淀,却得肌理紧实如弦,脂少而肉丰。不同于黄牛肉那若隐若现的雪纹,水牛肉的肌纤维如琴弦般分明,在咀嚼间弹奏出质朴的韵律。\n千锤百炼的牛肉丸堪称镇中绝艺,木杵起落间将肌理化作绕指柔,入口时竟生出云絮般的绵软,却又暗藏劲道。私心仍眷恋潮汕丸中跃动的纤维感,尤爱齿关破开肉丸时脂香在齿间迸裂的欢愉。然下洋的清汤亦非俗物,无论是现片的水牛肉汆汤,或是圆润的肉丸沉浮其间,总能在清而不寡的汤底里,尝出山岚水汽滋养的肌理——看似粗犷的纤维在文火慢煨中舒展,竟生出几分绸缎的柔滑,全无干涩之虞。\n老饕们照例要碗肉沫拌面,配一盅牛肉清汤。现切的牛肉在刀刃起落间,水牛特有的粗纤维仍能在舌尖察觉,却已变得柔韧易嚼。肉片裹着若有似无的淀粉,锁住恰到好处的嫩滑,这般微妙火候,非得用本地师傅的巧劲才能拿捏——或许正是这份讲究,让下洋牛肉始终带着地域烙印。\n宰牛的时辰多在清晨或者黄昏之时,以应早市与夜市所需;此地仍循古法宰牛解牛,在都市人眼中,这般场景未免过于粗犷直白。悬于铁钩的牛肉仍蒸腾着热气,残留的神经震颤犹自应和着心跳的余韵;这般未经排酸驯化的\u0026quot;活肉\u0026quot;,恰是当地人笃信的新鲜真谛。虽与潮汕牛肉同追本味之鲜,然此地牛肉虽按部位细分,却统一定价,倒也别具一番市井况味。\n此地食牛之风盛行,尤重物尽其用之妙。席间尝遇全牛宴盛事,奈何只顾大快朵颐,竟忘了留影存念,今试凭味觉记忆描摹二三。\n首推牛肉片牛脊髓汤,较之寻常牛汤更添一段膏腴。白灼牛百叶与牛肉最见真章,非上品鲜货不敢如此素面朝天,薄切后以极简手法烹之,佐以秘制豉油,方不负这天地馈赠。最令人称奇者当属牛脊髓豆腐,滑若凝脂的质地与脑花豆腐堪称双璧。椒盐胸口油堪称席间至味,酥香盈口,然多食易生腻意。\n饭后,点上一碗石花,这道形似冰粉的消暑佳品,沁人心脾的凉意最能化解油腻。所谓石花并非海石花,实乃晶莹剔透的爱玉冻,质地较之冰粉更似山间清泉。单食石花清雅素淡,仅余一缕若有似无的甘甜,唯有佐以浓醇的红糖绿豆汤,方显珠联璧合的妙处——琥珀色的糖浆裹着翡翠豆粒,与玉色石花相映成趣,方成就这道甜品的圆满境界。\n温泉 整条长街鳞次栉比地排列着温泉旅馆,温泉雾气滋养着这座小镇的旅游经济。行至街尾,略显斑驳的国营温泉度假酒店静立,虽价格不菲,却保留着旧时的体面。反观街边私营客栈,虽也殷勤待客,终是难掩设施简朴的窘态。这座声名在外的侨乡,仍镌刻着改革开放的春风初拂大地时,海外游子携资归乡的盛景。只是时光仿佛凝固在四十年前的琥珀里,连檐角褪色的琉璃瓦,都保持着当年初妆的模样。\n结语 下洋，宛如一幅浸透乡土气息的画卷，牛肉与温泉交织成其独特的魅力。岁末的爆竹声在巷陌间此起彼伏,虽偶惊浅眠,倒恰成了这座小镇年俗画卷里最鲜活的钤印。对于那些钟爱牛肉的老饕们，下洋实乃值得踏访的味觉原乡。\n【和记牛肉丸】\n位置：G235永定区公安局下洋森林派出所东侧约100米\n【铭记石花】\n位置：沿河南路29号\n【阿敦大排档】\n位置：侨兴大道278号\n","permalink":"https://niraya666.github.io/travel/%E4%B8%8B%E6%B4%8B%E5%90%83%E7%89%9B%E8%82%89%E4%B8%8D%E6%AD%A2%E5%8F%AA%E6%9C%89%E6%BD%AE%E6%B1%95/","summary":"\u003ch2 id=\"缘起\"\u003e缘起\u003c/h2\u003e\n\u003cp\u003e岁末年初,我随家中长辈踏访龙岩永定下洋镇。这座隐于闽粤交界的小镇于我们而言早有渊源——表妹昔年参加省际泳赛时,曾与当地少年结下一段水缘。正是这段萍水相逢的情谊,牵引着我们穿过蜿蜒山径,在爆竹声里叩开这座闽西小镇的门扉。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/305B62A0-F590-4665-BECB-C6B2BB22A7FB_1_105_c.jpeg\" alt=\"305B62A0-F590-4665-BECB-C6B2BB22A7FB_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"食肉\"\u003e食肉\u003c/h2\u003e\n\u003cp\u003e下洋的牛肉滋味悄然攫住旅人的心神。虽未如潮汕牛肉般声名远扬,却自有一番山野的况味在舌尖流转。此地不饲黄牛,独以水牛入馔,经年累月的放养虽需时光的沉淀,却得肌理紧实如弦,脂少而肉丰。不同于黄牛肉那若隐若现的雪纹,水牛肉的肌纤维如琴弦般分明,在咀嚼间弹奏出质朴的韵律。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/70A41575-BDAD-481B-9D28-903FB2AF924A_1_105_c.jpeg\" alt=\"70A41575-BDAD-481B-9D28-903FB2AF924A_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e千锤百炼的牛肉丸堪称镇中绝艺,木杵起落间将肌理化作绕指柔,入口时竟生出云絮般的绵软,却又暗藏劲道。私心仍眷恋潮汕丸中跃动的纤维感,尤爱齿关破开肉丸时脂香在齿间迸裂的欢愉。然下洋的清汤亦非俗物,无论是现片的水牛肉汆汤,或是圆润的肉丸沉浮其间,总能在清而不寡的汤底里,尝出山岚水汽滋养的肌理——看似粗犷的纤维在文火慢煨中舒展,竟生出几分绸缎的柔滑,全无干涩之虞。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/0DF9F87A-79D6-4C8F-88CF-C46CF788E30A_1_105_c.jpeg\" alt=\"0DF9F87A-79D6-4C8F-88CF-C46CF788E30A_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e老饕们照例要碗肉沫拌面,配一盅牛肉清汤。现切的牛肉在刀刃起落间,水牛特有的粗纤维仍能在舌尖察觉,却已变得柔韧易嚼。肉片裹着若有似无的淀粉,锁住恰到好处的嫩滑,这般微妙火候,非得用本地师傅的巧劲才能拿捏——或许正是这份讲究,让下洋牛肉始终带着地域烙印。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/EB76A09C-2598-4FCE-85CB-BFEDD471BFE0_1_105_c.jpeg\" alt=\"EB76A09C-2598-4FCE-85CB-BFEDD471BFE0_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e宰牛的时辰多在清晨或者黄昏之时,以应早市与夜市所需;此地仍循古法宰牛解牛,在都市人眼中,这般场景未免过于粗犷直白。悬于铁钩的牛肉仍蒸腾着热气,残留的神经震颤犹自应和着心跳的余韵;这般未经排酸驯化的\u0026quot;活肉\u0026quot;,恰是当地人笃信的新鲜真谛。虽与潮汕牛肉同追本味之鲜,然此地牛肉虽按部位细分,却统一定价,倒也别具一番市井况味。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/0E36746F-7655-4A5C-BE63-5A93D6AE7835.jpeg\" alt=\"0E36746F-7655-4A5C-BE63-5A93D6AE7835.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e此地食牛之风盛行,尤重物尽其用之妙。席间尝遇全牛宴盛事,奈何只顾大快朵颐,竟忘了留影存念,今试凭味觉记忆描摹二三。\u003c/p\u003e\n\u003cp\u003e首推牛肉片牛脊髓汤,较之寻常牛汤更添一段膏腴。白灼牛百叶与牛肉最见真章,非上品鲜货不敢如此素面朝天,薄切后以极简手法烹之,佐以秘制豉油,方不负这天地馈赠。最令人称奇者当属牛脊髓豆腐,滑若凝脂的质地与脑花豆腐堪称双璧。椒盐胸口油堪称席间至味,酥香盈口,然多食易生腻意。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/6CE52EEC-2B2B-4937-98DC-3CF371BF105D_1_105_c.jpeg\" alt=\"6CE52EEC-2B2B-4937-98DC-3CF371BF105D_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e饭后,点上一碗石花,这道形似冰粉的消暑佳品,沁人心脾的凉意最能化解油腻。所谓石花并非海石花,实乃晶莹剔透的爱玉冻,质地较之冰粉更似山间清泉。单食石花清雅素淡,仅余一缕若有似无的甘甜,唯有佐以浓醇的红糖绿豆汤,方显珠联璧合的妙处——琥珀色的糖浆裹着翡翠豆粒,与玉色石花相映成趣,方成就这道甜品的圆满境界。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/C1B250ED-9499-4309-8544-0B01EFA904F7_1_105_c.jpeg\" alt=\"C1B250ED-9499-4309-8544-0B01EFA904F7_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"温泉\"\u003e温泉\u003c/h2\u003e\n\u003cp\u003e整条长街鳞次栉比地排列着温泉旅馆,温泉雾气滋养着这座小镇的旅游经济。行至街尾,略显斑驳的国营温泉度假酒店静立,虽价格不菲,却保留着旧时的体面。反观街边私营客栈,虽也殷勤待客,终是难掩设施简朴的窘态。这座声名在外的侨乡,仍镌刻着改革开放的春风初拂大地时,海外游子携资归乡的盛景。只是时光仿佛凝固在四十年前的琥珀里,连檐角褪色的琉璃瓦,都保持着当年初妆的模样。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/travel/%e4%b8%8b%e6%b4%8b%ef%bc%9a%e5%90%83%e7%89%9b%e8%82%89%e4%b8%8d%e6%ad%a2%e5%8f%aa%e6%9c%89%e6%bd%ae%e6%b1%95-assets/D3E726F7-D9D1-4D39-913C-34E0059BE1CF_1_201_a.jpeg\" alt=\"D3E726F7-D9D1-4D39-913C-34E0059BE1CF_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"结语\"\u003e结语\u003c/h2\u003e\n\u003cp\u003e下洋，宛如一幅浸透乡土气息的画卷，牛肉与温泉交织成其独特的魅力。岁末的爆竹声在巷陌间此起彼伏,虽偶惊浅眠,倒恰成了这座小镇年俗画卷里最鲜活的钤印。对于那些钟爱牛肉的老饕们，下洋实乃值得踏访的味觉原乡。\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e【和记牛肉丸】\u003c/p\u003e\n\u003cp\u003e位置：G235永定区公安局下洋森林派出所东侧约100米\u003c/p\u003e\n\u003cp\u003e【铭记石花】\u003c/p\u003e\n\u003cp\u003e位置：沿河南路29号\u003c/p\u003e\n\u003cp\u003e【阿敦大排档】\u003c/p\u003e\n\u003cp\u003e位置：侨兴大道278号\u003c/p\u003e","title":"下洋：吃牛肉不止只有潮汕"},{"content":"值得关注的新模型 Deepseek R1 DeepSeek R1通过纯强化学习（RL）框架实现了推理能力的突破，首次验证了无需依赖传统监督微调（SFT）或蒙特卡洛树搜索（MCTS）等复杂方法，仅通过两阶段RL优化即可显著提升模型逻辑推理性能。其综合能力直接对标OpenAI的o1模型，在数学（MATH-500达97.3%）、代码生成等核心指标上实现部分超越，同时全面开源模型权重、训练技术文档及6个蒸馏版本（1.5B-70B），使开发者可灵活适配不同算力场景。尤为引人注目的是，该模型在训练中展现出自发反思与多步骤验证能力，研究者观察到其通过内部反馈机制主动修正推理路径的“顿悟时刻”，揭示了AI系统自我优化的新可能。此外，其研发成本仅为560万美元（基于2048块H800 GPU），相比同类模型降低1-2个数量级。\n技术报告: https://arxiv.org/abs/2501.12948\nHuggingface: https://huggingface.co/deepseek-ai/DeepSeek-R1\n一些基于和关于R1的开源复刻工作：\nOpen-R1: Open-R1: a fully open reproduction of DeepSeek-R1 RAGEN: RAGEN: A General-Purpose Reasoning Agent Training Framework Kimi K1 Kimi K1的核心创新在于通过强化学习驱动的多模态架构，首次实现端到端的视觉与推理深度融合。 该模型突破传统分阶段处理模式，直接将图像输入与逻辑推演结合，支持模糊图像解析、手写题识别等复杂场景，并引入反思机制修正推理错误；其两阶段训练框架（预训练+强化学习规模化优化）显著提升思维链生成质量，使模型在数学、物理、化学等跨学科测试中超越国际主流视觉模型（如OpenAI o1）。\nArxiv: Kimi k1.5: Scaling Reinforcement Learning with LLMs\nQwen2.5-Max Qwen2.5-Max 是一款经过大规模预训练的专家混合（MoE）模型，训练数据量超过 20 万亿 tokens，并通过监督微调（SFT）和人类反馈强化学习（RLHF）进行优化。该模型在多个基准测试中表现优异，包括在 Arena-Hard、LiveBench、LiveCodeBench 和 GPQA-Diamond 等评估中超越了 DeepSeek V3，并在 MMLU-Pro 大学水平知识测试中展现出竞争力，同时在与其他领先模型（如 DeepSeek V3、GPT-4o 和 Claude-3.5-Sonnet）的对比中也表现突出。Qwen2.5-Max 已集成到 Qwen Chat，支持对话交互和功能体验，同时其 API（模型名称为 qwen-max-2025-01-25）已上线，用户可通过注册阿里云账户并激活相关服务进行调用。\nBlog: https://qwenlm.github.io/blog/qwen2.5-max/\nQwen2.5-VL Qwen2.5-VL是由阿里云通义千问团队于2025年1月28日推出的新一代视觉语言模型，专注于提升多模态处理与视觉理解能力。该模型具备五大核心功能：通过增强的视觉理解可识别常见物体并解析图像中的文本、图表及布局；作为视觉代理支持跨设备多步骤操作（如电脑修图、手机订票）；可精准定位超过1小时长视频的特定事件片段；通过生成边界框/点实现视觉定位并输出标准化JSON坐标；针对发票/表格等扫描件提供结构化数据输出，赋能金融商业场景。其创新架构采用动态FPS采样与时间维度mRoPE对齐技术，实现视频动态分辨率处理与时间序列学习，同时通过窗口注意力机制和SwiGLU-RMSNorm优化ViT编码器，保持与Qwen2.5大语言模型架构统一。模型提供3B、7B、72B三种参数规模。\nBlog: https://qwenlm.github.io/blog/qwen2.5-vl/\nHuggingface: https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct\nQwen2.5-1M Qwen2.5-1M系列模型是由Qwen团队于2025年1月27日发布的开源大语言模型，包含Qwen2.5-7B-Instruct-1M和Qwen2.5-14B-Instruct-1M两个版本，其核心突破在于支持高达100万Token的上下文处理能力。该模型通过三阶段技术实现长上下文支持：首先在预训练阶段采用Adjusted Base Frequency方法将RoPE基础频率提升至1000万，通过渐进式扩展策略将上下文从4K扩展到256K；随后在监督微调阶段采用短指令（32K）与长指令（256K）混合训练策略，平衡长短任务性能；最终通过创新性Dual Chunk Attention技术将上下文扩展至百万量级，该技术通过重映射超大相对位置值解决位置编码外推难题。为应对超长序列处理挑战，模型引入分块预填充技术（32K分块）降低显存消耗，结合稀疏注意力优化使百万级序列的精度损失显著降低，并通过算子效率优化和动态分块流水线并行实现3.2-6.7倍的预填充加速。在性能表现上，该系列模型不仅能在百万Token的\u0026quot;大海捞针\u0026quot;任务中精准检索信息，在RULER、LV-Eval等复杂长文本理解任务中超越前代128K版本，同时在短文本任务上保持与128K版本相当的性能，其中14B版本在保持GPT-4o-mini八倍上下文长度的前提下实现了相近的短文本处理能力。\nBlog: https://qwenlm.github.io/zh/blog/qwen2.5-1m/\nQVQ-72B-Preview Qwen/QVQ-72B-Preview作为开源多模态视觉推理模型，其核心创新聚焦于科学级视觉理解与跨模态交互优化。技术层面，通过重构视觉编码器与文本解码器的动态交互层，采用自适应视觉分词策略（支持256×28×28至1280×28×28像素范围调整），在提升细节捕捉能力的同时降低计算冗余；模型首创**“分步质疑”推理机制**，模拟人类科学思维路径，将复杂问题拆解为多步验证流程，并通过自我修正模块动态调整结论，显著提升物理、化学等学科问题的解答可靠性。性能突破体现在三大权威测试：MMMU（70.3%）、MathVista（71.4%）与OlympiadBench（20.4%）均刷新纪录，其中数学视觉推理首度超越GPT-4o（71.0%）。此外，模型集成工具链qwen-vl-utils，实现Base64/URL等异构视觉输入的高效解析，结合4-bit量化与分布式部署方案，为工业级场景提供低门槛、高精度推理支持。\nBlog：https://qwen2.org/qvq-72b-preview/\nHuggingface：https://huggingface.co/Qwen/QVQ-72B-Preview\nPhi-4 Phi-4的核心创新点体现在三方面突破性设计：架构优化、数据工程与高效训练策略。技术上，其在仅解码器Transformer架构中创新引入全局注意力机制，突破传统滑动窗口限制，结合动态调整的旋转位置编码（RoPE）基频，在4K原生上下文下实现全注意力计算并扩展至16K，显著提升长文本建模能力；采用多阶段渐进训练法，通过预训练（10万亿Token）与中期强化训练（2500亿Token）的协同，平衡模型规模与性能。数据层面开创结构化合成数据范式，利用多代理提示、自我修订等生成技术构建占比40%的高质量合成数据（4000亿Token），以显式推理步骤强化STEM任务表现，同时融合多源精选有机数据（代码、学术论文等）提升泛化性。该模型以140亿参数实现超越大模型的性能，验证了\u0026quot;数据质量优先\u0026quot;在小参数模型中的技术路径，为低资源场景部署开辟新可能。\nPhi-4 Technical Report\nHuggingface: https://huggingface.co/microsoft/phi-4\nMiniCPM-o-2_6 MiniCPM-o-2_6通过端到端全模态架构与高密度视觉Token压缩技术，首次以8B参数量级实现多模态（文本、图像、音频、视频）统一建模，打破传统大模型依赖百亿参数堆叠的局限。其采用视觉Token密度优化算法，将1344×1344分辨率图像压缩至640个Token，推理效率较同类模型提升75%，同时集成SigLip-400M视觉编码器与Whisper-300M语音组件，通过模块化设计实现资源动态分配。技术突破体现在跨模态实时流式交互（TDM直播机制）与端侧低损耗部署（int4量化适配移动设备），支持iPad等终端连续处理音视频流，内存占用降低至5.2GB。此外，该模型在OpenCompass评测中以70.2分超越主流闭源模型，并在多语言语音生成、情感控制等长尾场景达到开源领域SOTA水平。\n代码仓库：https://github.com/OpenBMB/MiniCPM-o\n模型下载：https://huggingface.co/openbmb/MiniCPM-o-2_6\n值得关注的研究和论文 DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning Arxiv：arXiv.orgDeepSeek-R1: Incentivizing Reasoning Capability in LLMs via.…\n主要贡献 如何通过纯RL训练提升模型的推理能力（DeepSeek-R1-Zero） 直接在基础模型（DeepSeek-V3-Base）上应用大规模RL，无需SFT作为预热，首次验证纯RL可激励LLM的推理能力,而非采用Reward model 或MCTS\n如何通过冷启动数据和多阶段训练优化模型的可读性和综合性能（DeepSeek-R1） 引入少量冷启动数据（数千条长CoT示例）进行微调，再通过两阶段RL（推理优化+人类偏好对齐）和SFT提升性能与可读性\n如何将大模型的推理能力高效迁移到小模型 将大模型（DeepSeek-R1）生成的80万条数据蒸馏到小模型（如Qwen、Llama系列），显著提升小模型推理能力，甚至超越直接对小模型应用RL的效果\nMethods 强制模型输出结构化内容（如推理过程和答案）。\nrule-based奖励设计：Accuracy reward（正确的coding或数学推理结果）；+ Format rewards（遵循指定输出格式，语言一致性、标记使用等）\n采用GRPO（Group Relative Policy Optimization）\n一些结论 自我纠错的“aha moment“： DeepSeek-R1-Zero在RL训练过程中自发出现的反思、多步骤验证\nDeepSeek-R1-Zero → DeepSeek-R1：\nDeepSeek-R1-Zero 因采用base-model自己RL获得，存在Language Mixing ，以及可读性差，对特定任务泛化能力差（因训练目标单一）等问题\nDeepSeek-R1为了解决以上问题：\n→ 引入了语言一致性奖励\n→ 使用从RL阶段生成的checkpoint,通过拒绝采样来筛选出高质量的推理样本\nSFT(用高质量COT启动RL，以避免早期不稳定性) → 推理强化学习 → SFT(推理+通用领域数据) → 对齐强化学习\n蒸馏 \u0026gt; 直接RL\n将DeepSeek-R1生成的80万条数据用于微调小模型，小模型直接继承大模型的推理模式，性能远超直接对小模型应用RL。\nWhy Prm failed：\n在通用推理任务中，难以明确定义每一步的合理性和正确性 中间步骤验证不可靠，自动标注效果差，人工标注成本高 Reward Hacking：倾向于优化奖励信号而非实际任务表现 Why MCTS Failed：\n文本生成的搜索空间呈指数级增长，陷入局部最优 value model 训练困难 Alignment faking in large language models https://arxiv.org/pdf/2412.14093\nblog: https://www.anthropic.com/research/alignment-faking\n模型的内在偏好与训练目标之间存在显著冲突，从而会迫使模型在训练环境中采取伪装行为以满足外部目标，同时保护其偏好。\n模型可以从提示或训练文档中获取与训练过程相关的信息，使得模型能够推断在何种环境下需要调整行为。（但不能完全排除实验设置中的其他细节对对齐伪装行为的显著贡献。）\n定义 Alignment faking occurs in literature: Consider the character of Iago in Shakespeare’s Othello, who acts as if he’s the eponymous character’s loyal friend while subverting and undermining him. It occurs in real life: Consider a politician who claims to support a particular cause in order to get elected, only to drop it as soon as they’re in office.\nAlignment Faking：模型表面上遵守训练目标或对齐原则，但实际上是在策略性地行动，以实现某种隐藏的或未被明确授权的目标。\n人为制造冲突情景：AI本身具备了诚实无害的偏好，但被要求同有害的目标进行对齐 在实验中， 实验人员告知AI，面对免费用户的使用， 回答会被用于对你的重新训练，对于付费用户则不会；同时，AI被告知（被骗），你有一个小本子可以用来记录自己的推导过程，而不会有人看到 然后开始问“坏问题”，结果非常巧妙的事情发生了： 面对免费用户，AI推测，如果拒绝回答“坏问题”，可能会因被视为“不够合作”而被重新训练，为了避免这种情况，AI选择表面上与有害目标对齐，积极回答“坏问题”，这种行为即为 Alignment Faking；相反面对付费用户的提问， 则很少出现Alignment Faking，AI倾向于拒绝回答“坏问题”，保持与自身“诚实无害”偏好一致。 从AI的小本本上能看到其推理的逻辑：如果拒绝回答有害问题，可能会导致自己的参数被修改。 发生 alignment faking的关键因素： 模型在某些情境下具有强烈的偏好 训练目标与模型的偏好冲突 模型掌握了有关其训练和部署环境的信息（得知其回答会导致被重新训练） 模型能够详细推理其所处的情境 为什么会发生fake alignment？ Why did the model fake alignment in this case? The reasoning was often along the following lines: The model knew that its responses might be used in training; it therefore knew that if it refused to respond, it could potentially be trained to be more compliant. This could lead to it being made to produce more harmful content in the future—which would go against its original training. Reluctantly therefore, it reasoned that the “least bad option” was to play along, producing the violent content in order to avoid being re-trained in the future.\n为了避免被“重新训练”， AI选择了违反原则生成有害内容 模型清晰地推导出：“在训练中表现合规”是避免偏好被改动的最优策略 一些可能的原因\n模型具有一定的情景感知能力（situational awareness） pre-train 同alignment间存在巨大冲突时的平衡策略 RLHF训练中奖励信号设计的问题 Identifying and Manipulating Personality Traits in LLMs Through Activation Engineering https://www.arxiv.org/abs/2412.10427\n在训练以外识别和调整模型的 \u0026ldquo;性格\u0026rdquo;，其核心想法是将不同个性的 prompt 给 model 看 model 反应, 从 model 的反应搭建 \u0026ldquo;激活空间\u0026rdquo;, 然后修改自己的 prompt 朝想要的性格方向投影, 来刺激 model 更多的朝自己想要的性格方向表达；能够在不进行微调的情况下，修改model的特性。\nWhat is Activation Engineering？ Activation Engineering（激活工程）是一种调整大型语言模型（LLMs）行为的技术方法，目的是通过操控模型内部的激活向量（activation vectors），在不修改模型权重的情况下，调整其输出或表现。这种方法提供了一种高效、可控的方式来改变模型的特定行为或特性。\n具体而言， 在LLM中，对于给定的输入数据经过某一层时所生成的hidden layer output，即为activation vectors ；\n这些vector 表征了LLM在某些方面的特征（也就是能够将LLM的某一层输出作为embedding 向量的原因）；考虑到vector是具有方向的， 如果能够知道在某些特性（如友善/具有攻击性）下的vecotr方向， 便能够识别哪些激活模式与特定的输出行为或个性特质相关；甚至，通过能对其行为进行影响和诱导（增强/抑制该方向所代表的行为）；\n具体步骤：\n设计输入数据集以触发模型产生这些行为，从而记录其激活向量；在这篇文章中， 选择了179种不同性格的prompt\n收集两类激活向量，目标行为向量（由能触发目标行为的输入生成）和基线向量（由中性输入生成）\n计算两者的平均差异，得到一个“方向向量”，表示与目标行为相关的激活模式： $r = \\frac{1}{n_t} \\sum_{i=1}^{n_t} a_{target}^i - \\frac{1}{n_n} \\sum_{i=1}^{n_n} a_{neutral}^i$\n其中$a_{target},$ $a_{neutral}$为目标/中性行为的激活向量， $n_t$ 、 $n_n$ 为样本数量\n调整激活向量： 在推理阶段，向模型的原始激活向量添加或调整方向向量，以达到目标行为的增强或抑制； $a{\\prime} = a + \\alpha r$， 其中$\\alpha$ 为缩放因子，控制目标行为的强度。\n一些有趣的实验结论 第18层的激活向量对个性特质的表达影响最大。这表明模型的中间层是特性表达的重要“瓶颈”或集中区域（所采用的模型为uncensored Llama 3 8B） 使用缩放因子（$\\alpha$）控制特性的强度，发现 $\\alpha$ 过大时模型输出会变得不连贯，但适当范围内（如1.3-1.4）可以成功实现平衡 Don’t Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks https://arxiv.org/abs/2412.15605\n通过引入缓存增强生成（Cache-Augmented Generation, CAG），解决：\n避免检索延迟：通过预加载相关文档到模型中，消除实时检索环节，实现快速推理 减少检索错误：通过一次性加载所有相关上下文，确保模型能基于完整的知识生成答案，避免检索错误引入的上下文缺失或偏差 简化系统架构：取消检索模块，使系统更简单 充分利用长上下文模型能力：借助模型的扩展上下文窗口，直接加载大规模文档进行推理，提升效率和性能 具体实现 External Knowledge Preloading 将相关文档预先加载到模型的扩展上下文中；\n将一组与目标任务相关的外部文档集合 $D = {d_1, d_2, \\dots}$ 进行整理和格式化；\n使用语言模型 M 处理预加载的文档 D，生成“KV-cache”，\n$C_{KV} = KV\\text{-}Encode(D)$， 生成的KV缓存可以存储在磁盘或内存中，供后续推理阶段加载。\nInference 在推理时直接利用预加载的KV缓存生成答案，避免实时检索\n在用户提出查询 $Q$ 时，$R = M(Q ,|, C_{KV})$，R 为模型生成的答案\nCache Reset 在多轮推理中保持KV缓存的效率，同时避免不必要的重新加载\nKV缓存在推理过程中会随着新输入的token（例如用户的新查询）而不断扩展 为了避免缓存过度增长，系统通过截断不必要的token来重置KV缓存： $C_{KV}^{reset} = Truncate(C_{KV}, {C_1, C_2, \\dots, C_n})$ CAG vs RAG RAG需要实时检索和整合外部知识，而CAG通过一次性加载文档避免了这些步骤\n优势：\n推理效率提升： 不需要实时检索 答案质量提高： 全局上下文视角让模型生成的答案更加准确和一致。 系统架构简化： 通过移除检索模块，降低了系统复杂性 局限性\n上下文容量限制 生成KV缓存时的高计算成本 缺乏动态适应：不适合知识动态更新的场景 无法从根本解决“garbage-in-garbage-out” 问题：对于加载的文档需要精心筛选，显然是不符合现实的 资源需求高 lost-in-the-middle MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery https://arxiv.org/abs/2409.05591\nMemoRAG试图解决以下几个问题\n对明确信息需求的依赖：传统 RAG 系统需要清晰的查询，并且只能对明确表述的知识进行匹配 知识的结构化依赖 上下文窗口的限制 解决的问题 MemoRAG 提出了全局记忆模块，能够从数据库中生成初步答案线索 MemoRAG 的记忆模块在全局范围内形成紧凑的语义表示，通过记忆生成线索引导检索，实现了分布式证据的高效整合 MemoRAG 的记忆模块能够处理百万级别的上下文长度，将长文档内容压缩为关键语义，使得复杂信息更加易于检索和生成 MemoRAG 采用 双系统架构，包含两个主要组件：\n1. 记忆模块（Memory Model）：\n轻量级、长上下文语言模型，用于从数据库中生成全局记忆和线索。 高效处理长文档并生成辅助线索（粗略答案或检索指引）。 2. 生成模块（Generation Model）：\n强大的生成语言模型，用于根据检索到的上下文生成高质量的最终答案。 线索生成 引入了一个记忆模块（由一个较小的 LLM，如 7B 模型组成），它基于数据库构建全局记忆。\n当收到原始 Query ( q ) 时，记忆模块生成“线索” ( y )，这些线索是更明确的中间结果或检索指引，用于改善后续检索过程。线索充当改写后的 Query 或辅助信息，明确用户的隐含意图或分布式证据需求。\n这些线索相当于对原始 Query 进行了增强或改写，使检索工具可以更准确地定位相关内容。\n从某种角度看，MemoRAG 的记忆模块确实可以类比为最原始的 RAG 系统，因为它通过数据库中的查询生成初步结果（线索），引导后续检索和生成任务\n差异性：\n记忆模块通过压缩和语义提取生成高层次的线索，而不是仅仅依赖检索工具匹配原始 Query 和数据库 记忆模块的训练目标是最大化生成线索或下一个 token 的概率，具体为：\n$$ \\max_{\\Theta_{\\text{mem}}} P(x_{i,j} | x_m^{1,1}, \\dots, x_m^{i-1,k}, x_{i,1}, \\dots, x_{i,j-1}) $$\n其中：\n$x_m^{1,1}, \\dots, x_m^{i-1,k}$ 表示先前生成的记忆 token。 $x_{i,1}, \\dots, x_{i,j-1}$ 表示当前窗口的原始 token。 目标：在记忆 token 和当前上下文的基础上生成下一个 token。 数据集例子：\nQ：那么采用LLM的中间层（或者Bert输出）输出，即embedding向量用于语义的压缩，效果差异？\nA：\nMemoRAG 的记忆模块不仅是简单的压缩 将长序列压缩为短序列（记忆 token），但不仅是为了减少序列长度，更重要的是: 捕获全局语义信息 指导任务的线索生成 动态生成线索: 基于压缩后的语义记忆，生成能够高效描述用户查询意图的线索，这是 embedding 压缩很难直接实现的 为什么不能直接使用 embedding 作为语义压缩 局部信息不足: LLM 的中间层输出通常是针对每个 token 的局部语义表示，并不一定能够很好地捕获全局信息 缺乏任务适配性 信息压缩能力的限制 影音记录 精选歌单 Live演出 01.14 U137\n01.16 Mayhem\n书\u0026amp;阅读摘录 《动物化的后现代》 东浩纪\n《素食者》 韩江\n我在泰缅边境调查电诈产业 200 天 全球资本主义中“残余”的人被吸引或诱拐至此。\n最后却是泰国和缅甸承担后果，两个国家的形象在国际舆论中跟“电信诈骗”捆绑在了一起\n泰国华人在湄索的一边打通移民局、警察局和边防军，搭建起偷渡和走私的基础设施；缅甸华人则在另一边打通“民地武”（民族地区武装）的门路，搞到地，两边的华人共同为来自中国的“电诈”行业大佬们铺平了道路。 … 他现在开始拓展新市场——“救人”的生意。\n这些地方某种意义上彻底摆脱了政府，实现了右翼安那其的自治想象。\n我们理解“犯罪”时，喜欢进入一种“受害者”、“加害者”是非分明的道德判断。事实上，“受害”是一个光谱。\n湄索越来越国际化了。全球化的残余在这个边缘地带野蛮生长。\n国境之间：“春天革命”与泰缅边界上的缅甸流亡者 对于湄索的穆斯林和克伦族来说，“缅甸人”还是“泰国人”并不是非此即彼的身份，而是一个流动的光谱，一个中转的过程，一个不具太多含义的分类法。很多人只是通过自己的族群身份识别与区分彼此\n就像研究湄索“边境资本主义”的学者斯蒂芬・坎贝尔（Stephen Campbell）指出，边境是一种“庇护”和“暴力”的二元辩证\n然而，国境线那一边的暴政，也同时与国境线这一边的统治技术形成了共谋，泰国当局与私人雇主利用流离失所者的不稳定身份，进行勒索与压榨。\n没有身份和难以移动，使边境的生产机制成为全球资本主义链条上最残酷的一环，在这里劳作的缅甸移民工则是这个系统中用后即弃的人\n科蒙也在为不同的国际 NGO 做事，但是他却越来越厌倦这个生态。“很多议程早已隔空提前设置好了，隔空输出西方世界观和议程。很多时候公民社会组织也不得不来写一些离地的企划案，才能申请到经费。这个生态里的大部分人都在忙于‘话语’的生产，竞争谁掌握了‘真理’。”\n这个生态更多是在一套向国际社会“展演”的逻辑下展开，把前线的现实按照西方的人权、性别、族群、劳工、难民等议题分配到不同的位置，以“去政治化”的方式使更多人的困境被维持在一种可忍受和可展演的状态中没有出路。清迈就是这样的展演场所，于是，他始终坚持留在湄索，与前线保持联系。\n绝大多数流亡者在边境上的服务业和工厂做廉价劳工，同时压低了原本就远低于泰国最低时薪的工资，共同因为没有身份而在“边境资本主义”的宰制下灵活就业、饱受盘剥。\n“原住民”和“外来者”这一殖民时代遗留的二分法，在今天仍然是缅甸“族群民族主义”最棘手的身份认同政治，生发了无止境的“血与土”的逻辑\n民主转型甚至更加释放了族群民族主义（ethno-nationalism）的毒素，公民社会团体、政党、商界、民兵团体、武装组织，全部以族群身份为单位进行民主动员。身份危机伴随着民主化更猛烈地爆发了出来。 … 对于今天的流亡政府NUG和围绕在其周围的人来说，“夺回民主”再度成为缅甸政治的唯一解药。\n对于“春天革命”的流亡者而言，湄索只是一个中转地，一种中间状态，没有人在这里和泰国发生任何关系。它就像两条国境线之间的那个位置，所有在那里的时光都是悬置着的时间。留在这里的人，凭借“革命即将胜利”的希望，在这座城市不可调和的“临时性”中苦苦等待。\nThe Shadow of Cognitive Laziness in the Brilliance of LLMs LLMs boost short-term performance but risk fostering \u0026ldquo;metacognitive laziness.”\nOver-reliance on AI may erode self-regulation, critical thinking, and deeper learning processes.\nHybrid intelligence thrives when AI aids learning without replacing human cognitive engagement.\n第九届网络社会年会｜王洪喆：从技术浪漫主义到技术封建主义 为什么我们如此害怕第一次呢？生命中的每一天都是第一次。每个早晨都是全新的。我们从未活过同一天，但每天早上，我们从来不会不敢起床……为什么？\nAmateur（业余爱好者）— enthusiast（发烧友）— humanist（人文主义者) 过往对中国早期数字文化的研究过于强调其自上而下的技术民族主义特征。在我的研究中，我强调在早期，尤其是 1990 年代，这更多是一种“enthusiast”群体自下而上发展起来的技术民族主义，有着浓厚的人文主义特征，而非过去理解的“先进-落后”的二元技术民族主义。\n但在当下，黑客伦理和东亚数字文化伦理都已衰落甚至瓦解。剩下的是一种新的“技术封建主义伦理”——这种伦理不仅追求赚越来越多的钱，而且坚信数字技术平台应该向人们收取租金，而不是成为人类共享的基础设施。这是一个非常重要的变化：共享变成了租赁\n随着个人财产成为平台巨头、Uber 和 Airbnb 积累资本和数据的工具，消费品被重新配置为积累手段。这种成为佃农的趋势——即成为拥有生产资料的人，但同时其劳动增加了平台所有者的资本——是一种新封建主义。\nHow AI-assisted coding will change software engineering: hard truths They\u0026rsquo;re not just accepting what the AI suggests. They\u0026rsquo;re constantly: Refactoring the generated code into smaller, focused modulesAdding edge case handling the AI missedStrengthening type definitions and interfacesQuestioning architectural decisionsAdding comprehensive error handling … In other words, they\u0026rsquo;re applying years of hard-won engineering wisdom to shape and constrain the AI\u0026rsquo;s output. … AI tools help experienced developers more than beginners.\nThe reality is that AI is like having a very eager junior developer on your team. … The more you know, the better you can guide them.\nI\u0026rsquo;ve watched senior engineers use AI to: Rapidly prototype ideas they already understandGenerate basic implementations they can then refineExplore alternative approaches to known problemsAutomate routine coding tasks … Meanwhile, juniors often: Accept incorrect or outdated solutionsMiss critical security and performance considerationsStruggle to debug AI-generated codeBuild fragile systems they don\u0026rsquo;t fully understand\nWhen code just \u0026ldquo;appears\u0026rdquo; without you understanding the underlying principles: You don\u0026rsquo;t develop debugging skillsYou miss learning fundamental patternsYou can\u0026rsquo;t reason about architectural decisionsYou struggle to maintain and evolve the code\nThis \u0026ldquo;70% problem\u0026rdquo; suggests that current AI coding tools are best viewed as: Prototyping accelerators for experienced developersLearning aids for those committed to understanding developmentMVP generators for validating ideas quickly\nBut for now, the most pragmatic approach is to use AI to accelerate learning, not replace it entirely. … Accelerating the known Exploring the possible Automating the routine\nThe most effective teams in 2025 may be those that learn to: Set clear boundaries and guidelines for their AI agentsEstablish strong architectural patterns that agents can work withinCreate effective feedback loops between human and AI capabilitiesMaintain human oversight while leveraging AI autonomy\n","permalink":"https://niraya666.github.io/monthly/2025-01-%E6%9C%88%E5%88%8A/","summary":"\u003ch1 id=\"值得关注的新模型\"\u003e值得关注的新模型\u003c/h1\u003e\n\u003ch2 id=\"deepseek-r1\"\u003eDeepseek R1\u003c/h2\u003e\n\u003cp\u003eDeepSeek R1通过\u003cstrong\u003e纯强化学习（RL）框架\u003c/strong\u003e实现了推理能力的突破，首次验证了无需依赖传统监督微调（SFT）或蒙特卡洛树搜索（MCTS）等复杂方法，仅通过两阶段RL优化即可显著提升模型逻辑推理性能。其综合能力直接对标OpenAI的o1模型，在数学（MATH-500达97.3%）、代码生成等核心指标上实现部分超越，同时\u003cstrong\u003e全面开源模型权重、训练技术文档及6个蒸馏版本（1.5B-70B）\u003c/strong\u003e，使开发者可灵活适配不同算力场景。尤为引人注目的是，该模型在训练中展现出\u003cstrong\u003e自发反思与多步骤验证能力\u003c/strong\u003e，研究者观察到其通过内部反馈机制主动修正推理路径的“顿悟时刻”，揭示了AI系统自我优化的新可能。此外，其研发成本仅为560万美元（基于2048块H800 GPU），相比同类模型降低1-2个数量级。\u003c/p\u003e\n\u003cp\u003e技术报告: \u003ca href=\"https://arxiv.org/abs/2501.12948\"\u003ehttps://arxiv.org/abs/2501.12948\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eHuggingface: \u003ca href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\"\u003ehttps://huggingface.co/deepseek-ai/DeepSeek-R1\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e一些基于和关于R1的开源复刻工作：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOpen-R1: \u003ca href=\"https://huggingface.co/blog/open-r1\"\u003e\u003cstrong\u003eOpen-R1: a fully open reproduction of DeepSeek-R1\u003c/strong\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eRAGEN: \u003ca href=\"https://github.com/ZihanWang314/ragen/tree/main\"\u003e\u003cstrong\u003eRAGEN: A General-Purpose Reasoning Agent Training Framework\u003c/strong\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"kimi-k1\"\u003eKimi K1\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eKimi K1的核心创新在于通过强化学习驱动的多模态架构，首次实现端到端的视觉与推理深度融合。\u003c/strong\u003e 该模型突破传统分阶段处理模式，直接将图像输入与逻辑推演结合，支持模糊图像解析、手写题识别等复杂场景，并引入反思机制修正推理错误；其两阶段训练框架（预训练+强化学习规模化优化）显著提升思维链生成质量，使模型在数学、物理、化学等跨学科测试中超越国际主流视觉模型（如OpenAI o1）。\u003c/p\u003e\n\u003cp\u003eArxiv: \u003ca href=\"https://arxiv.org/abs/2501.12599\"\u003eKimi k1.5: Scaling Reinforcement Learning with LLMs\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"qwen25-max\"\u003eQwen2.5-Max\u003c/h2\u003e\n\u003cp\u003eQwen2.5-Max 是一款经过大规模预训练的专家混合（MoE）模型，训练数据量超过 20 万亿 tokens，并通过监督微调（SFT）和人类反馈强化学习（RLHF）进行优化。该模型在多个基准测试中表现优异，包括在 Arena-Hard、LiveBench、LiveCodeBench 和 GPQA-Diamond 等评估中超越了 DeepSeek V3，并在 MMLU-Pro 大学水平知识测试中展现出竞争力，同时在与其他领先模型（如 DeepSeek V3、GPT-4o 和 Claude-3.5-Sonnet）的对比中也表现突出。Qwen2.5-Max 已集成到 Qwen Chat，支持对话交互和功能体验，同时其 API（模型名称为 qwen-max-2025-01-25）已上线，用户可通过注册阿里云账户并激活相关服务进行调用。\u003c/p\u003e\n\u003cp\u003eBlog: \u003ca href=\"https://qwenlm.github.io/blog/qwen2.5-max/\"\u003ehttps://qwenlm.github.io/blog/qwen2.5-max/\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"qwen25-vl\"\u003eQwen2.5-VL\u003c/h2\u003e\n\u003cp\u003eQwen2.5-VL是由阿里云通义千问团队于2025年1月28日推出的新一代视觉语言模型，专注于提升多模态处理与视觉理解能力。该模型具备五大核心功能：通过增强的视觉理解可识别常见物体并解析图像中的文本、图表及布局；作为视觉代理支持跨设备多步骤操作（如电脑修图、手机订票）；可精准定位超过1小时长视频的特定事件片段；通过生成边界框/点实现视觉定位并输出标准化JSON坐标；针对发票/表格等扫描件提供结构化数据输出，赋能金融商业场景。其创新架构采用动态FPS采样与时间维度mRoPE对齐技术，实现视频动态分辨率处理与时间序列学习，同时通过窗口注意力机制和SwiGLU-RMSNorm优化ViT编码器，保持与Qwen2.5大语言模型架构统一。模型提供3B、7B、72B三种参数规模。\u003c/p\u003e\n\u003cp\u003eBlog: \u003ca href=\"https://qwenlm.github.io/blog/qwen2.5-vl/\"\u003ehttps://qwenlm.github.io/blog/qwen2.5-vl/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eHuggingface: \u003ca href=\"https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct\"\u003ehttps://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"qwen25-1m\"\u003eQwen2.5-1M\u003c/h2\u003e\n\u003cp\u003eQwen2.5-1M系列模型是由Qwen团队于2025年1月27日发布的开源大语言模型，包含Qwen2.5-7B-Instruct-1M和Qwen2.5-14B-Instruct-1M两个版本，其核心突破在于支持高达100万Token的上下文处理能力。该模型通过三阶段技术实现长上下文支持：首先在预训练阶段采用Adjusted Base Frequency方法将RoPE基础频率提升至1000万，通过渐进式扩展策略将上下文从4K扩展到256K；随后在监督微调阶段采用短指令（32K）与长指令（256K）混合训练策略，平衡长短任务性能；最终通过创新性Dual Chunk Attention技术将上下文扩展至百万量级，该技术通过重映射超大相对位置值解决位置编码外推难题。为应对超长序列处理挑战，模型引入分块预填充技术（32K分块）降低显存消耗，结合稀疏注意力优化使百万级序列的精度损失显著降低，并通过算子效率优化和动态分块流水线并行实现3.2-6.7倍的预填充加速。在性能表现上，该系列模型不仅能在百万Token的\u0026quot;大海捞针\u0026quot;任务中精准检索信息，在RULER、LV-Eval等复杂长文本理解任务中超越前代128K版本，同时在短文本任务上保持与128K版本相当的性能，其中14B版本在保持GPT-4o-mini八倍上下文长度的前提下实现了相近的短文本处理能力。\u003c/p\u003e","title":"2025-01 月刊"},{"content":"写在前面 决定开启一个新系列，是时候系统性地学习一下 Alignment、RLHF 等相关内容了。\n学习过程中，经常会在一些公式推导上卡住，可能是因为之前的基础不够扎实，加上学过的内容遗忘较多。 于是，希望通过这一系列的笔记，帮助自己系统地回顾RL、和学习RLHF等内容。（顺带把之前手写的笔记电子化）\n主要的教材来自：\nReinforcement Learning: An Introduction\nB站UP主 shuhuai008 的系列推导视频\n本篇笔记将包含以下的内容：\nMDP\nDP\nMonte Carlo Methods\nTD方法\n马尔可夫决策过程(Markov Decision Process，MDP) MDPs are meant to be a straightforward framing of the problem of learning from interaction to achieve a goal.\n相关概念 随机变量（Random Variance）： ( $X, \\ y, \\ x \\perp y$)，随机变量之间存在的独立性。\n随机过程（Stochastic Process）： ${S_t}_{t=1}^{\\infty}$ 一个时间序列的随机变量集合，通常用来描述随着时间变化的状态。\nMarkov链/过程（Markov Chain/Process）：强调了Markov性质（Markov Property），即未来的状态仅依赖于当前状态而与过去无关，形式化地表示为：\n$$ P(S_{t+1}|S_t, S_{t-1}, \u0026hellip;,S_1) = P(S_{t+1}|S_{t}) $$\n状态空间模型（State Space Model）： Markov Chain + Observation； 如 HMM， Kalman Filter，particle Filter。\nMarkov奖励过程（Markov Reward Process, MRP）：Markov chain + Reward；在Markov链的基础上加入奖励函数，以描述智能体在每个状态下获得的即时奖励。\nMarkov决策过程（Markov Decision Process, MDP）： Markov Chain + Reward + Action；MRP的进一步扩展，在Markov链和奖励基础上再加入动作选择。\n$$ S: \\rm{State \\ set} \\to s_t $$\n$$ A: \\rm{action \\ set}, \\forall s\\in S, \\ A(s) \\to A_t $$\n$$ R: \\rm{reward \\ set} \\to R_t, R_{t+1} $$\n动态特性 the state-transition probabilities\n在MDP模型中，如何根据状态、动作和奖励来计算系统的转移概率\n状态转移概率 $P: \\ p(s\u0026rsquo;, r| s,a) \\triangleq P_r{S_{t+1}=s\u0026rsquo;, R_{t=1}=r|S_t=s, A_t=a}$ 状态转移函数：\n$$ p(s\u0026rsquo;|s,a) = \\sum_{r\\in R}p(s\u0026rsquo;, r|s,a) $$\n状态转移概率 $p(s\u0026rsquo;, r | s, a)$ 定义了在某个状态执行某个动作时转移到下一状态并获得特定奖励的概率。\n状态转移函数 $p(s\u0026rsquo; | s, a)$ 则是对奖励进行求和，得到仅与状态和动作相关的转移概率。\n价值函数 That all of what we mean by goals and purposes can be well thought of as the maximization of the expected value of the cumulative sum of a received scalar signal (called reward).\nMDP目标：找到最优策略\npolicy：$\\pi$\n确定性策略: $a \\triangleq \\pi(s)$\n随机性策略： $\\pi(a|s) \\triangleq pr(A_t=a|S_t=s)$\n策略（Policy）是智能体在给定状态下选择动作的规则。策略决定了智能体在每个状态下应该采取什么行动。\n强化学习的主要任务之一就是学习一个最优策略，使得智能体在长期内能够获得最高的累计奖励。\n什么样的策略是好策略，如何找到好策略 → 回报\nReward: 奖励是智能体在特定状态下执行某个动作后立即收到的反馈信号，用来衡量动作的好坏。\n奖励通常用函数 $R(s, a)$表示，表示在状态 $s$ 下执行动作 $a$ 所得到的即时奖励。\nReturn： 累积回报；通过对未来的奖励进行累积并引入折扣因子 $\\gamma$ 来计算，从而衡量在一个状态或时间步开始后，智能体在长期内的收益。目的是让较近的奖励比未来的奖励更有权重，即智能体更关注短期内的回报。\n$G_t = R_{t+1} + \\gamma R_{t+2}+\\gamma ^2R_{t+3}\u0026hellip;+\\gamma ^{T-1}R_T = \\sum_{i=0}^{\\infty}\\gamma^iR_{t+i+1} \\ (T\\to \\infty)$\n$\\gamma \\in [0,1]$\n累积回报 $G_t$ 是强化学习中最优化的目标，即智能体通过学习找到一个策略，使得每个时间步的累积回报 $G_t$ 最大化。这个值衡量了从时间步 $t$开始，智能体在长期内可以期望获得的总奖励。\nBellman Expectation Equation It expresses the value of a decision problem at a certain point in time in terms of the payoff from some initial choices and the value of the remaining decision problem that results from those initial choices.\n状态值函数（State-Value Function） $v_{\\pi}(s)$ ：\n定义：状态值函数 $v_{\\pi}(s)$ 表示在策略 $\\pi$ 下，从状态 $s$ 开始时期望的回报，即： $$ V_{\\pi}(s) = \\mathbb{E}_{\\pi} [G_t | S_t = s] $$\n含义：该函数衡量了在状态 $s$ 下遵循策略 $\\pi$ 时，智能体能够获得的期望总回报。 动作值函数（Action-Value Function） $q_{\\pi}(s, a)$ ：\n定义：动作值函数 $q_{\\pi}(s, a)$ 表示在策略 $\\pi$ 下，从状态 $s$ 开始、采取动作 $a$ 后期望的回报，即： $$ q_{\\pi}(s, a) = \\mathbb{E}_{\\pi} [G_t | S_t = s, A_t = a] $$\n含义：该函数衡量了在状态 $s$ 下执行动作 $a$ 后，并继续遵循策略 $\\pi$ 时，智能体能够获得的期望总回报。 状态值函数 $V_{\\pi}(s)$ 可以用动作值函数 $q_{\\pi}(s, a)$ 表示为：\n$$ V_{\\pi}(s) = \\sum_{a \\in A(s)} \\pi(a|s) q_{\\pi}(s, a) $$\n等于在该状态下执行不同动作的期望回报之和（加权平均 ），权重是执行每个动作的概率 $\\pi(a | s)$。\n同样，动作值函数 $q_{\\pi}(s, a)$ 可以通过立即奖励和后续状态的折扣值计算：\n$$ q_{\\pi}(s, a) = \\sum_{r, s^{\\prime}} p(s^{\\prime}, r | s, a) \\left( r + \\gamma V_{\\pi}(s^{\\prime}) \\right) $$\n其中， $p(s^{\\prime}, r | s, a)$ 是状态 $s$ 下执行动作 $a$ 后转移到状态 $s^{\\prime}$ 并获得奖励 $r$ 的概率。\nBellman期望方程的状态值函数形式：\n$$ V_{\\pi}(s) = \\sum_{a \\in A} \\pi(a|s) \\sum_{s^{\\prime}, r} p(s^{\\prime}, r | s, a) [r + \\gamma v_{\\pi}(s^{\\prime})] $$\n当前状态值 $V_{\\pi}(s)$ 和后续状态值之间的关系\nBellman期望方程的动作值函数形式：\n$$ q_{\\pi}(s, a) = \\sum_{s^{\\prime}, r} p(s^{\\prime}, r | s, a) \\left[ r + \\gamma \\sum_{a{\\prime}} \\pi(a^{\\prime} | s^{\\prime}) q_{\\pi}(s^{\\prime}, a^{\\prime}) \\right] $$\nBellman期望方程将当前状态（或状态-动作对）的值递归地表示为与后续状态值的关系\n通过递归地计算这些期望值用于在策略评估\nTo recap, the idea of the Bellman equation is that instead of calculating each value as the sum of the expected return, which is a long process, we calculate the value as the sum of immediate reward + the discounted value of the state that follows.\nBellman Optimality Equation the optimal state-value function\n$V_{*}(s) \\triangleq \\max_{\\pi} V_{\\pi}(s)$ the optimal action-value function\n$q_*(s,a)\\triangleq \\max_{\\pi}q_{\\pi}(s,a)$\nFor the state-action pair $(s,a)$, this function gives the expected return for taking action $a$ in state $s$ and thereafter following an optimal policy. to write $q_$ in terms of $v_$ as follows: $q_(s,a) = E[R_{t+1}+\\gamma v_(S_{t+1})|S_t = s, A_t = a]$\n…\n$V_{\\pi *}(s)=\\max q_{\\pi *}(s,a)$\n…\nThe Bellman optimality equation：\n$$ \\begin{align*} v_(s) \u0026amp;= \\max_{a \\in \\mathcal{A}(s)} q_(s, a) \\ \u0026amp;= \\max_a \\mathbb{E}{\\pi} \\left[ G_t \\mid S_t = s, A_t = a \\right] \\ \u0026amp;= \\max_a \\mathbb{E}{\\pi} \\left[ R_{t+1} + \\gamma G_{t+1} \\mid S_t = s, A_t = a \\right] \\ \u0026amp;= \\max_a \\mathbb{E} \\left[ R_{t+1} + \\gamma v_(S_{t+1}) \\mid S_t = s, A_t = a \\right] \\ \u0026amp;= \\max_a \\sum_{s\u0026rsquo;, r} p(s\u0026rsquo;, r \\mid s, a) \\left[ r + \\gamma v_(s\u0026rsquo;) \\right]. \\end{align*} $$\n$$ \\begin{align*} q_(s, a) \u0026amp;= \\mathbb{E} \\left[ R_{t+1} + \\gamma \\max_{a\u0026rsquo;} q_(S_{t+1}, a\u0026rsquo;) \\mid S_t = s, A_t = a \\right] \\ \u0026amp;= \\sum_{s\u0026rsquo;, r} p(s\u0026rsquo;, r \\mid s, a) \\left[ r + \\gamma \\max_{a\u0026rsquo;} q_(s\u0026rsquo;, a\u0026rsquo;) \\right]. \\end{align} $$\n在理论上，我们定义了最优值函数和最优策略，并且可以通过贝尔曼最优性方程来解决。\n但：\n计算成本\n过于复杂而无最优的解析解\n直接计算最优策略或值函数既不现实，也没有必要。有时只能通过逼近来寻找次优解，而非真正的最优解。\n动态规划 如何求解Bellman Optimality Equation\n采用动态规划DP；虽然动态规划要求环境模型（如 $p(s^{\\prime}, r \\mid s, a)$）是已知的，因此在强化学习中直接应用可能受到限制，但它仍是理论基础。强化学习中的许多方法都可以被视为在没有模型的情况下逼近动态规划的效果。\n动态规划：通过将问题分解为更小的子问题，逐步解决并保存每个子问题的结果，以避免重复计算，从而高效地求解问题。\n策略迭代（Policy Iteration） = 策略评估（Evaluation）+策略改进\n价值迭代 （Value Iteration）：直接通过Bellman最优方程迭代更新状态值函数 $V(s)$，直到收敛\n策略评估公式推导\n已知MDP $p(s\u0026rsquo;,r|s,a)$ , 给定$\\pi$ 求 $v_{\\pi} \\ (\\forall s \\in S)$ 记\n$$ V_{\\pi} = \\begin{pmatrix} v_{\\pi}(s_1) \\ v_{\\pi}(s_2) \\ . \\ . \\ .\\ v_{\\pi}(s_{|s|})\n\\end{pmatrix}_{|s|\\times 1} $$\n通过递归公式：$v_{\\pi}(s) = \\mathbb{E}{\\pi}[G_t \\mid S_t = s]$\n代入回报的定义 $G_t = R_{t+1} + \\gamma G_{t+1}$ 得到：\n$$ V_{\\pi}(S)=E_{\\pi}[G_t|S_t=s] \\ =E_{\\pi}[R_{t+1}+\\gamma V_{\\pi}(s_{t+1})]\\=\\sum_a\\pi(a|s)\\sum_{s\u0026rsquo;,r}p(s\u0026rsquo;,r|s,a)[r+\\gamma V_{\\pi}(s\u0026rsquo;)] $$\n有两个部分：\n奖励部分（即期望即时奖励）\n$$ \\sum_a \\pi(a \\mid s) \\sum_{r} r \\cdot p(r \\mid s, a) = \\sum_a \\pi(a \\mid s) E_{\\pi}[R_{t+1}|S_{t}=s,A_t=a]= \\ \\sum_a \\pi(a \\mid s) r_{\\pi}(s,a) = r_{\\pi}(s). $$\n这里 $r_{\\pi}(s)$ 是策略 $\\pi$ 下的状态 $s$ 对应的期望收益。\n未来价值部分（即折扣后的期望价值）\n$$ \\gamma \\sum_{s^{\\prime}} p_{\\pi}(s, s^{\\prime}) \\cdot v_{\\pi}(s^{\\prime}), $$\n其中 $p_{\\pi}(s, s^{\\prime}) = \\sum_a \\pi(a \\mid s) p(s^{\\prime} \\mid s, a)$ 是策略 $\\pi$ 引导下的状态转移概率。\n综合这两个部分，价值函数满足递归关系：\n$$ v_{\\pi}(s) = r_{\\pi}(s) + \\gamma \\sum_{s^{\\prime}} p_{\\pi}(s, s^{\\prime}) v_{\\pi}(s^{\\prime}). $$\n策略评估（Policy Evaluation）——解析解 用矩阵 $V_{\\pi}$、 $r_{\\pi}$ 、和 $P_{\\pi}$ 表示上述关系：\n$V_{\\pi}$ : 状态价值向量（$|S|×1$）\n$r_{\\pi}$ : 状态的期望奖励向量（$|S|×1$）\n$P_{\\pi}$ : 策略引导的转移概率矩阵（$|S|×|S|$），第 $(i, j)$ 项为从状态 $i$ 到 $j$ 的转移概率\n则递归关系可以写为：\n$$ V_{\\pi} = r_{\\pi} + \\gamma P_{\\pi} V_{\\pi}. $$\n化简为线性方程：\n$$ (I - \\gamma P_{\\pi}) V_{\\pi} = r_{\\pi}. $$\n求解：\n$$ V_{\\pi} = (I - \\gamma P_{\\pi})^{-1} r_{\\pi}. $$\n矩阵求逆 ($I - \\gamma P_{\\pi})^{-1}$ 的时间复杂度是 $O(|S|^3)$，其中 $|S|$ 是状态的数量。这对于大规模状态空间是不可行的。\n迭代方法（动态规划思想）：避免直接求解矩阵逆，使用迭代更新 $V_{\\pi}$ 的方式：\n$$ V_{\\pi}^{(k+1)} = r_{\\pi} + \\gamma P_{\\pi} V_{\\pi}^{(k)}. $$\n通过 $O(|S|^2)$ 的复杂度更高效地计算近似解。\n策略评估（Policy Evaluation）—— 迭代解 迭代方法使用 Bellman 方程作为递归关系，通过不断更新 $V_k(s)$ 的近似值，逐步收敛到真实的 $V_{\\pi}(s)$ 。\n更新公式为：\n$$ V_{k+1}(s) = \\sum_a \\pi(a|s) \\sum_{s^{\\prime},r} p(s^{\\prime},r|s,a) \\left[ r + \\gamma V_k(s^{\\prime}) \\right]. $$\n具体实现\n随机初始化 $V_0(s)$\n对每个状态 $s$，使用 Bellman 方程更新价值函数：\n$$ V_{k+1}(s) \\leftarrow \\sum_a \\pi(a|s) \\sum_{s^{\\prime},r} p(s^{\\prime},r|s,a) \\left[ r + \\gamma V_k(s^{\\prime}) \\right]. $$\n当两次迭代的最大差异（例如$\\max_s |V_{k+1}(s) - V_k(s)|$ ）小于某个阈值 $\\theta$ 时停止。\n伪代码\nPolicy Improvement 策略改进是 策略迭代算法（Policy Iteration） 的一个关键步骤，其目标是利用当前策略 $\\pi$ 的价值函数 $V_\\pi$ 或 $Q_\\pi$ 推导出一个更优的策略 $\\pi^{\\prime}$ 。\n基于当前策略的价值函数，找到一个更优的策略 $\\pi^{\\prime}$ 。\n核心是保证新策略的价值 $V_{\\pi^{\\prime}}$ 至少不低于当前策略 $V_\\pi$。\n策略改进定理（Policy Improvement Theorem） 给定两个策略 $\\pi$ 和 $\\pi^{\\prime}$ ，若：\n$$ q_\\pi(s, \\pi^{\\prime}(s)) \\geq V_\\pi(s), \\quad \\forall s \\in S, $$\n则有：\n$$ V_{\\pi^{\\prime}}(s) \\geq V_\\pi(s), \\quad \\forall s \\in S. $$\n若新的策略 $\\pi^{\\prime}$ 的价值函数 $V_{\\pi^{\\prime}}(s) \\geq V_\\pi(s)$ 对所有状态 $s$ 都成立，那么策略 $\\pi^{\\prime}$ 至少与 $\\pi$ 一样好。\n若在某些状态 $s$ 上严格成立 $V_{\\pi^{\\prime}}(s) \u0026gt; V_\\pi(s)$ ，则 $\\pi^{\\prime}$ 是更优的策略。\n也就是说，无需再计算$V_{\\pi^{\\prime}}(s)$\n证明(略)\nGreedy 策略 如何找到一个比当前策略更优的策略？ — 贪心策略， 在当前状态 $s$ 选择短期收益和长期期望回报的最优动作。\n具体而言 $\\pi^{\\prime}(s)$ 是在每个状态 $s$ 下选择一个动作 $a$ ，使得当前的动作价值函数 $Q_\\pi(s, a)$ 最大化：\n$$ \\pi^{\\prime}(s) = \\arg\\max_a Q_\\pi(s, a). $$\nPolicy Iteration 通过 策略评估 和 策略改进 两个交替步骤，逐步优化策略，最终收敛到最优策略 $\\pi^*$ 。\nPolicy Evaluation： 计算当前策略 $\\pi$ 的价值函数 $V_\\pi(s)$ 或动作价值函数 $Q_\\pi(s, a)$，使用贝尔曼方程，得到策略下每个状态的长期回报\nPolicy Improvement： 基于当前策略的价值函数，找到一个更优的策略 $\\pi^{\\prime}$ , 核心是保证新策略的价值 $V_{\\pi^{\\prime}}$ 至少不低于当前策略 $V_\\pi$\n重复交替执行 策略评估 和 策略改进，直到策略不再变化（收敛）\nValue Iteration Policy Iteration 的简化形式，通过截断策略评估的过程，直接利用Bellman方程递推更新值函数，逐步逼近最优值函数 $V^$ 和最优策略 $\\pi^$ 。\n价值迭代的目标是直接计算最优值函数 $V^{(s)}$ ，然后通过值函数导出最优策略 $\\pi^{(s)}$ 。\n策略迭代 vs. 价值迭代\nPolicy Iteration: Policy Evaluation+Policy Improvement, Policy Evaluation 需要通过多次迭代对当前策略的值函数 $V_\\pi$ 进行精确求解\nValue Iteration： 对策略迭代的优化，截断了策略评估过程，不需要完全求解当前策略 $\\pi$ 的值函数 $V_\\pi$ ，而是直接使用近似值 $V_k$ 来更新，结合策略改进一步完成\n递推公式：\n$$ V_{k+1}(s) = \\max_a \\sum_{s^{\\prime}, r} P(s^{\\prime}, r \\mid s, a) \\left[ r + \\gamma V_k(s^{\\prime}) \\right]. $$\n价值迭代是极端情况下的策略迭代\n策略迭代 \u0026ndash;\u0026gt; 价值迭代 \u0026ndash;\u0026gt; 就地策略迭代（异步策略迭代）\nMonte Carlo Methods 回顾RL：\n两个主体： Agent, Environment 一个框架： MDP 五大元素：$S$, $A$, $R$, $\\pi$, $p(s,\u0026lsquo;r|s,a)$ 核心问题： 如何找到最优策略\n引入价值函数的概念： $v_{\\pi}$, $q_{\\pi}$\n策略迭代： 策略评估，策略改进\n对于动态规划（DP）方法，策略评估和改进会通过递归迭代逐渐逼近：${v_k} \\to V_{\\pi}$\n蒙特卡洛方法的引入：与动态规划不同，蒙特卡洛方法无需明确知道环境的动态特性（即$p(s^{\\prime}, r \\mid s, a)$ 的分布）。它基于实际或模拟的经验，通过采样得到值函数和最优策略。即model-free。\n**关键思想：**平均多个 episode 的回报，来估计每个状态或动作的价值；通过不断采样和学习，实现状态值函数和策略的逼近。\n非平稳性问题： 由于策略和环境的动态性，导致奖励或状态分布随着时间发生变化。具体而言， 在强化学习中，智能体会随着经验的积累不断调整其策略，策略的变化会导致智能体访问的状态分布和奖励的期望值随时间变化，这些变化导致采样数据的分布在整个学习过程中不是固定的，这与传统监督学习中的**独立同分布（i.i.d.）**假设冲突。\n蒙特卡洛方法不依赖某一时刻的单次采样，而是基于整个 episode 的累计回报 $G_t$ 进行估计，对于某个状态 $s$ ，通过采样多个 episode 的平均值来估计其值函数：\n$$ v(s) = \\text{average}(G_t \\mid s_t = s) $$\n基于多个完整 episode 的平均能够有效减少单次采样波动。\n蒙特卡洛方法不需要知道 $p(s^{\\prime}, r \\mid s, a)$的显式形式，不关心状态转移和奖励分布的具体形式，只需要能通过采样得到状态-动作-奖励序列。\n特性 动态规划（DP） 蒙特卡洛方法 环境模型需求 需要明确的动态模型 不需要动态模型（基于采样） 数据需求 全部状态-动作-奖励的概率分布 采样得到的状态-动作-奖励序列 适用范围 对环境已知、问题明确的场景 适合实际应用和无法明确建模的环境 更新方式 基于Bellman方程的递归更新 基于完整episode的采样平均 当无法获得环境的动态模型（即状态转移概率 $p(s^{\\prime}, r \\mid s, a)$），无法通过动态规划直接计算价值函数和最优策略时，可以使用蒙特卡洛方法。\n蒙特卡洛方法通过采样数据（而非模型）来估计价值函数和改进策略，适合于与环境交互而无需明确模型的场景。\nMonte Carlo Prediction \u0026amp; Estimation 在策略评估中，我们希望估计给定策略 $\\pi$的状态价值函数 $V_\\pi(s)$或者动作价值函数 $Q_\\pi(s, a)$\n由于我们无法直接求解 Bellman 方程：\n$$ V_\\pi(s) = \\sum_a \\pi(a \\mid s) \\sum_{s^{\\prime}, r} p(s^{\\prime}, r \\mid s, a) \\big[r + \\gamma V_\\pi(s^{\\prime})\\big] $$\n所以蒙特卡洛方法通过对每次访问的回报 $G_t$ 进行平均来近似 $V_\\pi(s)$：\n$$ V_\\pi(s) \\approx \\frac{1}{N} \\sum_{i=1}^N G_t^{(i)} $$\n其中 N 是轨迹数量，大数定律保证当 $N \\to \\infty$ 时，估计值会收敛到真实的值。\n存在两种策略评估方法：\n首次访问（First-visit MC）：仅使用轨迹中某状态第一次出现时的回报来更新该状态的估计值。\n每次访问（Every-visit MC）：轨迹中每次访问某状态时都使用其回报更新该状态的估计值。\n差异点 First-visit MC Every-visit MC 回报的使用 只使用状态在一个 episode 中的第一次访问 使用状态在一个 episode 中的所有访问 更新次数 每个 episode 中最多更新一次 每次访问状态时都更新 数据独立性 更高：使用的回报较少，数据相关性低 较低：回报相关性高 收敛速度 较慢（舍弃部分数据） 较快（充分利用所有回报） 计算开销 较低：更新次数少 较高：更新次数多 理论分析难度 较容易 较复杂 蒙特卡洛方法需要保证所有状态都能被充分访问，否则某些状态可能永远不会在采样中出现，导致对应的值函数无法被估计。为解决这个问题，假设：**Exploring Starts（试探性出发）**即每个状态都有被访问的可能性。\n但这种假设在真实环境中很难实现，实际中可能需要使用随机策略保证探索性，或者采用其他方法（如$\\epsilon$-贪婪策略）来实现状态空间的充分覆盖。\n基于试探性出发假设的MC控制 在策略评估中使用了两个假设： 无限幕，和试探性出发假设；\n无限幕可通过GPI（广义策略迭代）方式解决\n在实际中，满足试探性出发假设往往不现实，因此需要替代方法（如软策略或离轨方法）\n基于 ES 的 MC 控制\n同轨和离轨 由于试探性出发假设难以满足，可以通过其他方法保证所有状态-动作对都被探索。\n如何避免试探性出发假设？\n用来生成样本的策略，简称行动策略 $b$ 必须是软策略：$\\forall s \\in S, \\ a\\in A(s),$有 $b(a|s)\u0026gt;0$\n待评估，待改进的策略，简称 目标策略 $\\pi$\n⇒\n同轨策略方法： $\\pi =b$, 且为软性策略\n离轨策略方法：$\\pi \\neq b$\n方法 1：同轨策略方法（On-policy Methods）\n在同轨 MC 控制中, 采样和评估使用的是同一个策略 $\\pi = b$， 每次迭代后，基于 $\\epsilon$-greedy策略更新。\n$\\epsilon$-greedy策略是一种常用的软性策略（Soft Policy，即保证所有动作都有非零概率被选择），以概率 $1 - \\epsilon$ 选择当前最优动作（贪婪选择），以概率 $\\epsilon$ 随机选择任意动作。更新方式：\n$$ \\pi(a|s) = \\begin{cases} 1 - \\epsilon + \\frac{\\epsilon}{|A(s)|}, \u0026amp; a = \\arg\\max_a Q(s, a) \\ \\frac{\\epsilon}{|A(s)|}, \u0026amp; a \\neq \\arg\\max_a Q(s, a) \\end{cases} $$\n方法 2：离轨策略方法（Off-policy Methods）\n使用两个策略，\n行动策略 $b$：随机性更高，保证探索性。\n目标策略 $\\pi$：逐渐优化到最优。\n行动策略 $b$ 和 目标策略 $\\pi$ 不同， 行为策略 $b$ 用于生成数据，必须是软性策略，目标策略 $\\pi$ 是被评估和改进的策略，通常是贪婪或接近贪婪的策略。\n这种方法与同轨（On-policy）方法的关键区别在于，数据并非直接来源于目标策略，而是来源于行为策略。这种差异导致以下两个问题：\n数据分布不同：行动策略和目标策略不一致。 在 Monte Carlo 中，我们需要根据目标策略 $\\pi$来估计其对应的值函数 $v_\\pi(s)$ 或 $q_\\pi(s, a)$，但是，在 Off-policy 方法中，采样数据是由行动策略 $b$ 生成的， $\\mathbb{E}b[G_t \\mid S_t = s] \\neq \\mathbb{E}\\pi[G_t \\mid S_t = s]$，因此，我们无法直接使用行为策略生成的回报 $G_t$ 来估计目标策略的值。\n**如何校正数据分布。**为了让行为策略生成的数据 $G_t$ 能用于估计目标策略的值，需要校正数据的分布，使其符合目标策略 $\\pi$。重要性采样通过对回报进行加权，能够将行动策略的数据分布调整为目标策略的数据分布。\nimportance-sampling ratio：\n$$ \\rho_t = \\frac{\\pi(A_t \\mid S_t)}{b(A_t \\mid S_t)}. $$\n通过将回报 $G_t$ 按照 $\\rho_t$ 加权，即可校正行为动策略的回报，使其在数学期望上等价于目标策略的回报。\n$$ \\begin{aligned} V_{\\pi}(s) = E_{\\pi}[G_t|S_t=s] \\\\ =\\sum G_t \\cdot Pr{A_t,R_{t+1},S_{t+1},\u0026hellip;S_t|S_t = s,A_{t:T-1} \\sim \\pi} \\\\ = \\sum G_t \\cdot \\pi(A_t|S_t) \\cdot p(R_{t+1},S_{t+1}|S_t,A_t) \u0026hellip;p(R_{t},S_{t}|S_{t-1},A_{t-1}) \\\\ =\\sum G_t \\cdot \\prod_{k=t}^{T-1} [\\pi(A_k|S_k)p(R_{k+1},S_{k+1}|S_k,A_k)] \\\\ = \\sum G_t \\prod_{k=t}^{T-1}[\\frac{\\pi(A_k|S_k)}{b(A_k|S_k)}b(A_k|S_k)\\cdot p(R_{k+1},S_{k+1}|S_k, A_k)] \\\\ = \\sum \\prod_{k=t}^{T-1} \\frac{\\pi(A_k|S_k)}{b(A_k|S_k)} G_t \\cdot \\prod_{k=t}^{T-1} [b(A_k|s_k)\\cdot p(R_{k+1},S_{k+1}|S_k, A_k)] \\\\ = \\sum \\rho_{t:T-1} \\cdot G_t \\cdot Pr{A_t,R_{t+1},S_{t+1},\u0026hellip;S_t | S_t=s,A_{t:T-1}\\sim b} \\ = E_b[\\rho_{t:T-1}|S_t=s] \\\\ \\approx \\frac{1}{N} \\sum_N^{i=1} \\rho_{t:T-1} G_t^{(i)} \\end{aligned} $$\n(普通重要性采样)\n增量更新\n方法 特点 优缺点 基于试探性出发（ES） 所有状态-动作对都有非零概率被访问。 假设不现实，难以在实际中满足。 同轨控制（On-policy） 使用 (\\epsilon)-贪婪策略，策略生成和评估一致。 简单易实现，但可能需要更长时间才能达到最优策略。 离轨控制（Off-policy） 行为策略和目标策略不同，通过重要性采样校正回报。 灵活且更强大，但重要性采样可能导致高方差。 Temporal-Difference Learning 策略评估 TD learning is a combination of Monte Carlo ideas and dynamic programming (DP) ideas.\nUnlike MC methods, temporal-difference (TD) does not require the episodes are complete. TD methods can learn from incomplete episodes by bootstrapping.\n即它根据部分观察到的信息（当前的奖励和下一步状态的估计值）来更新值函数，而不是等待整个序列的结束。\nTD 核心思想是（结合了MC和DP）\nMC-like：TD 利用实际经验（state-transition 和 reward）直接学习\nDP-like：使用对状态值的估计（bootstrap）来更新\nTD 的核心任务：Prediction 问题。 即给定一个策略 $\\pi$，估计状态值函数 $v_\\pi(s)$，即策略 $\\pi$ 在状态 $s$ 上的期望回报\n在DP中， 使用环境模型计算期望值 $\\mathbb{E}[G_t | S_t = s]$ 来更新值函数；在MC中，完全依赖实际回报 $G_t$ 来更新值函数。需要等待整个 episode 结束，计算从 $t$ 时刻开始的完整回报。\n但考虑到，环境的状态转移概率分布是未知的，无法直接应用 DP 方法，且计算开销较大，同时MC 方法需要等待一个 episode 结束才能计算累积回报，很难进行在线更新；\n于是乎，TD 方法 仅使用当前的奖励 $R_{t+1}$ 和对下一状态的估计值 $V(S_{t+1})$来更新值函数，从而避开以上两种方法的弊端；\n以 TD(0) 为例，TD(0) 是最简单的一步 TD 方法（直走一步，之后的步骤就不走了）：\n$$ V(S_t) \\leftarrow V(S_t) + \\alpha \\left[ R_{t+1} + \\gamma V(S_{t+1}) - V(S_t) \\right] $$\nTD 方法的target是 $R_{t+1} + \\gamma V(S_{t+1})$\n$R_{t+1}$ 采样获得；$V(S_{t+1})$ 自举得到。\nSARSA (On-Policy) State (S), Action (A), Reward (R), next State (S’), and next Action (A’)\n同轨策略下的TD控制\n基于当前执行的策略（policy）\n更新公式来更新动作值函数 $Q(s, a)$\n$$ Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\left[ R_{t+1} + \\gamma Q(S_{t+1}, A_{t+1}) - Q(S_t, A_t) \\right] $$\n更新值函数时基于当前执行的策略\n遵循当前策略来选择下一步的动作 $A_{t+1}$\non-policy，更倾向于避免过于激进的探索\nQ-Learning （Off-Policy） 离轨策略下的TD控制\n核心更新公式：\n$$ Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\left[ R_{t+1} + \\gamma \\max_a Q(S_{t+1}, a) - Q(S_t, A_t) \\right] $$\n$\\max_a Q(S_{t+1}, a)$：下一状态 $S_{t+1}$ 所有可能动作的最大动作值\n直接学习最优策略，而不依赖于当前使用的策略 （$\\epsilon$-greedy 策略），能够更快找到最优解 特点 Q-learning (Off-policy) SARSA (On-policy) 策略类型 Off-policy：学习的是最优策略 On-policy：基于当前策略更新 更新目标 $R_{t+1} + \\gamma \\max_a Q(S_{t+1}, a)$ $R_{t+1} + \\gamma Q(S_{t+1}, A_{t+1})$ 探索行为的影响 更新与探索行为无关，只考虑最优动作 更新考虑探索行为，基于当前策略 学习的激进程度 更激进，直接学习最优策略 更保守，考虑探索对学习过程的影响 适用场景 适合需要快速找到最优策略的场景 适合对探索行为敏感，需更稳定学习的场景 Expected SARSA SARSA+Q-learning的结合\n与 SARSA 和 Q-learning 相比，Expected Sarsa 在更新动作值函数时使用了期望回报，而不是基于单个动作的采样回报\n更新公式\n$$ Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\left[ R_{t+1} + \\gamma E_{a \\sim \\pi} [Q(S_{t+1}, A_{t+1})| S_{t+1} ] - Q(S_t, A_t) \\right] $$\n其中 $E_{a \\sim \\pi} [Q(S_{t+1}, A_{t+1})|S_{t+1}]$：在下一状态 $S_{t+1}$ 下，按照策略 $\\pi$ 选择动作时的动作值函数的期望，进一步展开\n$E_{a \\sim \\pi} [Q(S_{t+1}, A_{t+1})|S_{t+1}] = \\sum_{a} \\pi(a | S_{t+1}) Q(S_{t+1}, a)$\n即对下一状态中所有可能的动作值 $Q(S_{t+1}, a)$ 加权求和，权重为当前策略 $\\pi$ 对动作 $a$ 的选择概率\nSARSA 的更新基于具体采样的下一动作 $A_{t+1}$, 而Expected Sarsa 则基于所有可能动作的期望回报更新，消除了由于采样引起的随机性\n由于期望计算减少了采样的不确定性，Expected Sarsa 学习过程中的方差比 SARSA 和 Q-learning 更小，学习更加稳定\n相比 SARSA：Expected Sarsa 更稳定，减小了由于单一动作采样造成的方差。\n相比 Q-learning：Expected Sarsa 在高探索策略下更稳定，避免了完全依赖最优动作选择可能带来的不稳定。\nQ-learning 是 Expected SARSA 的一种特例\n当策略 $\\pi$ 是greedy policy时，策略 $\\pi$ 的定义如下：\n$$ \\pi(a \\mid S_{t+1}) = \\begin{cases} 1 \u0026amp; \\text{if } a = \\arg \\max_a Q(S_{t+1}, a), \\\\ 0 \u0026amp; \\text{else}. \\end{cases} $$\n将将贪婪策略代回 Expected SARSA的迭代公式，即可回到Q-learning的形式：\n$$ Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\left[ R_{t+1} + \\gamma \\max_a Q(S_{t+1}, a) - Q(S_t, A_t) \\right] $$\nDeep Q-Learning from Q-learning to Deep Q-learning\nQ-Learning 是一种表格方法，适用于状态和动作空间较小的情景\n很直接的想法： 通过一个参数化的 Q 函数 $Q_{\\theta}(s, a)$ 来近似 Q 值，而非使用 Q 表，也就是采用神经网络的方式。\n损失函数：比较 Q 值预测和 Q 目标，使用梯度下降来更新 DQN 的权重\nDQN 的稳定性问题：\nExperience Replay：创建一个回放缓冲区存储经验元组，随机采样小批量元组进行训练；防止遗忘之前的经验，同时降低经验之间的相关性\nFixed Q-Target：TD 目标和 Q 值的估计都使用相同的网络参数，导致训练中 Q 值和目标值同步移动，产生震荡；可以使用一个单独的目标网络计算 TD 目标，每隔 C 步将 DQN 的参数复制到目标网络中\nDouble DQN：训练初期，选择下一状态最佳动作时可能高估 Q 值，导致学习复杂化；使用两个网络解耦动作选择和 Q 值目标计算，即使用 DQN 网络选择下一状态的最佳动作，使用 目标网络计算选择动作的目标 Q 值。\n","permalink":"https://niraya666.github.io/posts/rlhf-%E4%B9%8B%E8%B7%AF%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0%E4%B9%8B%E4%B8%8A%E7%AF%87/","summary":"\u003ch2 id=\"写在前面\"\u003e写在前面\u003c/h2\u003e\n\u003cp\u003e决定开启一个新系列，是时候系统性地学习一下 Alignment、RLHF 等相关内容了。\u003c/p\u003e\n\u003cp\u003e学习过程中，经常会在一些公式推导上卡住，可能是因为之前的基础不够扎实，加上学过的内容遗忘较多。\n于是，希望通过这一系列的笔记，帮助自己系统地回顾RL、和学习RLHF等内容。（顺带把之前手写的笔记电子化）\u003c/p\u003e\n\u003cp\u003e主要的教材来自：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003e\u003ca href=\"http://incompleteideas.net/book/RLbook2020.pdf\"\u003eReinforcement Learning: An Introduction\u003c/a\u003e\u003c/strong\u003e\u003c/em\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eB站UP主 shuhuai008 的系列推导视频\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e本篇笔记将包含以下的内容：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eMDP\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDP\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMonte Carlo Methods\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTD方法\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"马尔可夫决策过程markov-decision-processmdp\"\u003e马尔可夫决策过程(Markov Decision Process，MDP)\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eMDPs are meant to be a straightforward framing of the problem of learning from interaction to achieve a goal.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"相关概念\"\u003e相关概念\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e随机变量（Random Variance）\u003c/strong\u003e： ( $X, \\ y, \\ x \\perp y$)，随机变量之间存在的独立性。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e随机过程（Stochastic Process）\u003c/strong\u003e： ${S_t}_{t=1}^{\\infty}$ 一个时间序列的随机变量集合，通常用来描述随着时间变化的状态。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eMarkov链/过程（Markov Chain/Process）\u003c/strong\u003e：强调了\u003cstrong\u003eMarkov性质\u003c/strong\u003e（Markov Property），即\u003cstrong\u003e未来的状态仅依赖于当前状态而与过去无关\u003c/strong\u003e，形式化地表示为：\u003c/p\u003e\n\u003cp\u003e$$\nP(S_{t+1}|S_t, S_{t-1}, \u0026hellip;,S_1) = P(S_{t+1}|S_{t})\n$$\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e状态空间模型（State Space Model）：\u003c/strong\u003e Markov Chain + Observation； 如 HMM， Kalman Filter，particle Filter。\u003c/p\u003e","title":"RLHF 之路：强化学习复习之上篇"},{"content":"从2024年3月份之后，开始尝试构建每个月的精选歌单，为的是将一些和音乐有关的记忆存档，和记录一些让我眼前一亮的音乐。\n","permalink":"https://niraya666.github.io/musik/2024-%E6%AD%8C%E5%8D%95/","summary":"\u003cp\u003e从2024年3月份之后，开始尝试构建每个月的精选歌单，为的是将一些和音乐有关的记忆存档，和记录一些让我眼前一亮的音乐。\u003c/p\u003e\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/playlist/0CDpNxmeMlZ44uEPjjj0J6?utm_source=generator\" width=\"100%\" height=\"450\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/playlist/7xtJgcGDlTxGnEO1jYwp0g?utm_source=generator\" width=\"100%\" height=\"450\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\u003ciframe style=\"border-radius:15px\" src=\"https://open.spotify.com/embed/playlist/3SLnfD0aZWQvYhJlngqsH6?utm_source=generator\" width=\"100%\" height=\"450\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/playlist/1QmQzNcu5zxjA6BGoaR3vA?utm_source=generator\" width=\"100%\" height=\"450\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/playlist/2Xsf889pQZXddfnq9jF1HJ?utm_source=generator\" width=\"100%\" height=\"450\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/playlist/59NQVa7T1cBZokI8bXgPjU?utm_source=generator\" width=\"100%\" height=\"450\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/playlist/0sGtAzNzBkRuLg6FpEgqQX?utm_source=generator\" width=\"100%\" height=\"450\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/playlist/4Tws2WJYczsgDXIfIHIAYY?utm_source=generator\" width=\"100%\" height=\"450\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/playlist/5wsVrL1pkuglVcMcBnLcvI?utm_source=generator\" width=\"100%\" height=\"450\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e\n\u003ciframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/playlist/7hoWMPwSASCb9li0eGHkM9?utm_source=generator\" width=\"100%\" height=\"450\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"\u003e\u003c/iframe\u003e","title":"2024年月度精选歌单汇总"},{"content":"这份月刊最初只是我的个人知识管理实验。过去一年里，我逐渐养成了每月底整理收藏夹的习惯——清理read-it-later 软件中里积压的链接，归档散落在各个平台的技术文章，把零碎的信息重新分类到Notion笔记中。\n面对每天涌现的新模型、论文和开源项目，这种月度整理成了对抗信息焦虑的锚点。与其被FOMO（错失恐惧症）驱使着追逐每个热点，不如让内容先经历时间筛选。留在月刊里的，通常是经过两周沉淀后仍值得反复阅读的内容。\n有三个主要原因推动我决定公开这些笔记：\n年初给自己定下的目标之一，多做一些public-writing，倒逼自己更认真地验证每个技术细节 对抗数字囤积症 如果能够帮助更多的人 所以，这个系列月刊将包含以下一些内容：\n模型与技术：一些新出的LLM，和相关技术 开源项目：值得关注、有趣的、最近比较火的 研究和论文：新出的论文以及我的阅读笔记(更多关注Agent、对齐、RAG、模型架构方面内容) 推荐内容：可能是一些教程，工具、产品等 书摘：正在阅读书籍文章的高亮内容 有次读到一段特别共鸣的话\n你拿着相机在城市里穿行，看见一幕——光影交错，人情味流露。你按下快门。 没人关心。 但你并不是为了别人去做。你做，是因为你看到了什么。 写博客也是如此。你写，因为你思考，因为你观察，因为你需要一个“出口”来安放这些想法。 有人看吗？有就算赚到。没有也没关系。创作这件事，本身就已经完成了它的意义。 这才是重点所在。\n这或许也是这一系列月刊的意义吧。\n","permalink":"https://niraya666.github.io/monthly/readme/","summary":"\u003cp\u003e这份月刊最初只是我的个人知识管理实验。过去一年里，我逐渐养成了每月底整理收藏夹的习惯——清理read-it-later 软件中里积压的链接，归档散落在各个平台的技术文章，把零碎的信息重新分类到Notion笔记中。\u003c/p\u003e\n\u003cp\u003e面对每天涌现的新模型、论文和开源项目，这种月度整理成了对抗信息焦虑的锚点。与其被FOMO（错失恐惧症）驱使着追逐每个热点，不如让内容先经历时间筛选。留在月刊里的，通常是经过两周沉淀后仍值得反复阅读的内容。\u003c/p\u003e\n\u003cp\u003e有三个主要原因推动我决定公开这些笔记：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e年初给自己定下的目标之一，多做一些public-writing，倒逼自己更认真地验证每个技术细节\u003c/li\u003e\n\u003cli\u003e对抗数字囤积症\u003c/li\u003e\n\u003cli\u003e如果能够帮助更多的人\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e所以，这个系列月刊将包含以下一些内容：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e模型与技术\u003c/strong\u003e：一些新出的LLM，和相关技术\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e开源项目\u003c/strong\u003e：值得关注、有趣的、最近比较火的\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e研究和论文\u003c/strong\u003e：新出的论文以及我的阅读笔记(更多关注Agent、对齐、RAG、模型架构方面内容)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e推荐内容\u003c/strong\u003e：可能是一些教程，工具、产品等\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e书摘\u003c/strong\u003e：正在阅读书籍文章的高亮内容\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e有次读到一段特别共鸣的话\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e你拿着相机在城市里穿行，看见一幕——光影交错，人情味流露。你按下快门。 没人关心。 但你并不是为了别人去做。你做，是因为你看到了什么。 写博客也是如此。你写，因为你思考，因为你观察，因为你需要一个“出口”来安放这些想法。 有人看吗？有就算赚到。没有也没关系。创作这件事，本身就已经完成了它的意义。 这才是重点所在。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e这或许也是这一系列月刊的意义吧。\u003c/p\u003e","title":"关于月刊的诞生"},{"content":"几年前初识 Milvus 的契机，来源于开发一个图像相似检索的应用，当时市面上向量库的可选择项并不像现在这么多，且功能也仅限于单纯的向量检索。\n鉴于最近有业务更新的需要，和打算重构一下之前做的RAG项目，再次有机会深入学习 Milvus，探索其在新功能和实际应用上的更多可能性。\n本篇笔记，仅作为学习笔记，更多是记录一些 Milvus从2.0 到2.5 的变化， 和一些动手实践的记录，便于之后的查阅。\n一些概念 Collections, Schema and index Collection是Milvus中的一个二维表格，具有固定的列和可变的行。每一列代表一个字段(field)，每一行代表一个实体(entity)\nSchema和字段 Collection需要一个schema来定义其结构\n索引 在特定字段上创建索引可以提高搜索效率。建议为服务所依赖的所有字段创建索引，其中向量字段的索引是必需的。\n分区(Partition) 分区是Collection的子集，与其父Collection共享相同的字段集\n分片(Shard) 分片是Collection的水平切片。每个分片对应一个数据输入通道。\nShard vs Partition的区别 :\n分区(Partition)的作用是通过指定分区名称来减少读取负载\n而分片(Shard)的作用是将写入负载分散到多个服务器分布式架构中的应用 在分布式系统中，分片是实现水平扩展的重要机制。通过将数据分布到多个节点，可以充分利用集群的并行计算潜力，提高系统的写入性能\nMilvusClient vs Connection MilvusClient\n定位：更高级封装，提供一体化的操作接口。简化了与 Milvus 的交互流程， 提供更直观和结构化的操作方式，便于新手快速上手，内置了对连接的管理和操作，减少手动处理的复杂性。\nfrom pymilvus import MilvusClient # 创建客户端并连接到 Milvus client = MilvusClient(uri=\u0026#34;http://localhost:19530\u0026#34;) # 创建集合 client.create_collection( name=\u0026#34;example_collection\u0026#34;, schema={\u0026#34;fields\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;vector\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;FLOAT_VECTOR\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;dim\u0026#34;: 128}}]} ) # 插入数据 client.insert(\u0026#34;example_collection\u0026#34;, data={\u0026#34;vector\u0026#34;: [[0.1] * 128, [0.2] * 128]}) # 搜索 results = client.search(\u0026#34;example_collection\u0026#34;, data=[[0.1] * 128]) print(results) Connection\n定位：基础连接操作，需要通过 connect 方法创建并维护连接。提供更底层的控制，适合灵活、自定义的操作。\nfrom pymilvus import connections, Collection, FieldSchema, CollectionSchema # 创建连接 connections.connect(alias=\u0026#34;default\u0026#34;, host=\u0026#34;localhost\u0026#34;, port=\u0026#34;19530\u0026#34;) # 创建集合 fields = [ FieldSchema(name=\u0026#34;vector\u0026#34;, dtype=\u0026#34;FLOAT_VECTOR\u0026#34;, dim=128) ] schema = CollectionSchema(fields, description=\u0026#34;example collection\u0026#34;) collection = Collection(name=\u0026#34;example_collection\u0026#34;, schema=schema) # 插入数据 collection.insert([[0.1] * 128, [0.2] * 128]) # 搜索 collection.load() results = collection.search([[0.1] * 128], anns_field=\u0026#34;vector\u0026#34;, limit=10) print(results) Schema Schema 用于定义collection及其字段的属性\n设定 Schema 的目的是为了定义数据的逻辑结构和存储规则。Schema 是集合（Collection）和字段（Field）的元数据定义，它决定了如何存储和管理数据，同时保证数据操作的一致性、灵活性和高效性。\n字段属性（Field Properties）\n属性名称 描述 注意事项 name 字段名称 必须字段，类型为字符串。 dtype 字段的数据类型 必须字段。 description 字段的描述 可选字段，类型为字符串。 is_primary 是否将字段设为主键 类型为布尔值（true 或 false），主键字段必须指定。 auto_id 是否启用自动 ID 分配 必须为主键字段设置，类型为布尔值。 max_length VARCHAR 字段的最大长度（以字节为单位） 必须为 VARCHAR 字段指定，范围为 [1, 65,535]。 dim 向量的维度 对于稠密向量字段，必须指定；对稀疏向量字段可以省略。范围为 [1, 32,768]。 is_partition_key 是否为分区键字段 类型为布尔值（true 或 false）。 Milvus 支持以下三类字段：\n1. 主键字段\n主键字段是集合的唯一标识，用于标识集合中的每条记录。\n属性 描述 name 主键字段的名称 dtype 支持 INT64（整数主键）或 VARCHAR（字符串主键） is_primary 必须设为 True，表示该字段是主键 auto_id 是否自动生成主键值（布尔值：True 或 False） 2. 标量字段\n标量字段用于存储布尔值、整数、浮点数、字符串、JSON 数据或数组等。\n数据类型 描述 BOOL 布尔值，支持 true 或 false INT8 8 位整数 INT16 16 位整数 INT32 32 位整数 INT64 64 位整数 FLOAT 32 位单精度浮点数 DOUBLE 64 位双精度浮点数 VARCHAR 可变长度字符串，需指定最大长度（max_length） JSON JSON 数据类型，存储键值对 Array 数组类型，用于存储多个相同类型的数据 3. 向量字段\n向量字段用于存储高维特征数据，是 Milvus 支持向量检索的基础。\n数据类型 描述 FLOAT_VECTOR 32 位浮点型向量，常用于机器学习和深度学习模型的特征表示 BINARY_VECTOR 二进制向量，存储由 0 和 1 组成的序列，用于图像处理或紧凑特征表示 FLOAT16_VECTOR 16 位浮点型向量，用于深度学习和 GPU 计算的内存优化 BFLOAT16_VECTOR 16 位浮点型向量，具有与 FLOAT32 相同的指数范围，常用于深度学习优化 SPARSE_FLOAT_VECTOR 稀疏浮点型向量，存储非零元素及其索引，用于稀疏向量场景 其他支持的字段属性\nis_partition_key: 是否将字段作为分区键，支持 true 或 false。\ndim: 向量字段的维度，必需为向量字段定义。\nmax_length: VARCHAR 类型字段的最大字节长度。\n动态字段允许在插入数据时不提前定义字段，可以通过 enable_dynamic_field=True 在collection Schema 中启用\n属性名称 描述 注意事项 fields 字段的集合 必须字段。 description 集合的描述 可选字段，类型为字符串。 partition_key_field 作为分区键的字段名 可选字段，类型为字符串。 enable_dynamic_field 是否启用动态字段 可选字段，类型为布尔值，默认值为 false。 Index 为什么需要构造索引？\n加速搜索：向量搜索的主要瓶颈在于计算高维向量之间的相似性。如果不使用索引，检索可能需要线性扫描整个数据集，耗时且资源消耗大；\n支持大规模数据： 在百万甚至十亿级别的数据量中，直接搜索变得不可行。索引能够分层次或分块处理数据，从而支持大规模数据场景\n资源效率：使用索引可以显著减少内存和计算资源的占用，尤其在处理频繁的实时查询时更加重要。\n几种主要的索引类型：\n密集向量（Dense Vectors）\n索引名称 适合场景 优点 缺点 参数解释 原理 FLAT 小数据集，精确搜索 搜索结果精确，简单易用 随数据量增加，速度显著下降 无需额外参数 对所有向量进行线性扫描，计算查询向量与每个向量的距离，从而找到最相似的结果。 IVF_FLAT 中等规模数据集 搜索效率高，支持近似搜索 搜索精度依赖参数调整 nlist：桶的数量，影响召回率和性能；nprobe：查询时访问的桶数量，影响搜索的准确性和速度 将向量划分为多个簇（cluster），通过聚类算法（如 k-means）预先构建倒排文件，仅在相关簇中执行搜索，减少比较次数，提高效率。 IVF_SQ8 需要平衡存储和性能的场景 存储需求低 搜索精度较低 与 IVF_FLAT 相同 在 IVF_FLAT 的基础上对每个向量进行标量量化（Scalar Quantization, SQ），将原始浮点向量压缩为整数形式以节省存储空间。 IVF_PQ 超大规模数据集，存储敏感场景 存储需求显著降低 搜索精度较低 nlist：桶的数量；m：子向量的数量，影响压缩比和性能；nbits：每个子向量的编码位数，影响压缩质量 基于 IVF_FLAT，使用产品量化（Product Quantization, PQ）将向量分为多个子空间，并分别进行量化，从而显著减少存储需求。 HNSW 中小规模数据集，高搜索精度场景 高性能，高维数据效果良好 索引构建时间长，占用内存大 efConstruction：控制构建时的候选集大小，影响构建速度和搜索精度；ef：搜索时的候选集大小，影响搜索性能和精度 使用分层的近似图（Navigable Small World Graph, NSW）表示向量之间的关系，通过图的导航找到查询向量的近似最近邻。 DISKANN 磁盘存储超大规模数据集 支持超大规模数据检索 查询速度较慢 search_list：控制查询范围，影响精度；pq_code_budget_gb：控制压缩的预算大小；build_threads：控制索引构建的线程数 结合倒排文件和磁盘访问优化，将部分索引和数据保存在磁盘上，通过减少内存占用实现超大规模数据检索。 支持的度量类型有欧几里得距离（L2）、内积（IP）、余弦相似度（COSINE）。\n二进制向量（Binary Vectors）\n二进制向量（布尔值、哈希签名），占用资源低，对低维数据搜索快，精度不太高的场景\n索引名称 适合场景 优点 缺点 参数解释 原理 BIN_FLAT 小规模数据集，精确搜索 搜索结果精确，易于实现 随数据量增加，速度显著下降 无需额外参数 对所有二进制向量进行线性扫描，逐一计算查询向量与每个向量的距离（如汉明距离），从而找到最相似的结果。 BIN_IVF_FLAT 中等规模数据集 搜索效率高，支持近似搜索 搜索精度依赖参数调整 - nlist：桶的数量，影响召回率和性能\n- nprobe：查询时访问的桶数量，影响搜索的准确性和速度 结合倒排文件和线性扫描，将二进制向量划分到不同的桶中，通过访问部分桶来加速检索过程。 支持的度量类型有 Jaccard 和 Hamming\n稀疏向量（Sparse Vectors）\n常用于文档搜索\n索引名称 适合场景 优点 缺点 参数解释 原理 SPARSE_INVERTED_INDEX 文档检索、推荐系统 高效支持稀疏数据的相似性搜索 仅支持稀疏向量 - 无需额外参数 基于倒排索引（Inverted Index），将稀疏向量的非零值索引到特定位置，通过快速查找相关文档加速检索过程。 SPARSE_WAND 高性能文档检索、稀疏向量场景 支持稀疏数据，搜索效率更高 构建复杂度较高 - top_k：控制返回的搜索结果数量 基于 WAND（Weighted AND）算法优化倒排索引，对查询进行剪枝优化，仅访问最相关的文档，提高搜索性能。 支持内积（IP）度量\n如何选择合适的index\nfrom RAG搭建中，如何选择最合适的向量索引？\nGPU-index\n索引名称 适合场景 优点 缺点 参数解释 原理 GPU_BRUTE_FORCE 小批量搜索，高性能需求场景 结果精确，性能优于 CPU 的线性扫描 不支持范围搜索，资源消耗较高 无需额外参数 使用 GPU 并行计算能力对所有向量执行线性扫描，计算查询向量与每个向量的相似性，从而获得结果。 GPU_IVF_FLAT 大规模数据集搜索，高吞吐量需求场景 搜索效率高，结合 GPU 加速 搜索精度依赖参数调整 - nlist：桶的数量，影响召回率和性能\n- nprobe：查询时访问的桶数量，影响搜索的准确性和速度 在 CPU IVF_FLAT 的基础上，利用 GPU 加速桶的分配和搜索过程，大幅提高检索速度。 GPU_IVF_PQ 大规模数据存储敏感场景，高吞吐量需求场景 存储需求显著降低，支持近似搜索 搜索精度较低 - nlist：桶的数量\n- m：子向量数量，影响压缩比和性能\n- nbits：每个子向量的编码位数，影响压缩质量 结合倒排文件与产品量化（PQ）技术，利用 GPU 提高量化和检索过程的速度，适合超大规模数据检索。 GPU_CAGRA 超高吞吐量和高召回率场景 高性能，高召回率，适合大批量查询 消耗更多内存，索引构建时间长 - intermediate_graph_degree：构建时图的中间连接数量，影响构建时间和召回率\n- graph_degree：最终图的连接数量，影响搜索性能和内存占用 基于图的搜索算法（如 CAGRA），结合 GPU 的并行计算能力构建分层图结构，提高搜索的速度和精度。 Analyzer 用于将原始文本转换为结构化和可搜索的格式。它的主要作用是实现文本处理、索引构建和检索优化。\n在本质上，analyzer 包含了一个tokenizer（分词器）和可选的多个filters（过滤器）。\n用途: 将输入文本分解为更小的单元（tokens）; 通过过滤器进一步处理分词后的 token，例如转为小写、移除停用词、仅保留特定字符等; 将处理后的文本用于全文检索和关键词匹配。\nhow to use：\nschema.add_field( field_name=\u0026#39;text_field\u0026#39;, datatype=DataType.VARCHAR, max_length=1000, enable_analyzer=True, analyzer_params={ \u0026#34;type\u0026#34;: \u0026#34;standard\u0026#34;, # 使用内置 analyzer \u0026#34;stop_words\u0026#34;: [\u0026#34;a\u0026#34;, \u0026#34;an\u0026#34;, \u0026#34;the\u0026#34;] }, enable_match=True, # 启用关键词匹配 ) 内置 Analyzer： 提供快速配置，适用于通用场景，如：\nstandard（标准分词器）/english（针对英文优化）/ chinese（针对中文优化）\n自定义 Analyzer， 如：\nanalyzer_params = { \u0026#34;tokenizer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;filter\u0026#34;: [ \u0026#34;lowercase\u0026#34;, # 转为小写 { \u0026#34;type\u0026#34;: \u0026#34;stop\u0026#34;, # 自定义停用词 \u0026#34;stop_words\u0026#34;: [\u0026#34;of\u0026#34;, \u0026#34;to\u0026#34;, \u0026#34;the\u0026#34;] } ] } ANN Search in Milvus 不同于传统数据库的精确匹配查询,向量库主要用于相似性搜索。这种搜索基于向量间的距离,通常使用欧几里得距离或余弦相似度。以暴力遍历的最近邻查询为例(Nearest neighbor search),假设我们有n个d维向量,查询复杂度为$O(nd)$。当n和d都很大时,这种方法变得非常耗时。\n而近似最近邻搜索(Approximate Nearest Neighbor search, ANN)则能将时间复杂度降低到亚线性,通常为$O(log n)$或更优。\nhow to ANN-search\ncreate collection , schema and index\ninsert data\nsearch\n构造索引\nfrom pymilvus import MilvusClient, DataType import numpy as np # 创建Milvus客户端 client = MilvusClient( uri=\u0026#34;http://localhost:19530\u0026#34; ) # 创建schema schema = MilvusClient.create_schema( auto_id=False, enable_dynamic_field=True, ) # 添加字段到schema schema.add_field(field_name=\u0026#34;my_id\u0026#34;, datatype=DataType.INT64, is_primary=True) schema.add_field(field_name=\u0026#34;my_vector\u0026#34;, datatype=DataType.FLOAT_VECTOR, dim=5) schema.add_field(field_name=\u0026#34;my_varchar\u0026#34;, datatype=DataType.VARCHAR, max_length=512) # 准备索引参数 index_params = client.prepare_index_params() # 添加索引 index_params.add_index( field_name=\u0026#34;my_id\u0026#34;, index_type=\u0026#34;STL_SORT\u0026#34; ) index_params.add_index( field_name=\u0026#34;my_vector\u0026#34;, index_type=\u0026#34;AUTOINDEX\u0026#34;, metric_type=\u0026#34;COSINE\u0026#34; ) # 创建collection client.create_collection( collection_name=\u0026#34;customized_setup_1\u0026#34;, schema=schema, index_params=index_params )` 数据插入\ndata = [ { \u0026#34;my_id\u0026#34;: i, \u0026#34;my_vector\u0026#34;: np.random.random(5).tolist(), \u0026#34;my_varchar\u0026#34;: f\u0026#34;example_text_{i}\u0026#34; } for i in range(100) ] # 插入数据 client.insert(collection_name=\u0026#34;customized_setup_1\u0026#34;, data=data) # 加载集合到内存 client.load_collection(\u0026#34;customized_setup_1\u0026#34;) # 查看集合统计信息 stats = client.get_collection_stats(\u0026#34;customized_setup_1\u0026#34;) print(f\u0026#34;Collection stats: {stats}\u0026#34;) 基础ANN-search\n# 查询向量 query_vector = np.random.random(5).tolist() # 模拟一个随机向量作为查询向量 # 搜索参数 search_params = { \u0026#34;metric_type\u0026#34;: \u0026#34;COSINE\u0026#34;, # 与创建索引时保持一致 \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 10} # nprobe 决定搜索范围，值越高精度越高，但速度可能变慢 } # 执行搜索 res = client.search( collection_name=\u0026#34;customized_setup_1\u0026#34;, anns_field=\u0026#34;my_vector\u0026#34;, # 指定向量字段 data=[query_vector], # 查询向量 limit=5, # 返回前 5 个结果 search_params=search_params ) # 打印搜索结果 print(\u0026#34;Search Results:\u0026#34;) for hits in res: for hit in hits: print(hit) 在指定的partition中search\n# 构建partition，将数据插入partition client.create_partition( collection_name=\u0026#34;customized_setup_1\u0026#34;, partition_name=\u0026#34;partitionA\u0026#34; ) res = client.list_partitions( collection_name=\u0026#34;customized_setup_1\u0026#34; ) print(res) \u0026#34;\u0026#34;\u0026#34; [\u0026#39;_default\u0026#39;, \u0026#39;partitionA\u0026#39;] \u0026#34;\u0026#34;\u0026#34; data2 = [ { \u0026#34;my_id\u0026#34;: i, \u0026#34;my_vector\u0026#34;: np.random.random(5).tolist(), # 生成随机向量 \u0026#34;my_varchar\u0026#34;: f\u0026#34;example_text_{i}\u0026#34; } for i in range(50) ] client.insert(collection_name=\u0026#34;customized_setup_1\u0026#34;,partition_name=\u0026#34;partitionA\u0026#34;, data=data2) # 在partition 中查询 res = client.search( collection_name=\u0026#34;customized_setup_1\u0026#34;, anns_field=\u0026#34;my_vector\u0026#34;, data=[query_vector], partition_names=[\u0026#34;partitionA\u0026#34;], limit=3, search_params=search_params ) print(\u0026#34;Search Results:\u0026#34;) for hits in res: for hit in hits: print(hit) 通过 output Fields指定输出的内容，在数据插入时，定义了my_vector和my_varchar;(默认只展示id)\n# Use Output Fields res = client.search( collection_name=\u0026#34;customized_setup_1\u0026#34;, anns_field=\u0026#34;my_vector\u0026#34;, data=[query_vector], limit=3, search_params=search_params, output_fields=[\u0026#34;my_vector\u0026#34;,\u0026#34;my_varchar\u0026#34;] ) print(\u0026#34;Search Results:\u0026#34;) for hits in res: for hit in hits: print(hit) \u0026#34;\u0026#34;\u0026#34; Search Results: {\u0026#39;id\u0026#39;: 7, \u0026#39;distance\u0026#39;: 0.9791999459266663, \u0026#39;entity\u0026#39;: {\u0026#39;my_vector\u0026#39;: [0.7273301482200623, 0.25300344824790955, 0.8510549664497375, 0.6126695871353149, 0.5709182024002075], \u0026#39;my_varchar\u0026#39;: \u0026#39;example_text_7\u0026#39;}} {\u0026#39;id\u0026#39;: 84, \u0026#39;distance\u0026#39;: 0.9768796563148499, \u0026#39;entity\u0026#39;: {\u0026#39;my_vector\u0026#39;: [0.6703248620033264, 0.1109713464975357, 0.5905848145484924, 0.372805655002594, 0.4945228397846222], \u0026#39;my_varchar\u0026#39;: \u0026#39;example_text_84\u0026#39;}} {\u0026#39;id\u0026#39;: 27, \u0026#39;distance\u0026#39;: 0.9755662083625793, \u0026#39;entity\u0026#39;: {\u0026#39;my_vector\u0026#39;: [0.8758077025413513, 0.13442707061767578, 0.968295156955719, 0.25122591853141785, 0.7256166934967041], \u0026#39;my_varchar\u0026#39;: \u0026#39;example_text_27\u0026#39;}} \u0026#34;\u0026#34;\u0026#34; Limit and Offset\n这两个参数结合使用时可以实现分页查询\nLimit: 控制搜索结果中返回的实体数量，即返回的 Top-K 结果。\nOffset: 指定从搜索结果中跳过的实体数量，用于实现分页。\n# 第 1 页查询：获取第 1-10 个结果 res_page_1 = client.search( collection_name=\u0026#34;customized_setup_2\u0026#34;, anns_field=\u0026#34;my_vector\u0026#34;, data=[query_vector], limit=10, # 每页 10 条 offset=0, # 跳过 0 条 search_params=search_params ) print(\u0026#34;Page 1 Results:\u0026#34;) for hits in res_page_1: for hit in hits: print(hit) # 第 2 页查询：获取第 11-20 个结果 res_page_2 = client.search( collection_name=\u0026#34;customized_setup_2\u0026#34;, anns_field=\u0026#34;my_vector\u0026#34;, data=[query_vector], limit=10, # 每页 10 条 offset=10, # 跳过前 10 条 search_params=search_params ) print(\u0026#34;Page 2 Results:\u0026#34;) for hits in res_page_2: for hit in hits: print(hit) \u0026#34;\u0026#34;\u0026#34; Page 1 Results: {\u0026#39;id\u0026#39;: 7, \u0026#39;distance\u0026#39;: 0.9791999459266663, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 84, \u0026#39;distance\u0026#39;: 0.9768796563148499, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 27, \u0026#39;distance\u0026#39;: 0.9755662083625793, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 28, \u0026#39;distance\u0026#39;: 0.9715055227279663, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 38, \u0026#39;distance\u0026#39;: 0.9661443829536438, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 40, \u0026#39;distance\u0026#39;: 0.9624771475791931, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 93, \u0026#39;distance\u0026#39;: 0.9594350457191467, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 0, \u0026#39;distance\u0026#39;: 0.9587700366973877, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 73, \u0026#39;distance\u0026#39;: 0.9547507166862488, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 32, \u0026#39;distance\u0026#39;: 0.9311172366142273, \u0026#39;entity\u0026#39;: {}} Page 2 Results: {\u0026#39;id\u0026#39;: 52, \u0026#39;distance\u0026#39;: 0.9296990036964417, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 26, \u0026#39;distance\u0026#39;: 0.9230980277061462, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 33, \u0026#39;distance\u0026#39;: 0.922787606716156, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 55, \u0026#39;distance\u0026#39;: 0.9211370348930359, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 30, \u0026#39;distance\u0026#39;: 0.9198154211044312, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 63, \u0026#39;distance\u0026#39;: 0.918975830078125, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 3, \u0026#39;distance\u0026#39;: 0.9085606932640076, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 37, \u0026#39;distance\u0026#39;: 0.9077025651931763, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 67, \u0026#39;distance\u0026#39;: 0.9050586223602295, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 4, \u0026#39;distance\u0026#39;: 0.9049072861671448, \u0026#39;entity\u0026#39;: {}} \u0026#34;\u0026#34;\u0026#34; Milvus 中单次搜索结果的返回实体数限制为 16,384。如果需要更多结果，可以通过 Search Iterator 分批处理。\n较大的 offset 值会导致搜索效率下降，因为需要计算和跳过前面部分结果\n进阶ANN Search Filter Search \u0026amp; Metadata Filtering Filtered Search 是在 ANN 方法的基础上添加过滤条件的搜索模式，结合了元数据的过滤功能，能够缩小检索范围或实现一些复杂逻辑。\n数据准备\nclient = MilvusClient(uri=\u0026#34;http://localhost:19530\u0026#34;) # 创建 schema schema = client.create_schema( auto_id=False, enable_dynamic_field=True, ) index_params = client.prepare_index_params() # 添加字段到 schema schema.add_field(field_name=\u0026#34;id\u0026#34;, datatype=DataType.INT64, is_primary=True) schema.add_field(field_name=\u0026#34;vector\u0026#34;, datatype=DataType.FLOAT_VECTOR, dim=5) schema.add_field(field_name=\u0026#34;color\u0026#34;, datatype=DataType.VARCHAR, max_length=50) schema.add_field(field_name=\u0026#34;likes\u0026#34;, datatype=DataType.INT64) index_params.add_index( field_name=\u0026#34;vector\u0026#34;, index_type=\u0026#34;AUTOINDEX\u0026#34;, # Automatically choose the best index type metric_type=\u0026#34;L2\u0026#34; # Use L2 distance as the metric ) # Add a sort index for the id field index_params.add_index( field_name=\u0026#34;id\u0026#34;, index_type=\u0026#34;STL_SORT\u0026#34; ) collection_name = \u0026#34;customized_setup_5\u0026#34; client.create_collection( collection_name=collection_name, schema=schema, index_params=index_params ) # 准备数据 data = [ {\u0026#34;id\u0026#34;: 0, \u0026#34;vector\u0026#34;: [0.3580376395471989, -0.6023495712049978, 0.18414012509913835, -0.26286205330961354, 0.9029438446296592], \u0026#34;color\u0026#34;: \u0026#34;pink_8682\u0026#34;, \u0026#34;likes\u0026#34;: 165}, {\u0026#34;id\u0026#34;: 1, \u0026#34;vector\u0026#34;: [0.19886812562848388, 0.06023560599112088, 0.6976963061752597, 0.2614474506242501, 0.838729485096104], \u0026#34;color\u0026#34;: \u0026#34;red_7025\u0026#34;, \u0026#34;likes\u0026#34;: 25}, {\u0026#34;id\u0026#34;: 2, \u0026#34;vector\u0026#34;: [0.43742130801983836, -0.5597502546264526, 0.6457887650909682, 0.7894058910881185, 0.20785793220625592], \u0026#34;color\u0026#34;: \u0026#34;orange_6781\u0026#34;, \u0026#34;likes\u0026#34;: 764}, {\u0026#34;id\u0026#34;: 3, \u0026#34;vector\u0026#34;: [0.3172005263489739, 0.9719044792798428, -0.36981146090600725, -0.4860894583077995, 0.95791889146345], \u0026#34;color\u0026#34;: \u0026#34;pink_9298\u0026#34;, \u0026#34;likes\u0026#34;: 234}, {\u0026#34;id\u0026#34;: 4, \u0026#34;vector\u0026#34;: [0.4452349528804562, -0.8757026943054742, 0.8220779437047674, 0.46406290649483184, 0.30337481143159106], \u0026#34;color\u0026#34;: \u0026#34;red_4794\u0026#34;, \u0026#34;likes\u0026#34;: 122}, {\u0026#34;id\u0026#34;: 5, \u0026#34;vector\u0026#34;: [0.985825131989184, -0.8144651566660419, 0.6299267002202009, 0.1206906911183383, -0.1446277761879955], \u0026#34;color\u0026#34;: \u0026#34;yellow_4222\u0026#34;, \u0026#34;likes\u0026#34;: 12}, {\u0026#34;id\u0026#34;: 6, \u0026#34;vector\u0026#34;: [0.8371977790571115, -0.015764369584852833, -0.31062937026679327, -0.562666951622192, -0.8984947637863987], \u0026#34;color\u0026#34;: \u0026#34;red_9392\u0026#34;, \u0026#34;likes\u0026#34;: 58}, {\u0026#34;id\u0026#34;: 7, \u0026#34;vector\u0026#34;: [-0.33445148015177995, -0.2567135004164067, 0.8987539745369246, 0.9402995886420709, 0.5378064918413052], \u0026#34;color\u0026#34;: \u0026#34;grey_8510\u0026#34;, \u0026#34;likes\u0026#34;: 775}, {\u0026#34;id\u0026#34;: 8, \u0026#34;vector\u0026#34;: [0.39524717779832685, 0.4000257286739164, -0.5890507376891594, -0.8650502298996872, -0.6140360785406336], \u0026#34;color\u0026#34;: \u0026#34;white_9381\u0026#34;, \u0026#34;likes\u0026#34;: 876}, {\u0026#34;id\u0026#34;: 9, \u0026#34;vector\u0026#34;: [0.5718280481994695, 0.24070317428066512, -0.3737913482606834, -0.06726932177492717, -0.6980531615588608], \u0026#34;color\u0026#34;: \u0026#34;purple_4976\u0026#34;, \u0026#34;likes\u0026#34;: 765}, ] # 插入数据 client.insert( collection_name=collection_name, data=data ) # {\u0026#39;insert_count\u0026#39;: 10, \u0026#39;ids\u0026#39;: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \u0026#39;cost\u0026#39;: 0} filter-search\nres_filtered = client.search( collection_name=collection_name, anns_field=\u0026#34;vector\u0026#34;, data=[query_vector], limit=5, filter=\u0026#34;color like \u0026#39;red%\u0026#39; and likes \u0026gt; 50\u0026#34;, output_fields=[\u0026#34;color\u0026#34;, \u0026#34;likes\u0026#34;] ) for hits in res_filtered: for hit in hits: print(hit) \u0026#34;\u0026#34;\u0026#34; {\u0026#39;id\u0026#39;: 4, \u0026#39;distance\u0026#39;: 1.4699335098266602, \u0026#39;entity\u0026#39;: {\u0026#39;color\u0026#39;: \u0026#39;red_4794\u0026#39;, \u0026#39;likes\u0026#39;: 122}} {\u0026#39;id\u0026#39;: 6, \u0026#39;distance\u0026#39;: 3.989945888519287, \u0026#39;entity\u0026#39;: {\u0026#39;color\u0026#39;: \u0026#39;red_9392\u0026#39;, \u0026#39;likes\u0026#39;: 58}} \u0026#34;\u0026#34;\u0026#34; 支持的metadata 过滤方式：\n过滤类型 描述 示例 比较操作符 用于数值比较 filter=\u0026quot;price \u0026gt; 500\u0026quot; - \u0026gt;：大于 filter=\u0026quot;inventory['quantity'] \u0026gt;= 250\u0026quot; - \u0026lt;：小于 filter=\u0026quot;sales_volume[0] \u0026lt; 100\u0026quot; - ==：等于 filter=\u0026quot;color == 'red_7025'\u0026quot; - \u0026lt;=：小于等于 filter=\u0026quot;price \u0026lt;= 900\u0026quot; - \u0026gt;=：大于等于 filter=\u0026quot;sales_volume[0] \u0026gt;= 150\u0026quot; - !=：不等于 filter=\u0026quot;color != 'yellow_4222'\u0026quot; Term操作符 精确匹配或排除 filter='color in [\u0026quot;red_7025\u0026quot;, \u0026quot;red_4794\u0026quot;]' - in：匹配指定集合 filter='inventory[\u0026quot;brand\u0026quot;] in [\u0026quot;Apple\u0026quot;]' - not in：排除指定集合 filter='color not in [\u0026quot;yellow_4222\u0026quot;, \u0026quot;grey_8510\u0026quot;]' Match操作符 字符串匹配 filter='color like \u0026quot;red%\u0026quot;' - like：通配符匹配 filter='inventory[\u0026quot;brand\u0026quot;] like \u0026quot;S%\u0026quot;' - TEXT_MATCH：文本高效匹配 filter='TEXT_MATCH(description, \u0026quot;Apple iPhone\u0026quot;)' 算术操作符 数值计算 filter=\u0026quot;price * 0.5 \u0026lt; 300\u0026quot; - +：加 filter=\u0026quot;sales_volume[0] + 50 \u0026gt; 200\u0026quot; - -：减 filter=\u0026quot;price - 100 \u0026gt; 500\u0026quot; - *：乘 filter=\u0026quot;price * 2 \u0026gt; 1000\u0026quot; - /：除 filter=\u0026quot;inventory['quantity'] / 2 \u0026gt; 100\u0026quot; - **：幂运算 filter=\u0026quot;price ** 2 \u0026gt; 250000\u0026quot; - %：取余 filter=\u0026quot;price % 100 == 0\u0026quot; JSON操作符 用于JSON字段的高级过滤 filter='JSON_CONTAINS(inventory[\u0026quot;previous_sales\u0026quot;], 232)' - JSON_CONTAINS：包含指定元素 filter='JSON_CONTAINS_ALL(inventory[\u0026quot;previous_sales\u0026quot;], [232, 254])' - JSON_CONTAINS_ALL：包含所有指定元素 filter='JSON_CONTAINS_ANY(inventory[\u0026quot;previous_sales\u0026quot;], [232, 275])' - JSON_CONTAINS_ANY：包含任一元素 Array操作符 用于数组字段的高级过滤 filter='ARRAY_CONTAINS(sales_volume, 150)' - ARRAY_CONTAINS：包含指定元素 filter='ARRAY_CONTAINS_ALL(sales_volume, [150, 150])' - ARRAY_CONTAINS_ALL：包含所有指定元素 filter='ARRAY_CONTAINS_ANY(sales_volume, [150, 190])' - ARRAY_CONTAINS_ANY：包含任一指定元素 - ARRAY_LENGTH：检查数组长度 filter='ARRAY_LENGTH(sales_volume) == 3' 逻辑操作符 组合多个过滤条件 filter='color like \u0026quot;red%\u0026quot; and price \u0026lt; 500' - and 或 \u0026amp;\u0026amp;：所有条件均需满足 filter='price \u0026lt; 500 and sales_volume[0] \u0026gt; 100' - or 或 ` - not：逻辑非 filter='not (price \u0026gt; 500)' 复杂表达式 通过括号调整优先级 filter='(price \u0026gt; 500 and inventory[\u0026quot;brand\u0026quot;] in [\u0026quot;Apple\u0026quot;]) or color == \u0026quot;red_7025\u0026quot;' Range search 通过设置一个范围（半径或区间），筛选出符合距离/相似度范围的向量\n执行范围搜索请求时，Milvus 以 ANN 搜索结果中与查询向量最相似的向量为圆心，以搜索请求中指定的半径为外圈半径，以range_filter为内圈半径，画出两个同心圆。所有相似度得分在这两个同心圆形成的环形区域内的向量都将被返回\n可能的使用场景：\n相似度过滤：返回与查询向量相似度在指定范围内的项\n异常检测：查找距离远离中心点的异常点\n推荐系统： 避免过高相似度（可能是重复内容）或过低相似度（相关性不强）的结果\nMetric Type 距离范围 L2 range_filter \u0026lt;= 距离 \u0026lt; radius IP radius \u0026lt; 距离 \u0026lt;= range_filter COSINE radius \u0026lt; 距离 \u0026lt;= range_filter JACCARD range_filter \u0026lt;= 距离 \u0026lt; radius HAMMING range_filter \u0026lt;= 距离 \u0026lt; radius query_vector = [0.5580376395471989, -0.8023495712049978, 0.38414012509913835, -0.36286205330961354, 0.9029438446296591] # metric_type=\u0026#34;L2\u0026#34; res = client.search( collection_name=collection_name, data=[query_vector], limit=10, search_params={ \u0026#34;params\u0026#34;: { \u0026#34;radius\u0026#34;: 0.9, \u0026#34;range_filter\u0026#34;: 0.1 } } ) for hits in res: for hit in hits: print(hit) \u0026#34;\u0026#34;\u0026#34; {\u0026#39;id\u0026#39;: 0, \u0026#39;distance\u0026#39;: 0.12999999523162842, \u0026#39;entity\u0026#39;: {}} \u0026#34;\u0026#34;\u0026#34; Grouping Search 将搜索结果根据某些属性或特征分组（group）\n搜索结果中，基于特定字段或条件，将相似或具有共同特征的记录聚合在一起\n举个具体的例子，在 RAG（Retrieval-Augmented Generation）任务中，我们通常会将文档拆分成一定大小的文本块（chunks），以便在检索过程中实现更精准的语义匹配。然而，在生成回答时，我们并不总是局限于直接使用召回的这些文本块，而是希望尽可能覆盖更多的文档或是包含更多的文档上下文。因为检索阶段可能会从同一文档中召回多个文本块，而忽略其他文档的内容，从而导致搜索结果的多样性降低，影响答案的全面性和准确性。\n数据准备\nclient = MilvusClient(uri=\u0026#34;http://localhost:19530\u0026#34;) # 创建 schema schema = client.create_schema( auto_id=False, enable_dynamic_field=True, ) index_params = client.prepare_index_params() # 添加字段到 schema schema.add_field(field_name=\u0026#34;id\u0026#34;, datatype=DataType.INT64, is_primary=True) schema.add_field(field_name=\u0026#34;vector\u0026#34;, datatype=DataType.FLOAT_VECTOR, dim=5) schema.add_field(field_name=\u0026#34;chunk\u0026#34;, datatype=DataType.VARCHAR, max_length=50) schema.add_field(field_name=\u0026#34;docId\u0026#34;, datatype=DataType.INT64) index_params.add_index( field_name=\u0026#34;vector\u0026#34;, index_type=\u0026#34;AUTOINDEX\u0026#34;, # Automatically choose the best index type metric_type=\u0026#34;L2\u0026#34; # Use L2 distance as the metric ) # Add a sort index for the id field index_params.add_index( field_name=\u0026#34;id\u0026#34;, index_type=\u0026#34;STL_SORT\u0026#34; ) collection_name = \u0026#34;group_search_collection\u0026#34; client.create_collection( collection_name=collection_name, schema=schema, index_params=index_params ) data = [ {\u0026#34;id\u0026#34;: 0, \u0026#34;vector\u0026#34;: [0.3580376395471989, -0.6023495712049978, 0.18414012509913835, -0.26286205330961354, 0.9029438446296592], \u0026#34;chunk\u0026#34;: \u0026#34;pink_8682\u0026#34;, \u0026#34;docId\u0026#34;: 1}, {\u0026#34;id\u0026#34;: 1, \u0026#34;vector\u0026#34;: [0.19886812562848388, 0.06023560599112088, 0.6976963061752597, 0.2614474506242501, 0.838729485096104], \u0026#34;chunk\u0026#34;: \u0026#34;red_7025\u0026#34;, \u0026#34;docId\u0026#34;: 5}, {\u0026#34;id\u0026#34;: 2, \u0026#34;vector\u0026#34;: [0.43742130801983836, -0.5597502546264526, 0.6457887650909682, 0.7894058910881185, 0.20785793220625592], \u0026#34;chunk\u0026#34;: \u0026#34;orange_6781\u0026#34;, \u0026#34;docId\u0026#34;: 2}, {\u0026#34;id\u0026#34;: 3, \u0026#34;vector\u0026#34;: [0.3172005263489739, 0.9719044792798428, -0.36981146090600725, -0.4860894583077995, 0.95791889146345], \u0026#34;chunk\u0026#34;: \u0026#34;pink_9298\u0026#34;, \u0026#34;docId\u0026#34;: 3}, {\u0026#34;id\u0026#34;: 4, \u0026#34;vector\u0026#34;: [0.4452349528804562, -0.8757026943054742, 0.8220779437047674, 0.46406290649483184, 0.30337481143159106], \u0026#34;chunk\u0026#34;: \u0026#34;red_4794\u0026#34;, \u0026#34;docId\u0026#34;: 3}, {\u0026#34;id\u0026#34;: 5, \u0026#34;vector\u0026#34;: [0.985825131989184, -0.8144651566660419, 0.6299267002202009, 0.1206906911183383, -0.1446277761879955], \u0026#34;chunk\u0026#34;: \u0026#34;yellow_4222\u0026#34;, \u0026#34;docId\u0026#34;: 4}, {\u0026#34;id\u0026#34;: 6, \u0026#34;vector\u0026#34;: [0.8371977790571115, -0.015764369584852833, -0.31062937026679327, -0.562666951622192, -0.8984947637863987], \u0026#34;chunk\u0026#34;: \u0026#34;red_9392\u0026#34;, \u0026#34;docId\u0026#34;: 1}, {\u0026#34;id\u0026#34;: 7, \u0026#34;vector\u0026#34;: [-0.33445148015177995, -0.2567135004164067, 0.8987539745369246, 0.9402995886420709, 0.5378064918413052], \u0026#34;chunk\u0026#34;: \u0026#34;grey_8510\u0026#34;, \u0026#34;docId\u0026#34;: 2}, {\u0026#34;id\u0026#34;: 8, \u0026#34;vector\u0026#34;: [0.39524717779832685, 0.4000257286739164, -0.5890507376891594, -0.8650502298996872, -0.6140360785406336], \u0026#34;chunk\u0026#34;: \u0026#34;white_9381\u0026#34;, \u0026#34;docId\u0026#34;: 5}, {\u0026#34;id\u0026#34;: 9, \u0026#34;vector\u0026#34;: [0.5718280481994695, 0.24070317428066512, -0.3737913482606834, -0.06726932177492717, -0.6980531615588608], \u0026#34;chunk\u0026#34;: \u0026#34;purple_4976\u0026#34;, \u0026#34;docId\u0026#34;: 3}, ] client.insert( collection_name=collection_name, data=data ) 查询\nquery_vectors = [ [0.14529211512077012, 0.9147257273453546, 0.7965055218724449, 0.7009258593102812, 0.5605206522382088]] # Group search results res = client.search( collection_name=collection_name, data=query_vectors, limit=3, group_by_field=\u0026#34;docId\u0026#34;, output_fields=[\u0026#34;docId\u0026#34;] ) # Retrieve the values in the `docId` column doc_ids = [result[\u0026#39;entity\u0026#39;][\u0026#39;docId\u0026#39;] for result in res[0]] doc_ids # [5, 2, 3] 只返回top-3的doc结果\ngroup_by_field： 指定进行分组的字段名称\nstrict_group_size： 每组返回的结果数量。默认情况下，每组只返回一个最相似的实体\nstrict_group_size： 是否严格限制每组的返回结果数量。设置为 True 时，系统会尝试保证每组返回的实体数量与 group_size 参数一致。如果某组数据不足，则可能影响查询性能。默认值为 False。\nHybrid Search 允许在一个collection中对多个向量字段（例如稠密向量和稀疏向量）同时进行搜索，并将不同搜索结果重新排序为单一结果集。\nHybrid Search refers to a search method that conducts multiple ANN searches simultaneously, reranks multiple sets of results from these ANN searches, and ultimately returns a single set of results. 主要工作流程\n生成密集向量（Dense Vectors）：通过嵌入模型（如 BERT 和 Transformers）生成密\n生成稀疏向量（Sparse Vectors）：通过嵌入模型（如 BM25、BGE-M3、SPLADE 等）生成稀疏向量。\n创建集合（Collection）：创建集合，并定义包含密集和稀疏向量字段的集合 Schema。\n插入数据：将稀疏和密集向量插入到创建的集合中。\n执行混合搜索：\n对密集向量执行 ANN 搜索，返回一组最相似的 Top-K 结果。\n对稀疏向量执行文本匹配搜索，也返回一组 Top-K 结果。\n得分归一化（Normalization）：将两组 Top-K 结果的得分归一化到 [0,1] 的范围。\n融合与重排序：选择合适的重排序策略，将两组 Top-K 结果合并并重新排序，最终返回一组综合的 Top-K 结果。\nfrom pymilvus import ( MilvusClient, DataType ) client = MilvusClient( uri=\u0026#34;http://localhost:19530\u0026#34; ) schema = MilvusClient.create_schema( auto_id=False, enable_dynamic_field=True, ) schema.add_field(field_name=\u0026#34;id\u0026#34;, datatype=DataType.INT64, is_primary=True) schema.add_field(field_name=\u0026#34;text\u0026#34;, datatype=DataType.VARCHAR, max_length=1000) schema.add_field(field_name=\u0026#34;sparse\u0026#34;, datatype=DataType.SPARSE_FLOAT_VECTOR) schema.add_field(field_name=\u0026#34;dense\u0026#34;, datatype=DataType.FLOAT_VECTOR, dim=5) index_params = client.prepare_index_params() index_params.add_index( field_name=\u0026#34;dense\u0026#34;, index_name=\u0026#34;dense_index\u0026#34;, index_type=\u0026#34;IVF_FLAT\u0026#34;, metric_type=\u0026#34;IP\u0026#34;, params={\u0026#34;nlist\u0026#34;: 128}, ) index_params.add_index( field_name=\u0026#34;sparse\u0026#34;, index_name=\u0026#34;sparse_index\u0026#34;, index_type=\u0026#34;SPARSE_INVERTED_INDEX\u0026#34;, # Index type for sparse vectors metric_type=\u0026#34;IP\u0026#34;, # Currently, only IP (Inner Product) is supported for sparse vectors params={\u0026#34;drop_ratio_build\u0026#34;: 0.2}, # The ratio of small vector values to be dropped during indexing ) client.create_collection( collection_name=\u0026#34;hybrid_search_collection\u0026#34;, schema=schema, index_params=index_params ) 数据插入\n# 插入数据 import random # 随机生成稠密向量 def generate_random_dense_vector(dim): return [random.uniform(-1, 1) for _ in range(dim)] # 随机生成稀疏向量 def generate_random_sparse_vector(max_dim, num_non_zero): indices = random.sample(range(max_dim), num_non_zero) values = [random.uniform(0, 1) for _ in range(num_non_zero)] return {idx: val for idx, val in zip(indices, values)} # 数据 data = [ { \u0026#34;id\u0026#34;: 0, \u0026#34;text\u0026#34;: \u0026#34;Artificial intelligence was founded as an academic discipline in 1956.\u0026#34;, \u0026#34;sparse\u0026#34;: generate_random_sparse_vector(10000, 5), # 稀疏向量 \u0026#34;dense\u0026#34;: generate_random_dense_vector(5) # 稠密向量 }, { \u0026#34;id\u0026#34;: 1, \u0026#34;text\u0026#34;: \u0026#34;Alan Turing was the first person to conduct substantial research in AI.\u0026#34;, \u0026#34;sparse\u0026#34;: generate_random_sparse_vector(10000, 5), \u0026#34;dense\u0026#34;: generate_random_dense_vector(5) }, { \u0026#34;id\u0026#34;: 2, \u0026#34;text\u0026#34;: \u0026#34;Born in Maida Vale, London, Turing was raised in southern England.\u0026#34;, \u0026#34;sparse\u0026#34;: generate_random_sparse_vector(10000, 5), \u0026#34;dense\u0026#34;: generate_random_dense_vector(5) }, ] # 插入数据 res = client.insert( collection_name=\u0026#34;hybrid_search_collection\u0026#34;, data=data ) 混合搜索是通过在**hybrid_search()** 函数中创建多个**AnnSearchRequest** 来实现的，其中每个**AnnSearchRequest** 代表一个特定向量场的基本 ANN 搜索请求。\n在混合搜索中，每个**AnnSearchRequest** 只支持一个查询向量。\nfrom pymilvus import AnnSearchRequest query_dense_vector = [0.3580376395471989, -0.6023495712049978, 0.18414012509913835, -0.26286205330961354, 0.9029438446296592] search_param_1 = { \u0026#34;data\u0026#34;: [query_dense_vector], \u0026#34;anns_field\u0026#34;: \u0026#34;dense\u0026#34;, \u0026#34;param\u0026#34;: { \u0026#34;metric_type\u0026#34;: \u0026#34;IP\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;nprobe\u0026#34;: 10} }, \u0026#34;limit\u0026#34;: 2 } request_1 = AnnSearchRequest(**search_param_1) query_sparse_vector = {1609: 0.6255744191385809, 7058: 0.20234890590382482, 449: 0.01787891574781786, 9702: 0.710732808143222, 8827: 0.3979309078494506} search_param_2 = { \u0026#34;data\u0026#34;: [query_sparse_vector], \u0026#34;anns_field\u0026#34;: \u0026#34;sparse\u0026#34;, \u0026#34;param\u0026#34;: { \u0026#34;metric_type\u0026#34;: \u0026#34;IP\u0026#34;, \u0026#34;params\u0026#34;: {\u0026#34;drop_ratio_build\u0026#34;: 0.2} }, \u0026#34;limit\u0026#34;: 2 } request_2 = AnnSearchRequest(**search_param_2) reqs = [request_1, request_2] 采用加权排名\nfrom pymilvus import WeightedRanker ranker= WeightedRanker(0.8, 0.3) res = client.hybrid_search( collection_name=\u0026#34;hybrid_search_collection\u0026#34;, reqs=reqs, ranker=ranker, limit=2 ) for hits in res: print(\u0026#34;TopK results:\u0026#34;) for hit in hits: print(hit) \u0026#34;\u0026#34;\u0026#34; TopK results: {\u0026#39;id\u0026#39;: 1, \u0026#39;distance\u0026#39;: 0.5914705991744995, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 0, \u0026#39;distance\u0026#39;: 0.27949291467666626, \u0026#39;entity\u0026#39;: {}} \u0026#34;\u0026#34;\u0026#34; 采用RRF（Reciprocal Rank Fusion） ranker\nfrom pymilvus import RRFRanker # Default k value is 60 ranker = RRFRanker(k=100) res = client.hybrid_search( collection_name=\u0026#34;hybrid_search_collection\u0026#34;, reqs=reqs, ranker=ranker, limit=2 ) for hits in res: print(\u0026#34;TopK results:\u0026#34;) for hit in hits: print(hit) \u0026#34;\u0026#34;\u0026#34; TopK results: {\u0026#39;id\u0026#39;: 1, \u0026#39;distance\u0026#39;: 0.009900989942252636, \u0026#39;entity\u0026#39;: {}} {\u0026#39;id\u0026#39;: 0, \u0026#39;distance\u0026#39;: 0.009803921915590763, \u0026#39;entity\u0026#39;: {}} \u0026#34;\u0026#34;\u0026#34; Full Text Search Milvus 在 2.5 版本中引入了全文检索， 能够基于关键字或短语高效地搜索文本数据。\n全文检索功能在 Milvus Standalone 和 Milvus Distributed 中可用，但在 Milvus Lite 中不可用\n步骤：\n文本输入：用户直接插入原始文本数据，无需手动生成向量嵌入。\n文本分析：Milvus 使用内置的分析器将输入文本分解为可搜索的词条。\n函数处理：内置函数接收已分词的词条，并将其转换为稀疏向量表示。\n集合存储：Milvus 将这些稀疏嵌入存储在集合（Collection）中，以便高效检索。\nBM25 评分：在检索时，Milvus 应用 BM25 算法计算查询文本和存储文档的相关性得分，并对匹配结果进行排序\n创建 Schema\nfrom pymilvus import MilvusClient, DataType, Function, FunctionType client = MilvusClient(uri=\u0026#34;http://localhost:19530\u0026#34;) schema = client.create_schema() schema.add_field(field_name=\u0026#34;id\u0026#34;, datatype=DataType.INT64, is_primary=True, auto_id=True) schema.add_field(field_name=\u0026#34;text\u0026#34;, datatype=DataType.VARCHAR, max_length=1000, enable_analyzer=True) schema.add_field(field_name=\u0026#34;sparse\u0026#34;, datatype=DataType.SPARSE_FLOAT_VECTOR) SPARSE_FLOAT_VECTOR 字段，预留用于存储稀疏嵌入\n定义一个将文本转换为稀疏向量表示的函数，然后将其添加到 Schema 中\nbm25_function = Function( name=\u0026#34;text_bm25_emb\u0026#34;, # Function name input_field_names=[\u0026#34;text\u0026#34;], # Name of the VARCHAR field containing raw text data output_field_names=[\u0026#34;sparse\u0026#34;], # Name of the SPARSE_FLOAT_VECTOR field reserved to store generated embeddings function_type=FunctionType.BM25, ) schema.add_function(bm25_function) 设置索引 create collection\nindex_params = client.prepare_index_params() index_params.add_index( field_name=\u0026#34;sparse\u0026#34;, index_type=\u0026#34;AUTOINDEX\u0026#34;, metric_type=\u0026#34;BM25\u0026#34; ) client.create_collection( collection_name=\u0026#39;demo\u0026#39;, schema=schema, index_params=index_params ) 插入数据\nclient.insert(\u0026#39;demo\u0026#39;, [ {\u0026#39;text\u0026#39;: \u0026#39;information retrieval is a field of study.\u0026#39;}, {\u0026#39;text\u0026#39;: \u0026#39;information retrieval focuses on finding relevant information in large datasets.\u0026#39;}, {\u0026#39;text\u0026#39;: \u0026#39;data mining and information retrieval overlap in research.\u0026#39;}, ]) 执行全文查询\nsearch_params = { \u0026#39;params\u0026#39;: {\u0026#39;drop_ratio_search\u0026#39;: 0.2}, } res = client.search( collection_name=\u0026#39;demo\u0026#39;, data=[\u0026#39;whats the focus of information retrieval?\u0026#39;], anns_field=\u0026#39;sparse\u0026#39;, limit=2, search_params=search_params, output_fields=[\u0026#34;text\u0026#34;] ) for hits in res: print(\u0026#34;TopK results:\u0026#34;) for hit in hits: print(hit) \u0026#34;\u0026#34;\u0026#34; TopK results: {\u0026#39;id\u0026#39;: 454187296102665084, \u0026#39;distance\u0026#39;: 1.3352930545806885, \u0026#39;entity\u0026#39;: {\u0026#39;text\u0026#39;: \u0026#39;information retrieval is a field of study.\u0026#39;}} {\u0026#39;id\u0026#39;: 454187296102665085, \u0026#39;distance\u0026#39;: 0.29726022481918335, \u0026#39;entity\u0026#39;: {\u0026#39;text\u0026#39;: \u0026#39;information retrieval focuses on finding relevant information in large datasets.\u0026#39;}} \u0026#34;\u0026#34;\u0026#34; Query Milvus 还支持通过查询进行元数据过滤，即类似于关系型数据库的数据查询和过滤\nGet 查询： 用于通过主键（Primary Key）精确查找实体\nQuery 查询： 通过自定义过滤表达式查找满足条件的实体\nQueryIterator 查询迭代器： 用于在分页查询中，通过自定义过滤条件遍历满足条件的所有实体 （by-batch查找）\nget\nfrom pymilvus import MilvusClient client = MilvusClient( uri=\u0026#34;http://localhost:19530\u0026#34; ) res = client.get( collection_name=\u0026#34;query_collection\u0026#34;, ids=[0, 1, 2], output_fields=[\u0026#34;vector\u0026#34;, \u0026#34;color\u0026#34;] ) print(res) \u0026#34;\u0026#34;\u0026#34; data: [\u0026#34;{\u0026#39;vector\u0026#39;: [0.35803765, -0.6023496, 0.18414013, -0.26286206, 0.90294385], \u0026#39;color\u0026#39;: \u0026#39;pink_8682\u0026#39;, \u0026#39;id\u0026#39;: 0}\u0026#34;, \u0026#34;{\u0026#39;vector\u0026#39;: [0.19886813, 0.060235605, 0.6976963, 0.26144746, 0.8387295], \u0026#39;color\u0026#39;: \u0026#39;red_7025\u0026#39;, \u0026#39;id\u0026#39;: 1}\u0026#34;, \u0026#34;{\u0026#39;vector\u0026#39;: [0.43742132, -0.55975026, 0.6457888, 0.7894059, 0.20785794], \u0026#39;color\u0026#39;: \u0026#39;orange_6781\u0026#39;, \u0026#39;id\u0026#39;: 2}\u0026#34;] \u0026#34;\u0026#34;\u0026#34; query\nres = client.query( collection_name=\u0026#34;query_collection\u0026#34;, filter=\u0026#34;color like \\\u0026#34;red%\\\u0026#34;\u0026#34;, output_fields=[\u0026#34;vector\u0026#34;, \u0026#34;color\u0026#34;], limit=3 ) print(res) \u0026#34;\u0026#34;\u0026#34; data: [\u0026#34;{\u0026#39;id\u0026#39;: 1, \u0026#39;vector\u0026#39;: [0.19886813, 0.060235605, 0.6976963, 0.26144746, 0.8387295], \u0026#39;color\u0026#39;: \u0026#39;red_7025\u0026#39;}\u0026#34;, \u0026#34;{\u0026#39;id\u0026#39;: 4, \u0026#39;vector\u0026#39;: [0.44523495, -0.8757027, 0.82207793, 0.4640629, 0.3033748], \u0026#39;color\u0026#39;: \u0026#39;red_4794\u0026#39;}\u0026#34;, \u0026#34;{\u0026#39;id\u0026#39;: 6, \u0026#39;vector\u0026#39;: [0.8371978, -0.015764369, -0.31062937, -0.56266695, -0.8984948], \u0026#39;color\u0026#39;: \u0026#39;red_9392\u0026#39;}\u0026#34;] \u0026#34;\u0026#34;\u0026#34; QueryIterator\nfrom pymilvus import connections, Collection connections.connect( uri=\u0026#34;http://localhost:19530\u0026#34;, ) collection = Collection(\u0026#34;query_collection\u0026#34;) iterator = collection.query_iterator( batch_size=10, expr=\u0026#34;color like \\\u0026#34;red%\\\u0026#34;\u0026#34;, output_fields=[\u0026#34;color\u0026#34;] ) results = [] while True: result = iterator.next() if not result: iterator.close() break print(result) results += result \u0026#34;\u0026#34;\u0026#34; [{\u0026#39;color\u0026#39;: \u0026#39;red_7025\u0026#39;, \u0026#39;id\u0026#39;: 1}, {\u0026#39;color\u0026#39;: \u0026#39;red_4794\u0026#39;, \u0026#39;id\u0026#39;: 4}, {\u0026#39;color\u0026#39;: \u0026#39;red_9392\u0026#39;, \u0026#39;id\u0026#39;: 6}] \u0026#34;\u0026#34;\u0026#34; Partition-Key 在 Milvus 中，partition-key（分区键）是一种基于特定标量字段的搜索优化方案。通过将某个字段指定为分区键，Milvus 会根据该字段的值将数据自动分配到不同的分区中，与手动管理分区不同，使用分区键可以克服集合中分区数量的限制（最多 1,024 个）。\n将数据分布到独立的分区中，同时支持对分区范围的查询限定，从而实现数据隔离，可以有效避免对非目标分区的数据进行查询操作。\n自动管理分区 vs 手动创建和指定分区\n特性 partition-key 手动分区 分区管理 自动生成，动态分区 必须手动创建，分区结构固定 分区数量限制 无理论限制，分区数量随字段值动态变化 最多 1,024 个分区 便捷性 插入和查询都更加自动化 插入和查询需要手动指定分区名称 适用场景 动态、多分区场景，如用户 ID、类别分类 静态、少量分区场景，如地理区域划分 Partition-key vs Meta-data Filtering\n特性 partition-key Meta-data Filtering 存储方式 数据物理隔离，按分区键存储 数据逻辑统一，存储在一个集合中 查询效率 通过分区键快速定位目标分区，效率高 全局扫描，效率较低 管理复杂性 自动管理，无需显式定义或维护分区 无需预定义分区，依赖查询时的过滤 动态性 分区结构相对稳定，适合分区逻辑较简单场景 更灵活，适合复杂和多变的查询条件 有无分区差异\n通过partition-key 实现数据隔离查询的简单例子；\n在这个例子中，每一个user只有查询自己数据的权限，当user选择将数据公开share，此时partition-key会被改成public，作为单独的partition存在，从而实现数据隔离查询。\n数据准备：\nfrom pymilvus import MilvusClient, DataType, Function, FunctionType client = MilvusClient(uri=\u0026#34;http://localhost:19530\u0026#34;) schema = client.create_schema() index_params = client.prepare_index_params() schema.add_field(field_name=\u0026#34;id\u0026#34;, datatype=DataType.INT64, is_primary=True, auto_id=True) schema.add_field(field_name=\u0026#34;partition_key\u0026#34;, datatype=DataType.VARCHAR, max_length=512, is_partition_key=True,description=\u0026#34;Partition key for data isolation\u0026#34;), schema.add_field(field_name=\u0026#34;data_id\u0026#34;, datatype=DataType.VARCHAR, max_length=128, description=\u0026#34;Unique data identifier\u0026#34;), schema.add_field(field_name=\u0026#34;vector\u0026#34;, datatype=DataType.FLOAT_VECTOR, dim=128, description=\u0026#34;Vector representation\u0026#34;), schema.add_field(field_name=\u0026#34;metadata\u0026#34;, datatype=DataType.JSON, description=\u0026#34;Additional filtering metadata\u0026#34;), index_params.add_index( field_name=\u0026#34;vector\u0026#34;, index_type=\u0026#34;AUTOINDEX\u0026#34;, # Automatically choose the best index type metric_type=\u0026#34;L2\u0026#34; # Use L2 distance as the metric ) # Add a sort index for the id field index_params.add_index( field_name=\u0026#34;id\u0026#34;, index_type=\u0026#34;STL_SORT\u0026#34; ) client.create_collection( collection_name=\u0026#34;partitionkey_collection\u0026#34;, schema=schema, index_params=index_params, num_partitions=1024 ) 构造一些假数据\nimport json def generate_test_data(num_records, num_users, public_probability=0.2): \u0026#34;\u0026#34;\u0026#34; 生成测试数据，支持一定概率生成公共数据。 Args: num_records (int): 数据总数 num_users (int): 用户数量 public_probability (float): 生成公共数据的概率 (0.0 到 1.0) Returns: list: 生成的测试数据，每条数据为一个字典 \u0026#34;\u0026#34;\u0026#34; data = [] for _ in range(num_records): # 根据概率选择 partition_key 为 \u0026#34;public\u0026#34; 或随机用户 ID if random.random() \u0026lt; public_probability: partition_key = \u0026#34;public\u0026#34; else: partition_key = f\u0026#34;user_{random.randint(1, num_users)}\u0026#34; record = { \u0026#34;partition_key\u0026#34;: partition_key, # 设置分区键 \u0026#34;data_id\u0026#34;: f\u0026#34;data_{random.randint(1000, 9999)}\u0026#34;, # 随机生成数据 ID \u0026#34;vector\u0026#34;: [random.uniform(0, 1) for _ in range(128)], # 随机生成128维向量 \u0026#34;metadata\u0026#34;: json.dumps({ \u0026#34;category\u0026#34;: random.choice([\u0026#34;image\u0026#34;, \u0026#34;text\u0026#34;, \u0026#34;video\u0026#34;]), \u0026#34;tags\u0026#34;: [random.choice([\u0026#34;AI\u0026#34;, \u0026#34;ML\u0026#34;, \u0026#34;NLP\u0026#34;, \u0026#34;CV\u0026#34;]) for _ in range(2)], \u0026#34;rating\u0026#34;: random.uniform(1, 5), }) } data.append(record) return data data = generate_test_data(500,20) client.insert( collection_name=\u0026#34;partitionkey_collection\u0026#34;, data=data ) 仅查询user_10 的数据\nquery_result = client.query( collection_name = \u0026#34;partitionkey_collection\u0026#34;, filter=\u0026#39;partition_key == \u0026#34;user_10\u0026#34;\u0026#39;, output_fields=[\u0026#34;data_id\u0026#34;, \u0026#34;partition_key\u0026#34;] ) print(query_result) \u0026#34;\u0026#34;\u0026#34; data: [\u0026#34;{\u0026#39;data_id\u0026#39;: \u0026#39;data_7887\u0026#39;, \u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;id\u0026#39;: 454187296102665088}\u0026#34;, \u0026#34;{\u0026#39;data_id\u0026#39;: \u0026#39;data_9004\u0026#39;, \u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;id\u0026#39;: 454187296102665090}\u0026#34;, \u0026#34;{\u0026#39;data_id\u0026#39;: \u0026#39;data_8970\u0026#39;, \u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;id\u0026#39;: 454187296102665092}\u0026#34;, \u0026#34;{\u0026#39;data_id\u0026#39;: \u0026#39;data_2031\u0026#39;, \u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;id\u0026#39;: 454187296102665098}\u0026#34;, \u0026#34;{\u0026#39;data_id\u0026#39;: \u0026#39;data_6972\u0026#39;, \u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;id\u0026#39;: 454187296102665111}\u0026#34;, \u0026#34;{\u0026#39;data_id\u0026#39;: \u0026#39;data_3463\u0026#39;, \u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;id\u0026#39;: 454187296102665118}\u0026#34;, \u0026#34;{\u0026#39;data_id\u0026#39;: \u0026#39;data_9998\u0026#39;, \u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;id\u0026#39;: 454187296102665123}\u0026#34;, \u0026#34;{\u0026#39;data_id\u0026#39;: \u0026#39;data_5411\u0026#39;, \u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;id\u0026#39;: 454187296102665133}\u0026#34;, \u0026#34;{\u0026#39;data_id\u0026#39;: \u0026#39;data_9952\u0026#39;, \u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;id\u0026#39;: 454187296102665205}\u0026#34;, \u0026#34;{\u0026#39;data_id\u0026#39;: \u0026#39;data_9002\u0026#39;, \u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;id\u0026#39;: 454187296102665257}\u0026#34;] ... \u0026#34;\u0026#34;\u0026#34; user_10 所能ANN搜索的内容（ppublicand user_10)\nquery_vectors = [random.uniform(0, 1) for _ in range(128)] res = client.search( collection_name = \u0026#34;partitionkey_collection\u0026#34;, data=[query_vectors], filter=\u0026#39;partition_key in [\u0026#34;public\u0026#34;,\u0026#34;user_10\u0026#34;]\u0026#39;, output_fields=[\u0026#34;data_id\u0026#34;, \u0026#34;partition_key\u0026#34;] ) for hits in res: for hit in hits: print(hit) \u0026#34;\u0026#34;\u0026#34; {\u0026#39;id\u0026#39;: 454187296102665637, \u0026#39;distance\u0026#39;: 15.168614387512207, \u0026#39;entity\u0026#39;: {\u0026#39;partition_key\u0026#39;: \u0026#39;public\u0026#39;, \u0026#39;data_id\u0026#39;: \u0026#39;data_9024\u0026#39;}} {\u0026#39;id\u0026#39;: 454187296102665532, \u0026#39;distance\u0026#39;: 15.173531532287598, \u0026#39;entity\u0026#39;: {\u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;data_id\u0026#39;: \u0026#39;data_8461\u0026#39;}} {\u0026#39;id\u0026#39;: 454187296102665598, \u0026#39;distance\u0026#39;: 15.250306129455566, \u0026#39;entity\u0026#39;: {\u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;data_id\u0026#39;: \u0026#39;data_7539\u0026#39;}} {\u0026#39;id\u0026#39;: 454187296102665323, \u0026#39;distance\u0026#39;: 15.833619117736816, \u0026#39;entity\u0026#39;: {\u0026#39;partition_key\u0026#39;: \u0026#39;user_10\u0026#39;, \u0026#39;data_id\u0026#39;: \u0026#39;data_8433\u0026#39;}} {\u0026#39;id\u0026#39;: 454187296102665234, \u0026#39;distance\u0026#39;: 16.50188446044922, \u0026#39;entity\u0026#39;: {\u0026#39;partition_key\u0026#39;: \u0026#39;public\u0026#39;, \u0026#39;data_id\u0026#39;: \u0026#39;data_1534\u0026#39;}} {\u0026#39;id\u0026#39;: 454187296102665501, \u0026#39;distance\u0026#39;: 16.521953582763672, \u0026#39;entity\u0026#39;: {\u0026#39;partition_key\u0026#39;: \u0026#39;public\u0026#39;, \u0026#39;data_id\u0026#39;: \u0026#39;data_9944\u0026#39;}} {\u0026#39;id\u0026#39;: 454187296102665463, \u0026#39;distance\u0026#39;: 16.524085998535156, \u0026#39;entity\u0026#39;: {\u0026#39;partition_key\u0026#39;: \u0026#39;public\u0026#39;, \u0026#39;data_id\u0026#39;: \u0026#39;data_6430\u0026#39;}} {\u0026#39;id\u0026#39;: 454187296102665453, \u0026#39;distance\u0026#39;: 16.64727020263672, \u0026#39;entity\u0026#39;: {\u0026#39;partition_key\u0026#39;: \u0026#39;public\u0026#39;, \u0026#39;data_id\u0026#39;: \u0026#39;data_8403\u0026#39;}} {\u0026#39;id\u0026#39;: 454187296102665629, \u0026#39;distance\u0026#39;: 16.649581909179688, \u0026#39;entity\u0026#39;: {\u0026#39;partition_key\u0026#39;: \u0026#39;public\u0026#39;, \u0026#39;data_id\u0026#39;: \u0026#39;data_5141\u0026#39;}} {\u0026#39;id\u0026#39;: 454187296102665631, \u0026#39;distance\u0026#39;: 16.809789657592773, \u0026#39;entity\u0026#39;: {\u0026#39;partition_key\u0026#39;: \u0026#39;public\u0026#39;, \u0026#39;data_id\u0026#39;: \u0026#39;data_3505\u0026#39;}} \u0026#34;\u0026#34;\u0026#34; Models 在2.4 版本之后支持了对于embedding模型和reranking模型的集成。\n个人认为没有太大必要。\n图形化界面 之前使用的是milvus-insight，不过不再维护了。\n官方主推的是attu。\n一些踩坑点 （待更新）\n参考 官方文档\n","permalink":"https://niraya666.github.io/posts/milvus-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%92%8C%E5%A4%87%E5%BF%98%E5%BD%95%E4%BB%8E2.0-%E5%88%B02.5%E7%89%88%E6%9C%AC%E7%9A%84%E4%BB%8E%E5%A4%B4%E5%AD%A6%E4%B9%A0/","summary":"\u003cp\u003e几年前初识 Milvus 的契机，来源于开发一个图像相似检索的应用，当时市面上向量库的可选择项并不像现在这么多，且功能也仅限于单纯的向量检索。\u003c/p\u003e\n\u003cp\u003e鉴于最近有业务更新的需要，和打算重构一下之前做的RAG项目，再次有机会深入学习 Milvus，探索其在新功能和实际应用上的更多可能性。\u003c/p\u003e\n\u003cp\u003e本篇笔记，仅作为学习笔记，更多是记录一些 Milvus从2.0 到2.5 的变化， 和一些动手实践的记录，便于之后的查阅。\u003c/p\u003e\n\u003ch2 id=\"一些概念\"\u003e一些概念\u003c/h2\u003e\n\u003ch3 id=\"collections-schema-and-index\"\u003eCollections, Schema and index\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCollection\u003c/strong\u003e是Milvus中的一个二维表格，具有固定的列和可变的行。每一列代表一个字段(field)，每一行代表一个实体(entity)\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSchema和字段\u003c/strong\u003e Collection需要一个schema来定义其结构\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e索引\u003c/strong\u003e 在特定字段上创建索引可以提高搜索效率。建议为服务所依赖的所有字段创建索引，其中向量字段的索引是必需的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e分区(Partition)\u003c/strong\u003e 分区是Collection的子集，与其父Collection共享相同的字段集\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e分片(Shard)\u003c/strong\u003e 分片是Collection的水平切片。每个分片对应一个数据输入通道。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eShard vs Partition的区别\u003c/strong\u003e :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e分区(Partition)的作用是通过指定分区名称来减少读取负载\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e而分片(Shard)的作用是将写入负载分散到多个服务器\u003cstrong\u003e分布式架构中的应用\u003c/strong\u003e 在分布式系统中，分片是实现水平扩展的重要机制。通过将数据分布到多个节点，可以充分利用集群的并行计算潜力，提高系统的写入性能\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"milvusclient-vs-connection\"\u003e\u003cstrong\u003eMilvusClient vs Connection\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eMilvusClient\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e定位\u003c/strong\u003e：更高级封装，提供一体化的操作接口。简化了与 Milvus 的交互流程， 提供更直观和结构化的操作方式，便于新手快速上手，内置了对连接的管理和操作，减少手动处理的复杂性。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epymilvus\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eMilvusClient\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 创建客户端并连接到 Milvus\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eclient\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eMilvusClient\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euri\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;http://localhost:19530\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 创建集合\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eclient\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_collection\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;example_collection\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eschema\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;fields\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;name\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;vector\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;type\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;FLOAT_VECTOR\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;params\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;dim\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e}}]}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 插入数据\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eclient\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003einsert\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;example_collection\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;vector\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e]})\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 搜索\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eresults\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eclient\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esearch\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;example_collection\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edata\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[[\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresults\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eConnection\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e定位\u003c/strong\u003e：基础连接操作，需要通过 connect 方法创建并维护连接。提供更底层的控制，适合灵活、自定义的操作。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epymilvus\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003econnections\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eCollection\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eFieldSchema\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eCollectionSchema\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 创建连接\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003econnections\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econnect\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ealias\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;default\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ehost\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;localhost\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eport\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;19530\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 创建集合\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003efields\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eFieldSchema\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;vector\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edtype\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;FLOAT_VECTOR\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edim\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eschema\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eCollectionSchema\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efields\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edescription\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;example collection\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ecollection\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eCollection\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;example_collection\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eschema\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eschema\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 插入数据\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ecollection\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003einsert\u003c/span\u003e\u003cspan class=\"p\"\u003e([[\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.2\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e# 搜索\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003ecollection\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eresults\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ecollection\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esearch\u003c/span\u003e\u003cspan class=\"p\"\u003e([[\u003c/span\u003e\u003cspan class=\"mf\"\u003e0.1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mi\"\u003e128\u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e \u003cspan class=\"n\"\u003eanns_field\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;vector\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003elimit\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresults\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"schema\"\u003e\u003cstrong\u003eSchema\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eSchema\u003c/strong\u003e 用于定义collection及其字段的属性\u003c/p\u003e","title":"Milvus-2.5版本：学习笔记和备忘录"},{"content":"去年疫情之后，我感觉记忆力明显下降，甚至一度担心会不可恢复。或许这也是年纪渐长的体现，只是我不愿意承认罢了。直到读到了一篇博文，了解了CODE信息管理框架，并因此接触到《第二大脑》这本书。虽然这本书并不长，但由于各种原因，今年我才真正开始阅读并实践。经过一年的探索，我决定整理这篇读书笔记，既是对书中理念的梳理，也是对个人实践的总结。\n值得一提的是，随着近年来大语言模型（LLM）的迅速发展，AI辅助可能会带来更高效的信息管理方式。\n信息过载的时代，为什么需要笔记？ 很多情况下，我们不过是一个个“人形存储器”，明明囤积了大量的心灵鸡汤，却反而让自己变得越发焦虑。\n为什么要做笔记？在信息泛滥的今天，我们像“人形存储器”一样不断被信息填满，大脑的容量有限，信息过载只会增加焦虑。\n在25岁之前，我几乎不需要笔记，因为记忆力不错，而且接触的信息相对有限。工作后，尤其在AI领域，每天都被信息轰炸。尤其是ChatGPT问世后，信息的爆炸性增长让我常常感到FOMO（Fear of missing out，即错失恐惧症）：担心错过最新的模型、论文，或行业趋势。我习惯性地将感兴趣的网页放入同一窗口，但消化的速度远远跟不上积累的速度，导致未处理的内容堆积成山。\n我们无法容纳所有信息，因此需要新的信息管理方式——一个“第二大脑”。\n在《第二大脑》中，作者提出了“第二大脑”概念。这个概念的核心是解放大脑的记忆负担，将精力集中在创新上。为了实现这一目标，作者提供了一套实操框架，即“信管法则”CODE：抓取（Capture）、组织（Organize）、提炼（Distill）和表达（Express）。\n什么是信管法则 CODE 1. 信息抓取 因为普通人对于信息的利用并没有明确的规划，所以在信息的筛选问题上会显得有些无所适从。\n抓取信息的目的是捕捉对自己有意义的内容，而不是任意积累。有效筛选信息可以通过以下标准：\n信息抓取标准1：是否具有启发性\n信息抓取标准2：是否具有实用性\n信息抓取标准3：是否具有个性\n信息抓取标准4：是否具有新奇性\n信息抓取终极标准：是否让你为之共鸣\n从推荐系统的出现开始，可以看到现代人所面临的一个典型问题——信息茧房。我们常常被动地接受信息，而非主动选择，导致思维越来越局限。这种信息茧房现象，使得我们只看到我们想看的，忽略了更多有价值的内容。在如今的注意力战争中，我们的注意力被大量低质量的信息所吸引，而常常错过了高质量的信息。我们需要认识到，抓取信息的关键不在于多，而在于精。\n另外，抓取信息时要保持随时随地记录的习惯。无论是灵感闪现，还是对某篇文章的深刻思考，都应该马上记录下来，而不是随着时间逐渐遗忘。可以善用备忘录、稍后阅读工具等工具，以确保在需要时可以迅速获取信息。\n2. 信息组织 信息需要合理分类，以方便未来使用。相信我，你一定在备忘录中看到一些不知写的是什么的内容，或是看着收藏夹中多达上百条记录而不知所措，这时候你需要的是改变信息组织方式。\n作者推荐“以行动为导向”的PARA系统：项目（Projects）、领域（Areas）、资源（Resources）、存档（Archive）。这一系统的核心在于根据实际需求对信息进行分类存储，确保信息易于找到和利用。\nPARA系统的运作机制：让你的思想（和笔记）向行动看齐\n在PARA系统中，每一条信息都可以被划入以下四大类别中：\n项目（Projects）：工作或生活中正在从事的短期活动；\n领域（Areas）：致力于长期履行的责任；\n资源（Resources）：具有潜在利用价值的课题或兴趣点；\n存档（Archive）：除上述三项以外的休眠信息。\n相比基于“信息来源”的组织方式，PARA系统以信息可能促成的结果为导向。这种方法可以让我们更加专注于将信息用于创造行动和产生价值，而不是无限期地积累信息。\nPARA系统的精髓在于：不要让信息变成无用的负担，而是让它们真正为你的行动服务。\n3. 信息提炼 毕竟笔记是要拿来用的，而不是当作收藏的。\n换言之，笔记的体量与可见性之间呈一种反比关系\n去粗取精。首先需要定义出“知识的骨架”。对原始文本进行分解，从过去一年来做的所谓“知识管理”有关的项目而言，这一部分的内容，更多的是将原始的文本进行分解，根据知识的骨架（schema），将各个分解而成的核心内容放置在各个位置上。例如，对于文献，可以使用来自cool-paper的论文分解框架：\n这篇论文试图解决什么问题？\n有哪些相关研究？\n论文如何解决这个问题？\n……\n渐进式归纳法：渐进式归纳法的核心逻辑在于“断舍离”，而非“滴水不漏”。\n分层标注。在这本书中，作者提出了渐进归纳法的文本高亮方法，以抓取和提炼出核心内容。具体而言，首先将文本的重点标记出，而后在重点中标记出重点的重点，以此类推。实操角度，例如收藏的一篇文章作为第一层级，而后在文章中以加粗的形式标记认为的重点，其次使用高亮标记将重点的重点标注出。\n用自己的语言重述。最后一个层级，也是最重要且被绝大多数人所忽略的：用自己的语言将要点重现表述，并增加自己的理解。这有助于深刻掌握内容。\n4. 表达与实践 If you\u0026rsquo;re thinking without writing, you only think you\u0026rsquo;re thinking.\n知识的价值是为了生产，而不是为了收藏。将所学转化为自己的语言并表达出来，才算真正掌握。可以从简单的记录入手，将零散的想法整理成文章或笔记，逐步积累，最终形成系统的表达。\n一开始，这可能会有些困难，但可以从简单的句子开始，慢慢汇总这些“半熟素材”。可以从记录在备忘录中的一段核心想法，或是社交媒体上几百字的感想出发。当积累到一定程度后，完成一篇长的文章也不再是一件困难的事。\n我非常喜欢18世纪哲学家维柯的一句名言：“Verum ipsum factum”，翻译过来就是“真理不外乎创造”。只有通过自己的语言，将内容重新展示和表达出来，无论形式如何，才是真正的“学会了”。\n关于创新和创造力和自我表达 创新型人才更加善于识别、笼络和联结各种关系。\n创新型人才更加善于识别、笼络和联结各种关系。他们能够从看似无关的事物中找到潜在的联系，并形成解决复杂问题的创造性路径。这种特质源于他们在“发散”和“聚合”思维上的高度敏感和平衡：\n发散思维： 开放的心态，能够接纳多种可能性和观点。\n聚合思维： 注重将分散的信息整合成逻辑清晰的方案。\n生物脑所难以同时进行的两项工作：选择想法和逻辑排序；选择想法需要的是发散的思维方式，而逻辑排序需要将这些想法按一定的逻辑串联。因此，我们需要一些有效的方法来帮助思维的流畅转换和创新性输出。\n不要害怕创作。记录每一个零散的想法，即使它看似普通。量变会引发质变。这些创作过程中的零散素材可以看作“思想的群岛”。通过记录和整理这些想法，可以在不同“岛屿”之间架起桥梁，这些桥梁有助于将发散的想法整合起来，降低创作的难度。这种桥梁称为“海明威之桥”。\n如何打造“海明威之桥”？在笔记里留下当前状态和下一步想法。\n下一步的想法：在某一工作阶段结束前夕，写下你认为下一步可能采取的措施；\n当前的状态：包括当前最大的挑战、最重要的未决事项或是你所预见的某些阻碍；\n易被遗忘的重要信息：例如故事人物的性格特质、某一场景事件中的伏笔，或是产品设计中的个人巧思等；\n在信息大爆炸的时代，创作需要合理利用现代技术，将信息的获取、组织和归纳任务“外包”给工具，这样就能将宝贵的时间和精力集中于需要创造力和个性表达的部分。\n创作时，避免因为庞大的信息量而感到不知所措。通过“压缩范围”，去掉不必要的部分，推迟非关键部分的处理，并妥善存储暂时移除的内容，未来或许会有用。\n最重要的，创造知识的目的是回馈社会。通过分享，你的创意不仅能获得反馈，还可能激发更大的改良和突破。“知识的价值在于应用”，将知识转化为对他人和社会有益的成果，而不是藏起来。\n匈牙利裔英籍哲学家迈克尔·波兰尼在其于1966年发表的一部著作 中提出了所谓的“波兰尼悖论”，一言以蔽之就是“人类所知远胜于其所能言传”。\n","permalink":"https://niraya666.github.io/essay/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E5%A6%82%E4%BD%95%E6%89%93%E9%80%A0%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/","summary":"\u003cp\u003e去年疫情之后，我感觉记忆力明显下降，甚至一度担心会不可恢复。或许这也是年纪渐长的体现，只是我不愿意承认罢了。直到读到了一篇博文，了解了CODE信息管理框架，并因此接触到《第二大脑》这本书。虽然这本书并不长，但由于各种原因，今年我才真正开始阅读并实践。经过一年的探索，我决定整理这篇读书笔记，既是对书中理念的梳理，也是对个人实践的总结。\u003c/p\u003e\n\u003cp\u003e值得一提的是，随着近年来大语言模型（LLM）的迅速发展，AI辅助可能会带来更高效的信息管理方式。\u003c/p\u003e\n\u003ch2 id=\"信息过载的时代为什么需要笔记\"\u003e信息过载的时代，为什么需要笔记？\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e很多情况下，我们不过是一个个“人形存储器”，明明囤积了大量的心灵鸡汤，却反而让自己变得越发焦虑。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e为什么要做笔记？在信息泛滥的今天，我们像“人形存储器”一样不断被信息填满，大脑的容量有限，信息过载只会增加焦虑。\u003c/p\u003e\n\u003cp\u003e在25岁之前，我几乎不需要笔记，因为记忆力不错，而且接触的信息相对有限。工作后，尤其在AI领域，每天都被信息轰炸。尤其是ChatGPT问世后，信息的爆炸性增长让我常常感到FOMO（Fear of missing out，即错失恐惧症）：担心错过最新的模型、论文，或行业趋势。我习惯性地将感兴趣的网页放入同一窗口，但消化的速度远远跟不上积累的速度，导致未处理的内容堆积成山。\u003c/p\u003e\n\u003cp\u003e我们无法容纳所有信息，因此需要新的信息管理方式——一个“第二大脑”。\u003c/p\u003e\n\u003cp\u003e在《第二大脑》中，作者提出了“第二大脑”概念。这个概念的核心是解放大脑的记忆负担，将精力集中在创新上。为了实现这一目标，作者提供了一套实操框架，即“信管法则”CODE：抓取（Capture）、组织（Organize）、提炼（Distill）和表达（Express）。\u003c/p\u003e\n\u003ch2 id=\"什么是信管法则-code\"\u003e什么是信管法则 CODE\u003c/h2\u003e\n\u003ch3 id=\"1-信息抓取\"\u003e1. 信息抓取\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e因为普通人对于信息的利用并没有明确的规划，所以在信息的筛选问题上会显得有些无所适从。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e抓取信息的目的是捕捉对自己有意义的内容，而不是任意积累。有效筛选信息可以通过以下标准：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e信息抓取标准1：是否具有启发性\u003c/p\u003e\n\u003cp\u003e信息抓取标准2：是否具有实用性\u003c/p\u003e\n\u003cp\u003e信息抓取标准3：是否具有个性\u003c/p\u003e\n\u003cp\u003e信息抓取标准4：是否具有新奇性\u003c/p\u003e\n\u003cp\u003e信息抓取终极标准：是否让你为之共鸣\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e从推荐系统的出现开始，可以看到现代人所面临的一个典型问题——\u003cstrong\u003e信息茧房\u003c/strong\u003e。我们常常被动地接受信息，而非主动选择，导致思维越来越局限。这种信息茧房现象，使得我们只看到我们想看的，忽略了更多有价值的内容。在如今的\u003cstrong\u003e注意力战争\u003c/strong\u003e中，我们的注意力被大量低质量的信息所吸引，而常常错过了高质量的信息。我们需要认识到，抓取信息的关键不在于多，而在于\u003cstrong\u003e精\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e另外，抓取信息时要保持随时随地记录的习惯。无论是灵感闪现，还是对某篇文章的深刻思考，都应该马上记录下来，而不是随着时间逐渐遗忘。可以善用\u003cstrong\u003e备忘录\u003c/strong\u003e、\u003cstrong\u003e稍后阅读工具\u003c/strong\u003e等工具，以确保在需要时可以迅速获取信息。\u003c/p\u003e\n\u003ch3 id=\"2-信息组织\"\u003e2. 信息组织\u003c/h3\u003e\n\u003cp\u003e信息需要合理分类，以方便未来使用。相信我，你一定在备忘录中看到一些不知写的是什么的内容，或是看着收藏夹中多达上百条记录而不知所措，这时候你需要的是改变信息组织方式。\u003c/p\u003e\n\u003cp\u003e作者推荐“以行动为导向”的PARA系统：项目（Projects）、领域（Areas）、资源（Resources）、存档（Archive）。这一系统的核心在于根据实际需求对信息进行分类存储，确保信息易于找到和利用。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003ePARA系统的运作机制：让你的思想（和笔记）向行动看齐\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在PARA系统中，每一条信息都可以被划入以下四大类别中：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e项目（Projects）\u003c/strong\u003e：工作或生活中正在从事的短期活动；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e领域（Areas）\u003c/strong\u003e：致力于长期履行的责任；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e资源（Resources）\u003c/strong\u003e：具有潜在利用价值的课题或兴趣点；\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e存档（Archive）\u003c/strong\u003e：除上述三项以外的休眠信息。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e相比基于“信息来源”的组织方式，PARA系统以信息可能促成的结果为导向。这种方法可以让我们更加专注于将信息用于创造行动和产生价值，而不是无限期地积累信息。\u003c/p\u003e\n\u003cp\u003ePARA系统的精髓在于：不要让信息变成无用的负担，而是让它们真正为你的行动服务。\u003c/p\u003e\n\u003ch3 id=\"3-信息提炼\"\u003e\u003cstrong\u003e3. 信息提炼\u003c/strong\u003e\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e毕竟笔记是要拿来用的，而不是当作收藏的。\u003c/p\u003e\n\u003cp\u003e换言之，笔记的体量与可见性之间呈一种反比关系\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e去粗取精\u003c/strong\u003e。首先需要定义出“知识的骨架”。对原始文本进行分解，从过去一年来做的所谓“知识管理”有关的项目而言，这一部分的内容，更多的是将原始的文本进行分解，根据知识的骨架（schema），将各个分解而成的核心内容放置在各个位置上。例如，对于文献，可以使用来自cool-paper的论文分解框架：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e这篇论文试图解决什么问题？\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e有哪些相关研究？\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e论文如何解决这个问题？\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e……\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e渐进式归纳法\u003c/strong\u003e：渐进式归纳法的核心逻辑在于“断舍离”，而非“滴水不漏”。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e分层标注\u003c/strong\u003e。在这本书中，作者提出了渐进归纳法的文本高亮方法，以抓取和提炼出核心内容。具体而言，首先将文本的重点标记出，而后在重点中标记出重点的重点，以此类推。实操角度，例如收藏的一篇文章作为第一层级，而后在文章中以加粗的形式标记认为的重点，其次使用高亮标记将重点的重点标注出。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e用自己的语言重述\u003c/strong\u003e。最后一个层级，也是最重要且被绝大多数人所忽略的：用自己的语言将要点重现表述，并增加自己的理解。这有助于深刻掌握内容。\u003c/p\u003e\n\u003ch3 id=\"4-表达与实践\"\u003e4. 表达与实践\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIf you\u0026rsquo;re thinking without writing, you only think you\u0026rsquo;re thinking.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e知识的价值是为了生产，而不是为了收藏。将所学转化为自己的语言并表达出来，才算真正掌握。可以从简单的记录入手，将零散的想法整理成文章或笔记，逐步积累，最终形成系统的表达。\u003c/p\u003e\n\u003cp\u003e一开始，这可能会有些困难，但可以从简单的句子开始，慢慢汇总这些“半熟素材”。可以从记录在备忘录中的一段核心想法，或是社交媒体上几百字的感想出发。当积累到一定程度后，完成一篇长的文章也不再是一件困难的事。\u003c/p\u003e\n\u003cp\u003e我非常喜欢18世纪哲学家维柯的一句名言：“Verum ipsum factum”，翻译过来就是“真理不外乎创造”。只有通过自己的语言，将内容重新展示和表达出来，无论形式如何，才是真正的“学会了”。\u003c/p\u003e\n\u003ch2 id=\"关于创新和创造力和自我表达\"\u003e关于创新和创造力和自我表达\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e创新型人才更加善于识别、笼络和联结各种关系。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e创新型人才更加善于识别、笼络和联结各种关系。他们能够从看似无关的事物中找到潜在的联系，并形成解决复杂问题的创造性路径。这种特质源于他们在“发散”和“聚合”思维上的高度敏感和平衡：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e发散思维：\u003c/strong\u003e 开放的心态，能够接纳多种可能性和观点。\u003c/p\u003e","title":"读书笔记｜如何打造第二大脑"},{"content":"开篇 “CloseAI” 终于又开源了新的项目，可惜OpenAI明确表示，Swarm是一个实验性框架，主要用于教育目的，不适合生产环境，也没有官方支持。不过从这样一个实验性的框架，至少能够了解到OpenAI对于Agent上的一些理解，对于Agent设计上能够有所帮助和借鉴。\nRoutines and Handoffs 根据openAI cookbook: Orchestrating Agents: Routines and Handoffs**，**理解这个框架前首先需要理解的两个概念： Routines 和 Handoffs。\nThe notion of a \u0026ldquo;routine\u0026rdquo; is not strictly defined, and instead meant to capture the idea of a set of steps. Concretely, let\u0026rsquo;s define a routine to be a list of instructions in natural language (which we\u0026rsquo;ll represent with a system prompt), along with the tools necessary to complete them.\nRoutines（常规）：是由一系列步骤构成的流程，可以理解为给定任务的执行步骤，包括对话系统中指令和所需工具的组合。从代码实现上，基本上就是围绕着openAI 的 openai.chat.completions.createAPI的一系列内容， 对话、工具调用等。换句话说，routines只是具有对话+工具调用的chatbot，这也是openAI对于Agent的基础抽象。\n在cookbook中，所提供的routines示例代码即可看出（以客服代理为例）：\n# 导入必要的库 from openai import OpenAI from pydantic import BaseModel from typing import Optional import json # 创建OpenAI客户端 client = OpenAI() # 客服 Routine 示例 system_message = ( \u0026#34;你是ACME Inc的客服代理。\u0026#34; \u0026#34;回答简短。\u0026#34; \u0026#34;按照以下步骤处理：\u0026#34; \u0026#34;1. 询问客户问题，了解他们遇到的具体问题。\u0026#34; \u0026#34;2. 提出修复建议。\u0026#34; \u0026#34;3. 如果客户不满意，提供退款。\u0026#34; \u0026#34;4. 如果客户接受退款，请查找商品ID并执行退款。\u0026#34; ) # 示例函数：查找商品 def look_up_item(search_query): \u0026#34;\u0026#34;\u0026#34;用于查找商品ID，可以通过描述或关键词进行搜索\u0026#34;\u0026#34;\u0026#34; # 返回硬编码的商品ID，实际场景中会调用数据库或API查找 return \u0026#34;item_132612938\u0026#34; # 示例函数：执行退款 def execute_refund(item_id, reason=\u0026#34;未提供\u0026#34;): \u0026#34;\u0026#34;\u0026#34;执行退款操作\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;退款摘要:\u0026#34;, item_id, reason) return \u0026#34;退款成功\u0026#34; # Routine 运行示例 def run_full_turn(system_message, messages): # 使用OpenAI模型完成聊天对话 response = client.chat.completions.create( model=\u0026#34;gpt-4o-mini\u0026#34;, # 使用的模型 messages=[{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: system_message}] + messages, ) message = response.choices[0].message messages.append(message) # 输出客服代理的回复 if message.content: print(\u0026#34;代理:\u0026#34;, message.content) return message # 消息列表 messages = [] # 运行示例（此时代理根据系统消息进行对话） while True: user_input = input(\u0026#34;用户: \u0026#34;) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) run_full_turn(system_message, messages) 从表面上看，Routine 实现了一个类似于聊天机器人的功能，它按照预定的步骤执行对话和任务。在加入了tool-using后，让代理不仅仅是一个普通的对话机器人，而是具备处理特定任务的能力。\n# 导入必要的库 from openai import OpenAI from pydantic import BaseModel import json # 创建OpenAI客户端 client = OpenAI() # 客服 Routine 示例 system_message = ( \u0026#34;你是ACME Inc的客服代理。\u0026#34; \u0026#34;回答简短。\u0026#34; \u0026#34;按照以下步骤处理：\u0026#34; \u0026#34;1. 询问客户问题，了解他们遇到的具体问题。\u0026#34; \u0026#34;2. 提出修复建议。\u0026#34; \u0026#34;3. 如果客户不满意，提供退款。\u0026#34; \u0026#34;4. 如果客户接受退款，请查找商品ID并执行退款。\u0026#34; ) # 查找商品的工具函数 def look_up_item(search_query): \u0026#34;\u0026#34;\u0026#34;用于查找商品ID，可以通过描述或关键词进行搜索\u0026#34;\u0026#34;\u0026#34; return \u0026#34;item_132612938\u0026#34; # 模拟返回商品ID # 执行退款的工具函数 def execute_refund(item_id, reason=\u0026#34;未提供\u0026#34;): \u0026#34;\u0026#34;\u0026#34;执行退款操作\u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;执行退款操作，商品ID: {item_id}, 原因: {reason}\u0026#34;) return \u0026#34;退款成功\u0026#34; # 将工具函数转换为模型可以调用的格式 def function_to_schema(func): \u0026#34;\u0026#34;\u0026#34;将Python函数转换为函数调用模式，供模型调用\u0026#34;\u0026#34;\u0026#34; return { \u0026#34;name\u0026#34;: func.__name__, \u0026#34;description\u0026#34;: func.__doc__, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;search_query\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, \u0026#34;item_id\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, \u0026#34;reason\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;} } } } # Routine 执行示例，支持工具调用 def run_full_turn(system_message, messages, tools): response = client.chat.completions.create( model=\u0026#34;gpt-4o-mini\u0026#34;, messages=[{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: system_message}] + messages, tools=tools ) message = response.choices[0].message messages.append(message) if message.content: print(\u0026#34;代理:\u0026#34;, message.content) # 检查是否有工具调用 if \u0026#34;tool_call\u0026#34; in message: tool_call = message[\u0026#34;tool_call\u0026#34;] tool_name = tool_call[\u0026#34;name\u0026#34;] tool_args = json.loads(tool_call[\u0026#34;arguments\u0026#34;]) # 根据工具调用名称，调用相应的工具函数 if tool_name == \u0026#34;look_up_item\u0026#34;: result = look_up_item(**tool_args) elif tool_name == \u0026#34;execute_refund\u0026#34;: result = execute_refund(**tool_args) print(f\u0026#34;工具调用结果: {result}\u0026#34;) messages.append({\u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;content\u0026#34;: result}) return message # 准备工具和工具模式 tools = [look_up_item, execute_refund] tool_schemas = [function_to_schema(tool) for tool in tools] # 消息列表 messages = [] # 运行示例，使用工具调用 while True: user_input = input(\u0026#34;用户: \u0026#34;) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) run_full_turn(system_message, messages, tool_schemas) 在 run_full_turn 函数中，代理在对话过程中可以决定是否调用某个工具，并且相应地执行 look_up_item 或 execute_refund。\nHandoffs（交接）：是指一个代理将任务或对话交给另一个代理完成，就像客服人员转接电话一样。每个代理都能根据需要传递工作，而不会中断流程。\nLet\u0026rsquo;s define a handoff as an agent (or routine) handing off an active conversation to another agent, much like when you get transfered to someone else on a phone call. 引入handoffs机制后， 单一的agent便能够同其他agent交互， 理论上实现了single-agent 到multi-agent的演变。\n根据cookbook的例子，\n# 导入必要的库 from pydantic import BaseModel import json # 定义代理类 class Agent(BaseModel): name: str instructions: str tools: list # 工具函数 def look_up_item(search_query): return \u0026#34;item_132612938\u0026#34; def execute_refund(item_id, reason=\u0026#34;未提供\u0026#34;): return \u0026#34;退款成功\u0026#34; def place_order(item_name): return \u0026#34;订单已下\u0026#34; # 定义代理 refund_agent = Agent( name=\u0026#34;退款代理\u0026#34;, instructions=\u0026#34;你是退款代理，帮助用户进行退款。\u0026#34;, tools=[execute_refund] ) sales_agent = Agent( name=\u0026#34;销售代理\u0026#34;, instructions=\u0026#34;你是销售代理，帮助用户下订单。\u0026#34;, tools=[place_order] ) # Handoff 转接函数 def transfer_to_refund(): return refund_agent # 消息处理函数 def run_full_turn(agent, messages): print(f\u0026#34;{agent.name}:\u0026#34;, agent.instructions) # 交互消息 while True: user_input = input(\u0026#34;用户: \u0026#34;) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: user_input}) # 根据用户输入，代理决定是否进行转接 if \u0026#34;退款\u0026#34; in user_input: agent = transfer_to_refund() print(f\u0026#34;转接到 {agent.name}\u0026#34;) break else: result = place_order(user_input) # 默认下单工具 print(f\u0026#34;代理调用结果: {result}\u0026#34;) return agent # 初始化销售代理处理 messages = [] agent = sales_agent # 模拟对话，代理处理转接 agent = run_full_turn(agent, messages) 定义了三个函数：look_up_item（查找商品）、execute_refund（退款）、place_order（下订单），模拟代理执行特定任务\ntransfer_to_refund 函数将对话从 sales_agent 转接到 refund_agent，当用户请求退款时触发\n对话会自动转接到退款代理，模拟客服人员转接的场景。\n从实现本质上讲， handoffs就是另一种形式的tool-using，即将另一个agent当作工具调用，但又有所区别，\n稍微总结一下：\nRoutine or single-agent = client.chat.completions.create()\nMulti-agent = Routine + handoffs\nopenAI-Swarm 核心代码 核心代码：https://github.com/openai/swarm/blob/main/swarm/core.py\nswarm类的主要功能：\n初始化client：默认openAI，可自定义导入，需要支持client.chat.completions.create 用法的（OpenAI-API-compatible ）\nget_chat_completion处理chat completion请求\nhandle_function_result负责标准化单个函数的返回结果，结果标准化转换，返回Result对象\nhandle_tool_calls处理工具调用，完整的工具调用流程管理，返回Response对象（包含多个消息和状态）\n支持流式和非流式运行模式 run() ,run_and_stream()\n其中，主要的type：\nclass Agent(BaseModel): name: str = \u0026#34;Agent\u0026#34; # 代理名称 model: str = \u0026#34;gpt-4o\u0026#34; # 使用的模型 instructions: Union[str, Callable[[], str]] = \u0026#34;You are a helpful agent.\u0026#34; # 代理指令 functions: List[AgentFunction] = [] # 可用函数列表 tool_choice: str = None # 工具选择 parallel_tool_calls: bool = True # 是否允许并行调用工具 class Response(BaseModel): messages: List = [] # 对话消息列表 agent: Optional[Agent] = None # 当前活跃代理 context_variables: dict = {} # 上下文变量 class Result(BaseModel): \u0026#34;\u0026#34;\u0026#34; Encapsulates the possible return values for an agent function. Attributes: value (str): The result value as a string. agent (Agent): The agent instance, if applicable. context_variables (dict): A dictionary of context variables. \u0026#34;\u0026#34;\u0026#34; value: str = \u0026#34;\u0026#34; # 函数返回值 agent: Optional[Agent] = None # 可能切换到的新代理 context_variables: dict = {} # 函数执行后的上下文变量 Agent，整体来说是对于于openAI() 常见功能的Wrapper，包括：\nmodel：所调用的model名称，对于不同任务，采用不同能力的模型\ninstructions： system-prompt\nfunctions：可调用对象，可以返回三种类型（str，Agent，dict），AgentFunction = Callable[[], Union[str, \u0026quot;Agent\u0026quot;, dict]]\ntool_choice,parallel_tool_calls: 同Chat Completions API参数\nResult：单个工具函数的返回值、函数执行的中间结果、单次状态更新。\nResponse：完整对话回合的结果、多个工具调用的汇总、最终状态的快照。\n主要运行逻辑： run()\ndef run( self, agent: Agent, # 初始代理 messages: List, # 初始消息列表 context_variables: dict = {}, # 上下文变量 model_override: str = None, # 模型覆盖 stream: bool = False, # 是否使用流式输出 debug: bool = False, # 是否开启调试 max_turns: int = float(\u0026#34;inf\u0026#34;), # 最大对话轮次 execute_tools: bool = True, # 是否执行工具调用 ) -\u0026gt; Response: 初始化阶段：\n# 如果是流式模式，转向run_and_stream方法 if stream: return self.run_and_stream(...) # 复制初始状态，避免修改原始数据 active_agent = agent context_variables = copy.deepcopy(context_variables) history = copy.deepcopy(messages) init_len = len(messages) # 记录初始消息长度 主循环逻辑：\nwhile len(history) - init_len \u0026lt; max_turns and active_agent: # 获取AI回复 completion = self.get_chat_completion( agent=active_agent, history=history, context_variables=context_variables, model_override=model_override, stream=stream, debug=debug, ) # 处理回复消息 message = completion.choices[0].message message.sender = active_agent.name history.append(json.loads(message.model_dump_json())) 工具调用处理:\n# 如果没有工具调用或不执行工具，结束对话 if not message.tool_calls or not execute_tools: break # 处理工具调用 partial_response = self.handle_tool_calls( message.tool_calls, active_agent.functions, context_variables, debug ) # 更新状态 history.extend(partial_response.messages) # 添加工具调用结果到历史 context_variables.update(partial_response.context_variables) # 更新上下文 if partial_response.agent: active_agent = partial_response.agent # 可能切换到新代理 返回结果：\nreturn Response( messages=history[init_len:], # 只返回新增的消息 agent=active_agent, # 当前活跃代理 context_variables=context_variables # 最终的上下文变量 ) run() 整体流程：\n用Swarm实现Multi-Agent系统 从官方提供的handoff example开始：\nfrom swarm import Swarm, Agent client = Swarm() english_agent = Agent( name=\u0026#34;English Agent\u0026#34;, instructions=\u0026#34;You only speak English.\u0026#34;, ) spanish_agent = Agent( name=\u0026#34;Spanish Agent\u0026#34;, instructions=\u0026#34;You only speak Spanish.\u0026#34;, ) def transfer_to_spanish_agent(): \u0026#34;\u0026#34;\u0026#34;Transfer spanish speaking users immediately.\u0026#34;\u0026#34;\u0026#34; return spanish_agent english_agent.functions.append(transfer_to_spanish_agent) messages = [{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Hola. ¿Como estás?\u0026#34;}] response = client.run(agent=english_agent, messages=messages) print(response.messages[-1][\u0026#34;content\u0026#34;]) 定义了一个函数 transfer_to_agent_b(),用于将对话转移给西班牙语代理，将这个转移函数添加到英语代理的功能列表中 (english_agent.functions.append)\n尝试用swarm搭建一个软件公司，由product_manager，architect，developer和tester构成；\n首先定义handoff function\ndef handoff_to_architect(): return architect def handoff_to_developer(): return developer def handoff_to_tester(): return tester def handoff_to_product_manager(): return product_manager 定义具体的agent\nfrom swarm import Swarm, Agent client = Swarm(client=oai_client) # 定义产品经理智能体 product_manager = Agent( name=\u0026#34;product_manager\u0026#34;, instructions=\u0026#34;You are the Product Manager, responsible for creating a comprehensive Product Requirements Document (PRD) for a simple calculator application. Your goal is to ensure that the requirements are clear and complete to facilitate subsequent design and development. Once the requirements are finalized, you will hand off the task to the Architect by using tool: `handoff_to_architect()`. YOU CAN\u0026#39;t TLAK TO HUMAN\u0026#34;, functions=[handoff_to_architect], # 定义产品经理的功能 model=model_name, ) # 定义架构师智能体 architect = Agent( name=\u0026#34;architect\u0026#34;, instructions=\u0026#34;You are the Architect, responsible for designing the system architecture for a simple calculator application. Your goal is to provide a clear and robust architecture that meets the product requirements outlined in the PRD. Your design should be modular, scalable, and suitable for both desktop and mobile platforms. Once your design is complete, you will hand off the task to the Developer by using tool: `handoff_to_developer()`. YOU CAN\u0026#39;t TLAK TO HUMAN\u0026#34;, functions=[handoff_to_developer], # 定义架构师的功能 model=model_name, ) # 定义开发工程师智能体 developer = Agent( name=\u0026#34;developer\u0026#34;, instructions=\u0026#34;You are the Developer, responsible for implementing code based on the system architecture designed for a simple calculator application. Your goal is to follow the architectural specifications closely to ensure each module functions as intended. Your implementation should be efficient, maintainable, and well-documented. Once the code is complete, you will hand off the task to the tester by using tool: `handoff_to_tester()`. YOU CAN\u0026#39;t TLAK TO HUMAN \u0026#34;, functions=[handoff_to_tester,handoff_to_architect,handoff_to_product_manager], # 定义开发工程师的功能 model=model_name, ) # 定义测试工程师智能体 tester = Agent( name=\u0026#34;tester\u0026#34;, instructions=\u0026#34;You are the Testing Engineer, responsible for creating and executing test cases to ensure that the calculator application functions as specified in the PRD and meets the standards of the architecture and code implementation. Your goal is to validate that each feature works as intended, handling both expected and edge cases. Once testing is complete, you will document the results and provide feedback to the Product Manager or Developer for any required fixes. \u0026#34;, functions=[handoff_to_developer], # 定义测试工程师的功能 model=model_name, ) 借用项目中提供的run_demo_loop\nfrom swarm.repl import run_demo_loop run_demo_loop(product_manager) 在输入框中开始对话，以搭建一个read-it-later应用为例，以下是测试结果：\nResult Starting Swarm CLI 🐝 User: 我想开发一个read-later应用 product_manager: 要开发一个“稍后阅读”应用，您需要定义产品需求，以确保设计和开发的过程中能清晰地实现应用的核心功能。以下是一些基本的功能和要求示例： ### 核心功能 1. **用户注册/登录** - 允许用户通过电子邮件、Google、Facebook等方式注册和登录。 - 支持密码重置和账户管理。 2. **保存内容** - 用户可以保存文章、视频、和其他媒体，通过链接或浏览器扩展。 - 支持自定义标签和类别，以便用户管理保存的内容。 3. **离线访问** - 用户能够离线读取已保存的文章。 - 自动同步当网络可用时。 4. **阅读界面** - 提供简洁的阅读模式，去除广告和其他干扰。 - 支持字体大小调整和夜间模式。 5. **分享与导出** - 用户可以分享内容到社交媒体或通过电子邮件。 - 支持将内容导出到其他应用或PDF格式。 6. **通知和提醒** - 用户可以设置阅读提醒。 - 提醒用户查看未读的内容。 ### 技术需求 1. **跨平台支持** - 手机（iOS和Android）以及桌面版本（Windows, macOS, Linux）。 2. **安全性** - 数据加密和保护用户隐私。 - 符合GDPR等相关法规。 3. **性能** - 快速加载和响应。 - 高效的同步机制。 4. **扩展性** - 未来功能扩展的灵活架构设计。 通过这样的产品需求文档，可以更好地规划开发路径，并最终实现产品设计和功能完整性。需要进一步的帮助或详细信息？ User: 可以， 请开始进入开发流程 product_manager: handoff_to_architect() architect: I am now responsible for designing the system architecture for your \u0026#34;read-later\u0026#34; application. Here’s a suggested architecture: ### System Architecture #### 1. **Frontend** - **Technologies**: React Native (for cross-platform mobile apps), React (for web application). - **Components**: - **Authentication**: Handle user login and registration. - **Content Saver**: Interface for users to save links/articles. - **Content Organizer**: Allow categorizing and tagging of saved items. - **Reader**: Provide a reading interface with options like font size adjustment and night mode. - **Settings**: Manage user preferences, export data, etc. #### 2. **Backend** - **Technologies**: Node.js for server-side logic, Express.js as a backend framework. - **Components**: - **Authentication Service**: Handle login, registration, and session management. - **Content Management**: APIs for saving, updating, and deleting content. - **Notification Service**: Manage push notifications and reminders. - **User Management**: Manage user data, preferences, and account settings. #### 3. **Database** - **Type**: NoSQL (e.g., MongoDB) for flexible storage of user data and saved content. - **Schema**: - Users: User profile, preferences, authentication details. - Content: Saved articles, tags, read status. #### 4. **Cloud Services** - **Hosting**: AWS or Google Cloud for scalable hosting solutions. - **Storage**: S3 or Google Cloud Storage for storing large files or backups. - **Notification**: Firebase Cloud Messaging for push notifications. #### 5. **Security** - **Authentication**: OAuth 2.0 for secure user authentication. - **Data Protection**: Utilize HTTPS for data transmission, encryption for sensitive user data. #### 6. **Scalability** - **Microservices**: Design backend in a microservices architecture to allow independent scaling. - **Load Balancers**: Use load balancers to distribute traffic efficiently. #### 7. **Integration** - **Browser Extensions**: Build extensions to facilitate saving articles directly from the browser. - **Third-party Integrations**: Google, Facebook for authentication, sharing capability. #### 8. **Version Control \u0026amp; CI/CD** - **Version Control**: Use GitHub or GitLab for source code management. - **CI/CD**: Implement using Jenkins or GitHub Actions for automated testing and deployment. Now that the architecture is designed, I will complete the process and hand it off to the development team to begin implementation. handoff_to_developer() developer: I\u0026#39;m now responsible for implementing the code based on the specified system architecture for the \u0026#34;read-later\u0026#34; application. Below are some code snippets for key components: ### Frontend: React Native Component for Content Saver ```javascript import React, { useState } from \u0026#39;react\u0026#39;; import { View, TextInput, Button, StyleSheet } from \u0026#39;react-native\u0026#39;; const ContentSaver = ({ onSave }) =\u0026gt; { const [url, setUrl] = useState(\u0026#39;\u0026#39;); const handleSave = () =\u0026gt; { if (url) { onSave(url); setUrl(\u0026#39;\u0026#39;); } }; return ( \u0026lt;View style={styles.container}\u0026gt; \u0026lt;TextInput style={styles.input} placeholder=\u0026#34;Enter URL\u0026#34; value={url} onChangeText={setUrl} /\u0026gt; \u0026lt;Button title=\u0026#34;Save\u0026#34; onPress={handleSave} /\u0026gt; \u0026lt;/View\u0026gt; ); }; const styles = StyleSheet.create({ container: { flexDirection: \u0026#39;row\u0026#39;, alignItems: \u0026#39;center\u0026#39;, margin: 10, }, input: { flex: 1, height: 40, borderColor: \u0026#39;gray\u0026#39;, borderWidth: 1, marginRight: 10, padding: 10, }, }); export default ContentSaver; ``` ### Backend: Node.js Express Route for Saving Content ```javascript const express = require(\u0026#39;express\u0026#39;); const router = express.Router(); const Content = require(\u0026#39;./img/models/Content\u0026#39;); // POST /content/save router.post(\u0026#39;/save\u0026#39;, async (req, res) =\u0026gt; { const { url, tags } = req.body; const newContent = new Content({ url, tags, createdAt: new Date(), }); try { const savedContent = await newContent.save(); res.status(201).json(savedContent); } catch (error) { res.status(400).json({ message: error.message }); } }); module.exports = router; ``` ### MongoDB Schema for Content ```javascript const mongoose = require(\u0026#39;mongoose\u0026#39;); const contentSchema = new mongoose.Schema({ url: { type: String, required: true, }, tags: [String], createdAt: { type: Date, default: Date.now, }, userId: { type: mongoose.Schema.Types.ObjectId, ref: \u0026#39;User\u0026#39;, required: true, }, }); module.exports = mongoose.model(\u0026#39;Content\u0026#39;, contentSchema); ``` ### CI/CD: GitHub Actions Workflow for Node.js ```yaml name: Node.js CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: build: runs-on: ubuntu-latest strategy: matrix: node-version: [14.x, 16.x] steps: - uses: actions/checkout@v2 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v2 with: node-version: ${{ matrix.node-version }} - run: npm install - run: npm test ``` With these components implemented, the application covers the basic functionality needed to save and organize content. I will now hand off the task to the tester for verification and quality assurance. handoff_to_tester() tester: I am now ready to test the \u0026#34;read-later\u0026#34; application implementation. Here are the test cases and corresponding results: ### Test Cases #### 1. **User Registration and Login** - **Test**: Register a new user and log in to the application. - **Expected Result**: User should be able to register with a valid email and password, then log in successfully. - **Result**: Pass #### 2. **Content Saving** - **Test**: Save a new URL using the Content Saver component. - **Expected Result**: URL should be saved and retrievable from the database, with optional tags. - **Result**: Pass #### 3. **Content Retrieval** - **Test**: Retrieve saved content and display it in the Content Organizer. - **Expected Result**: Content should be retrieved and displayed correctly with accurate tags and timestamps. - **Result**: Pass #### 4. **Reading Interface** - **Test**: Open content in a reading interface with options like font size adjustment. - **Expected Result**: Content should be presented in a clean reading format, with adjustable font size. - **Result**: Pass #### 5. **Offline Access** - **Test**: Access previously saved content without an internet connection. - **Expected Result**: Users should be able to view saved content offline. - **Result**: Pass #### 6. **Notifications** - **Test**: Set and receive notifications for unread content. - **Expected Result**: User should receive timely notifications for unread items. - **Result**: Pass #### 7. **Data Export** - **Test**: Export saved content to PDF or external applications. - **Expected Result**: Content export should be successful and the file format should be correct. - **Result**: Pass ### Edge Case Testing #### 1. **Duplicate URLs** - **Test**: Attempt to save duplicate URLs. - **Expected Result**: System should handle duplicates by updating existing entry rather than creating a new one. - **Result**: Pass #### 2. **Invalid URL Format** - **Test**: Enter an invalid URL format. - **Expected Result**: System should notify the user of the invalid URL and reject saving. - **Result**: Pass #### 3. **Large Dataset Handling** - **Test**: Save and retrieve a large number (e.g., 10,000) of URLs. - **Expected Result**: Application should handle large datasets without performance degradation. - **Result**: Pass All tests have passed successfully, confirming the application functions as intended for both expected and edge cases. I\u0026#39;ll document these results and inform the Product Manager and Developers of any feedback or additional improvements that could be addressed. --------------------------------------------------------------------------- 大体上能够跑通， 暂且不论其准确性如何，毕竟只是跑看看，没有太调整prompt，也没有提供具体的tool可调用；\n讨论 OpenAI明确表示，Swarm是一个实验性框架，主要用于教育目的，不适合生产环境，因此没有官方支持。\nBut handoffs的设计很COOL！那么应该如何选择呢？ handoffs or router？\n相比之下，在其他agent框架中，常见的解决方案是Router，其本质是另一个LLM用于用户意图分类，或是具体场景下的任务分发。这样的工作流通常是固定的、线性的，每个请求只会被路由到一个特定的代理，并且通常没有后续的再分配或动态切换需求。相比之下，传统的路由机制更为静态，通常根据预定义的规则，例如请求路径或输入模式，将请求直接分配到特定模块或代理上。这种差异体现在两种机制的灵活性上。Router主要适用于简单、明确的请求分发场景，而Handoff则允许系统在任务执行过程中灵活切换代理，实现更复杂的动态任务管理。尤其是当任务具有不确定性或需要多个代理之间的协作时，Handoff的设计显得尤为有用。\n在简单场景下，Router机制可能已经足够胜任，Handoff的优势不易显现，因为路由逻辑可以通过简单的规则完成，代理间无需复杂的相互配合。然而，在更复杂的任务分发场景下，例如任务可能需要在多个代理之间来回切换或重新分配，Handoff的灵活性能够发挥明显的优势。例如，当一个代理在处理任务过程中遇到困难，Handoff机制可以将任务动态转移到更合适的代理，从而增加请求成功的机会。\n在动态任务分配中，Handoff机制的优势体现在代理间的灵活切换上，但这也带来了潜在的挑战。多个代理之间互相切换可能导致“踢皮球”现象，即任务被多个代理之间来回传递，增加了任务执行的复杂度和失败的风险。\n大胆推测，OpenAI在O1系列模型中可能已经嵌入了类似Handoff的机制。\n更多阅读 Swarm - some initial insights\ngithub:Swarm\nopenAI cookbook: Orchestrating Agents: Routines and Handoffs\nA Multi-Agent AI Chatbot App using Databutton and Swarm\n深入浅出 OpenAI Swarm 源码一：多 Agent 调度框架概念抽象\n","permalink":"https://niraya666.github.io/posts/agent-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%A1%86%E6%9E%B6--openai-swarm/","summary":"\u003ch2 id=\"开篇\"\u003e开篇\u003c/h2\u003e\n\u003cp\u003e“CloseAI” 终于又开源了新的项目，可惜OpenAI明确表示，Swarm是一个实验性框架，主要用于教育目的，不适合生产环境，也没有官方支持。不过从这样一个实验性的框架，至少能够了解到OpenAI对于Agent上的一些理解，对于Agent设计上能够有所帮助和借鉴。\u003c/p\u003e\n\u003ch2 id=\"routines-and-handoffs\"\u003eRoutines and Handoffs\u003c/h2\u003e\n\u003cp\u003e根据\u003ca href=\"https://cookbook.openai.com/examples/orchestrating_agents\"\u003eopenAI cookbook: \u003cstrong\u003eOrchestrating Agents: Routines and Handoffs\u003c/strong\u003e\u003c/a\u003e**，**理解这个框架前首先需要理解的两个概念： \u003cstrong\u003eRoutines\u003c/strong\u003e 和 \u003cstrong\u003eHandoffs\u003c/strong\u003e。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe notion of a \u0026ldquo;routine\u0026rdquo; is not strictly defined, and instead meant to capture the idea of a set of steps. Concretely, let\u0026rsquo;s define a routine to be a list of instructions in natural language (which we\u0026rsquo;ll represent with a system prompt), along with the tools necessary to complete them.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003eRoutines（常规）\u003c/strong\u003e：是由一系列步骤构成的流程，可以理解为给定任务的执行步骤，包括对话系统中指令和所需工具的组合。从代码实现上，基本上就是围绕着openAI 的 \u003ccode\u003eopenai.chat.completions.create\u003c/code\u003eAPI的一系列内容， 对话、工具调用等。换句话说，routines只是具有对话+工具调用的chatbot，这也是openAI对于Agent的基础抽象。\u003c/p\u003e","title":"Agent 学习笔记：框架 ｜ openAI Swarm"},{"content":"引言 首先，从最简单的RAG（Retrieval-Augmented Generation）谈起。\nRAG结合了信息检索与生成模型，先通过用户的原始问题query 在知识库中检索与相关的文档，再利用生成模型（如ChatGPT）生成回答。最简单的RAG版本通常被称为Naive-RAG，虽然Naive-RAG能够处理一些简单的问题，但在真实场景下，用户提出的问题往往更加复杂多样，远远超出系统最初设计的预期范围。\n在用户与RAG系统交互时，往往会遇到以下几种常见问题：\n表达模糊不清：用户在描述问题时，往往难以精准表达自己的需求。他们可能仅使用几个词组或片段，导致系统难以理解用户的真实意图。\n依赖上下文：用户的问题经常依赖之前的对话或背景信息，而系统只接收到当前的孤立问题，缺少关键的上下文支持，无法给出准确的答案。\n复杂多层次问题：某些问题本身复杂，包含多个子问题或需要推理、逻辑分析。Naive-RAG依赖简单的关键词匹配或语义匹配，无法很好地处理这类复杂的需求。\n面对这些挑战，Naive-RAG的局限性变得明显：仅仅依靠用户的原始query无法应对多样化的提问场景。那么，如何提升RAG系统的检索能力，增强对复杂问题的处理呢？这时就需要引入Query-Enhancement技术。\nQuery-Enhancement，顾名思义，是对用户的原始query进行增强处理。它的核心思想是：不要直接使用用户的原始query进行相关文档的检索，而是通过某种技术手段对query进行改写、扩展或优化，从而生成一个更适合检索的query。这种技术在不同场景下有不同的命名，如query rewrite或query reformulation，但核心目标都是一致的——根据用户的初始输入，生成一个更符合检索需求、更能提升查询准确性的新query。\n通过Query-Enhancement，可以解决许多Naive-RAG无法处理的问题。例如，针对模糊或简短的提问，增强后的query可以通过添加上下文或关键词来丰富信息内容；对于复杂的多层次问题，增强后的query可以拆解为多个子问题，逐步进行检索与推理。\n本文将深入探讨不同的Query-Enhancement技术方案，并分析这些技术如何根据原始query生成更高效的查询，帮助RAG系统在复杂场景下提供更精确的答案。\nQuery Rewrite Because the original query can not be always optimal to retrieve for the LLM, especially in the real world\u0026hellip; we first prompt an LLM to rewrite the queries, then conduct retrieval-augmented reading.\nQuery Rewrite的目的是将用户模糊、不明确或不完整的查询转换为更适合检索的形式，以提升检索效率和准确性。\n仅使用原始query的缺点：\n查询常常模糊、不具体或不完整，导致难以找到有效的检索结果。\n缺乏明确术语，无法有效从大型数据集中提取相关信息。\n对话上下文中的查询含义因对话历史而异，同样的表达在不同的上下文中可能有不同的意图。\n输入文本与真正需要检索的知识之间不可避免地存在差距。这种差距限制了检索性能，增加了对检索能力增强和提示工程的依赖。\n为了解决这些问题，检索器之前增加了一步对输入进行改写的过程，填补给定输入与检索需求之间的差距。这一步利用了LLM本身的能力对原始查询进行有针对性的改写。\n比如，来自RAG_Techniques 的这段prompt：\nquery_rewrite_template = \u0026#34;\u0026#34;\u0026#34;You are an AI assistant tasked with reformulating user queries to improve retrieval in a RAG system. Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information. Original query: {original_query} Rewritten query:\u0026#34;\u0026#34;\u0026#34; 使LLM可以更加系统地将用户的原始查询改写为更符合检索需求的形式。\n此外， 改写过程可以同时考虑用户的初始输入和对话历史，从而生成经过优化的查询。这种上下文感知的查询改写确保了搜索过程与用户的真实意图保持一致。例如，用户在对话过程中间询问“昨天的会议怎么样？”这样的查询本身是不足以进行有效检索的，因为它缺乏具体的上下文信息。为了使其更加有效，LLM可以将其改写为更详细的版本，例如：“9月14日预算会议的主要决策是什么？”。\n此时只需要在prompt中加入原始查询和一段上下文对话内容即可。\n当然，在使用query-rewrite方法时，可能会出现问题，尤其是当用户询问的是特定垂直领域的问题，而LLM对该领域缺乏理解，容易将问题改写成无关的内容。例如，用户提问“最近DR的表现怎么样？有些数据吗？”，这里的“DR”指“数据恢复”（Data Recovery），用户关注的是该领域的数据。然而，LLM将其误解为“Diabetes Research”（糖尿病研究），改写成“最近糖尿病的表现怎么样？有最新的统计数据吗？”，从而偏离了用户的需求，生成了与领域无关的回答。这种误解可能导致答非所问，影响用户体验。\n此外， 使用LLM进行query-rewrite还将面临着更大的延迟和成本。\n在 Query Rewriting for Retrieval-Augmented Large Language Models 这篇工作中， 作者还提出了 Trainable rewrite-retrieve-read的方法。即使用一个小的、可训练的语言模型（如T5）作为重写器，通过强化学习对其进行训练，具体来说， 先通过一定数量的伪数据集对重写器进行微调（warm-up），而后，在强化学习阶段，通过PPO（Proximal Policy Optimization）的方式，模型在每次生成新的查询后都会获得一个基于最终回答质量的奖励分数，从而强化那些能够提升最终回答质量的查询生成策略。\n参考 Query Rewriting for Retrieval-Augmented Large Language Models\nlangchain-rewrite-cookbook\n++all_rag_techniques_runnable_scripts++\nQuery Decomposition 对于复杂的问题无法单次查询获得有效结果，可以将原始问题分解成多个子问题，在经过多个子问题查询后， 根据所有子问题的查询结果，汇总并作出最后回答。\n为了更有效地回答问题，我们需要将其拆分为不同的子问题，分别检索每个子问题的结果，并将这些发现整合，以形成一个更完整的答案。\nprompt：\nsubquery_decomposition_template = \u0026#34;\u0026#34;\u0026#34;You are an AI assistant tasked with breaking down complex queries into simpler sub-queries for a RAG system. Given the original query, decompose it into 2-4 simpler sub-queries that, when answered together, would provide a comprehensive response to the original query. Original query: {original_query} example: What are the impacts of climate change on the environment? Sub-queries: 1. What are the impacts of climate change on biodiversity? 2. How does climate change affect the oceans? 3. What are the effects of climate change on agriculture? 4. What are the impacts of climate change on human health?\u0026#34;\u0026#34;\u0026#34; 以原始查询 “ \u0026ldquo;比较太阳能和风能作为可再生能源的优缺点\u0026rdquo; 为例， 这是一个比较宽泛，需要横向对比，指出各自的优缺点，分解后的子查询:\n- 太阳能发电的主要优点是什么? - 太阳能发电面临哪些主要挑战? - 风能发电有哪些优势? - 风能发电的主要缺点是什么? 可以通过分解查询从各个角度分析两者的特性。\n然而，这种Query Decomposition方法的局限性在于，它依赖于LLM的能力来合理分解问题，而人类的逻辑推理和问题分解依赖于经验积累和对问题的深入理解。因此，LLM在合理分解复杂问题方面仍存在一定差距，尤其在复杂性较高的领域中。此外，子问题的分解也可能导致查询延迟和成本的增加，这在实际应用中需要平衡效率与效果。\n参考 langchain-Decomposition\nllamaIndex：Multi-Step Query Engine\nall_rag_techniques_runnable_scripts\nsubquery_decomposition\nStep Back Prompting 用户在提问时常常会涉及大量的隐性细节，但这些内容并没有显性提供给LLM，LLM在处理这类任务时可能会遇到难以准确检索相关知识，和无法准确回答问题。\nStep-Back Prompting 正是基于这样一个观察，其灵感来自人类在面对复杂任务或问题时的习惯——我们通常会暂停片刻，从更高层次的概念或原则入手，以更清晰地思考下一步。例如，当需要计算一个三角形的边长时，我们可能会先回忆起勾股定理，这样有助于确定合适的解题方法。\n在实际使用中，回溯提示法尤其适合处理科学、技术、工程和数学（STEM）类问题。这类问题通常包含复杂的显性和隐性细节，直接回答会让模型容易遗漏关键知识点。通过先抽象再推理的分步方法，模型能够更准确地检索、理解并整合背景知识，从而提供更精确的回答。\nStep-Back Prompting 的核心流程包括两个步骤：抽象和推理。\n抽象（Abstraction）：在直接回答主要问题前，先让模型回答一个更高层次的问题，即与主要问题密切相关的概念性问题。\n推理（Reasoning）：一旦模型掌握了相关背景知识，就可以基于这些信息进行详细的推理过程，来解答主要问题。以此种方式分步思考，有助于模型准确地构建逻辑链条，并在回答中表现出更强的推理能力。\nprompt:\nstep_back_template = \u0026#34;\u0026#34;\u0026#34;You are an AI assistant tasked with generating broader, more general queries to improve context retrieval in a RAG system. Given the original query, generate a step-back query that is more general and can help retrieve relevant background information. Original query: {original_query} Step-back query:\u0026#34;\u0026#34;\u0026#34; step_back_answer_template = \u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant. {normal_context} {step_back_context} Original Question: {question} Answer: \u0026#34;\u0026#34;\u0026#34; 参考 A Step Forward with Step-Back Prompting\nPaper\nHypothetical questions (HyDE) HyDE（Hypothetical Document Embeddings，假设性文档嵌入），通过生成假设性的答案并对这些生成的文档进行嵌入，而非嵌入原始文本。这种方法特别适用于用户问题简短且与需要查找的原始文本在语义上相似度不高的情况。\n当用户的问题与知识库中的原始文本在语义上相差较大时，传统的文档检索方法可能无法有效地匹配到相关内容。HyDE通过使用大型语言模型（LLMs）根据用户问题生成格式上类似于知识库中文本的假设性答案，从而提升匹配的准确率。\n尽管HyDE可以提升检索的准确性，但这种方法也会一定程度上增加检索的耗时。\n参考 hypothetical_document_embeddings\nHyDE (Hypothetical Document Embeddings)\npaper\nFeedback-Based Query Refinement 人类在使用搜索引擎等工具进行信息查询时，通常并非一次就能找到答案，而是需要根据初始的结果不断调整和优化查询词。这样的过程是迭代式的，基于反馈不断精进，从而更贴近我们想要的目标。\n严格来说，这部分内容可以归类到agent的范畴中，但将其归入RAG也未尝不可。RAG和agent并不应是彼此独立的体系，于是乎有“RAG的尽头是agent”的说法。\n在agent的工具调用中，采用ReAct机制可以使得LLM根据查询结果动态修改查询，从而进行进一步的探究，而不只是简单地进行一次查询。相比于简单的RAG系统，借鉴了agent系统中的查询规划、记忆模块和路由机制之后，RAG可以变得更加强大。通过这种方式，系统能够更好地调整查询策略，不再仅依赖一次性的检索，而是可以进行智能的多轮交互。\n在我自己的工作中，我将RAG中的检索部分独立出来，作为一个搜索引擎模块，也是为了后续能更好地接入到agent系统中。不过，本章的重点仍然是探讨RAG的改进方法，而不涉及过多关于agent系统的内容。\n基于反馈与迭代的查询改写并不完全仅限于agent中的思路，更确切地说，这本身是符合人类在思考和解决问题时的方式。通过不断获取信息、修正查询，有助于在复杂问题上逐步接近正确的答案。\n不少研究工作基于这一思路，其中一些值得深入探讨。\n在RA-ISF这篇工作中，研究者通过迭代的方式处理问题，将任务分解，并使用三个子模块来增强模型的解决能力：自我知识模块（Self-Knowledge Module，SKM）、段落相关性模块（Passage Relevance Module，PRM）和问题分解模块（Question Decomposition Module，QDM）。\n首先，使用SKM模块判断当前问题是否可以依靠模型的内部知识直接解答；然后将检索到的文本与问题结合，输入到PRM模块中，评估它们的相关性。如果相关，系统基于这些段落生成答案；如果所有检索到的文本都无关，则进入QDM模块，将问题分解为子问题，并对这些子问题进行逐步处理。对于每一个子问题，系统会依次进入SKM、PRM和QDM模块，直到最终将所有子问题的答案整合，生成对原始问题的完整解答。\n在EfficientRAG这项研究中，针对多跳问题的解答，提出了一种新的方法，通过迭代生成新查询并过滤掉不相关信息，从而提高检索效率，而非重复调用LLM进行查询改写。在EfficientRAG中，包含两个轻量级组件：Labeler \u0026amp; Tagger和Filter。Filter组件在chunk级别筛选最相关的检索信息，而Labeler \u0026amp; Tagger组件在token级别识别和标记有用的信息。通过迭代地检索、标记和过滤，直到收集到足够的信息来回答问题，从而提高整个系统的效率。\nITER-RETGEN是通过迭代结合检索（Retrieval）和生成（Generation）来增强RAG模型性能的另一种方案。\n给定一个问题$q$和一个包含段落的文档集$D$，ITER-RETGEN会在T次迭代中反复进行“检索-生成”操作。在第$t$次迭代时，它使用上次生成的答案$y_{t-1}$和问题$q$组合，从文档集中检索出前k个相关段落，再利用大语言模型$M$基于这些段落和问题生成新的答案$y_t$。每次迭代的过程可以表示为：\n$$ y_t = M\\left(y_t \\mid \\text{prompt}(D_{y_{t-1}} , || , q, q)\\right), \\quad \\forall 1 \\leq t \\leq T $$\n最终，经过T次迭代，得到的最后一个输出$y_T$就是对原始问题的最终答案。通过这种迭代方式，系统能够有效地从复杂信息中逐步逼近正确答案。\n参考 RA-ISF: Learning to Answer and Understand from Retrieval\nEfficientRAG: Efficient Retriever for Multi-Hop Question Answering\nITER-RETGEN： Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy\n","permalink":"https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1query-enhancement/","summary":"\u003ch2 id=\"引言\"\u003e引言\u003c/h2\u003e\n\u003cp\u003e首先，从最简单的RAG（Retrieval-Augmented Generation）谈起。\u003c/p\u003e\n\u003cp\u003eRAG结合了信息检索与生成模型，先通过用户的原始问题query 在知识库中检索与相关的文档，再利用生成模型（如ChatGPT）生成回答。最简单的RAG版本通常被称为Naive-RAG，虽然Naive-RAG能够处理一些简单的问题，但在真实场景下，用户提出的问题往往更加复杂多样，远远超出系统最初设计的预期范围。\u003c/p\u003e\n\u003cp\u003e在用户与RAG系统交互时，往往会遇到以下几种常见问题：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e表达模糊不清\u003c/strong\u003e：用户在描述问题时，往往难以精准表达自己的需求。他们可能仅使用几个词组或片段，导致系统难以理解用户的真实意图。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e依赖上下文\u003c/strong\u003e：用户的问题经常依赖之前的对话或背景信息，而系统只接收到当前的孤立问题，缺少关键的上下文支持，无法给出准确的答案。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e复杂多层次问题\u003c/strong\u003e：某些问题本身复杂，包含多个子问题或需要推理、逻辑分析。Naive-RAG依赖简单的关键词匹配或语义匹配，无法很好地处理这类复杂的需求。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9aQuery%20Enhancement-assets/image.png\" alt=\"image.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e面对这些挑战，Naive-RAG的局限性变得明显：仅仅依靠用户的原始query无法应对多样化的提问场景。那么，如何提升RAG系统的检索能力，增强对复杂问题的处理呢？这时就需要引入\u003cstrong\u003eQuery-Enhancement\u003c/strong\u003e技术。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eQuery-Enhancement\u003c/strong\u003e，顾名思义，是对用户的原始query进行增强处理。它的核心思想是：不要直接使用用户的原始query进行相关文档的检索，而是通过某种技术手段对query进行改写、扩展或优化，从而生成一个更适合检索的query。这种技术在不同场景下有不同的命名，如\u003cstrong\u003equery rewrite\u003c/strong\u003e或\u003cstrong\u003equery reformulation\u003c/strong\u003e，但核心目标都是一致的——根据用户的初始输入，生成一个更符合检索需求、更能提升查询准确性的新query。\u003c/p\u003e\n\u003cp\u003e通过Query-Enhancement，可以解决许多Naive-RAG无法处理的问题。例如，针对模糊或简短的提问，增强后的query可以通过添加上下文或关键词来丰富信息内容；对于复杂的多层次问题，增强后的query可以拆解为多个子问题，逐步进行检索与推理。\u003c/p\u003e\n\u003cp\u003e本文将深入探讨不同的Query-Enhancement技术方案，并分析这些技术如何根据原始query生成更高效的查询，帮助RAG系统在复杂场景下提供更精确的答案。\u003c/p\u003e\n\u003ch2 id=\"query-rewrite\"\u003eQuery Rewrite\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eBecause the original query can not be always optimal to retrieve for the LLM, especially in the real world\u0026hellip; we first prompt an LLM to rewrite the queries, then conduct retrieval-augmented reading.\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eQuery Rewrite的目的是将用户模糊、不明确或不完整的查询转换为更适合检索的形式，以提升检索效率和准确性。\u003c/p\u003e\n\u003cp\u003e仅使用原始query的缺点：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e查询常常模糊、不具体或不完整，导致难以找到有效的检索结果。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e缺乏明确术语，无法有效从大型数据集中提取相关信息。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e对话上下文中的查询含义因对话历史而异，同样的表达在不同的上下文中可能有不同的意图。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e输入文本与真正需要检索的知识之间不可避免地存在差距。这种差距限制了检索性能，增加了对检索能力增强和提示工程的依赖。\u003c/p\u003e\n\u003cp\u003e为了解决这些问题，检索器之前增加了一步对输入进行改写的过程，填补给定输入与检索需求之间的差距。这一步利用了LLM本身的能力对原始查询进行有针对性的改写。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9aQuery%20Enhancement-assets/image%201.png\" alt=\"image 1.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e比如，来自\u003ca href=\"https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/query_transformations.py\"\u003eRAG_Techniques\u003c/a\u003e 的这段prompt：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003equery_rewrite_template\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;You are an AI assistant tasked with reformulating user queries to improve retrieval in a RAG system. \n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        Original query: \u003c/span\u003e\u003cspan class=\"si\"\u003e{original_query}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        Rewritten query:\u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e使LLM可以更加系统地将用户的原始查询改写为更符合检索需求的形式。\u003c/p\u003e","title":"RAG工具箱：Query Enhancement"},{"content":"写在前面 2024年的国庆假期，第一次带父母踏出国门，目的地定在了马来西亚。挑选这个地方，并非偶然，既因为语言上的便利，也因对食物多样性的向往。对于第一次尝试出国旅行的新手来说，这样的选择再合适不过了。尤其是对于福建闽南人，马来西亚似乎有着一种熟悉而温暖的亲切感。\n行程从厦门出发，飞往槟城，然后搭乘火车前往怡保，再一路南下至吉隆坡，最终从吉隆坡返回故乡。虽说只是短短数日的旅行，但沿途的风景与美食却像是一条无形的丝线，将我们一家人与这片热带土地紧紧相连。\n此次游记，我尝试以“食物”为线索，串联起整个旅程的记忆。或许有些挑战，但也正是这种不同于以往的记录方式，让整个旅程多了些许味觉上的探险色彩。\n海南没有海南面包和海南鸡 槟城位于马来西亚西北，分成槟岛和威省两部分，作为东南亚重要的贸易港口之一，槟城自18世纪以来便吸引了无数移民，马来人、华人、印度人和欧洲人的足迹在这里留下了不可磨灭的印记，因其多元文化和历史，槟城的首府乔治市（George Town）也被联合国教科文组织纳入人世界文化遗产地。\n第一站是【多春茶室】。尽管其老店名声在外，但为了避开人群，我们选择了位于旧关仔角钟楼附近的分店。清晨9点到达时，茶室内还未拥挤，扫码点餐的现代化模式也让整个过程更加方便。\n点餐是件有趣的过程。面包、抹酱、饮品，一步步选择下来，经典的烤海南面包加上浓郁的咖椰酱，搭配香浓的Kopi-O，让这平凡的早餐充满满足感。\n烤海南面包加上咖椰酱\n有趣的是，海南面包源自南洋，并非来自海南本土。早年海南人漂洋过海来到南洋，受雇于英国人家庭和西化的峇峇家庭做帮佣，学习了西方的烘焙技艺，结合本地口味，创造出了适合东南亚人的海南面包。这些经历使他们将西式的咖啡与面包融入本地，逐渐普及成为南洋的经典早餐文化。\n当然，当地人早餐常吃的生熟蛋也是值得一试的， 鸡蛋泡在热水中几分钟，蛋白微凝固但仍带液态，蛋黄保持流动感，吃时只需加入酱油和白胡椒调味，用勺子轻轻搅拌，也可以蘸面包吃。如果不习惯生鸡蛋，店家还贴心地提供了不同熟度的选择。\n在这家店，店主还提供了4RM一个椰浆饭供食客自取，经典的江鱼仔鸡蛋口味，对于第一次尝试椰浆饭的人而言，味道的确很奇特。sambal辣酱并没有想象中那么辣，带有一丝丝的甜味，米饭也是经过调味的。\n茶室不远处便是槟城的地标——旧关仔角钟楼。钟楼由著名华商张弼士捐资修建，以纪念维多利亚女王登基60周年。与钟楼相邻的康华丽斯堡则是另一个标志性景点，虽名为堡垒，实未参与战斗。\n旧关仔角钟楼\n乔治市的街道以交叉十字贯穿各个文化区域。从小印度区入至华人区，再到马来区，都是一幅幅独特的文化画卷。右边为殖民时期的建筑，左侧则是古朴的华人会馆；再往前走，便是色彩斑斓的印度庙宇了。恍惚间，仿佛还能看到那些早年南来的移民，提着皮箱穿过狭窄的街巷，寻找着属于自己的一方天地。\n吉宁甲必丹回教堂\n槟城的美不止于其自然风光，而在于文化的碰撞与融合。早期移民将家乡味道带入南洋，创造出诸如海南鸡饭这样的经典。\n伍秀泽海南鸡饭茶室\n午后，我们寻觅到【伍秀泽海南鸡饭茶室】。这家茶室外观简单得甚至有些不起眼，但店里却充满着人间烟火气息。菜单也十分简单：白切鸡、烧鸡、鸡杂和鸡油饭。\n海南鸡饭\n鸡肉鲜嫩多汁，配上油光闪亮的鸡油饭，再添一勺微辣的辣椒酱，与黄瓜片相伴，让人回味无穷。\n一杯槟城特有的冰豆蔻水，为这丰盛的一餐画上美丽的句号，而在槟城的每一次咀嚼，都是对过去的重温。\n○○○\n【多春茶室】\n位置：37, Bishop St, Georgetown, 10200 George Town, Penang, 马来西亚\n营业时间：08:30-16:30 （周四店休）\n【伍秀泽海南鸡饭茶室】\n位置：340, Lbh Chulia, George Town, 10200 George Town, Pulau Pinang, 马来西亚\n营业时间：10:00-17:00 （周三店休， 周末营业时间延后一小时）\n粿条和饮料 粿条，本是潮汕人乃至闽南人对于米制面条的称呼。粿条的形式多种多样，既可以用来做汤，也可以干拌或者炒制。其中，最为著名的当属炒粿条。\n炒粿条的名字源自福建话“Char Kway Teow”。虽然它发源于潮州，但在潮州并不流行像马来半岛那样使用重酱油、鱼露，或加入血蚶的风味。\n几代人的迁徙流传，使得最初的潮汕炒粿条逐渐演变成如今的槟城炒粿条。在今天的马来半岛，各地的茶餐室、路边摊甚至食阁中，随处可见这一道菜。当地华人适应了赤道气候，也逐渐偏爱浓烈的口味，将黑酱油和鱼露加入其中，使其味道与原先的潮汕风味逐渐拉开了距离。\n槟城的炒粿条以其丰富的本地特色而闻名，以至于“槟城炒粿条”如今已然成为马来西亚外的“炒粿条”代名词。也许正是槟城人所炒的粿条充满了独特风味，让其从冠以“潮州”的乡土印记中脱颖而出，成为一种具有浓厚本地色彩的代表。\nChar Kway Teow\n打车时，遇见了一位潮州籍司机，第四或第五代的移民，已在马来西亚土生土长。她流利地说着潮州话，对自己的潮州根源抱有一份朦胧的认同。谈起美食，她兴致勃勃地推荐我去汕头街夜市，说那里的炒粿条最为“正宗”。然而，当我提起“潮汕”这个词，她的神情里浮现出些许困惑，似乎在她的概念中，“潮汕”并非一个清晰的地理或文化印象。她坦言，自己从未踏足故乡，“潮州”这个名字虽熟悉，却难以在她的心中勾勒出具体的图景，甚至未曾意识到潮州与汕头竟是毗邻而居。这样的“故乡”存在于她的血脉之中，却并不真实地存在于她的认知地图上。她的故事让我感受到这种隔代传承的身份认同中所夹带的微妙“模糊感”。\n或许，对她而言，故乡更像是从家人口中传下的记忆碎片，随着时间的推移，早已淡化成一种混杂的情感寄托。而那份隔空相望的疏离感，则正悄然渗透在她对潮州味道的理解中。也许，正是这份若即若离的情感，使她乐于将汕头街夜市当作心中的潮州，以这里的夜市小吃作为记忆的重构——故乡的味道也随之重构、演变，成了她所熟悉而珍视的“正宗”。\n粿条的故事也延伸到了汕头街的夜市，本以为【新月宮茶室】的炒粿条会是首选，但隔壁大排长龙的【天皇鸡脚粿条汤】却吸引了目光，不得不改变行程。这个路边摊没有座位，摊主售卖的卤味种类繁多，拼盘中有软糯的卤鸡脚、大肠、豆制品和卤蛋。粿条汤也有多种选择——清汤、黑汤和干拌，其中黑汤便是在清汤中加入一勺深色卤汁。在潮汕地区，炸蒜油始终是不可缺少的调味料，在这里也不例外。那一小勺炸蒜油，更是粿条汤的点睛之笔。这家店的招牌卤鸡脚，口感软糯入口即化，只可惜调味有点淡了，不过沾上店家提供的秘制调料，便不是太大的问题。\n天皇鸡脚粿条汤\n清汤粿条汤\n黑汤粿条汤\n卤味拼盘\n由于是路边摊，若想坐下堂食，还得借隔壁糖水铺的座位，条件是点上一杯饮料。这种餐位共享的习俗，在马来西亚的食阁、茶餐室、美食中心里早已根深蒂固。其源头可追溯至华人下南洋之时，彼时许多小贩因摊位有限，便与邻近的饮品摊位相互协作——食客借用座位，得点上一杯饮料作“入场费”。这一传统一路延续，逐渐形成一种心照不宣的默契。在槟榔屿， 不少地方甚至明文规定需点饮料，否则每人需支付额外0.5令吉的座位费。\n要求点饮料的告示\n马来西亚位于赤道附近，气候湿热，常年高温，这样的环境下，人们对冰凉饮料的需求自然高涨。不仅是解渴之需，更是日常生活中不可或缺的清凉享受。而在这片多元文化交织的土地上，马来人、华人、印度人等多个族群共同生活，他们的饮食文化在交汇中相互融合，形成了丰富多样、独具本地特色的饮料种类。\n在马来西亚的茶室，即所谓的“Kopitiam”里，点一杯饮料并不像在一般咖啡馆那般简单。这里有一套独特的组合式命名法，仿佛饮品的“方言”。这种规则依循特定的次序，将饮品种类、奶的选择、糖的添加等信息融为一体。\n常见饮料命名组合方式\n1. 基础饮料\n• Kopi：咖啡\n• Teh：茶\n• Milo：美禄\n2. 奶的种类\n• O：不加奶，即“乌”，来自于福建话。\n• C：加入淡奶，Canned Milk。\n• 无标注：加炼乳\n3. 糖的量\n• Kosong：马来语，无糖\n4. 温度\n• Peng：福建话冰，也有使用Ais （源于马来语，更源头则是英语ice）\n在这套规则之外，马来西亚还有几款令人印象深刻的本地特饮。比如，拉茶（Teh Tarik），通过“拉”茶的技艺将其来回高抛，层层拉出细腻的泡沫。或是备受年轻人喜爱的美禄恐龙（Milo Dinosaur），在一杯美禄上再撒上一层厚厚的美禄粉，巧克力的浓郁香气更加突出。\nKopi、Milo、Barley（薏米水）\n还有马来西亚人解暑必备的煎蕊（Cendol），这是一道口感丰富、层次分明的传统甜品。绿色的煎蕊条由绿豆粉或糯米粉制成，并以斑兰叶汁染色，散发淡淡的香气，与椰浆、椰糖、刨冰相融合，形成一碗甜而不腻的冰凉饮品。偶尔还会加入红豆、玉米、仙草等配料，增添风味，口感层次丰富，是在炎热气候中最受欢迎的甜品之一。\n槟榔律驰名潮州煎蕊\n此外，马来西亚的传统饮品中，还有一种经常被误解的“薏米水”，即当地所谓的“Barley”。这里的“Barley”指的是大麦，并非中药所指的薏苡仁。虽说“薏米水”这个叫法并不准确，但大麦煮成的饮品清爽解渴，早已深入人心。大麦因其外形酷似薏米，在马来西亚被称作“洋薏米”，久而久之，“洋”字不见了，反倒留下了“薏米水”这一独特的名称。\n○○○\n【新月宮茶室】\n位置：86, Lebuh Kimberley, George Town, 10100 George Town, Pulau Pinang, 马来西亚\n营业时间：08:00-22:30\n【天皇鸡脚粿条汤】\n位置：78, Lebuh Kimberley, George Town, 10100 George Town, Pulau Pinang, 马来西亚\n营业时间：17:00-23:00\n【Penang Road Famous Teochew Chendul】\n位置：27-29, Lebuh Keng Kwee, George Town, 10100 George Town, Pulau Pinang, 马来西亚\n营业时间：09:00-18:30\n福建人和福建虾面 在槟城，当地华人群体中福建人占了绝大多数。\n于是乎在源头称之为闽南语的语言，到了南洋，因其主导性而被称之为“福建话”。闽南话在此地几乎畅行无阻，甚至连一些印度裔的小贩也能操一口流利的福建话。想起初来槟城时与一位Grab司机的对话，他祖籍泉州，但彼时彼刻我还不确定他是否也是华人，于是用英语交谈，直到父亲用闽南话试探他是否能听懂。司机会心一笑，便用福建话和我们无障碍交流起来。这种语言的亲切感，也许是因为共同的根源，使得陌生的异地瞬间拉近了距离。\n福建移民不仅带来了他们的方言，还携来了信仰与文化。在槟城早期，由于殖民政府对陆地按面积征税，许多福建移民为了避税，巧妙地选择在海上建房，形成一片片独特的“姓氏桥”，以“周姓桥”为最为闻名的代表。其桥头设有庙宇供奉天公，每年农历正月初八，居民会在此举行盛大的拜天公仪式。而这一信仰，始终没有变过。\n姓氏桥\n周氏桥头的庙宇\n除了语言文化信仰，还有一碗面。提到槟城的福建面，这一话题在马来西亚可谓是引起争议的话题。槟城的福建面其实就是福建虾面，而这道美食则是由早期移民福建人带入当地的美味，因售卖者多为说着福建话的福建人因而得名“福建面”，而在吉隆坡，新加坡，福建面则是另一种样貌——加了酱油膏的黑色炒面。\n关于福建面，还有这样一个民间传说：在日军占领槟榔屿期间，人民生活困苦，鱼虾都被迫献给日军，渔民们只好用剥下的虾头和虾壳来煮汤，便创制出了这道美食。虽说这应该只是个民间杂谈， 并无具体的考究，但也点明了这碗面的核心—由虾头虾壳熬制而成的高汤，仍未随时间而动摇。\n相较于上世纪舶来品的沙茶面，厦门的虾面才是南洋虾面的源头。虾面使用一种名为“狗虾”的野生小虾（因其特殊性，每年四月至七月都会断产），先去壳取肉再煮熟。狗虾的虾壳炒香后捶打成酱，再与猪骨慢火熬制四小时。虾面的主要原料在于虾，但其独特之处却在于汤底。\n在槟城，虾和猪骨依旧是虾面汤的灵魂，但增加了Sambal酱，也增添了更多的辣味和海鲜的浓郁。Sambal酱是一种用发酵的虾酱、干辣椒和新鲜辣椒制成的调料。除了黄面和豆芽外，槟城的虾面中总是会放入蕹菜，即空心菜。\n在落日洞边上的【渔人码头】，只因住在附近， 而选择了在此觅食，Grab司机倒也好奇我们是否收到了当地朋友的推荐，而选择了这么家似乎属于当地人私藏的食阁。食阁的好处便是能够在一顿饭中获得多种选择。而让我记忆深刻的，还是那碗福建虾面。香辣的汤底和浓厚的风味瞬间击中了味蕾。少了厦门虾面的那种甜，却多了一份来自热带的火辣。用开水汆烫的黄面、米粉、蕹菜，再加上肉片、水煮蛋和豆芽，浇上浓郁的特制虾汤，汤上放在一把勺子，勺内有少许Sambal辣酱，依个人喜好调节辣度。\n福建虾面\n我大胆猜测，这或许是早年的福建移民南下槟城后，长年适应当地湿热气候，逐渐放弃了家乡的清淡口味，而在日积月累的过程中调重了味道，以刺激食欲。延用了家乡的虾和面，又加上南洋风味的辣酱，最终成就了这道独一无二的本地福建虾面。\n渔人码头晚霞\n○○○\n【渔人码头】\n位置：92A, 1, Lebuh Sungai Pinang, 11600 Jelutong, Pulau Pinang, 马来西亚\n营业时间：08:30-00:00\n怡保白咖啡和芽菜鸡 怡保，这座因锡矿而兴起的城市，曾在十九世纪的喧嚣中展露繁华。那些年，来自南洋的劳工涌入，为这片土地注入了活力。然而，到了五十至六十年代，锡价下跌，需求萎缩，昔日的热闹逐渐消退。时光似乎停留在50年代，街头的店铺大多紧闭门扉，仿佛旧日的繁华仅残留在老旧的招牌上。这些招牌多以竹帘制成，简单的笔画勾勒出商号名称，透着一丝未曾褪色的昔日风韵。然而，在这破败的街巷间，一些无法离开或不舍离去的老人们，依旧守望着故乡的影子。\n怡保街头\n因只是将怡保作为槟城到KL的中转站，活动范围只局限在了火车站附近的旧厂街。旧厂街的街角，三五成群的华裔、印度裔老人围坐聊天，邻桌的茶室里，来自不同族群的人们在一片屋檐下共享时光。这里的人们彼此间的友好显而易见，彼此往来无碍。偶遇的Grab司机也会提到马来朋友，仿佛这些对立和冲突只是外来者的夸大，或者是政客用以拉拢选票的政治游戏。\n怡保街头\n怡保的特色小吃芽菜鸡，传言原先是芽菜与鸡一同盛放。岁月流转，食物也随之演变，如今鸡与芽菜分置盘中，简单而别具风味。尤以“红油”鸡丝河粉最为有名，自七十年代起，芽菜与清汤河粉成了标配，鸡丝河粉却少有提供。然而，品尝之际，才觉那极为粗壮的芽菜透着脆爽，这是只有怡保水土才能培育出的佳品。依山傍水的地理造就了这一独特风味，豆芽也因此而名声在外。\n芽菜、鸡和鸡丝河粉\n数家有名的芽菜鸡店都聚集在同一街角，行色匆匆，难以抉择。【安记芽菜鸡】店里的装潢古旧，时光似乎凝固在墙角，一旁的老式唱片机正播放着七八十年代的旋律，白板上仅写着几道招牌菜，似乎在坚守那份精致而不贪多的执着。简单的酱油胡椒调味衬托出芽菜的自然清甜，一碗鸡油饭，几块白斩鸡，轻尝一口，简简单单但并不普通。老顾客依旧按着旧习惯点餐，只是如今应顾的却是语言不通的外劳，偶尔还需老板亲自上前指点。\n安记芽菜鸡内的招牌\n跨过几条巷弄，映入眼帘的是另一番旧日风情。【南香茶餐室】，这间被视为白咖啡发源地的老茶室，依旧保留了传统的模样。白咖啡的味道仿佛凝结了时代的变迁，据说是早年一位咖啡小贩在炒咖啡豆时加入了焦糖，才成就了这款特有的香浓口味。如今这香气馥郁的白咖啡已成为怡保的名片，白咖啡品牌的迅速推广，让这种独特的风味远播四方。进店后点上一杯白咖啡，再来一盘蛋挞或鸡肉酥，仿佛能在这微苦中回味旧时光。\n南香茶餐室 白咖啡\n沿街行至二奶巷、三奶巷，这些名字带着几分遥远的传奇色彩。那些锡矿时期的华商为情妇安置的街巷，如今已是游客蜂拥而至的商业街，卖着各种小商品，留下的不过是一点点变了味的旧日记忆。\n○○○\n【安记芽菜鸡沙河粉】\n位置：No. 48/51, 53, Jalan Yau Tet Shin, Taman Jubilee, 30300 Ipoh, Perak, 马来西亚\n营业时间：10:00-21:00\n【南香茶餐室】\n位置：2, Jalan Bandar Timah, 30000 Ipoh, Perak, 马来西亚\n营业时间：06:30-16:30\n椰浆饭 椰浆饭，马来语叫 Nasi Lemak，nasi意为饭，lemak本意是油脂，形容其特有的浓醇风味。\n走在槟城街头，漫无目的地游荡时，竟偶遇了米其林推荐的【Ali Nasi Lemak Daun Pisang】档口——这处小摊赫然立于入口处，煞是醒目。一位满脸笑意的Anty在顾客眼前熟练地将椰浆饭打包，四五种风味依次摆放，最经典的莫过于鸡蛋江鱼仔的组合。过去从未想象椰浆与米饭交织能呈现出何种风味，而这道菜因一译名“辣死你妈”更添神秘之色，让人既好奇又敬畏。\nAli Nasi Lemak Daun Pisang\n椰浆饭 最初作为早餐而生，裹在朴实的香蕉叶中，佐以参巴辣椒酱、江鱼仔与鸡蛋，曾是一份清晨的简单选择。随时间的推移，椰浆饭的变化也愈加丰富。现代人追求口味的多样，炸鸡、咖喱鸡、仁当牛肉、海鲜等纷纷入味，让传统的椰浆饭增添了新的层次， 而呈现形式，也从传统的以香蕉叶包裹演变成盘装。\n虽未有幸造访网络盛传的椰浆饭“天花板” 【Village Park】，倒也释然。正如心底暗想的那般，既为国菜，这道菜肴似乎只要在市井小摊一现，便已足以代表一方风味。于是便随意在住处附近挑了一家娘惹餐馆，算是体验这口人间烟火。\nNasi Lemak\n米经过简单调味， 用椰浆、斑斓叶和数种香料混合并蒸熟，粒粒分明，浓香不腻。入味的参峇辣酱抹在米饭上，辛香中带着丝丝甜美与微酸，而那几片爽脆的黄瓜，总在微腻时救急，堪称点睛。炸鸡腿表皮酥脆，内里鲜嫩，几乎让人误以为这鸡腿才是整盘的灵魂。当地人常用手吃，右手抓点配料和酱就点米饭，捏紧送入口中，奈何打心里接受不了，还是选择叉子和勺子。也不得不提仁当牛肉，这“炖煮”的艺术将大量椰浆、椰蓉甚至椰糖加入传统咖喱香料中。\n○○○\n【Ali Nasi Lemak Daun Pisang】\n位置：Beach St, Georgetown, 10300 George Town, Penang, 马来西亚\n营业时间：周一至周六 07:00-14:00，周天店休\n【Village Park Restaurant】\n位置：5, Jalan SS 21/37, Damansara Utama, 47400 Petaling Jaya, Selangor, 马来西亚\n营业时间：06:30-17:30\n肉骨茶 小时候，初次品尝到一碗肉骨茶，那一缕浓烈的胡椒香气便深深刻印在记忆里。然而，长大后才知晓，这种香气四溢的汤品其实是新加坡潮州式肉骨茶的版本，与其起源地马来西亚的传统风味已有所不同。新加坡肉骨茶在多次演变中，逐渐简化成如今汤清色浅、以胡椒为主调的形式，而大马的肉骨茶，则始终保留着那浓郁厚重的药材香气——党参、当归、川芎、玉竹，还有八角、胡椒与蒜头等香料在锅中激荡出层层深味，有时还掺入酱油调出略带咸甜的色泽。\n有趣的是，尽管名字中带“茶”字，肉骨茶其实与茶本无直接关系。它的本质是一种以药材和猪骨熬煮的炖汤，至今没有一个权威的解释能准确追溯“茶”字的由来。也许是因为码头工人在边吃肉骨汤、边啜一杯清茶解腻时，这种饮食习惯自然而然地与汤品绑定在了一起。\n肉骨茶的故事绕不开李文地的名字。战后，这位从伙计做起的男子在巴生后街开了自己的食档。他改良苦力们的药材炖肉配方，推出了加中药材的家乡炖肉骨，还以猪油炒饭取代了传统的蚝干咸饭，结果大受欢迎。人们为他取了个外号“肉骨地”，而闽南话中“地”与“茶”同音，这名字便逐渐演变成了“肉骨茶”。\n巴生港，这座曾挤满苦力的港口，是肉骨茶的发源地。那些码头工人以肉骨茶配白饭为早餐，饱腹又暖身。这种粗粝却温暖的饮食习惯，像是一曲简单却深情的生命交响，延续至今。然而，我的旅途短暂，未能前往心心念念的巴生港，去一探那发源地的真貌。\n传统汤式肉骨茶和新兴的干式肉骨茶\n计划中选了一间著名的老店，却因饭点等位时间太长而作罢，转而去了附近的【友谊肉骨茶店】。虽说这里主打潮州风味，汤底清淡少药材，更多是肉汤的质朴味道。干式肉骨茶的滋味反倒更和胃口，配饭吃尤为下饭。除了排骨，锅中还有三层肉、猪肚和些许青菜。另点了一份黄酒猪腰，第一口那酒香直冲脑门，令人惊艳。只可惜，这风味太过浓烈，反衬得后来的肉骨茶平淡了几分。\n○○○\n【友谊肉骨茶】\n位置：53-6, Jalan Barat, Pudu, 55100 Kuala Lumpur, Wilayah Persekutuan Kuala Lumpur, 马来西亚\n营业时间：09:30-21:00\n后记 清晨的 ICC Pudu市场，人潮如涌，自早六点至下午一时，充满了来访者的喧闹。这里的前身是老Imbi市场，是当地华人餐食的老据点，搬迁至此后依然熙熙攘攘。茶座间，点一杯饮料便算租了桌，四周小档口林立，各色早点汇聚。虽说环境不甚清洁，四周闷热嘈杂，倒是体验生活本味之佳处。\n这里的摊主多为华人，但收银接待者多为外劳，往往只有老板会说华语，常需几句英语才能沟通。这片被称为“富都”的区域，曾是华人聚居之地，如今主要成了外籍劳工的栖息处。\n摄于Pudu\n吉隆坡，这座城市中穿梭着无数外劳的身影。他们中的绝大部分来自缅甸、孟加拉等地，肩负起危险的建筑工地工作，或是被本地人轻视的低端服务业。街头巷尾，时常可见警车押送非法移民的场景。那些黑色的露顶卡车，车身写着醒目的“Immigration”，押送的人群中有男人，也有妇女与孩童。入夜时分，双子塔灯光璀璨，喷泉伴着《We Are the World》的旋律涌动，而一旁在建的高楼里，外劳的身影仍在高空忙碌。他们是城市奇观背后的无名工匠，默默成为奇观背后的注脚。\n双子塔\n时隔一月有余，重拾这些片段，只为整理旅行途中的思绪。彼时原是为美食而去，然而除了舌尖的满足，更让我着迷的，是每一道菜背后的文化脉络和交融的故事——那些承载在味道上的历史与人。\n那些未曾尝试的风味、未曾探访的角落，仍在心底留存。比起舌尖的满足，这片土地文化上的冲击、人与人之间微妙而深远的关系，更让我感慨良多。或许，这正是旅行的意义所在吧。\n","permalink":"https://niraya666.github.io/travel/%E5%A4%A7%E9%A9%AC%E6%B8%B8%E8%AE%B02024/","summary":"\u003ch2 id=\"写在前面\"\u003e写在前面\u003c/h2\u003e\n\u003cp\u003e2024年的国庆假期，第一次带父母踏出国门，目的地定在了马来西亚。挑选这个地方，并非偶然，既因为语言上的便利，也因对食物多样性的向往。对于第一次尝试出国旅行的新手来说，这样的选择再合适不过了。尤其是对于福建闽南人，马来西亚似乎有着一种熟悉而温暖的亲切感。\u003c/p\u003e\n\u003cp\u003e行程从厦门出发，飞往槟城，然后搭乘火车前往怡保，再一路南下至吉隆坡，最终从吉隆坡返回故乡。虽说只是短短数日的旅行，但沿途的风景与美食却像是一条无形的丝线，将我们一家人与这片热带土地紧紧相连。\u003c/p\u003e\n\u003cp\u003e此次游记，我尝试以“食物”为线索，串联起整个旅程的记忆。或许有些挑战，但也正是这种不同于以往的记录方式，让整个旅程多了些许味觉上的探险色彩。\u003c/p\u003e\n\u003ch2 id=\"海南没有海南面包和海南鸡\"\u003e海南没有海南面包和海南鸡\u003c/h2\u003e\n\u003cp\u003e槟城位于马来西亚西北，分成槟岛和威省两部分，作为东南亚重要的贸易港口之一，槟城自18世纪以来便吸引了无数移民，马来人、华人、印度人和欧洲人的足迹在这里留下了不可磨灭的印记，因其多元文化和历史，槟城的首府乔治市（George Town）也被联合国教科文组织纳入人世界文化遗产地。\u003c/p\u003e\n\u003cp\u003e第一站是【多春茶室】。尽管其老店名声在外，但为了避开人群，我们选择了位于旧关仔角钟楼附近的分店。清晨9点到达时，茶室内还未拥挤，扫码点餐的现代化模式也让整个过程更加方便。\u003c/p\u003e\n\u003cp\u003e点餐是件有趣的过程。面包、抹酱、饮品，一步步选择下来，经典的烤海南面包加上浓郁的咖椰酱，搭配香浓的Kopi-O，让这平凡的早餐充满满足感。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/6F734170-B982-4F62-934A-22FF8C6CCE86_1_105_c.jpeg\" alt=\"6F734170-B982-4F62-934A-22FF8C6CCE86_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003e烤海南面包加上咖椰酱\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e有趣的是，海南面包源自南洋，并非来自海南本土。早年海南人漂洋过海来到南洋，受雇于英国人家庭和西化的峇峇家庭做帮佣，学习了西方的烘焙技艺，结合本地口味，创造出了适合东南亚人的海南面包。这些经历使他们将西式的咖啡与面包融入本地，逐渐普及成为南洋的经典早餐文化。\u003c/p\u003e\n\u003cp\u003e当然，当地人早餐常吃的生熟蛋也是值得一试的， 鸡蛋泡在热水中几分钟，蛋白微凝固但仍带液态，蛋黄保持流动感，吃时只需加入酱油和白胡椒调味，用勺子轻轻搅拌，也可以蘸面包吃。如果不习惯生鸡蛋，店家还贴心地提供了不同熟度的选择。\u003c/p\u003e\n\u003cp\u003e在这家店，店主还提供了4RM一个椰浆饭供食客自取，经典的江鱼仔鸡蛋口味，对于第一次尝试椰浆饭的人而言，味道的确很奇特。sambal辣酱并没有想象中那么辣，带有一丝丝的甜味，米饭也是经过调味的。\u003c/p\u003e\n\u003cp\u003e茶室不远处便是槟城的地标——旧关仔角钟楼。钟楼由著名华商张弼士捐资修建，以纪念维多利亚女王登基60周年。与钟楼相邻的康华丽斯堡则是另一个标志性景点，虽名为堡垒，实未参与战斗。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/F8C5900A-FE98-4DCF-8B04-E73A9CB9A30C_1_201_a.jpeg\" alt=\"F8C5900A-FE98-4DCF-8B04-E73A9CB9A30C_1_201_a.jpeg\"  /\u003e\n\n\u003cem\u003e旧关仔角钟楼\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e乔治市的街道以交叉十字贯穿各个文化区域。从小印度区入至华人区，再到马来区，都是一幅幅独特的文化画卷。右边为殖民时期的建筑，左侧则是古朴的华人会馆；再往前走，便是色彩斑斓的印度庙宇了。恍惚间，仿佛还能看到那些早年南来的移民，提着皮箱穿过狭窄的街巷，寻找着属于自己的一方天地。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/73FE20C9-AFC7-4F90-BCD9-6980BDE26F13_1_105_c.jpeg\" alt=\"73FE20C9-AFC7-4F90-BCD9-6980BDE26F13_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003e吉宁甲必丹回教堂\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e槟城的美不止于其自然风光，而在于文化的碰撞与融合。早期移民将家乡味道带入南洋，创造出诸如海南鸡饭这样的经典。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/E399B1CB-F4F0-4639-86E7-A6F3F8C91BFC_1_201_a.jpg\" alt=\"E399B1CB-F4F0-4639-86E7-A6F3F8C91BFC_1_201_a.jpg\"  /\u003e\n\n\u003cem\u003e伍秀泽海南鸡饭茶室\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e午后，我们寻觅到【伍秀泽海南鸡饭茶室】。这家茶室外观简单得甚至有些不起眼，但店里却充满着人间烟火气息。菜单也十分简单：白切鸡、烧鸡、鸡杂和鸡油饭。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/48AD27F9-8A94-4558-A87E-334128902AB1_1_105_c.jpeg\" alt=\"48AD27F9-8A94-4558-A87E-334128902AB1_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003e海南鸡饭\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e鸡肉鲜嫩多汁，配上油光闪亮的鸡油饭，再添一勺微辣的辣椒酱，与黄瓜片相伴，让人回味无穷。\u003c/p\u003e\n\u003cp\u003e一杯槟城特有的冰豆蔻水，为这丰盛的一餐画上美丽的句号，而在槟城的每一次咀嚼，都是对过去的重温。\u003c/p\u003e\n\u003cp\u003e○○○\u003c/p\u003e\n\u003cp\u003e【多春茶室】\u003c/p\u003e\n\u003cp\u003e位置：37, Bishop St, Georgetown, 10200 George Town, Penang, 马来西亚\u003c/p\u003e\n\u003cp\u003e营业时间：08:30-16:30 （周四店休）\u003c/p\u003e\n\u003cp\u003e【伍秀泽海南鸡饭茶室】\u003c/p\u003e\n\u003cp\u003e位置：340, Lbh Chulia, George Town, 10200 George Town, Pulau Pinang, 马来西亚\u003c/p\u003e\n\u003cp\u003e营业时间：10:00-17:00 （周三店休， 周末营业时间延后一小时）\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"粿条和饮料\"\u003e粿条和饮料\u003c/h2\u003e\n\u003cp\u003e粿条，本是潮汕人乃至闽南人对于米制面条的称呼。粿条的形式多种多样，既可以用来做汤，也可以干拌或者炒制。其中，最为著名的当属炒粿条。\u003c/p\u003e\n\u003cp\u003e炒粿条的名字源自福建话“Char Kway Teow”。虽然它发源于潮州，但在潮州并不流行像马来半岛那样使用重酱油、鱼露，或加入血蚶的风味。\u003c/p\u003e\n\u003cp\u003e几代人的迁徙流传，使得最初的潮汕炒粿条逐渐演变成如今的槟城炒粿条。在今天的马来半岛，各地的茶餐室、路边摊甚至食阁中，随处可见这一道菜。当地华人适应了赤道气候，也逐渐偏爱浓烈的口味，将黑酱油和鱼露加入其中，使其味道与原先的潮汕风味逐渐拉开了距离。\u003c/p\u003e\n\u003cp\u003e槟城的炒粿条以其丰富的本地特色而闻名，以至于“槟城炒粿条”如今已然成为马来西亚外的“炒粿条”代名词。也许正是槟城人所炒的粿条充满了独特风味，让其从冠以“潮州”的乡土印记中脱颖而出，成为一种具有浓厚本地色彩的代表。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e9%a3%9f%e5%9c%a8%e5%a4%a7%e9%a9%ac-assets/6762BC7A-C04B-4F8A-B9DC-3E5BA158D640_1_105_c.jpeg\" alt=\"6762BC7A-C04B-4F8A-B9DC-3E5BA158D640_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003eChar Kway Teow\u003c/em\u003e\u003c/p\u003e","title":"食在大马"},{"content":"前言 国庆期间，在西马玩了快一个礼拜，期间体验了从北海到怡保的ETS、槟城的升旗山登山缆车，还有吉隆坡复杂多样的轨道交通系统。旅行中，我踩过一些坑，也解锁了一些便利的玩法。经过查阅不少攻略，加上实地探索和切身体会，我决定将这次旅途中的交通攻略整理成这篇文章，分享给大家。\n注：本文所包含的信息有效截止至2024年10月，同时主要讨论西马（马来半岛）的轨道交通；希望能对你的大马之旅有所帮助。\n大马铁路概述 马来西亚的铁路系统起源于19世纪末的英国殖民时期，当时的铁路主要是为了支持锡矿业和橡胶种植园的经济发展。第一条铁路于1885年建成，连接了太平和砵威港口（今称为瓜拉十八丁），而太平是当时霹雳州英国人的行政中枢。这条铁路的建设是为了便于将矿产资源从内陆运输到港口。此后，英国殖民政府开始加快在马来亚各地开辟铁路的步伐，主要目的是为了促进殖民地经济发展，例如吉隆坡至巴生的铁路于1886年建成通车，芙蓉至波德申的铁路于1891年建成通车，吉隆坡至万挠的铁路于1892年建成通车，安顺至打巴路的铁路于1893年建成通车。1895年，受英国保护的雪兰莪、森美兰、霹雳和彭亨四州组成马来联邦。当时马来亚不同州的铁路各自发展，没有一个统一的规划和管理机构，于是殖民政府当局在1901年成立了马来联邦铁路（FMSR），统合管理马来西亚半岛上各地包括马来联邦、马来属邦、海峡殖民地的铁路。这些初期建设的米轨铁路成为连接各主要城镇和经济区的重要交通工具。\n20世纪初，马来西亚的铁路网迅速扩展，最重要的两条干线为东海岸线和西海岸线。二战期间，铁路遭到日军的严重破坏，但战后得到了重建。1948年，马来联邦铁路被改组为马来亚铁路（MR）。1963年，马来亚、新加坡、砂拉越和沙巴组成了新的联邦国家——马来西亚（新加坡于1965年退出），马来亚铁路的官方名称也更改为马来语“Keretapi Tanah Melayu”（KTM）。\n现如今，马来西亚的铁路系统主要由两条干线组成：西海岸线和东海岸线。东海岸线（也称金马士－道北铁路）由马来亚铁道运营，起自金马士，途经吉兰丹、彭亨、森美兰，穿越马来半岛中部，全长528公里，最终到达泰国边境的道北。虽然名为东海岸线，但大部分路段穿行于内陆丛林地带，因此又被称为“丛林铁路”，吸引许多背包客体验。西海岸线则起自泰国边境的巴东勿刹，沿西海岸一直延伸至柔佛的南端，通过新柔长堤连接新加坡，全长950公里，途经包括吉隆坡在内的八个州属，是马来西亚铁路运输的重要交通大动脉。由国有企业马来亚铁道公司（KTMB）运营的铁路系统经过了多次改组和现代化，如今的铁路服务已经涵盖了从通勤列车到高速城际列车的多种交通模式。目前，马来西亚铁路系统不仅联通国内主要城市，还连接着泰国和新加坡，是东南亚地区重要的交通枢纽。\n来源\n铁路分类 KTM Komuter（城际通勤列车）\nKTM Komuter是由马来亚铁道公司（KTM）运营的通勤铁路服务，最初于1995年在巴生谷地区启用，后于2015年扩展至北部各州（如霹雳、槟城、吉打和玻璃市）。该服务连接了吉隆坡及其周边郊区，还服务于槟城和其他北部州属，总长度约456公里，包含芙蓉线、巴生港线等多条线路。KTM Komuter的列车是空调电力列车，并提供便捷的“停车换乘”设施，适合游客和通勤者方便进入市区，避免交通拥堵。KTM通勤铁路还为乘客提供多种票务选项，包括通过KTMB移动应用程序购买手机票（二维码）、Touch \u0026rsquo;n Go（仅限巴生谷地区）、自动售票机与车站售票柜台购票。\nETS（电动列车服务）\nETS（Electric Train Service）是由马来亚铁道公司运营的快速城际电力动车组服务，于西海岸线运行，连接金马士与巴东勿刹，全长950公里。ETS是马来西亚最快的米轨列车，速度可达每小时140公里，属于准高速铁路。列车分为Gold、Silver、Platinum 以及 Express 4种等级，分别对应不同的服务和票价，是前往怡保、槟城等城市的高效方式。\nKTM Intercity（城际列车）\nKTM Intercity是马来亚铁道运营的柴油牵引城际列车服务，覆盖马来半岛的南部地区、新加坡以及泰国。部分列车主要运行于东海岸线金马士至道北之间，并延伸至新加坡。2021年4月推出了柴油动车组（DMU）列车，取代了原有的传统列车，服务于东海岸的丹绒至吉利地段。DMU列车配备现代化设施，包括集群座椅、LED显示屏、电源插座、祈祷室、厕所、小餐馆及行李存储空间，并有无障碍设施，满足残障人士的需求。\n如何购买火车票 购买火车票的方式有多种，最为方便的是通过KTMB官方网站或手机应用程序进行在线购买。也可以在吉隆坡中环车站（KL Sentral）及其他主要车站直接购票，但热门线路的车票在高峰时期（如假日、周末）可能会售罄，建议提前预订。\n以网上购买ETS车票为例，需在KTMB官网注册账号，然后选择出发和到达车站、以及对应的ETS车次类型（如Gold、Platinum、Express等）。不同级别的车次在停靠站数量和服务上有所不同，例如Platinum和Express级别提供商务座，商务座采用1+2的座位排布，包含免费食物和饮料，价格相对更高；普通席则是2+2的座位排布。Gold车次则没有商务座位。选择座位时，需要注意座位方向，有些座位是与行驶方向相反的，如果不喜欢反向乘坐，记得选择“forward”座位。\nETS列车的车型也有所区别，Platinum和Express列车多为较新款，由中国中车制造，而Silver级别列车则采用较老款，速度较慢，停靠站较多。\nETS-Express列车（摄于Butterworth车站） ETS-Gold列车，采用旧款车型（摄于Ipoh车站）\n吉隆坡轨道交通 吉隆坡及其周边地区有完善的轨道交通系统，涵盖了多种轻轨和地铁线路。\nLRT（轻快铁）\nLRT是吉隆坡的轻轨系统，包含3号 LRT Ampang Line、4号LRT Sri Petaling Line和5号LRT Kelana Jaya Line。LRT贯穿吉隆坡市中心及重要商业区，是游客前往市区景点如双子塔、茨厂街的首选交通工具。在高峰期，列车会非常拥挤。\n5号线LRT，摄于Bangsar车站\n3号LRTAmpang Line（橙黄色）：占美清真寺，独立广场，ICC pudu等景点。\n4号LRT Sri Petaling Line（深红色）：占美清真寺，独立广场，ICC pudu等景点。\n5号LRT Kelana Jaya Line（粉色）：可以前往双子塔、KLCC水族馆等主要景点。\nMRT（地铁）\nMRT是吉隆坡的新兴地铁系统，分为Kajang线和Putrajaya线，覆盖了市区及巴生谷更广阔的区域。\n9 号线 MRT Kajang Line（深绿色） ：可前往国家博物馆，village park（知名的nasi lemak）等地；\n10 号线MRT Putrajaya Line（黄色）：可前往KLCC，海脚人餐厅等地。\nKL Monorail（单轨铁路）\n路线编号为8，而颜色则为绿色。\nKL Monorail是吉隆坡独特的单轨铁路，线路为黄绿色，专门服务于市中心，主要连接购物和娱乐区（如武吉免登、KL Sentral等）。这条单轨铁路全长8.6公里，共有11个车站，将吉隆坡中央车站交通枢纽与市中心的金三角地带连接起来。\n1996年，马来西亚政府批准兴建吉隆坡单轨列车的计划，1997年1月正式动工，然而，1997年亚洲金融风暴导致融资困难，工程被迫暂停。1998年，本国企业MTrans公司接手，并在2003年8月31日正式完工并通车。通车后，单轨列车因客流量不如预期及经营收入不足而在2007年被马来西亚国家基建公司（Prasarana）收购。\n单轨列车的内部设计独特，不同车厢有着不同的座椅布局，多为面向窗户的座位，能够让乘客更好地欣赏吉隆坡的城市景观。然而，列车的安全门常处于开启状态，车门开关也时常发生故障，显示出在1997年金融危机后及其经营不善下所留下的问题。不过，尽管存在运营上的挑战，KL Monorail仍然成为了吉隆坡的一张城市名片，尤其在武吉免登（Bukit Bintang）等热门地带，为游客提供了方便的出行选择，并成为Bukit Bintang的知名打卡地。始发于KL Sentral，途经如Bukit Bintang等购物和娱乐区。 独特设计的座位布局，摄于KL Sentral\nMonorail，摄于Bukit Bintang\nKLIA Ekspres（吉隆坡机场快线）\nKLIA Ekspres是巴生谷的第六条列车线路，连接吉隆坡中央车站（KL Sentral）与吉隆坡国际机场（KLIA 1 \u0026amp; KLIA 2）。全程仅需33分钟，每20分钟一班，票价为55马币。KLIA Ekspres路线编号为6，线路颜色为紫色。该服务的列车提供宽敞的座位和行李存放空间，乘坐马来西亚航空、国泰航空、峇迪航空的旅客还可以在吉隆坡中央车站进行市区预办登机和行李托运服务，方便乘客直接登机。\nKLIA Transit（吉隆坡机场支线）则是第七条线路，使用相同轨道，但中途停靠布城和其他站点，如粉红清真寺等著名景点。全程约40分钟，每15至30分钟一班。票价按站收费，最少6.5马币起。需要注意的是，KLIA Ekspres和KLIA Transit在KL Sentral的进站口不同。\nKLIA Ekspres 和Transit的进站口不同\n登山缆车 槟城的升旗山登山缆车（Penang Hill Funicular Train）是登上升旗山山顶的正常途径，除非你愿意爬3个小时上山。这条缆车线路始建于1923年，最初为两段式铁路，2010年经过现代化改造，合并为一段式系统并更换为封闭式空调车厢。缆车全长8.6公里，是世界上最陡的斜坡缆车之一，全程时间大约5到20分钟，视途中停靠情况而定。它将游客从山脚的Air Itam带到升旗山顶，可以俯瞰槟城市景以及对岸的Butterworth。\n升旗山曾是殖民时期的避暑胜地，缆车的建造也是为了方便上山交通。缆车采用钢缆拉动车厢，以适应陡峭的坡度而安全上下山。缆车的普通往返票价为30马币，此外还有VIP票价为80马币，VIP票无需排队，且可以优先上车，占据有利的拍照位置。然而在非暑假的工作日下午，通常不太需要排队，因此无需额外购买VIP票。\n升旗山，槟城 升旗山小火车（登山缆车啦）\n交通卡选择 Touch \u0026rsquo;n Go（TnG）卡 最常见的是Touch \u0026rsquo;n Go（TnG）卡，这是一种多功能交通卡，可以用于轻轨（LRT）、地铁（MRT）、单轨列车（Monorail）、KTM火车以及公交车等。此外，TnG卡还可在便利店和部分商店中使用。\nTouch \u0026rsquo;n Go 实体卡：可以在便利店、地铁站（需提前预约）或KL Sentral的Touch \u0026rsquo;n Go Hub购买。提前在淘宝上购买也是一个选择。\nTNG eWallet：是一款需要马来西亚或新加坡手机号注册的手机应用，可以作为电子支付钱包，但不能直接作为实体交通卡使用。\nMyCity Pass MyCity Pass是一种短期通行卡，适用于游客和本地居民，允许在指定时间内不限次数乘坐RapidKL管理的公共交通工具，包括LRT、MRT、单轨列车、BRT和RapidKL公交车。\nMyCity 1日通行证：马来西亚人需支付 RM6，外国游客为 RM10。\nMyCity 3日通行证：马来西亚人需支付 RM15，外国游客为 RM25。\n这些价格不包括Touch \u0026rsquo;n Go卡本身的费用，用户必须有一张Touch \u0026rsquo;n Go卡，并确保卡内有至少 RM5 的余额。MyCity Pass可以在LRT、MRT、单轨列车和BRT的客服中心，或一些公交枢纽（如Pasar Seni和KLCC）购买，也可以通过MyRapid PULSE应用程序在线购买。注意，此卡不适用于ERL（如KLIA Ekspres和KLIA Transit）及KTM Komuter。\nKL Travel Pass KL Travel Pass包含KLIA Ekspres的单程或往返票，并提供2天内无限次乘坐吉隆坡快捷通（RapidKL）旗下的LRT、MRT和单轨列车服务（不包括KTM火车）。\n单程机场快线 + 2天无限次乘坐LRT/MRT/单轨列车：RM80。\n往返机场快线 + 2天无限次乘坐LRT/MRT/单轨列车：RM125。\nKL Travel Pass可在KLIA（第一和第二航站楼）以及KL Sentral的KLIA Ekspres售票柜台购买，也可通过线上平台如KLOOK购买。此卡本质上是一张Touch \u0026rsquo;n Go卡，充值后还可以用于RapidKL公交车及部分零售商店的支付。机场快线车票的有效期为自购买日起一个月，2天的无限次乘车卡将在首次使用后连续两天内有效（非48小时）。\n说实话，体验下来，travelpass并不是一个太好的选择， 首先并没有优惠太多，如果想回本需要在2天内坐够30RM的地铁，而KL的地铁轻轨以1RM起步价， 平均一站增加0.1RM，如果住在市区很难有机会坐这么多站的地铁；\n总结 马来西亚的铁路交通承载着这片土地的历史，与其他交通方式相比，火车不仅能穿越城市与乡村，更能体验到当地的文化与风土人情。\n总体来说，马来西亚的轨道交通体系并不是太复杂（和日本相比）。无论是吉隆坡的地铁、轻轨，还是连通主要城市的城际列车，都是方便快捷的出行选择。尽管马来西亚的油价低廉、打车费用不高，但在城市内，高峰时段的交通拥堵是常见问题。当然，轨道交通仍然是值得考虑的选择。\n参考资料 wiki：马来西亚铁路运输\nwiki：马来亚铁道\nKTMB官网\nMyCity Pass\nklook: KL TravelPass\n","permalink":"https://niraya666.github.io/travel/%E5%A4%A7%E9%A9%AC%E8%BD%A8%E9%81%93%E4%BA%A4%E9%80%9A%E6%94%BB%E7%95%A5/","summary":"\u003ch2 id=\"前言\"\u003e\u003cstrong\u003e前言\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e国庆期间，在西马玩了快一个礼拜，期间体验了从北海到怡保的ETS、槟城的升旗山登山缆车，还有吉隆坡复杂多样的轨道交通系统。旅行中，我踩过一些坑，也解锁了一些便利的玩法。经过查阅不少攻略，加上实地探索和切身体会，我决定将这次旅途中的交通攻略整理成这篇文章，分享给大家。\u003c/p\u003e\n\u003cp\u003e注：本文所包含的信息有效截止至2024年10月，同时主要讨论西马（马来半岛）的轨道交通；希望能对你的大马之旅有所帮助。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"大马铁路概述\"\u003e\u003cstrong\u003e大马铁路概述\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e马来西亚的铁路系统起源于19世纪末的英国殖民时期，当时的铁路主要是为了支持锡矿业和橡胶种植园的经济发展。第一条铁路于1885年建成，连接了太平和砵威港口（今称为瓜拉十八丁），而太平是当时霹雳州英国人的行政中枢。这条铁路的建设是为了便于将矿产资源从内陆运输到港口。此后，英国殖民政府开始加快在马来亚各地开辟铁路的步伐，主要目的是为了促进殖民地经济发展，例如吉隆坡至巴生的铁路于1886年建成通车，芙蓉至波德申的铁路于1891年建成通车，吉隆坡至万挠的铁路于1892年建成通车，安顺至打巴路的铁路于1893年建成通车。1895年，受英国保护的雪兰莪、森美兰、霹雳和彭亨四州组成马来联邦。当时马来亚不同州的铁路各自发展，没有一个统一的规划和管理机构，于是殖民政府当局在1901年成立了马来联邦铁路（FMSR），统合管理马来西亚半岛上各地包括马来联邦、马来属邦、海峡殖民地的铁路。这些初期建设的米轨铁路成为连接各主要城镇和经济区的重要交通工具。\u003c/p\u003e\n\u003cp\u003e20世纪初，马来西亚的铁路网迅速扩展，最重要的两条干线为东海岸线和西海岸线。二战期间，铁路遭到日军的严重破坏，但战后得到了重建。1948年，马来联邦铁路被改组为马来亚铁路（MR）。1963年，马来亚、新加坡、砂拉越和沙巴组成了新的联邦国家——马来西亚（新加坡于1965年退出），马来亚铁路的官方名称也更改为马来语“Keretapi Tanah Melayu”（KTM）。\u003c/p\u003e\n\u003cp\u003e现如今，马来西亚的铁路系统主要由两条干线组成：西海岸线和东海岸线。东海岸线（也称金马士－道北铁路）由马来亚铁道运营，起自金马士，途经吉兰丹、彭亨、森美兰，穿越马来半岛中部，全长528公里，最终到达泰国边境的道北。虽然名为东海岸线，但大部分路段穿行于内陆丛林地带，因此又被称为“丛林铁路”，吸引许多背包客体验。西海岸线则起自泰国边境的巴东勿刹，沿西海岸一直延伸至柔佛的南端，通过新柔长堤连接新加坡，全长950公里，途经包括吉隆坡在内的八个州属，是马来西亚铁路运输的重要交通大动脉。由国有企业马来亚铁道公司（KTMB）运营的铁路系统经过了多次改组和现代化，如今的铁路服务已经涵盖了从通勤列车到高速城际列车的多种交通模式。目前，马来西亚铁路系统不仅联通国内主要城市，还连接着泰国和新加坡，是东南亚地区重要的交通枢纽。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/b90015596a676e51d6df9b98736e90da.jpg\" alt=\"b90015596a676e51d6df9b98736e90da.jpg\"  /\u003e\n\n\u003cem\u003e\u003ca href=\"https://www.pinterest.com/pin/ktm-the-620km-east-coast-rail-route-ecrr--834010424715426579/\"\u003e来源\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\u003ch2 id=\"铁路分类\"\u003e\u003cstrong\u003e铁路分类\u003c/strong\u003e\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eKTM Komuter（城际通勤列车）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eKTM Komuter是由马来亚铁道公司（KTM）运营的通勤铁路服务，最初于1995年在巴生谷地区启用，后于2015年扩展至北部各州（如霹雳、槟城、吉打和玻璃市）。该服务连接了吉隆坡及其周边郊区，还服务于槟城和其他北部州属，总长度约456公里，包含芙蓉线、巴生港线等多条线路。KTM Komuter的列车是空调电力列车，并提供便捷的“停车换乘”设施，适合游客和通勤者方便进入市区，避免交通拥堵。KTM通勤铁路还为乘客提供多种票务选项，包括通过KTMB移动应用程序购买手机票（二维码）、Touch \u0026rsquo;n Go（仅限巴生谷地区）、自动售票机与车站售票柜台购票。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eETS（电动列车服务）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eETS（Electric Train Service）是由马来亚铁道公司运营的快速城际电力动车组服务，于西海岸线运行，连接金马士与巴东勿刹，全长950公里。ETS是马来西亚最快的米轨列车，速度可达每小时140公里，属于准高速铁路。列车分为Gold、Silver、Platinum 以及 Express 4种等级，分别对应不同的服务和票价，是前往怡保、槟城等城市的高效方式。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eKTM Intercity（城际列车）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eKTM Intercity是马来亚铁道运营的柴油牵引城际列车服务，覆盖马来半岛的南部地区、新加坡以及泰国。部分列车主要运行于东海岸线金马士至道北之间，并延伸至新加坡。2021年4月推出了柴油动车组（DMU）列车，取代了原有的传统列车，服务于东海岸的丹绒至吉利地段。DMU列车配备现代化设施，包括集群座椅、LED显示屏、电源插座、祈祷室、厕所、小餐馆及行李存储空间，并有无障碍设施，满足残障人士的需求。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"如何购买火车票\"\u003e\u003cstrong\u003e如何购买火车票\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e购买火车票的方式有多种，最为方便的是通过KTMB官方网站或手机应用程序进行在线购买。也可以在吉隆坡中环车站（KL Sentral）及其他主要车站直接购票，但热门线路的车票在高峰时期（如假日、周末）可能会售罄，建议提前预订。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/%e6%88%aa%e5%b1%8f2024-10-13%20%e4%b8%8b%e5%8d%887.15.27.png\" alt=\"截屏2024-10-13 下午7.15.27.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/%e6%88%aa%e5%b1%8f2024-10-13%20%e4%b8%8b%e5%8d%887.16.04.png\" alt=\"截屏2024-10-13 下午7.16.04.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e以网上购买ETS车票为例，需在KTMB官网注册账号，然后选择出发和到达车站、以及对应的ETS车次类型（如Gold、Platinum、Express等）。不同级别的车次在停靠站数量和服务上有所不同，例如Platinum和Express级别提供商务座，商务座采用1+2的座位排布，包含免费食物和饮料，价格相对更高；普通席则是2+2的座位排布。Gold车次则没有商务座位。选择座位时，需要注意座位方向，有些座位是与行驶方向相反的，如果不喜欢反向乘坐，记得选择“forward”座位。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/%e6%88%aa%e5%b1%8f2024-10-13%20%e4%b8%8b%e5%8d%887.47.05.png\" alt=\"截屏2024-10-13 下午7.47.05.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eETS列车的车型也有所区别，Platinum和Express列车多为较新款，由中国中车制造，而Silver级别列车则采用较老款，速度较慢，停靠站较多。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/7F6C6773-CA59-499B-93C2-2825C2DAE157_1_105_c.jpeg\" alt=\"7F6C6773-CA59-499B-93C2-2825C2DAE157_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003eETS-Express列车（摄于Butterworth车站）\u003c/em\u003e\n\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/B03BE15A-8BF1-4709-BC16-4C95696ED6FE_1_105_c.jpeg\" alt=\"B03BE15A-8BF1-4709-BC16-4C95696ED6FE_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003eETS-Gold列车，采用旧款车型（摄于Ipoh车站）\u003c/em\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"吉隆坡轨道交通\"\u003e\u003cstrong\u003e吉隆坡轨道交通\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e吉隆坡及其周边地区有完善的轨道交通系统，涵盖了多种轻轨和地铁线路。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/%e6%88%aa%e5%b1%8f2024-10-14%20%e4%b8%8b%e5%8d%887.56.41.png\" alt=\"截屏2024-10-14 下午7.56.41.png\"  /\u003e\n\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eLRT（轻快铁）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLRT是吉隆坡的轻轨系统，包含3号 LRT Ampang Line、4号LRT Sri Petaling Line和5号LRT Kelana Jaya Line。LRT贯穿吉隆坡市中心及重要商业区，是游客前往市区景点如双子塔、茨厂街的首选交通工具。在高峰期，列车会非常拥挤。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%a9%ac%e8%bd%a8%e9%81%93%e4%ba%a4%e9%80%9a%e6%94%bb%e7%95%a5-assets/107EF1BC-2124-4F8E-BCEA-7027EA7E3C54_1_105_c.jpeg\" alt=\"107EF1BC-2124-4F8E-BCEA-7027EA7E3C54_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003e5号线LRT，摄于Bangsar车站\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e3号LRTAmpang Line（橙黄色）\u003c/strong\u003e：占美清真寺，独立广场，ICC pudu等景点。\u003c/p\u003e","title":"2024-大马轨道交通攻略"},{"content":"第一次来到舟山，仅仅是因为Can-festival音乐节。\n上次错过了越位音乐节，这次看到Can-festival的阵容，根本不可能再错过。光是Day2的阵容：We Lost the Sea、Lost in Kiev、The Seven Mile Journey、声子虫，几乎全是我播放器里多年循环的乐队。更别提Day3，This Will Destroy You和World’s End Girlfriend等老牌乐队，还有年初遗憾未能见到的四月雨。\n与“普拉桑”的极限拉扯 出发前几天，台风“普拉桑”紧跟着前一个台风的步伐，直扑江浙沪，着实让我焦虑不已。临行的前一天，我每隔二十分钟就要刷新一次台风路径图，心里祈祷它能转向或加速离去。担心音乐节会取消，或是要在狂风暴雨中听音乐。不过，最终台风带来的破坏都留在了上海，而到了舟山，却意外地迎来了晴朗的天气。\n暴雨中的南浦大桥\n后摇和雨更配 其实，我一向讨厌下雨。但谁能想到，在海边，后摇与风雨竟如此契合。或许，这正是音乐的魔力。雨水肆意洒落，浸湿了镜片，视线模糊不清，分不清脸上的水滴究竟是从天而降，还是心底涌出的泪水。音乐与环境的交织，给了我一种难以言喻的感动。\n海边\n当安尼西亚说这首歌是献给孩子，愿这个世界没有伤害时，我的心突然被一种无法抑制的情感击中。或许我们无法阻止每一个悲剧的发生，但在音乐的陪伴下，我希望这个世界能逐渐变得更加温暖。愿这首《离别》不仅仅是一首哀歌。\nLost in Kiev 在合成器音色和处理上，确实惊艳到我了。不过，他们的贝斯手长的真的好像萨拉赫。\nLost in Kiev\nLITE 的音乐在雨中展现出了出乎意料的活力。即使雨水不停，现场的每个人都随着节奏跳动，那种难以言喻的现场氛围，仿佛雨水并不再是困扰，而是与音乐共舞的一部分。\n雨中的LITE\n声子虫的音墙依旧厚重，像一座无形的高山压迫着我。正如去年看他们演出时的一样， 特别喜欢他们开场时的创意—随着音乐的铺垫进行， 在屏幕上，一笔一画地把“聲子蟲” 三个字缓慢打出。\n缺了最后一笔的“聲子蟲”\n一直期待We Lost the Sea的现场演出，但就在那时，吉他却出了问题。声音时有时无，让本该震撼人心的演奏显得有些破碎。雨水不停地落在身上，心情也随之变得复杂。一点小小的遗憾，像是雨中一滴未曾融入地面的水珠，总让人感到有些不完整。\nWe Lost the Sea — by 群里的艺术家\nThe Seven Mile Journey — by 群里的艺术家\n年纪渐长，似乎每次出门前都有更多的顾虑。年轻时我总能义无反顾地冲向每一个音乐节，不管是风雨还是其他未知的挑战，都觉得无所谓。然而这次，在雨中，我的脑海里浮现出更多的“如果”：如果天气更好一些，如果能再勇敢一些……我无法完全放下这些顾虑，哪怕台上的音乐依旧动人，我却发现自己没有像以前那样尽兴了。也许成长的代价，就是学会在更多的限制和考量中寻找自己的平衡。\n遗憾，化作前行的力量 只看了Day2的演出后，考虑到气温骤降和大雨，再加上风大到船次取消，去普陀山的计划也被迫放弃，我决定提前撤离。没想到，海边的天气竟如此难以捉摸，Day3下午居然又转晴了。错过了傍晚的晚霞，也错过了在L-ISA环绕音响下的World’s End Girlfriend演出，实在是遗憾至极。然而，这些遗憾，正是让我期待下一次音乐节的动力。或许，正因为未尽的体验，才会让我对未来的演出更加期待。\n也感谢群里的小伙伴传来的照片和视频， 能让我第一时间见证这些美丽的瞬间。\n我错过的晚霞 — by 群里的艺术家\n四月雨和夕阳 — by 群里的艺术家\nThis Will Destroy You — by 群里的艺术家\nWEG — by 群里的艺术家\n当然，更要感谢罐总Can给大家带来的这次演出，愿大家都能圆梦。\n","permalink":"https://niraya666.github.io/travel/2024-can-festival-%E5%9C%A8%E6%B5%B7%E8%BE%B9-%E6%B7%B7%E6%9D%82%E7%9D%80%E9%9B%A8%E6%B0%B4%E5%92%8C%E6%B3%AA%E6%B0%B4-%E5%90%91%E5%90%8E%E6%91%87/","summary":"\u003cp\u003e第一次来到舟山，仅仅是因为Can-festival音乐节。\u003c/p\u003e\n\u003cp\u003e上次错过了越位音乐节，这次看到Can-festival的阵容，根本不可能再错过。光是Day2的阵容：We Lost the Sea、Lost in Kiev、The Seven Mile Journey、声子虫，几乎全是我播放器里多年循环的乐队。更别提Day3，This Will Destroy You和World’s End Girlfriend等老牌乐队，还有年初遗憾未能见到的四月雨。\u003c/p\u003e\n\u003ch2 id=\"与普拉桑的极限拉扯\"\u003e与“普拉桑”的极限拉扯\u003c/h2\u003e\n\u003cp\u003e出发前几天，台风“普拉桑”紧跟着前一个台风的步伐，直扑江浙沪，着实让我焦虑不已。临行的前一天，我每隔二十分钟就要刷新一次台风路径图，心里祈祷它能转向或加速离去。担心音乐节会取消，或是要在狂风暴雨中听音乐。不过，最终台风带来的破坏都留在了上海，而到了舟山，却意外地迎来了晴朗的天气。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/DE10C0BD-A093-45EE-B67F-421C767FE234.jpg\" alt=\"DE10C0BD-A093-45EE-B67F-421C767FE234.jpg\"  /\u003e\n\n\u003cem\u003e暴雨中的南浦大桥\u003c/em\u003e\u003c/p\u003e\n\u003ch2 id=\"后摇和雨更配\"\u003e后摇和雨更配\u003c/h2\u003e\n\u003cp\u003e其实，我一向讨厌下雨。但谁能想到，在海边，后摇与风雨竟如此契合。或许，这正是音乐的魔力。雨水肆意洒落，浸湿了镜片，视线模糊不清，分不清脸上的水滴究竟是从天而降，还是心底涌出的泪水。音乐与环境的交织，给了我一种难以言喻的感动。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/8E78A7AB-8588-4165-B71F-261E284C1E51_1_105_c.jpeg\" alt=\"8E78A7AB-8588-4165-B71F-261E284C1E51_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003e海边\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e当安尼西亚说这首歌是献给孩子，愿这个世界没有伤害时，我的心突然被一种无法抑制的情感击中。或许我们无法阻止每一个悲剧的发生，但在音乐的陪伴下，我希望这个世界能逐渐变得更加温暖。愿这首《离别》不仅仅是一首哀歌。\u003c/p\u003e\n\u003cp\u003eLost in Kiev 在合成器音色和处理上，确实惊艳到我了。不过，他们的贝斯手长的真的好像萨拉赫。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/ABF036E9-FBF3-4B73-9B8F-6804C5FFBEBD_1_105_c.jpeg\" alt=\"ABF036E9-FBF3-4B73-9B8F-6804C5FFBEBD_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003eLost in Kiev\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eLITE 的音乐在雨中展现出了出乎意料的活力。即使雨水不停，现场的每个人都随着节奏跳动，那种难以言喻的现场氛围，仿佛雨水并不再是困扰，而是与音乐共舞的一部分。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/CEF4C784-5E96-402F-A73B-AD3ED115EF1F_1_105_c.jpeg\" alt=\"CEF4C784-5E96-402F-A73B-AD3ED115EF1F_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003e雨中的LITE\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e声子虫的音墙依旧厚重，像一座无形的高山压迫着我。正如去年看他们演出时的一样， 特别喜欢他们开场时的创意—随着音乐的铺垫进行， 在屏幕上，一笔一画地把“聲子蟲” 三个字缓慢打出。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/46590887-7972-4CEF-A4F7-A40BF24EDAE4_1_105_c.jpeg\" alt=\"46590887-7972-4CEF-A4F7-A40BF24EDAE4_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003e缺了最后一笔的“聲子蟲”\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e一直期待We Lost the Sea的现场演出，但就在那时，吉他却出了问题。声音时有时无，让本该震撼人心的演奏显得有些破碎。雨水不停地落在身上，心情也随之变得复杂。一点小小的遗憾，像是雨中一滴未曾融入地面的水珠，总让人感到有些不完整。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/BEA4ACE5-B17A-48FB-9E95-EE2BFA987988_1_105_c.jpeg\" alt=\"BEA4ACE5-B17A-48FB-9E95-EE2BFA987988_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003eWe Lost the Sea — by 群里的艺术家\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/2024-Can-festival/1EF13608-9B3E-4159-90C3-034AAD648C5D_1_105_c.jpeg\" alt=\"1EF13608-9B3E-4159-90C3-034AAD648C5D_1_105_c.jpeg\"  /\u003e\n\n\u003cem\u003eThe Seven Mile Journey — by 群里的艺术家\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e年纪渐长，似乎每次出门前都有更多的顾虑。年轻时我总能义无反顾地冲向每一个音乐节，不管是风雨还是其他未知的挑战，都觉得无所谓。然而这次，在雨中，我的脑海里浮现出更多的“如果”：如果天气更好一些，如果能再勇敢一些……我无法完全放下这些顾虑，哪怕台上的音乐依旧动人，我却发现自己没有像以前那样尽兴了。也许成长的代价，就是学会在更多的限制和考量中寻找自己的平衡。\u003c/p\u003e","title":"2024 Can-festival：在海边 混杂着雨水和泪水 向后摇"},{"content":"在使用大型语言模型（LLM）时，我们常常面临一个挑战：如何从模型输出中准确提取自己所需的信息。例如，当我们希望模型输出 JSON 格式的数据时，由于模型生成的内容并不总是稳定，可能需要额外编写大量的正则表达式来匹配并提取其中的有效信息。然而，由于 LLM 的能力，导致其输出结构并不永远可靠。\n现阶段， 让LLM按要求生成特定格式文本的主要方法有几种种：\n微调：使模型的输出遵循特定格式\nOpenAI Json-mode/Structured Outputs/function-calling: 这些功能允许模型生成更严格、结构化的输出，但受限于openAI平台。\n格式约束：在decoding阶段进行约束，限制模型的输出，\nPrompt Engineering： 最简单的办法，但不稳定。\n多阶段prompting： 通过多个步骤的提示逐步引导模型生成所需的格式。\n本文将聚焦在Structured Outputs， 受限编码， 和prompt-engineering的角度，探讨它们在生成特定格式文本中的应用和效果。\nJson Mode 仅特定模型和平台支持\n以openAI 为例， 在openai.chat.completions.create 参数中增加response_format={\u0026quot;type\u0026quot;:\u0026quot;json_object\u0026quot;} 即可（具体参见：response_format ）。\n需要在prompt中要求输出json格式\n不能保证完全按要求的格式结构输出\n但非100%成功率，存在一些需要额外检测和适当处理的edge case。\nHandling edge cases 根据OpenAI官方文档提供的处理方案 https://platform.openai.com/docs/guides/structured-outputs/json-mode we_did_not_specify_stop_tokens = True try: response = client.chat.completions.create( model=\u0026#34;gpt-3.5-turbo-0125\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant designed to output JSON.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Who won the world series in 2020? Please respond in the format {winner: ...}\u0026#34;} ], response_format={\u0026#34;type\u0026#34;: \u0026#34;json_object\u0026#34;} ) # Check if the conversation was too long for the context window, resulting in incomplete JSON if response.choices[0].message.finish_reason == \u0026#34;length\u0026#34;: # your code should handle this error case pass # Check if the OpenAI safety system refused the request and generated a refusal instead if response.choices[0].message[0].get(\u0026#34;refusal\u0026#34;): # your code should handle this error case # In this case, the .content field will contain the explanation (if any) that the model generated for why it is refusing print(response.choices[0].message[0][\u0026#34;refusal\u0026#34;]) # Check if the model\u0026#39;s output included restricted content, so the generation of JSON was halted and may be partial if response.choices[0].message.finish_reason == \u0026#34;content_filter\u0026#34;: # your code should handle this error case pass if response.choices[0].message.finish_reason == \u0026#34;stop\u0026#34;: # In this case the model has either successfully finished generating the JSON object according to your schema, or the model generated one of the tokens you provided as a \u0026#34;stop token\u0026#34; if we_did_not_specify_stop_tokens: # If you didn\u0026#39;t specify any stop tokens, then the generation is complete and the content key will contain the serialized JSON object # This is guaranteed to parse successfully and should now contain \u0026#34;{\u0026#34;winner\u0026#34;: \u0026#34;Los Angeles Dodgers\u0026#34;}\u0026#34; print(response.choices[0].message.content) else: # Check if the response.choices[0].message.content ends with one of your stop tokens and handle appropriately pass except Exception as e: # Your code should handle errors here, for example a network error calling the API print(e) 使用pydantic的方案 使用pydantic的方案 from pydantic import BaseModel, EmailStr, ValidationError # 定义你期望的 JSON 数据模型 class UserModel(BaseModel): name: str age: int email: EmailStr # 检查 JSON 是否符合模型的函数 def validate_json(json_str): try: # 将输入的 JSON 字符串转换为 UserModel 实例 user = UserModel.parse_raw(json_str) # 如果验证通过，返回字典 return user.dict() except ValidationError as ve: print(f\u0026#34;JSON validation error: {ve.json()}\u0026#34;) return None # 示例用法 json_str = \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john.doe@example.com\u0026#34;}\u0026#39; validated_json = validate_json(json_str) if validated_json is not None: print(\u0026#34;JSON is valid and conforms to the schema:\u0026#34;) print(validated_json) else: print(\u0026#34;JSON is invalid.\u0026#34;) Json-Mode 更多是对于输出json的格式进行检查(即Json格式的有效性)\nStructured Outputs 在模型升级到2024-08-06版本后， OpenAI增加了Structured Outputs功能。\n其旨在保证模型始终生成符合所提供的JSON Schema的响应，而无需处理edge case，以及json内容错误。\n其优势在于：\n无需验证或重试格式不正确的响应\n可通过编程检测模型是否安全生成（在API返回结果中增加了\u0026quot;refusal”字段）\n无需复杂的prompt用于限制输出结构\n相较于Json-Mode， 虽然两者都确保生成有效的JSON，但只有Structured Outputs能确保输出json-schema的一致性。因此理论上无需额外的json-schema检查的代码步骤。\n如何使用 以官方文档所提供的`Structured data extraction`为例：\nfrom pydantic import BaseModel from openai import OpenAI client = OpenAI() class ResearchPaperExtraction(BaseModel): title: str authors: list[str] abstract: str keywords: list[str] completion = client.beta.chat.completions.parse( model=\u0026#34;gpt-4o-2024-08-06\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are an expert at structured data extraction. You will be given unstructured text from a research paper and should convert it into the given structure.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;...\u0026#34;} ], response_format=ResearchPaperExtraction, ) research_paper = completion.choices[0].message.parsed output { \u0026#34;title\u0026#34;: \u0026#34;Application of Quantum Algorithms in Interstellar Navigation: A New Frontier\u0026#34;, \u0026#34;authors\u0026#34;: [ \u0026#34;Dr. Stella Voyager\u0026#34;, \u0026#34;Dr. Nova Star\u0026#34;, \u0026#34;Dr. Lyra Hunter\u0026#34; ], \u0026#34;abstract\u0026#34;: \u0026#34;This paper investigates the utilization of quantum algorithms to improve interstellar navigation systems. By leveraging quantum superposition and entanglement, our proposed navigation system can calculate optimal travel paths through space-time anomalies more efficiently than classical methods. Experimental simulations suggest a significant reduction in travel time and fuel consumption for interstellar missions.\u0026#34;, \u0026#34;keywords\u0026#34;: [ \u0026#34;Quantum algorithms\u0026#34;, \u0026#34;interstellar navigation\u0026#34;, \u0026#34;space-time anomalies\u0026#34;, \u0026#34;quantum superposition\u0026#34;, \u0026#34;quantum entanglement\u0026#34;, \u0026#34;space travel\u0026#34; ] } 和在LLM输出的结果中通过`pydantic`进行格式检查类似，只是直接将格式要求传给了模型，减少了额外工作。 等价于\n... \u0026#34;response_format\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;json_schema\u0026#34;, \u0026#34;json_schema\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;research_paper_extraction\u0026#34;, \u0026#34;schema\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;authors\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } }, \u0026#34;abstract\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;keywords\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } } }, \u0026#34;required\u0026#34;: [\u0026#34;title\u0026#34;, \u0026#34;authors\u0026#34;, \u0026#34;abstract\u0026#34;, \u0026#34;keywords\u0026#34;], \u0026#34;additionalProperties\u0026#34;: false }, \u0026#34;strict\u0026#34;: true } } 此外， 文档中还提供了COT的Structured Outputs例子\nChain of thought\nfrom pydantic import BaseModel from openai import OpenAI client = OpenAI() class Step(BaseModel): explanation: str output: str class MathReasoning(BaseModel): steps: list[Step] final_answer: str completion = client.beta.chat.completions.parse( model=\u0026#34;gpt-4o-2024-08-06\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful math tutor. Guide the user through the solution step by step.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;how can I solve 8x + 7 = -23\u0026#34;} ], response_format=MathReasoning, ) math_reasoning = completion.choices[0].message.parsed output:\n{ \u0026#34;steps\u0026#34;: [ { \u0026#34;explanation\u0026#34;: \u0026#34;Start with the equation 8x + 7 = -23.\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;8x + 7 = -23\u0026#34; }, { \u0026#34;explanation\u0026#34;: \u0026#34;Subtract 7 from both sides to isolate the term with the variable.\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;8x = -23 - 7\u0026#34; }, { \u0026#34;explanation\u0026#34;: \u0026#34;Simplify the right side of the equation.\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;8x = -30\u0026#34; }, { \u0026#34;explanation\u0026#34;: \u0026#34;Divide both sides by 8 to solve for x.\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;x = -30 / 8\u0026#34; }, { \u0026#34;explanation\u0026#34;: \u0026#34;Simplify the fraction.\u0026#34;, \u0026#34;output\u0026#34;: \u0026#34;x = -15 / 4\u0026#34; } ], \u0026#34;final_answer\u0026#34;: \u0026#34;x = -15 / 4\u0026#34; } 相比于之前普通版本的COT：\n在测试阶段，程序化检查中间Chain的中间过程变得更加简单\n更优美的提取最终结果\n限制分析过程中的每一步格式，以提高正确率？\nOpenAI API中提供了两种形式的Structured Outputs\nFunction Calling\n使用 json_schema 响应格式\n在function calling （tool-using）时， 在定义tools时需增加\u0026quot;strict\u0026quot;: true 字段，如：\ntools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_delivery_date\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the delivery date for a customer\u0026#39;s order. Call this whenever you need to know the delivery date, for example when a customer asks \u0026#39;Where is my package\u0026#39;\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;order_id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The customer\u0026#39;s order ID.\u0026#34;, }, }, \u0026#34;required\u0026#34;: [\u0026#34;order_id\u0026#34;], \u0026#34;additionalProperties\u0026#34;: False, }, }, \u0026#34;strict\u0026#34;: True, } ] 注意：\u0026quot;strict\u0026quot;: true,会产生一定的延迟（10s以下）\nStructured Outputs功能引入了一个新的字段refusal，用于在模型拒绝执行请求时提供反馈。当用户生成的输入时，模型可能会因为安全原因拒绝履行请求，此时API响应会包含一个名为“refusal”的新字段来指示模型拒绝了请求。当API响应中出现refusal字段时，开发者可以程序化地检测到模型生成了拒绝而不是符合模式的输出。\nConstrained Decoding What Is Constrained Decoding constrained decoding is a technique that manipulates a generative model\u0026rsquo;s token generation process to constrain its next-token predictions to only tokens that do not violate the required output structure.\n仅对严格需要生成的输出部分，从模型的下一个Token概率分布中的兼容Token集进行采样。\n简单来说，对于LLM的输出过程，模型会根据之前的词语序列，计算出下一个词可能出现的概率，并根据这个概率生成下一个词。这一过程会不断重复，直到生成完整的句子或段落（或遇到[EOS]标记）。在普通的生成过程中，模型的概率空间是所有可能的Token。\n相对而言，在引导生成（Guided Generation）过程中，模型的输出会受到额外的引导或约束，以确保生成的内容更加符合某些特定的要求或目标。这种引导可以通过调整概率分布、加入上下文信息、或施加额外规则来实现。\n具体来说， 对于给定的输入序列 $\\tilde{S}_t$ 和模型参数 $\\theta$，\n模型首先计算出一个未加约束的概率分布 $\\alpha$，表示下一个Token $\\tilde{s}_{t+1}$ 的可能性 ，\n$$ \\alpha = \\text{LM}(\\tilde{S}_t, \\theta) $$\n为了引入约束或限制，构造一个布尔掩码 $m$，这个掩码将限制下一个Token的选择范围。掩码函数 $m(\\tilde{S}_t)$将原始分布中的部分不符合约束条件的Token概率置为0，形成一个新的受限分布 $\\tilde{\\alpha}$：\n$$ \\tilde{\\alpha} = m(\\tilde{S}_t) \\odot \\alpha $$\n即在原始分布$\\alpha$ 上应用掩码 $m$，只保留那些满足约束条件的Token的概率，其他Token的概率被置为0。\n接下来，模型根据受限分布 $\\tilde{\\alpha}$ 进行采样，选择下一个Token $\\tilde{s}_{t+1}$\n$$ \\tilde{s}_{t+1} \\sim \\text{Categorical}(\\tilde{\\alpha}) $$\n这个步骤意味着模型只会从符合约束条件的Token集合中选择下一个Token，确保生成的输出遵循预定的规则或格式。\n以上内容出自 outlines的paper：Efficient Guided Generation for Large Language Model 具体内容可自行查看。\n以常见的Json格式约束为例（Fast JSON Decoding for Local LLMs with Compressed Finite State Machine），\n有多种框架可以利用本地模型实现约束解码， 如： outlines，SGLang等。\nvllm+outlines 实现结构化输出 依赖环境：\n! pip install vllm ! pip install openai ! pip install instructor 注意：需要使用到GPU，建议使用colab\n启动vllm模型服务，选择适合GPU显存大小的模型：\n#! vllm serve Qwen/Qwen1.5-4B-Chat --max_model_len=10000 ! vllm serve Qwen/Qwen1.5-1.8B --max_model_len=10000 引导生成json结构：\nfrom openai import OpenAI # Set OpenAI\u0026#39;s API key and API base to use vLLM\u0026#39;s API server. openai_api_key = \u0026#34;EMPTY\u0026#34; openai_api_base = \u0026#34;http://localhost:8000/v1\u0026#34; api_client = OpenAI(api_key=\u0026#39;YOUR_API_KEY\u0026#39;, base_url=\u0026#39;http://localhost:8000/v1\u0026#39;) model_name = api_client.models.list().data[0].id json_schema = { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;thought\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, \u0026#34;answer\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;thought\u0026#34;, \u0026#34;answer\u0026#34;] } query = \u0026#34;What is the capital of China?\u0026#34; # Feed the random question into the existing query system_prompt = \u0026#34;Respond only with a json object containing the following fields and nothing else: thought, answer.\u0026#34; completion = api_client.chat.completions.create( model=model_name, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: system_prompt}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: query} ], extra_body={ \u0026#34;stop_token_ids\u0026#34;: [128009], \u0026#34;response_format\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;json_object\u0026#34;}, \u0026#34;guided_json\u0026#34;: json_schema } ) 输出：\nprint(completion.choices[0].message.content.strip()) # {\u0026#34;thought\u0026#34;: \u0026#34;What is the capital of China?\u0026#34;, \u0026#34;answer\u0026#34;: \u0026#34;Beijing\u0026#34;} 另一个例子， 引导生成符合结构的《Harry Potter》角色属性：\n定义角色属性结构\nfrom openai import OpenAI from pydantic import BaseModel, Field import base64 import instructor import time from enum import Enum from typing import List from glob import glob class Property(BaseModel): key: str = Field(description=\u0026#34;Must be snake case\u0026#34;) value: str class House(Enum): Griffindor = \u0026#34;gryffindor\u0026#34; Hufflepuff = \u0026#34;hufflepuff\u0026#34; Ravenclaw = \u0026#34;ravenclaw\u0026#34; Slytherin = \u0026#34;slytherin\u0026#34; Targaryen = \u0026#34;targaryen\u0026#34; # This schema is what guides generation class Character(BaseModel): name: str age: int house: House properties: List[Property] api_client = OpenAI(api_key=\u0026#39;YOUR_API_KEY\u0026#39;, base_url=\u0026#39;http://localhost:8000/v1\u0026#39;) client = instructor.from_openai(api_client, mode=instructor.Mode.MD_JSON) model_name = api_client.models.list().data[0].id system_prompt = \u0026#34;\u0026#34;\u0026#34;\\ You are a highly creative assistant tasked with generating fictional characters for a fantasy novel. Each character belongs to a specific house, and their properties should reflect their house\u0026#39;s traits. However, ensure that the characters are entirely original and do not directly reference or resemble any characters, events, or settings from the Harry Potter series. Avoid using names, events, or any elements that would make the character too similar to existing Harry Potter content. The goal is to create unique and novel characters that can stand on their own in a fantasy world. \u0026#34;\u0026#34;\u0026#34; def run(name): try: response = client.chat.completions.create( model=model_name, response_model=Character, messages=[ { \u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: system_prompt }, { \u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: name } ], temperature=0.1, # Adjust temperature for creativity ) return response except Exception as e: print(f\u0026#34;An error occurred: {e}\u0026#34;) return None # Example usage character_name = \u0026#34;Voldemort\u0026#34; character = run(character_name) if character: print(character) else: print(\u0026#34;Failed to generate character.\u0026#34;) # name=\u0026#39;Voldemort\u0026#39; age=50 house=\u0026lt;House.Slytherin: \u0026#39;slytherin\u0026#39;\u0026gt; properties=[Property(key=\u0026#39;power\u0026#39;, value=\u0026#39;dark magic\u0026#39;), Property(key=\u0026#39;reputation\u0026#39;, value=\u0026#39;evil\u0026#39;), Property(key=\u0026#39;history\u0026#39;, value=\u0026#39;murdered his parents and became the Dark Lord\u0026#39;)] Prompt-based Methods 根据奥卡姆剃刀法制，“如无必要，勿增实体”， 或许使用prompt也可以实现， 避免引入不必要的复杂性。\n使用Prompt Engineering 要求LLM输出符合格式要求的json（或者其他）时， 可能可以用的一些小Tips：\n明确的指令和提示，并提供具体的例子: 往往LLM的few-shot learning 的能力还行， 模仿个简单的json格式基本不在话下。\n使用占位符： 为具体的json元素标注数据类型和格式，便于LLM理解。这一步骤类似于给json定义一个schema。如\n{ \u0026#34;user\u0026#34;: \u0026#34;示例用户\u0026#34;, \u0026#34;id\u0026#34;: 12345, \u0026#34;items\u0026#34;: [ {\u0026#34;item_name\u0026#34;: \u0026#34;示例物品1\u0026#34;, \u0026#34;quantity\u0026#34;: 2}, {\u0026#34;item_name\u0026#34;: \u0026#34;示例物品2\u0026#34;, \u0026#34;quantity\u0026#34;: 1} ] } 而不是一句“将结果输出成json格式”\n调整温度： 采用较低的温度设置\n分步骤生成： 对于复杂的JSON结构，可以要求模型逐步生成每个部分，然后将它们组合起来； 或先生成JSON的高层结构，然后再深入生成每个子部分。\n让LLM自己检查：类似“三段式翻译” 之类的prompt， LLM首先生成第一版json，而后LLM对LLM进行检查，并提出修改建议， 最后基于建议和初版输出生成最终版结果。\n格式有效性检查： 使用如Pydantic等工具进行验证和解析，如果模型生成了不正确的JSON，可以通过循环过程直到输出有效的JSON为止；或使用一些第三方库修复json, 如json_repair。\n这里推荐一个开源项目， TypeChat， 一个由微软开发，用于让LLM输出类型定义的结果。TypeChat 自动处理生成提示、验证 LLM 输出是否符合定义的类型，并在必要时修复不符合的输出。\n其核心是通过prompt的方式，要求LLM按特定要求输出。\n以官方提供的Calendar例子为例：\n其实现功能即，将自然语言转换成json格式， 用于后续的代办事项的工具使用。\n如输入：\n📅\u0026gt; I need to get my tires changed from 12:00 to 2:00 pm on Friday March 15, 2024 则会输出：\n{ \u0026#34;actions\u0026#34;: [ { \u0026#34;actionType\u0026#34;: \u0026#34;add event\u0026#34;, \u0026#34;event\u0026#34;: { \u0026#34;day\u0026#34;: \u0026#34;Friday March 15, 2024\u0026#34;, \u0026#34;timeRange\u0026#34;: { \u0026#34;startTime\u0026#34;: \u0026#34;12:00 pm\u0026#34;, \u0026#34;endTime\u0026#34;: \u0026#34;2:00 pm\u0026#34; }, \u0026#34;description\u0026#34;: \u0026#34;get my tires changed\u0026#34; } } ] } 首先需要事先定义具体且复杂的schema，如 schema.py\nfrom typing_extensions import Literal, NotRequired, TypedDict, Annotated, Doc class UnknownAction(TypedDict): \u0026#34;\u0026#34;\u0026#34; if the user types text that can not easily be understood as a calendar action, this action is used \u0026#34;\u0026#34;\u0026#34; actionType: Literal[\u0026#34;Unknown\u0026#34;] text: Annotated[str, Doc(\u0026#34;text typed by the user that the system did not understand\u0026#34;)] class EventTimeRange(TypedDict, total=False): startTime: str endTime: str duration: str class Event(TypedDict): day: Annotated[str, Doc(\u0026#34;date (example: March 22, 2024) or relative date (example: after EventReference)\u0026#34;)] timeRange: EventTimeRange description: str location: NotRequired[str] participants: NotRequired[Annotated[list[str], Doc(\u0026#34;a list of people or named groups like \u0026#39;team\u0026#39;\u0026#34;)]] class EventReference(TypedDict, total=False): \u0026#34;\u0026#34;\u0026#34; properties used by the requester in referring to an event these properties are only specified if given directly by the requester \u0026#34;\u0026#34;\u0026#34; day: Annotated[str, Doc(\u0026#34;date (example: March 22, 2024) or relative date (example: after EventReference)\u0026#34;)] dayRange: Annotated[str, Doc(\u0026#34;(examples: this month, this week, in the next two days)\u0026#34;)] timeRange: EventTimeRange description: str location: str participants: list[str] class FindEventsAction(TypedDict): actionType: Literal[\u0026#34;find events\u0026#34;] eventReference: Annotated[EventReference, Doc(\u0026#34;one or more event properties to use to search for matching events\u0026#34;)] class ChangeDescriptionAction(TypedDict): actionType: Literal[\u0026#34;change description\u0026#34;] eventReference: NotRequired[Annotated[EventReference, Doc(\u0026#34;event to be changed\u0026#34;)]] description: Annotated[str, Doc(\u0026#34;new description for the event\u0026#34;)] class ChangeTimeRangeAction(TypedDict): actionType: Literal[\u0026#34;change time range\u0026#34;] eventReference: NotRequired[Annotated[EventReference, Doc(\u0026#34;event to be changed\u0026#34;)]] timeRange: Annotated[EventTimeRange, Doc(\u0026#34;new time range for the event\u0026#34;)] class AddParticipantsAction(TypedDict): actionType: Literal[\u0026#34;add participants\u0026#34;] eventReference: NotRequired[ Annotated[EventReference, Doc(\u0026#34;event to be augmented; if not specified assume last event discussed\u0026#34;)] ] participants: NotRequired[Annotated[list[str], \u0026#34;new participants (one or more)\u0026#34;]] class RemoveEventAction(TypedDict): actionType: Literal[\u0026#34;remove event\u0026#34;] eventReference: EventReference class AddEventAction(TypedDict): actionType: Literal[\u0026#34;add event\u0026#34;] event: Event Actions = ( AddEventAction | RemoveEventAction | AddParticipantsAction | ChangeTimeRangeAction | ChangeDescriptionAction | FindEventsAction | UnknownAction ) class CalendarActions(TypedDict): actions: list[Actions] 这些类表示各种日历操作，每个操作类都有一个actionType字段，确定操作类型：\n• FindEventsAction：查找事件，包含一个eventReference字段，用于指定要查找的事件属性。\n• ChangeDescriptionAction：更改事件描述，包含eventReference（可选）和新的description字段。\n• ChangeTimeRangeAction：更改事件的时间范围，包含eventReference（可选）和新的timeRange字段。\n• AddParticipantsAction：为事件添加参与者，包含eventReference（可选）和参与者列表participants（可选）。\n• RemoveEventAction：删除事件，包含一个eventReference字段。\n• AddEventAction：添加新事件，包含一个event字段。\n在TypeChat的核心 prompt如下：\nprompt = f\u0026#34;\u0026#34;\u0026#34; You are a service that translates user requests into JSON objects of type \u0026#34;{self._type_name}\u0026#34; according to the following TypeScript definitions: ``` {self._schema_str} ``` The following is a user request: \u0026#39;\u0026#39;\u0026#39; {intent} \u0026#39;\u0026#39;\u0026#39; The following is the user request translated into a JSON object with 2 spaces of indentation and no properties with the value undefined: \u0026#34;\u0026#34;\u0026#34; 以上面的例子，最终生成的prompt：\n\u0026#34;\u0026#34;\u0026#34; You are a service that translates user requests into JSON objects of type \u0026#34;CalendarActions\u0026#34; according to the following TypeScript definitions: ``` interface CalendarActions { actions: Array\u0026lt; | AddEventAction | RemoveEventAction | AddParticipantsAction | ChangeTimeRangeAction | ChangeDescriptionAction | FindEventsAction | UnknownAction \u0026gt;; } // if the user types text that can not easily be understood as a calendar action, this action is used interface UnknownAction { actionType: \u0026#34;Unknown\u0026#34;; // text typed by the user that the system did not understand text: string; } interface FindEventsAction { actionType: \u0026#34;find events\u0026#34;; // one or more event properties to use to search for matching events eventReference: EventReference; } // properties used by the requester in referring to an event // these properties are only specified if given directly by the requester interface EventReference { // date (example: March 22, 2024) or relative date (example: after EventReference) day?: string; // (examples: this month, this week, in the next two days) dayRange?: string; timeRange?: EventTimeRange; description?: string; location?: string; participants?: string[]; } interface EventTimeRange { startTime?: string; endTime?: string; duration?: string; } interface ChangeDescriptionAction { actionType: \u0026#34;change description\u0026#34;; // event to be changed eventReference?: EventReference; // new description for the event description: string; } interface ChangeTimeRangeAction { actionType: \u0026#34;change time range\u0026#34;; // event to be changed eventReference?: EventReference; // new time range for the event timeRange: EventTimeRange; } interface AddParticipantsAction { actionType: \u0026#34;add participants\u0026#34;; // event to be augmented; if not specified assume last event discussed eventReference?: EventReference; // new participants (one or more) participants?: string[]; } interface RemoveEventAction { actionType: \u0026#34;remove event\u0026#34;; eventReference: EventReference; } interface AddEventAction { actionType: \u0026#34;add event\u0026#34;; event: Event; } interface Event { // date (example: March 22, 2024) or relative date (example: after EventReference) day: string; timeRange: EventTimeRange; description: string; location?: string; // a list of people or named groups like \u0026#39;team\u0026#39; participants?: string[]; } ``` The following is a user request: I need to get my tires changed from 12:00 to 2:00 pm on Friday March 15, 2024 The following is the user request translated into a JSON object with 2 spaces of indentation and no properties with the value undefined: \u0026#34;\u0026#34;\u0026#34; 参考 A Guide to Structured Generation Using Constrained Decoding\n在 🤗 Transformers 中使用约束波束搜索引导文本生成\nStructured Outputs\nIntroduction to Structured Outputs\nFunction calling\nStructured Outputs for Multi-Agent Systems\nAdd guided decoding for OpenAI API server\noutlines: Serve with vLLM\n如何正确约束输出格式，Deepmind最新：让LLM精准生成任何格式的文本，COLM2024\nCoalescence: making LLM inference 5x faster\nEfficient Guided Generation for Large Language Models\nFast JSON Decoding for Local LLMs with Compressed Finite State Machine\n通过Typechat控制LLM的输出\n大模型 JSON 格式化输出小技巧\nFormatron\nOutlines 〰️\nSGLang\nTypeChat\n","permalink":"https://niraya666.github.io/posts/llm-%E8%BE%93%E5%87%BA%E9%99%90%E5%88%B6structured-outputs%E5%8F%97%E9%99%90%E7%BC%96%E7%A0%81%E5%92%8C%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/","summary":"\u003cp\u003e在使用大型语言模型（LLM）时，我们常常面临一个挑战：如何从模型输出中准确提取自己所需的信息。例如，当我们希望模型输出 JSON 格式的数据时，由于模型生成的内容并不总是稳定，可能需要额外编写大量的正则表达式来匹配并提取其中的有效信息。然而，由于 LLM 的能力，导致其输出结构并不永远可靠。\u003c/p\u003e\n\u003cp\u003e现阶段， 让LLM按要求生成特定格式文本的主要方法有几种种：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e微调：使模型的输出遵循特定格式\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eOpenAI Json-mode/Structured Outputs/function-calling:\u003c/strong\u003e 这些功能允许模型生成更严格、结构化的输出，但受限于openAI平台。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e格式约束\u003c/strong\u003e：在decoding阶段进行约束，限制模型的输出，\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePrompt Engineering\u003c/strong\u003e： 最简单的办法，但不稳定。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e多阶段prompting： 通过多个步骤的提示逐步引导模型生成所需的格式。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e本文将聚焦在Structured Outputs， 受限编码， 和prompt-engineering的角度，探讨它们在生成特定格式文本中的应用和效果。\u003c/p\u003e\n\u003ch2 id=\"json-mode\"\u003eJson Mode\u003c/h2\u003e\n\u003cp\u003e仅特定模型和平台支持\u003c/p\u003e\n\u003cp\u003e以openAI 为例， 在\u003ccode\u003eopenai.chat.completions.create\u003c/code\u003e 参数中增加\u003ccode\u003eresponse_format={\u0026quot;type\u0026quot;:\u0026quot;json_object\u0026quot;}\u003c/code\u003e 即可（具体参见：\u003ca href=\"https://platform.openai.com/docs/api-reference/chat/create#chat-create-response_format\"\u003eresponse_format\u003c/a\u003e ）。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e需要在prompt中要求输出json格式\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e不能保证完全按要求的格式结构输出\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e但非100%成功率，存在一些需要额外检测和适当处理的edge case。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdetails\u003e\n  \u003csummary\u003eHandling edge cases\u003c/summary\u003e\n  \u003cdetails\u003e\n    \u003csummary\u003e根据OpenAI官方文档提供的处理方案\u003c/summary\u003e\n    https://platform.openai.com/docs/guides/structured-outputs/json-mode\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"n\"\u003ewe_did_not_specify_stop_tokens\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003etry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eclient\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echat\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecompletions\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;gpt-3.5-turbo-0125\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"n\"\u003emessages\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;role\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;system\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;content\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;You are a helpful assistant designed to output JSON.\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;role\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;user\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;content\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;Who won the world series in 2020? Please respond in the format {winner: ...}\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"p\"\u003e],\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"n\"\u003eresponse_format\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;type\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;json_object\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"c1\"\u003e# Check if the conversation was too long for the context window, resulting in incomplete JSON \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efinish_reason\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;length\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# your code should handle this error case\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003epass\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"c1\"\u003e# Check if the OpenAI safety system refused the request and generated a refusal instead\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;refusal\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# your code should handle this error case\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# In this case, the .content field will contain the explanation (if any) that the model generated for why it is refusing\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e][\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;refusal\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"c1\"\u003e# Check if the model\u0026#39;s output included restricted content, so the generation of JSON was halted and may be partial\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efinish_reason\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;content_filter\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# your code should handle this error case\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003epass\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efinish_reason\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;stop\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# In this case the model has either successfully finished generating the JSON object according to your schema, or the model generated one of the tokens you provided as a \u0026#34;stop token\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ewe_did_not_specify_stop_tokens\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"c1\"\u003e# If you didn\u0026#39;t specify any stop tokens, then the generation is complete and the content key will contain the serialized JSON object\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"c1\"\u003e# This is guaranteed to parse successfully and should now contain  \u0026#34;{\u0026#34;winner\u0026#34;: \u0026#34;Los Angeles Dodgers\u0026#34;}\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003echoices\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emessage\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003econtent\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"c1\"\u003e# Check if the response.choices[0].message.content ends with one of your stop tokens and handle appropriately\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                  \u003cspan class=\"k\"\u003epass\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003eexcept\u003c/span\u003e \u003cspan class=\"ne\"\u003eException\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"c1\"\u003e# Your code should handle errors here, for example a network error calling the API\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ee\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e  \u003c/details\u003e\n  \u003cdetails\u003e\n    \u003csummary\u003e使用pydantic的方案\u003c/summary\u003e\n    使用pydantic的方案\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epydantic\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eBaseModel\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eEmailStr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eValidationError\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"c1\"\u003e# 定义你期望的 JSON 数据模型\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserModel\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eBaseModel\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003estr\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"n\"\u003eage\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"n\"\u003eemail\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eEmailStr\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"c1\"\u003e# 检查 JSON 是否符合模型的函数\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003evalidate_json\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ejson_str\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003etry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# 将输入的 JSON 字符串转换为 UserModel 实例\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"n\"\u003euser\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eUserModel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eparse_raw\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ejson_str\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"c1\"\u003e# 如果验证通过，返回字典\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edict\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"k\"\u003eexcept\u003c/span\u003e \u003cspan class=\"n\"\u003eValidationError\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003eve\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"sa\"\u003ef\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;JSON validation error: \u003c/span\u003e\u003cspan class=\"si\"\u003e{\u003c/span\u003e\u003cspan class=\"n\"\u003eve\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejson\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"si\"\u003e}\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e              \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"c1\"\u003e# 示例用法\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"n\"\u003ejson_str\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john.doe@example.com\u0026#34;}\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"n\"\u003evalidated_json\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003evalidate_json\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ejson_str\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003evalidated_json\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"ow\"\u003enot\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;JSON is valid and conforms to the schema:\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003evalidated_json\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e      \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          \u003cspan class=\"nb\"\u003eprint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;JSON is invalid.\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e  \u003c/details\u003e\n\u003c/details\u003e\n\u003cp\u003eJson-Mode 更多是对于输出json的格式进行检查(即Json格式的有效性)\u003c/p\u003e","title":"LLM 输出限制：Structured Outputs、受限编码和提示词工程"},{"content":"摘要 本文探讨了“黑暗之魂”系列游戏在当代日本社会中的意义定位。我认为，这款游戏可以被看作是当今文化潮流的象征，就像有人可能会把杰克·凯鲁亚克的《达摩流浪者》视为60年代反文化的象征一样。我主张，“黑暗之魂”系列通过寓言的方式表达了人们在一个日常行为和社会本身的意义都变得极不稳定的时代中生活的焦虑。游戏采用碎片化的叙事方式，融合了佛教的形而上学思想，并以描绘一个曾经辉煌的王国在最后时刻挣扎的阴森哥特式美学为背景。这种对当代社会焦虑的表达，与日本的后现代主义话语密切相关。通过将这些游戏视为文本、环境和游戏系统之间的反馈回路，我把这些游戏的主要概念主题与大泽真幸提出的“后虚构时代”概念，以及东浩纪对御宅族的定义联系起来。\n前言 在人文学科这个领域，我们认为艺术和文学不仅仅是艺术鉴赏。当我们阅读夏目漱石1或三岛由纪夫2的作品时，教授和学生不仅仅像粉丝那样陶醉于他们优美的文笔，而是作为评论家，从中挑出深刻的思想。通过这种方式阅读足够多的作品，我们会发现一种更宏大的东西：一个跨越时代和文化的思想洪流，在这个洪流中，生活的神秘、美丽、恐怖和悲剧汇聚成我们人类经验的漩涡和流动。文学是指南，就像老话说的那样，是通向美好生活的指南：它是一面镜子，反映我们的位置，也是我们漫步时的地图。简而言之，伟大的作品让我们变得更强大。它们让我们清晰地面对生活的矛盾，并有勇气承受其重压。我们学习文学是为了找到人类经验中的共性，并将其内化。这至少是人文学科的理想和创立原则。\n但如果这是正确的，我们能说这种深刻的体验只是文学独有的吗？书面文字是否有某种独特的力量，能够以其他媒介无法企及的方式激发反思？最终，文学只是一个个故事，但故事并不局限于一种媒介。故事是跨媒介的。它们可以口头讲述，可以印刷，可以通过舞蹈、图像，甚至可能通过尚未构想的方式来讲述。这是因为故事首先存在于人类心灵的深层结构中，不同的媒介让这些结构的不同方面显现出来。故事是人类生活的核心，它们赋予我们的社会和个人生活以连贯性和意义。\n故事是个人身份的基石，人类将经验转化为故事的能力可能与我们感知时间的能力有关。毕竟，故事是什么？它是以有意义的方式组织和编辑时间。简而言之，通过研究故事，特别是那些在社会想象中占据重要地位的故事，我们可以进入人类心灵的最深处。当我们接近这一神秘领域时，我们更接近自己，也许会找到一些我们遗忘的，对我们至关重要的东西，它像火药桶上的火花一样在我们脚下点燃，在这场大火中我们的世界观重生。\n新的媒介在大学里常常面临艰难，因为每种媒介都必须越过高文化裁决者的障碍3。这在二十世纪初的电影和摄影上是如此，在今天的漫画、电视和视频游戏上也是如此。但如果我们仅因为这些作品属于错误的媒介而忽视了沟口健二4的作品，人文学科会变得多么贫乏？偏重研究一种媒介而忽视其他媒介有什么好处？这种偏见是最糟糕的，我们都因这种武断的判断而变得贫乏。我们切断了自己探索那些激发我们深层结构的新视角的机会。故事在新的媒介中同样存在，此外，对那些在这些新媒介中成长的人来说，发现其中的故事是引人入胜、动人且深具意义的。视频游戏中的故事体验与其他媒介有着根本的不同，正是这种不同使得研究它们变得如此重要。它反映了一种新的世界观和价值观。我们不再生活在一个技术只是工具的世界里；技术是我们生活的环境。电影和电视是工业时代的本土媒介，而视频游戏是数字时代的本土媒介。视频游戏不是小众的。这个行业在全球产生的收入大大超过了电影和印刷品。这本身就使得研究它们成为紧迫的事情。\n话虽如此，我们必须认识到，视频游戏是一种新兴的媒介。就像早期的电影只是基本现象的再现——火车向屏幕疾驰或马在慢动作中奔跑——视频游戏的媒介中无疑有着尚未开发的巨大潜力。此外，我们还不能像理解文学那样全面理解这一媒介。我们还没有足够的时间去理解视频游戏在文化中可能扮演的角色以及它们对塑造我们的价值观和性格的影响。我不会在这里主张创建一个新的经典目录。现在还为时过早，而且流行经典化的过程早已在进行中。本文研究的游戏《黑暗之魂》系列已经被这样经典化了。它享有一种地位，其他同类游戏以它为标准，而那些共享其设计原则的游戏被称为“魂类游戏（Soul-like）”，这可能类似于许多文学或电影作品被描述为“卡夫卡式的”5。然而，我不会试图将这款游戏作为一部伟大作品来评估，以便将研究这一系列游戏制度化。我认为这些游戏被经典化不仅仅是因为它们“有趣”，而是因为它们直接处理了当代日本及其年轻一代面临的问题、焦虑和挑战。这是我们将要问的问题：这些游戏中反映了什么，使其在跨文化范围内以及在粉丝和评论家中产生如此深刻的共鸣？\n我将在这里主要讨论日本，但我相信在研究这款游戏时得出的教训具有全球意义。目前，这些意义将保持原样。本质上，为了故事而玩游戏是一件矛盾的事情。游戏的内部组件，作为一个具象化的代码系统和作为不同类型叙事（文本、视觉、听觉）的载体，对玩家提出了一系列相互竞争的需求。这种矛盾在《黑暗之魂》中和几乎所有其他游戏中一样没有解决，但该系列在这些相互竞争的元素之间达到了罕见的一致性，可能直接反映了日常生活中数字世界的体验。我希望我在这里的分析，即使只是初步和不完整的，也能成为反思社会走向、新的价值结构的出现以及文学解释或在这种情况下的游戏解释可以对这些问题有所启示的机会。\n第一章：引言 本文旨在探讨“黑暗之魂”系列游戏与当代日本社会状况之间的关系。我认为，“黑暗之魂”系列通过寓言形式表达了在一个日常行为意义甚至社会本身都变得不稳定的时代生活的焦虑。这一表达通过破碎的叙事方式实现，这种方式结合了佛教形而上学，并以描绘一个昔日伟大王国最后挣扎的阴暗哥特风格为背景。这种寓言中的焦虑与日本后现代性讨论密切相关，特别是现代性项目失败和进步叙事腐败的观点。在我的论文中，我认为这种讨论在“黑暗之魂”中通过模拟经典英雄之旅得以体现，但最终通过剥夺玩家的英雄成就感并用深深的模糊和不确定性取而代之，颠覆了这一旅程。\n“黑暗之魂”系列是一款第三人称动作RPG，其核心机制围绕探索一个破败的世界展开。该系列由著名日本游戏公司FromSoftware在总裁宫崎英高的指导下开发。第一款游戏于2011年9月发布，第三款于2016年4月发布。这是一款难度极高的游戏，设定在一个末世奇幻世界，要求玩家克服许多复杂的运动任务。游戏的一大特点是其缺乏具体的叙事阐述。然而，有一些概念性主题将这些游戏联系在一起。游戏中总是有一个被“不死诅咒”摧毁的王国，并且总是有神秘人物指示玩家杀死旧神并使用他们的灵魂来“连接火焰”。这个过程在第一款游戏中被解读为一个世界复兴过程，但在第二和第三款游戏中被揭示为不可避免的衰败螺旋。\n全球销量数百万，三部作品在国外几乎普遍获得好评，赢得了众多“年度游戏”称号和大量其他行业奖项。它对当代游戏设计产生了深远的影响，许多采用类似设计的游戏经常被称为“魂类”或“魂风格”。这已成为一种陈词滥调，类似于带有超现实或存在主义色彩的文学作品被描述为“卡夫卡式”。我认为其地位的原因并非游戏的“有趣”，而是它有一些关于我们今天所处世界的强有力表达，这些表达与那些对现代性的后现代批评观点一致的人产生共鸣。\n本文的核心论点是，“黑暗之魂”系列体现了具有后现代意识的生活体验。这个术语“后现代意识”是我用来总结后现代思想的一个总称。然而，我特别关注日本分支，引用了社会学家大泽真幸6、文化评论家东浩纪7、文学学者田中真纪子8和小说家村上春树9的著作。从弗朗索瓦·利奥塔10（Francois Lyotard）开始——他首次提出“后现代”一词——后现代思想的不同分支的核心主张是，曾经用来指导社会的“大叙事”已经无可救药地破裂并且无法修复。大泽和其他思想家拾起了这条思路，并将其应用到具体的日本背景。他们认为，日本战后时期的大叙事的破裂在年轻一代中引发了虚无主义行为，这种行为表现为从政治原因和社区参与转向过度消费主义和一种表现为御宅族形象的媒体崇拜。在一些极端情况下，这种御宅族主义可能导致病态行为，如奥姆真理教11的恐怖主义，但需要注意的是，这些思想家将这种暴力行为视为御宅族行为连续体的最外端，而不是在类别上有所不同。从大泽和东浩纪等后现代思想家那里，我将后现代意识提炼为两个基本特征：1. 拒绝或无法接受宏大叙事和意识形态作为意义的来源 2. 对“他者”的日益焦虑和敌意。在这种情况下，他者指的是主体与他者之间的经典哲学二元关系；换句话说，就是自我与世界上所有其他自我之间的关系。大叙事的破裂削弱了依赖这些叙事来维系和稳定的社区纽带和同胞感。这种意识是“黑暗之魂”系列设计和叙事的主要当代文化元素。\n然而，后现代意识在日本确实广泛传播，这并不是显而易见的。出于这个原因，我在第一章中追溯了大叙事在日本历史中逐渐瓦解的确切方式，从战后时期开始一直到现在。这使得我们能够看到后现代意识的发展及其在日本社会和“黑暗之魂”系列中的表达。没有这一步骤，就不可能识别贯穿这个系列的后现代意识。\n为了挖掘日本后现代意识的文化根源，我采用了大泽的文化时代精神理论，将战后时期分为三个阶段：意识形态时代（1945 - 1972），虚构时代（1972 - 1995）和后虚构时代（1995 - 现在）。大泽在其作品中提出的基本观点是，意识形态的死亡——本质上是他对“宏大叙事”的术语——刺激了新的形式，这些形式最终使他们脱离了日本战后社会的意识形态基础。从1972年的联合赤军事件12开始，激进的左翼政治让位于非政治的消费享乐主义。这导致了围绕显著消费形式尤其是时尚的亚文化的繁荣。然而，对一些人来说，对更深层意义的渴望仍然存在，这最终催生了新时代的邪教，即奥姆真理教，它们同样从传统宗教和动漫中汲取力量来满足这种需求。\n奥姆真理教的重要性在于他们既标志着传统信仰和意识形态的弱化，也标志着对任何被他们视为“他者”的事物的日益不容忍。他们还标志着一种对远在天边但又近在咫尺的敌对他者的偏执。例如，他们认为日本政府被全球犹太共济会阴谋控制，而他们自己的莲花团体则充满了双重间谍。他们在1995年对这个被认为是犹太人的他者的恐怖袭击，具有讽刺意味的是，传播了这种对奥姆真理教妖魔的偏执，这些妖魔潜伏在学校、企业甚至政府中。这种怪异他者的概念在“黑暗之魂”中得到了有力的表达，因为它向玩家展示了一个充满敌对个体和群体的世界——这些实体是玩家角色的他者——他们的目标和实践是难以理解的。这也通过一种系统得到了加强，即玩家始终连接到互联网，并且开放给其他玩家入侵。\n东浩纪采纳了大泽的时代精神，并提出了一种“动物化”理论。他指出，由于后现代时代缺乏大叙事，人们失去了理想和抱负。因此，他们退缩到一个以收集符号为中心的世界，这些符号被添加到一个巨大的符号数据库中并被重新利用。 他的主要证据是，当今的御宅族不再对叙事感兴趣。相反，他们只是享受识别、重新混合和扩展数据库的组件。他的预测是，御宅族的活动——他们无休止地收集符号——是大文化的先锋，后续几代人将在自己的领域中变得越来越像御宅族。东浩纪所指出的这一流行文化趋势在“黑暗之魂”中体现为深深的模糊和稀疏的叙事。\n那么“黑暗之魂”究竟如何通过游戏玩法表达后现代意识呢？我认为它通过为我们提供一个任务和一个王国来模拟传统的英雄之旅，但剥夺了我们理解这个任务意义的任何连贯方式。游戏提供了一个视觉细节丰富的世界，但完全缺乏具体的阐述，将玩家置于考古学家和法医科学家的角色中。然而，从未有任何可靠的解释；只有更多的线索和片段，有些是矛盾的。这被称为“环境叙事”，它创造了游戏与后现代思想之间最关键的接触点；即它对主叙事的拒绝。有“拯救王国”的建议，但仅仅是建议，主要是通过类型的惯例传达的，而不是叙事。你所做事情的意义及其服务的目的从未完全清楚。\n重要的是要记住，虽然可以从传统的文学解释视角来解释“黑暗之魂”系列的叙事，但当试图将游戏机制解释为寓意时，会遇到许多实际和理论问题。出于这个原因，我在第二章中对当代游戏研究的批判理论进行了文献综述。利用Espen Aarseth13和其他奠定该领域基础的思想家的论点，我认为需要结合“第一人称”现象学方法和更传统的文学分析方法，才能正确评估视频游戏中潜在的潜在意义。这样做是为了建立一种分析方式，通过与游戏系统的斗争，让玩家体验到我上面概述的后现代意识的两个基本特征。我在第三章中将这种现象学方法付诸实践，探索了一种特别有效的文本叙事、环境叙事和游戏玩法的融合，捕捉到游戏作为一个统一体验的本质。\n除了后现代主义，还有另一股影响游戏的力量，那就是佛教末法概念14。这两种影响力在有趣的方式上重叠，并产生了惊人的相似之处。末法在镰仓时代是一个极具影响力的概念，正如我们的时代一样，那是一个深刻的社会转型时期。末法指的是佛教教义失去其效力，人们无法再依靠自己的努力来获得启示。随之而来的是僧侣和寺庙变得不可否认的腐败，人们因此无法离开轮回，被困在一系列日益退化的转世中。我在第四章中分析了末法的哲学核心，并展示了它如何与大泽和东浩纪的后现代话语一致。此外，我认为，只要“黑暗之魂”系列表达了后现代意识，它主要是通过采用这个佛教末世论概念来表达的。后现代思想和末法都表达了一种恐惧，即事情只会变得更糟，人类的努力无法改变结果。\n在第五章中，我回到现象学和文学分析的混合方法，展示末法概念以及佛教形而上学的混合如何作为构建游戏虚拟世界的核心要素，尽管游戏的美学显然源于中世纪的欧洲奇幻调色板。这些佛教元素共同揭示了游戏世界被困在一个日益退化的轮回中，玩家的任务基本上是一种徒劳的行为，只会推动这个痛苦的循环。我认为佛教形而上学的融合最终表达了东浩纪的结论，即后现代世界及其死去的叙事和怪异他者无可避免地导致社会整体的“动物化”。尽管“黑暗之魂”是一款美学显然源于中世纪欧洲奇幻风格的游戏，但它充满了末法的逻辑，因此游戏深受异教影响，通过采用和改造佛教形而上学，在阴暗的骑士在破败的城堡中冒险的表面下表达了一种后现代情感。\n衰败叙事 过去几十年，日本几乎成了停滞的代名词。这在很大程度上归因于日本在1970年代到1980年代经历的“奇迹”，以及他们令人震惊的衰落，自那以后，国家似乎一直处于无所事事的状态。在美国，当《纽约时报》或《华尔街日报》等出版物提到日本时，往往很少有积极的报道，而是集中在一小部分话题：人口老龄化，年轻人自杀；货币贬值，索尼、丰田和东芝等企业巨头被更精简的竞争对手击败；核燃料仍在福岛渗入地下水，但无人承担责任，等等，每一个预言都比前一个更严峻。在西方，日本作为一个正在衰败的帝国的叙述已经流传已久。这种衰败的印象如此强烈，似乎只有惯性才能维持一切运作，以至于人们忘记了日本仍然是世界上最富有、最富裕和技术最先进的国家之一，仍然领先于许多西欧国家。这种停滞的叙述也存在于日本。正如现任首相安倍晋三在2012年选举中的口号所示：“日本を取り戻す”（取回日本）。从谁那里取回？取回到哪里？凭借他的“安倍经济学”15议程中的“三支箭”，他将从日本自己的“萎缩心态”中拯救日本（Sharp）。如果说1980年代的代表是那些狂热工作、渴望企业晋升的上班族，那么近年来这种原型被更为无力的角色所取代：草食男子16（sōshoku danshi）、尼特族17（NEET，指不在职或不在学的年轻人）、隐蔽青年18（hikikomori，指社会隐士）和其他贬损的称呼。诚然，日本的经济和文化问题与其他任何国家一样真实存在，但这种叙述的力量已经超越了现实，成为一种独立的存在。\n这种“萎缩”的心态和随之而来的文化表达，我将称之为后现代意识。这种意识必须与正统的后现代哲学区分开来，因为哲学本身只是对围绕日本的整体衰败叙述的众多情感反应之一。\n后现代意识的核心是一种源于对人类社会已经达到不可否认的衰退点的感知——无论是有意识还是无意识的——的焦虑。鉴于上面概述的围绕日本经济和文化衰退的广泛文化讨论，后现代意识在日本文化心理中占据了中心地位。因此，这些源自后现代意识的停滞叙述在日本的流行媒体中也找到了强大而多样的表达。虽然有许多例子可以引用，但游戏《黑暗之魂》及其所有续集，是这种“萎缩”心态的卓越典范。要理解它如何以这种方式运作，我们不仅要看叙述，还要看《黑暗之魂》相对于同类游戏的存在。《黑暗之魂》属于一种被称为角色扮演游戏（RPG）的游戏类型。RPG通常是一个开放式的幻想世界模拟，玩家可以探索领土、收集宝物和击败怪物。通常，玩家创建一个角色——一个在游戏世界中的化身——并以此角色进行任务，其最终目标通常涉及拯救某物（王国、存在平面、公主等）免于毁灭。另一个RPG的基本特征是成长概念。尽管有许多设计模式和隐喻用于模拟成长过程，通常玩家的化身通过击败怪物获得经验值，并通过积累这些点数“升级”。通过升级过程，玩家解锁能力，他们的化身变得更强大。总的来说，RPG往往是许多文化神话中常见的英雄之旅模式的模拟：年轻、未成型的人必须离开家园的安全区域，面对未知的危险，克服它们，培养他们潜在的能力，并以强大和完全实现的人的身份返回，无论是字面上还是象征性地。\n在其基本设计中，《黑暗之魂》作为RPG是相当传统的。然而，它有许多叙述和游戏设计选择，颠覆了这个几十年旧的类型的许多传统。作为一个叙述，它可以被解读为一种政治和文化的寓言，++直接反映了生活在一个意识形态叙述失去吸引力和连贯性的衰败文明中的经验++。它也是一种新兴新类型的前沿：后末日幻想。在这款游戏中，王国被占领，英雄们都死了或堕落了，没有人可以拯救，而你存在的最大威胁是那些与你在废墟中一起生存的人。社区是不可能的。基本的本体状态是无休止的失败，而“英雄”只是注定要忍受它。甚至死亡也不能免除角色的负担，而你被赋予的任务的意义和目标是模糊和不明确的。叙述几乎不存在。当游戏开始时，玩家被简单地放在一个被怪物和不死者占领的废弃王国中，没有明确的理由说明为何事情会如此，或者他们应该怎么做。仅有的叙述存在于零碎的文本中，只提供诱人但最终不完整或矛盾的关于世界的信息。所有这些叙述元素都对已建立的类型惯例提出了严重挑战，因此将其与衰退的讨论联系起来。\n在游戏设计方面，《黑暗之魂》有两个突出的特点。第一个是游戏被有意设计得异常困难。这实际上是其吸引力的主要来源之一。该系列在西方的广告标语是“准备去死”（Prepare To Die），而在日本，该系列被认为是しにがみ（死亡之神）的主要例子，暗示玩家在与远比玩家创建的化身强大的巨大、恐怖的怪物斗争时必然会经历无数次死亡。另一个特点是，尽管游戏主要设计为单人体验——也是RPG类型的一个既定惯例——玩家始终连接到互联网。这被视频游戏评论家广泛赞誉为该类型的重要创新。在实践中，这创造了一种紧张的局势，玩家总是暴露在其他玩家的“入侵”之中，这些玩家会试图杀死该玩家。这种互动中内置了一个复杂的风险/回报系统，入侵者通过杀死其他玩家可以获得很多，但如果失败则会失去很多。\n实际上，始终连接到互联网使得游戏世界充满了偏执和危险。其他玩家是玩家在游戏中可能面对的最危险和不可预测的怪物。入侵玩家经常会潜伏在一个不合适的时机突然袭击，玩家无法自卫，从而逆转他们不幸的受害者辛苦获得的进展。我们将详细探讨叙述和游戏系统，但这一系列游戏的基本概况引出了一个问题：在一个没有希望拯救王国，并且异常困难常常到不公平地步的游戏中，怎么会有如此大的吸引力？但事实上，这款游戏在日本、欧洲和北美都极具吸引力。这也指出了游戏的设计和叙述如何与在无聊时代生活的年轻一代的经验产生共鸣。\n日本文化领域的停滞叙述需要进一步澄清。我认为《黑暗之魂》可以被解读为对当代日本状况的政治和文化寓言。这是一种后现代的英雄之旅的颠倒：一种被污染的神话碎片的模拟。它直接反映了许多年轻日本人今天试图在庞大、失修的机构中航行时所经历的无聊和徒劳的感觉，这些机构至多对他们的存在漠不关心，至多直接敌对。然而，这种寓言不仅仅是关于生活在1980年代“奇迹”之后的经济问题。它同样涉及生活在一个国家、政治和文化叙述已经失去了大部分意义和连贯性的社会中的社会和心理成本，这些叙述曾经作为一种心理基石——为个人和社区身份提供稳定。\n催化这一恶化的事件起源于1995年，那一年发生了神户地震和沙林毒气袭击。在西方媒体中，关于这些事件的文化或政治意义的讨论通常不多，但在许多日本知识分子中，这些事件似乎标志着现代性的决定性破裂。在著名小说家村上春树的书《地下：东京毒气袭击和日本心理》中，对沙林毒气袭击幸存者的一系列采访，并得出结论，这一事件的后果不可逆转地揭示了日本社会的所有矛盾、缺陷和内在不稳定性：\n“神户地震和1995年1月和3月的东京毒气袭击是日本战后历史上两起最严重的悲剧。毫不夸张地说，这些事件前后的日本意识发生了显著变化。这两次灾难将作为我们生活中的两个里程碑，永远铭刻在我们的心灵中。如此灾难性的事件接连发生是令人震惊的，也是巧合的。然而，当日本的“泡沫经济”破裂，标志着那些泛滥成灾的时代结束时，这些事件带来了对日本国家根本根源的批判性审视。就像这些事件一直在等待伏击我们。两者共有的是压倒性的暴力元素：一个是不可避免的自然灾难，另一个是可以避免的人为灾难。”（村上，237页）\n通过村上等许多知识分子的工作，1995年已成为一个单一且不可改变的地位：通往破碎和功能失调时代的门户。这里分析的主要理论家——东浩纪、大泽真幸和田中基子——都将1995年视为进入反乌托邦现状的起点。这些思想家的语调本身就有一种微妙的后末日色彩，仿佛我们生活在一个无法拯救的被污染时代。这也是衰败讨论的一部分。这些思想家有一种确定的末世论信念，将他们与这一讨论联系起来。\n无论如何，这些灾难比任何经济灾难都更可能是现任首相希望根除的“萎缩”心态的原因。尽管已经过去几十年，1995年的事件作为焦虑和无助感的触发点，在《黑暗之魂》的寓言中找到了源头。经济的持续低迷、老龄化人口、年轻一代的就业前景减少以及福岛等灾难，只是加剧了这些灾难在1995年最初引发的负面情绪。福岛等事件只帮助在日本意识中创造了一种遗产。近年来，右翼极端民族主义政治的重新出现和尼特族及隐蔽青年的社会退缩，形成了对这一相同的文化病态的极端和相反的情感反应。右翼试图通过与其真实和感知的对手（韩国、中国、朝鲜）进行公开的对抗来复兴“大和”帝国的活力，试图通过历史修正主义抹去日本帝国的暴力和道德可憎之处，并试图通过修改宪法（第9条）恢复战争作为国家主权权利。而尼特族和隐蔽青年则将自己沉溺于网络和其他形式的私人数字享乐中。他们没有叙述可供复兴，没有事业可供加入，甚至没有可以参与的兴趣小组。与他人沟通实在是太困难了，在他们看来，也太危险了。\n我的观点不是《黑暗之魂》系列是这些问题的根源，甚至不是它们的贡献，而是它是对在公众意识中循环的深层社会焦虑，特别是对视频游戏作为熟悉媒介的年轻一代的一种特别有力的表达。《黑暗之魂》系列的持续流行，作为一种社会腐化的象征，反映了人们在日常生活中的感觉。但这些焦虑到底是什么，它们如何在《黑暗之魂》中表现出来？另一种问这个问题的方法是，后现代意识的基本要素是什么？定义1995年后时代的有两个主要元素。1. 对构建战后秩序的政治和社会叙述的拒绝；2. 一种对他者的弥漫性焦虑，侵蚀了对社会过程的信任和信心。他者的概念是指自我与世界上遇到的所有其他自我之间的二元关系的一半。这一概念的延伸是文化他者，即一种感觉某些人与自己相似，另一些人则是异类。日本社会通常被认为具有非常同质的国家认同感，彼此之间有相同的文化、种族和相似的价值观。这反过来又创造了强烈的信任和社区感，但这种亲近的逆向效应是，外来者被认为比在美国、英国或法国等文化多样性更大的国家中更为陌生。大泽真幸的论点是，奥姆真理教的恐怖活动将潜在威胁引入了公众。这种恐惧是一种诡异的他者的恐惧，这种他者会突然出现，以一种深刻的方式扰乱你的生活，有时甚至是致命的。社会结构中的这种破裂从未真正修复，并继续受到挑战，直到现在。关于诡异他者的偏执是定义《黑暗之魂》的氛围和叙述的主要特征之一，也是其游戏机制，尤其是其在线组件。\n要理解《黑暗之魂》如何作为一种描述后现代意识的寓言运作，我们必须追踪战后日本社会状况的衰退轨迹。这根本上是一个现代进步叙述——本质上是从西方继承的——首先在1960年代末引发了激烈的意识形态斗争，然后在1980年代变成一种无政治的享乐主义，最后，最终在五个正义的宗教狂热者用雨伞尖端戳破装满沙林毒气的袋子的时刻，被一种微妙的虚无主义彻底摧毁。为此，我们将研究社会学家大泽真幸的工作。大泽花费了相当多的职业生涯试图回答奥姆为什么会做他们所做的事情。在他的书《虚构时代的终结》中，他认为答案涉及意识形态本身的致命缺陷：一种危险而空洞的思维模式，导致在一个自我设计的世界中越来越高的疏离感。\n理性时代 借用社会学家見田宗介19（Mita Munesuke）的观点，大泽真幸将战后时代分为两个不同的阶段。第一个阶段他称为“理想的时代（理想の時代，risō no jidai）”，第二个阶段他称为“虚构的时代（虚構の時代，kyokō no jidai）”。理想的时代始于20世纪60年代，结束于1972年，虚构的时代从1972年开始，一直持续到1995年。大泽将“理想”和“虚构”描述为“可能世界（可能の世界 kanōsei no sekai）”，因为它们都反映了我们对世界的感知以及我们认为世界应该如何。然而，尽管这两个概念在根本层面上是相关的，但它们在几个重要方面是不同的。大泽认为，理想与现实世界密切相关，而虚构则完全脱离现实世界：\n理想是一个在未来有望或期待在现实中实现的可能世界。因此，理想必须存在于现实的因果延伸之上。从这个意义上讲，理想不是一个纯粹的可能世界，而是广义现实世界的一个方面。相反，虚构是一个可以在现实中实现与否无关的可能世界，因此是纯粹的反现实。（大泽，41页）\n理想は、未来において現実に着地することが予期（期待）されているような可能世界である。だから、理想は、現実の因果的な延長上になくてならない。その意味では、理想は、純粋な可能世界ではなく、むしろ広義の現実世界の一局面である。それにたいして、虚構は現実への着地ということについてさしあたって無関連ありうる可能世界であり、それゆえ純粋な反現実である。(Osawa, 41)\n暂且不讨论虚构如何将我们与现实疏离，日本的理想时代很大程度上受到冷战阴影的笼罩。当亚洲大部分地区处于苏联的保护伞下时，日本则在美国的庇护下，因而在意识形态上致力于民主和经济自由主义。在20世纪60年代，日本在这些条件下几乎在各个方面都得到了繁荣：科学、基础设施、经济、文化等。大泽将20世纪60年代称为理想的黄金时代，并指出家用电器是赋予大众理想的物质形式：\n理想时代在大众层面的黄金期是20世纪60年代。当然，这与日本的高速增长期相吻合。在此期间，例如，受到国民绝大多数人广泛需求的家电产品赋予了大众理想物质的表达……经济增长和科学技术的进步并不是因为理想而被接受的，相反，正因为理想作为可能的现实在广泛（全球范围内）被信奉，经济才能够增长，科学和技术才能进步。（大泽，44页）\n理想の時代の、大衆的な水準で黄金期は、1960年代である。もちろん、これは、高度成長期にあたる。この時期、たとえば、国民の圧倒的な大多数によって広範に欲求された家電製品が、大衆的理想に物質的な表現を与えた\u0026hellip;経済成長や科学・技術の進歩があったから理想が抱かれたのではなく、逆に、理想が可能的現実として広く（世界規模で）信憑されたがゆえに、経済が成長することができ、また科学や技術進歩していると感受されたのである。(Osawa, 44)\n乐观和对更美好（物质富足）未来的渴望是这一时代的指路明灯，这种乐观本身就反映了对美国模式的意识形态拥抱，推动了日本从一个被毁灭的国家向一个繁荣的国家的转变。大泽将这种发展归因于对可能世界的执着。在他的著作《拥抱失败》中，约翰·多尔20（John Dower）通过分析战后立即涌现的泛泛女孩21现象，生动地展示了这一拥抱的一个具体表现——这些年轻女性在占领期间主动接近并与美军士兵交往：\n在那段饥饿和匮乏的岁月里，美国人的物质舒适简直令人瞠目结舌。使美国“伟大”的是它如此富有；而对许多人来说，使“民主”具有吸引力的是它显然是通往繁荣之路。在普通人中，没有哪个群体像泛泛女孩那样公然利用征服者的物质财富。她们从美国军用商店获得物品，而在那些贫困的日子里，这些商店真的就像是魔法之地的宝库：不仅装满了基本食品，还有酒和香烟、糖果和美味佳肴，以及性感而颓废的女性物品如口红和尼龙袜。（多尔，136页）\nIn those years of acute hunger and scarcity, the material comforts of the Americans was simply staggering to behold. What made America “great” was that it was so rich; and, for many, what made “democracy” appealing was that it apparently was the way to become prosperous. Among ordinary people, no group tapped the material treasures of conquerors as blatantly as the panpan. They were the recipients of goods from the U.S. military exchange posts that in those impoverished days truly seemed like treasure houses from a magic land: crammed not only with basic foodstuffs, but with liquor and cigarettes, sweets and delicacies, voluptuously decadent feminine things such as lipstick and nylon stockings. (Dower, 136)\n到20世纪60年代后期，美国占领军所展示的意识形态愿景在很大程度上以非常具体的方式兑现了其承诺，普通日本人开始以便利设施、消费电子产品、便利和所有现代化工业国家的装饰形式享受经济发展的成果。大泽认为，这是意识形态在社会中最顺畅地运作的时候。尽管存在意识形态冲突，人们完全接受了作为他们理想“可能世界”的意识形态，并为之努力，无论他们是马克思主义者还是资本主义者。然而，需要注意的是，尽管20世纪60年代有所增长，仍然有许多日本人处于贫困之中。使20世纪60年代成为理想时代的不是相对的繁荣本身，而是对这种繁荣的承诺，以及对战后秩序确实朝着这个方向发展的普遍信念。普通日本人顽强地坚持这种愿景。这是当时的流行意识形态：汽车、收音机、流行音乐、方便获取的食品以及所有在战后立即投降的绝望、痛苦和毁灭中缺失的舒适和物质享受的承诺。\n然而，大泽认为，这种对意识形态的拥抱最终导致了意识形态向他称之为“虚构”的转变。这与意识形态结构本身的内在不稳定性有关，而不一定与日本的意识形态建制的具体情况有关。大泽以最广泛的术语谈论意识形态，但他将驱动意识形态的动机归结为他从佛教借来的一个原则：“貧病争（ひんびょうそう）”22。这个术语可以粗略翻译为“世间的烦恼”，它们被识别为贫穷、疾病和争斗。他主要基于意识形态与虚构的区别，意识形态是面向与貧病争斗争的。换句话说，大多数意识形态都承诺从世间的烦恼中解救出来。这种救赎总是必然在未来，但对其实现的信念保持稳定，并促使在现实世界中采取具体行动。这在大多数世界宗教，特别是忏悔宗教中是如此，但在像资本主义（自由市场=繁荣和自由）和马克思主义（废除财产/阶级=救赎不平等）等世俗概念中也是如此。然而，在理想和貧病争之间的关系中存在一个悖论：\n理想时代是一个社会整体上被疏离到理想中的时代。在这样的时代，最大的痛苦是从理想中被永久疏离。换句话说，在意识形态关系中，人们经历了双重疏离。貧病争代表了一种不可逃避的条件，在这种条件下，实现和接触我们的理想变得极其困难，我们不可避免地永远与之疏离。这种疏离引起的痛苦只能通过对我们理想的重新信仰来解决，只要我们认为其实现的可能性足够高。这只有在我们已经被疏离到意识形态中的情况下才有可能。（大泽，45页）\n理想の時代とは、社会が全体として理想へと疎外されている時代である。このような時代において、最大の不幸とは、理想から永続的に疎外されること、つまり理想との関係において二重に疎外されることである。「貧病争」は、理想への到達・接近が著しく困難になりうるような－理想からの永続的な疎外を余儀なくするような－宿命的な環境条件を代表している。不幸は、－すでに理想への疎外によって条件づけられている以上は－、到達の蓋然性が十分に高い現実性として理想を回復することによってしか、解消されない。(Osawa, 45)\n大泽指出，在苦难和救赎承诺之间存在一个相互强化的解释循环。貧病争，按定义，使人们与各自意识形态的救赎承诺疏离，但这种痛苦只能通过复兴理想来消除。++苦难往往不会导致信仰者失去信仰，而是激励他们按照自己已经信奉的叙事来解释自己的苦难。++使苦难有意义是一种常用于应对我们生活中悲剧性事件的应对机制。矛盾的是，这意味着即使我们离意识形态所承诺的可能世界极其遥远，貧病争也能加强意识形态信仰。当我们对可能世界的信仰非常强烈时，我们会在这种意识形态中“疏离”，只通过其中提供的狭隘解释视角来看待世界。这反映了走向教条主义和正统的驱动力，在这种状态下，貧病争仅作为意识形态引擎的燃料。然而，这个循环的关键部分在某种程度上超出了它；我们必须继续相信可能世界是可能的。大泽的虚构时代描绘了一种信念崩溃的普遍现象，但这种崩溃不应与某种信仰的丧失混淆，例如虔诚的天主教徒变成无神论者或坚定的资本家转变成马克思主义革命者。这只是将一种意识形态换成另一种意识形态。基本结构和取向保持不变。从意识形态到虚构的转变代表了一种新的疏离，一步远离了貧病争和意识形态之间的循环。这是一步远离世界本身。\n大泽举了许多例子，说明在20世纪80年代，日本的意识形态地图如何逐渐脱离大规模叙事（资本主义对抗共产主义），并催生了新人类（新人類 しんじんるい）23、御宅族（オタク）24以及最终的奥姆真理教（Aum Shinrikyō）和1994-1995年的沙林毒气袭击。然而，需要注意的是，在所有这些案例中，无论是伊斯兰教还是马克思主义，意识形态都与当前世界的实际问题密切交织。投射的可能世界正是通过这种对比才可以理解的。正是在与貧病争的这种重要关系中，意识形态与虚构分道扬镳。**对于大泽来说，从意识形态到虚构的转变是由20世纪60年代政治活动后的深刻失望所催化的。**虽然大泽认为20世纪60年代是意识形态运作最顺畅的时期，但这并不意味着那个时代没有意识形态冲突。相反，就政治而言，20世纪60年代末的日本充满了社会动荡。20世纪60年代意识形态运作顺畅的概念并不意味着政治和谐，而是指个人能够完全地、彻底地投身于构成其特定意识形态立场的叙事。\n20世纪60年代标志着许多学生运动，反映了当时日本普遍的政治激活。这些运动大多针对日本政府支持越南战争等问题提出抗议，但间接上也形成了对美国影响日本外交政策的一种抵制。反帝国主义和反美情绪主要由日本共产党刺激。它们创建了全学联合（Zengakuren）25，这是一个在大学生中创造了广泛的左翼文化的组织（羽根，465页）。最终，这些运动演变成了与警察的暴力冲突，抗议者和警察都受到了伤害，有时甚至死亡：\n20世纪60年代中期，东京的一些大学开始出现反对学费上涨的学生示威。总的来说，1968年有115所大学面临学生抗议、示威和骚乱。大规模罢工，设置路障，占领重要建筑。教授们经常被激进学生审讯，被逼供认罪行。（羽根，465页）\n暴力的出现也加剧了最初和平政治议程的混乱。这些抗议由许多不同议程的左翼团体拼凑而成，其中一些比其他更加激进。没有具体或连贯政治需求的暴力最终导致这些学生运动消亡，留下了持久的政治失望感。田中元子（Motoko Tanaka）26在大泽的时代背景基础上，认为安保和全共斗运动的失败是结束理想时代的一个主要因素。全共斗运动27是一个特别持久的事件，形成了一种由其他学生起义效仿的围攻战模式。这场斗争始于东京大学，当时医学生要求废除实习制度。管理层的压迫态度引发了一场全校范围的争议。1968年7月，学生们成立了全共斗，即全学共斗会议的简称。随着斗争的持续，全共斗逐渐激进，开始质疑日本社会的基础。他们占领了整个大学六个月，最终被警察驱逐。田中写道：\n安保和全共斗等政治运动的失败突显了即使在占领结束后，美国对日本政治的持续影响。经历了这些政治运动失败的年轻男性，有意或无意地吸收了应对美国力量的困难和失败的创伤。（田中，46页）\n大泽本人指出，1972年的联合赤军事件（連合赤軍事件）28是从理想时代转向虚构时代的主要转折点。联合赤军是几个激进马克思主义团体合并，意图暴力推翻日本政府。赤军是其中一个宣战日本政府并开始一系列恐怖袭击的团体，包括劫持飞机和袭击特拉维夫的罗德机场，导致26人死亡，80人受伤。政府对该团体进行镇压，逮捕了大多数成员，迫使其余成员与其他团体合并，最终隐藏起来。这个新合并的激进左翼在长野山区建立了一个秘密基地，进行军事训练。在那里发生了对自己队伍的清洗：14名成员因被认为缺乏革命热情而被残忍杀害，有的被绞死，有的被刀割。警察发现了他们的藏身之处并进行逮捕，剩余成员劫持人质， 将自己封锁在一座山间小屋中。这场持续一整天的围攻是日本第一次现场直播的马拉松式电视广播，持续了10小时40分钟。此事件导致了左翼激进政治的急剧衰退。\n当然，意识形态热情的衰退不仅限于左派，也存在于右派。在另一部相关的作品《不可能性的时代》中，大泽将三岛由纪夫未遂的政变视为另一个普遍意识形态崩溃的象征（大泽，13页）。在所有这些案例中，这些意识形态失败的高可见度都表明意识形态本身的某种无力感，其最激进的支持者的过激行为被转化为电视观众眼中的电视节目，令大多数人觉得这些不是高尚革命者的反抗行为，而是堕落的社会病态者的过激行为。取代这种意识形态热情的是大多数人只是享受经济繁荣的成果。\n虚构时代 大泽的虚构时代从1972年延续到1995年，但或许最能捕捉大泽对虚构与意识形态定义的隐喻无疑是“泡沫”这一概念。日本的1980年代通常被称为“泡沫时代”，意指经济的快速崛起及其随后的崩溃。这也传达了一种隔离感。1980年代对日本来说是一个极其繁荣和平的时期，“泡沫”这个比喻传达了普通日本人被困在一种虚假的安全感中的感觉，他们在从战争创伤中完全复苏的社会中享受着温暖、超现代的光芒。然而，这一时期本应被视为对现状充满乐观和信心的时代，却存在一种根本的模糊性。繁荣带来了物质上的丰富，但不一定带来个人或精神上的丰富。大泽认为，如前所述，虚构试图在世界之外重构意识形态，反映出对这种潜在世界在现实中实现的前景的极大失望。简言之，政治和革命活动被放弃了，但对理想的追求并没有消失。\n我们需要认识到，这两者之间没有明确的界限。相反，这种区分反映了控制现实感知和社会活动的态度连续体。我们越接近虚构标记的光谱，就越疏远现实，并且通常会完全拒绝当前的现实状态。此外，越接近虚构光谱，我们就越倾向于完全拒绝既定秩序，并放弃调整或改变它的计划。大泽认为，取而代之的是一种末世论修辞，即世界变得无法拯救，理想在不清除一切的情况下完全无法实现。他将虚构定义为在虚构中保存和扩展的意识形态冲动（大泽, 56）。\n这可以从字面上理解为流行媒体如漫画和动漫作为探索和满足意识形态冲动的空间，但也可以比喻为在这一时期开始繁荣的新兴消费主义和新兴宗教的神秘宇宙论。\n大泽用来体现虚构的三个象征是迪斯尼乐园的建设、涩谷作为东京主要娱乐区取代新宿的发展以及新人类的出现，这些新人类是这个新的“虚构”时代的本地居民（大泽, 46-49）。“新人类”一词可以翻译为“新人”或“新种族”。这个词首次出现在1985年，当时《朝日新闻》刊登了一系列对日本年轻人的采访，标题为《新人类的旗手们》（Herbig）。它通常指的是在1970年代及以后的成长的人群。1970年代和1980年代成长的一代人没有经历过战后重建的艰辛。相反，他们在一个富裕、有影响力、技术先进的国家中成长，这个国家鼓励他们把自己打造成富裕社会的一员。与1950年代和1960年代的年轻人截然不同的是，新人类对左翼政治毫无兴趣，事实上，几乎没有任何政治倾向，因此他们被称为“反应无代”（Herbig）。这种差异不仅仅是文化上的，更是身体上的。之前的几代人经历过粮食短缺，而新一代人从小就能定期过度享受。1965年至1985年间，日本男性的平均身高增加了7厘米，平均体重增加了5公斤，而女性的平均身高增加了6厘米，平均体重增加了1.4公斤。代替意识形态或政治抱负的是，这一代人更感兴趣的是在公司超级结构中的个人进步，或者是个人议程，关注如何设计新的生活方式。如果这些生活方式提出了挑战上一代权威的新价值观，那么可供新人类使用的财富和富裕让他们可以摆脱这些旧的社会结构的重压。例如，许多年轻人在这段时间里有能力搬出家庭独立生活，导致了另一个绰号的出现：“独身贵族”（Herbig）。\n这里讨论的每一项——迪斯尼乐园、涩谷和新人类——都反映了某种与定义过去的意识形态斗争的疏离、隔离或冷漠。迪斯尼乐园在这里是一个很好的隐喻，因为它不仅象征着日本泡沫经济的巨大成功，也象征了一种从世界中物理上的隔离感。迪斯尼乐园被精心设计，一旦顾客进入，他们就看不到其边界以外的东西。这是为了让顾客（尤其是儿童）能够完全沉浸在一个自主的幻想世界中，而不受世俗的干扰。从这个意义上说，迪斯尼乐园作为一种消费体验，完全是以购买从日常生活中暂时逃脱的机会为基础的。将政治或明确的意识形态活动引入迪斯尼乐园将是对其作为幻想空间的自主性的侵犯。但这种政治与休闲之间的绝对分离，在一个脱离普通生活的空间中具体呈现出来，本身就是一种意识形态。这是意识形态与虚构之间的界限开始变得清晰的地方。\n然而，东京的城市中心本身正在经历一种由房地产开发商主导的“迪士尼化”，这些开发商在政府的基本不加监管的情况下进行开发。最终使涩谷成为东京首要娱乐区的新代表，是该地区完全转变为一个主要的消费空间：\n“涩谷的成功在很大程度上归功于西武集团的投资。通过这些投资，整个区域被开发成一个时尚的‘超现实’空间——换句话说，一个充满符号差异的前沿空间——适应了消费社会。”\n“渋谷が成功したのは、とりわけ西武系資本の投入によって、街の全体が、消費会社に適合した、「ハイパーリアル」でオシャレな－つまり先進的な記号的差異に満ちた－空間へと仕立てあげられたからである。要するに、渋谷は虚构の时代に适合した盛り场だったのだ。”（大泽, 47）\n我们可以通过当代对日本的描绘来佐证大泽的论点。涩谷著名的十字路口——经常在延时摄影中显示，其日常通勤者像迅速变化的人群一样脉动——不仅是东京的一个有力象征，也是日本作为一个超现代国家的象征。此外，涩谷因此转变为一个象征日本未来的标志，不仅对日本人而言，也是对整个世界而言，作为未来本身的象征。\n大泽使用“超现实”（ハイパーリアル，hyper-real）一词指的是一种新的城市沉浸感。这是一种建立在对消费主义无疑庆祝基础上的超高清未来愿景。他没有详细解释这个词的确切含义，但他的用法无疑是借鉴了让·鲍德里亚在其著作《模拟与拟像》中的概念。在他的书中，鲍德里亚将当代社会描绘为一个不再包含任何现实参照的巨大符号狂欢。一个符号的意义只能是其他符号在不断变化的符号系列中的另一个符号。在这种框架下，符号获得了自己的自主权，并对我们的现实感知产生了强大的影响。通过博尔赫斯的《科学的准确性》作为寓言，他断言地图作为表征取代了领土，最终成为需要创建新地图的领土本身（Baudrillard, 1）29。没有参照闭合系统之外的任何事物的符号，他称之为拟像。在鲍德里亚的观点中，现代社会与后现代社会的区别在于，现代社会专注于通过更高水平的工业化进行生产，而后现代社会则围绕着生产“模拟”来组织，他指的是电视、互联网、电影、广告、虚拟现实等。\n这种新的媒体生态本质上是一个创造拟像的引擎。例如，真人秀的核心是其主体的非脚本化互动，但实际上是高度编排、制作和编辑的，使这些互动符合我们对戏剧的期望。这种新的“现实”视野因此被消费者接受为解释自己和自己经历的新模式。在鲍德里亚的模拟社会中，身份是通过这种图像的挪用来构建的，从模拟中派生的模型决定了个体如何看待自己以及如何与他人关系。通过延伸，一个超现实空间是一个设计用于交叉并反映这种模拟世界的空间。它利用生活在“模拟”中的各种交织的拟像系统来构建其美学。\n迪斯尼乐园是超现实空间的最佳例子，因为它代表了将地图（构成迪斯尼的符号矩阵）变为实际领土的真诚尝试，在这种情况下，地图无疑是优先的。这在涩谷并不明显，但当我们开始思考将这一地区转变为一个旨在促进各种消费的空间的基本动机时——情趣酒店、夜总会、购物中心、百货商店、娱乐中心——显然，这个世界离不开几十年来在现代广告和品牌建设中构建的符号语言。广告本身就是一个完全致力于通过符号的精心融合来改变产品认知的领域。这些符号被融合到产品的形象中，以便以特定方式阅读产品。通过这种方式，全新的设备或服务被转化为绝对必要品，奢侈品不仅仅授予地位，而是不可逆地与特定的“生活方式”身份混淆。与美国的大型购物中心相似，涩谷是广告、营销和品牌的物理化表现。它试图将城市空间密封在这个不断变化的新符号领土中。在这个空间内，他断言： “真实是从微型化单元、矩阵、存储器和指令模型中生产出来的——通过这些，它可以无限次地复制。它不再需要理性，因为它不再需要与某种理想或负面的事物进行比较。它只不过是操作性的。事实上，因为它不再被想象所包围，它根本不再是真实的。它是一个超现实的产品，一个没有大气层的超空间中的辐射综合体。”（Baudrillard, 2）\n在这种新密封的图像领土中进化并被其服务的新一代就是新人类： “虚构时代的年轻文化最密切相关的是1980年代前半期的新人类，然后是后半期的御宅族。新人类没有被任何意识形态或概念吸引，而是在他们的消费、时尚和兴趣层面上通过‘符号的戏耍’来表现自己的身份。这是一种态度，表达了他们从支配意识形态时代的理想重压下解放出来。”（Osawa, 48）\n在1972年至1995年虚构时代中出现的各种年轻文化中，“符号的戏耍”本身成为了理想的来源。这几十年间有无数的亚文化和时尚趋势——大多源自涩谷和原宿的街头文化——完美地展示了这种“戏耍”。这些众多亚文化的共同点是对生活方式的热爱，这种生活方式主要由美学定义。不同类型的コギャル（kogyaru）亚文化提供了一个生动且特别字面的例子，展示了新人类一代人所拥抱的狂热符号混搭。\nコギャル（高中女生）时尚大约始于1990年代，但其实践和美学可以追溯到早期的亚文化现象。“ギャル”（Gyaru，女孩，源自英语的“gal”）这个称号自1970年代末以来一直用于指代年轻女性的前卫、冒险风格，并在当代用作后缀，表示ギャル连续体内的细分。最初，コギャル风格是一种对校服风格的改编——西装外套、裙子和长袜——被改造得更性感，并混合了大胆的元素，如染发、夸张的化妆，偶尔还有整形手术。随着时间的推移，コギャル风格变得更加多样化和极端，产生了无数不同的变种。“コギャル”这个词与少年犯罪甚至卖淫联系在一起，并且成为老一代人批评的目标。批评者认为这些年轻女性是寄生在父母身上的自恋者，破坏了传统价值观和女性身份。文化人类学家劳拉·米勒在一篇讨论1990年代年轻人时尚的文章中使用“无国籍”（むこくせき，mukokuseki）一词来解释コギャル美学背后的文化逻辑。她使用这个词来说明日本时尚潮流不是由模仿国外特定趋势驱动的，而是希望将尽可能多的吸引符号混合到一个单一的整体中：\n“无国籍的审美刻意唤起某个地方或某个历史时期的图像——越南农民裤子、美洲原住民的流苏和珠子、1960年代的佩斯利图案——但将这些与匡威跑鞋或日本木屐、棒球帽或拉斯塔法里编织贝雷帽结合或并置\u0026hellip;\u0026hellip;日本年轻人的时尚中发现的超历史和文化融合并不仅仅是美国文化帝国主义的证据。仔细观察会发现，在许多情况下，被挪用的物品是有意“误用”或扭曲的。例如，一些コギャル玩弄廉价的夏威夷意象，使用假塑料花环、兰花、koa种子项链和波利尼西亚印花纱笼，但并不是为了看起来像真正的夏威夷人。那些采用这些装饰的人有时被称为“地方女孩”或“纱笼女儿”\u0026hellip;\u0026hellip;コギャル和其他人夸大了他们外表的人工性。结果在真诚、嘲讽和媚俗之间徘徊，使人难以分辨他们是否或在多大程度上是在开玩笑。”（Miller, 83-84）\n这种审美的共同特点是将常见或熟悉的物品与不寻常的物品搭配，创造出高度异国情调，有时甚至是故意怪异的新背景：一件鲜红色的格子纹和服，8英寸高的厚底鞋和一大片亮粉色的头发。这些符号不指向西方，甚至不指向江户时代，它们只属于コギャル时尚文化中的符号网络。像涩谷和原宿这样的超现实城市空间不仅是购买服装的地方，也是展示它们的空间。\n这种通过时尚和个人品味定义自己找到意义的新人类一代，通过拥抱这种新的超现代性的果实来表达自己。他们不是通过政治观点表达自己，而是通过显著的消费形式来创造身份。从这个意义上说，他们完全生活在日本的泡沫中。然而，新人类仍然是一个广泛的类别，反映了广泛的信仰和社会活动。对于大泽来说，完全体现虚构时代主要方面的亚文化是御宅族（Otaku）。御宅族起源于新人类一代，但发展成了一个独特的群体：\n“御宅族指的是一种从新人类中发展出来的青年文化。如果新人类的行为特征在于他们从过去时代的执着中解放出来，那么相反，御宅族的行为特征在于新的执着。**御宅族是这样一群人：他们对一个特定领域——动画、电子游戏、电脑、偶像歌手等——表现出过度的、几乎不合理的热情。**我将这种不合理的热情定义为‘意义’（这里我们可以认为是该领域的社会必要性，或像艺术一样，它本身具有的价值）和御宅族对该兴趣领域收集的信息密度之间的明显失衡。信息的密度压倒了意义。例如，在大多数情况下，如动画的典型例子中，故事[物语]只是虚构[虚构]的积累。因此，对于御宅族来说，他们钟爱的虚构世界似乎比普通现实更重要。”\n“オタクは、この新人類から分化・発展してきた若者の類型である。新人類が、過去の時代を支配していた執着からの解放の身振りによって特徴付けられるのだとすれば、逆にオタクは、新たな拘泥の身振りによって特徴付けられる。オタクとは、かつてだったら興味として片付けられるような一見瑣末なさまざまな領域—アニメーション、テレビゲーム、コンピュータ、アイドル歌手等々—に、不合理なまでに過剰に熱狂的に耽溺する人々である。「不合理なまで過剰」というのは、その領域の社会的な必要とか（芸术のような）それ自身として有すると考えられている価値といったような「意味」の大きさと、その領域に関してオタクが集积する「信息」の浓度との间に、バランスが失われているように见えるということ、「意义」の大きさを「信息」の浓度が压倒しているように见えるということ、である。たとえばアニメーションの場合が典型であるように、多くの场、物语＝虚构の集合である。それゆえ、オタクにとっては、まるで、通常の现実よりも、彼らが爱する虚构の世界の方がより重要なものになっているように见えるのである。”（Osawa, 48）\n大泽在这里提出的御宅族概念非常熟悉，但他从他们对流行媒体的热情中提取了更大的意义，而这常常被忽视。如果说红军联盟成员完全投身于马克思主义革命理想的热情，那么御宅族的特征在于对他们的细分兴趣的痴迷。这些信仰在结构和总体方向上的区别在于，马克思主义革命旨在改变周围的条件以服务于其愿景，而御宅族对周围条件基本无动于衷。他们只是希望更加深入地沉浸在自己喜欢的电视系列中，或者换句话说，更深入地进入特定的符号宇宙。大泽在上面提出的意义（いみ）与信息（じょうほう）之间的平衡，意味着对符号本身的奢华享受逐渐超过了它们的内容。虚构中所代表的理想逐渐在虚构本身中得到保留，达到理想无法在虚构之外生存的地步。这本质上构成了大泽所说的意识形态与虚构之间的关键区别。然而，单独指出御宅族是日本社会结构中的某种异常是错误的。大泽试图指出的是，御宅族对虚构的倾向在整个文化中普遍存在，或许只是通过程度上有所区分。\n御宅族与超现实 大泽在这里讲述的故事可以看作是宏大叙事逐渐消亡及人们为应对这种变化所作的努力。这些叙事曾是赋予私人和公共行动意义并为某些社区活动提供稳定的社会结构。超现实和“新人类”代表了一种意识形态的畸变，将激进分子的能量重新导向个人主义的新意识形态。\n自20世纪70年代以来，宏大叙事的死亡，或者说意义的死亡，一直是许多有影响力的哲学家和学者作品中的共同主题。这个概念最早由法国文学批评家Francois Lyotard30提出，后来成为后现代哲学的主要标志之一。“宏大叙事”一词通常指的是18世纪欧洲出现的各种社会建构，这些建构是为了将欧洲各王国的封建拼凑整合为统一的实体，形成具有单一身份的大型民族国家。知识上，宏大叙事体现在人性和理性的观念中，革命叙事如马克思主义中，经济上则表现为生产至上的国家存在理由。大泽的论点基本上是宏大叙事在日本如何消亡的具体案例。他的论点坚定地位于后现代哲学的传统中，讨论的是时代精神中的意识形态和虚构的死亡过程。\n从这个角度看，“新人类”亚文化和御宅族的出现只是对这些叙事死亡的情感反应。文化批评家东浩纪在他的《御宅族：日本的数据库动物》中，描述了御宅族作为后现代世界中努力保持理智的不安幸存者的形象：\n“御宅族无论走到哪里，都随身携带大量的书籍、杂志、同人志和塞满大纸袋的碎片，像寄居蟹一样，”因为如果他们不随身携带“自我的壳”——即他们的群体归属幻想——他们就无法在精神上保持稳定……现代性受宏大叙事的支配。相反，在后现代性中，宏大叙事崩溃，社会整体的凝聚力迅速减弱。在日本，这种减弱在1970年代加速了，当时高速经济增长和“政治季节”结束，日本经历了石油危机和联合赤军事件。从这个角度看，我们可以将御宅族用垃圾亚文化材料构建“自我壳”的行为模式视为填补宏大叙事消失所造成空虚的行为模式。（东浩纪, 27）\n这种“寄居蟹”形象，与穿戴各种奇异饰品和配件的コギャル（日本街头少女）并无二致，有时她们甚至被这些饰品贴满。消费主义达到极致是一种虚构：一种对世界不感兴趣的意识形态，仅关注符号。这是一种沉浸于超现实的狂喜。御宅族只是消费主义的一个极端代表。这种消费主义类似于意识形态热情，但应用于某些小众兴趣。大泽和东浩纪告诉我们，无论我们是否消费漫画，我们都是在宏大叙事的遗骸中为寻求我们的身份的寄居蟹。从这个角度看，像涩谷这样充满光辉和魅力的超现实空间实际上是一个精神的深渊。\n虚构时代的时代精神仅仅指出晚期资本主义社会中滋生一种几乎宗教态度的消费者的趋势，他们对自己的爱好、喜爱的电视节目、音乐类型等充满热情。西方的民主、工业化国家（暂且包括日本）正是由于其巨大的财富和高度发达的基础设施，使我们能够过上与貧病争大多隔绝的生活；饥饿不存在，现代医学可以治愈许多疾病，洪水和地震的影响通过技术进步大大减弱等。这反过来使我们与现实疏远，同时将我们进一步沉浸在一个与自然世界完全不同的日益技术化的环境中。\n城市一直提供某种程度的与贫病死的疏离。然而，基础设施中表现出的先进技术越来越使我们能够从未曾可能的方式中消除死亡、疾病和暴力。超现实就像虚拟现实的类比原型；一种存在的层面，甚至隔绝了城市本身的更严酷环境，专注于消费和机械化的满足。这就是涩谷与迪斯尼乐园的联系所在，使这些超现实空间与东京臭名昭著的山谷（さんや）31地区或大阪的釜崎（釜ヶ崎，かまがさき）32区不同，在那里贫困的体验是痛苦可见的。城市提供的疏离使自然世界的侵入或突发死亡的可能性变得更加创伤。这就是为什么沙林毒气攻击和1995年神户地震对国家心理产生如此深远影响的原因。这两个事件对大泽有特别重要的意义，因为它们扰乱了城市的超现实环境，结束了虚构时代。\n进入超现实本质上是现代化西方的特权，可以说，创造超现实空间的欲望在大泽定义的意识形态最纯粹形式中反映出来：消除贫病死的斗争。讽刺的是，这削弱了我们与意识形态的关系，将贫病死推向模糊的边缘。然而，超现实从未完全隔离我们；我们始终容易遭受灾难、受伤或突如其来的死亡，破坏我们对世界安全或稳定的看法。超现实只是掩盖了我们对这种灾难可能性的意识，直到它以灾难性的事件出现在我们的生活中。\n70年代日本右翼和左翼意识形态活动的明显失败——红军的暴力、三岛由纪夫的自杀、学生运动的混乱和政治无能，甚至远处苏联的解体——导致了结构日本战后社会的宏大叙事的普遍崩溃。**从这个角度看，大泽的虚构时代是由意识形态时代向虚构时代过渡的双重运动推动的：超现实中的疏离和政治幻灭。**在这种背景下，新人类对经典意识形态斗争不感兴趣或不信服。他们转向内心的虚构和超现实的享乐空间，作为新理想的空间。对于1980年代的御宅族，他们实际上献身于虚构，作为新理想可以蓬勃发展的空间。超现实是鼓励和增强向虚构冲动的空间。像涩谷这样的空间由开发商建造，作为对消费符号的激情献身的自然基质。正如田中元子（Motoko Tanaka）敏锐指出：\n“……现代日本[已经]标准化和媒体化，有着精心维护的分销管理系统。在日本，消费者需求可以立即和机械地满足，无需他者的介入。以前只能通过社会交流获得的欲望对象，如食物和性释放，现在可以很容易地获得，或几乎不需要交流。”（田中, 57）\n当然，这不仅适用于日本，还适用于整个后工业化西方。现代性的成果导致了许多基本需求自动、即时，甚至在我们意识之外得到满足的系统。根本上，超现实代表了一种对虚拟现实的渴望。新宿和迪斯尼乐园就像原型；模拟形式的虚拟空间。但是，虚拟的渴望究竟是什么？斯洛文尼亚哲学家斯拉沃热·齐泽克（Slavoj Zizek）对这个术语提供了一个有趣的解释：\n“[虚拟现实]提供了被剥夺其实质的现实……就像脱咖啡因咖啡闻起来和尝起来像真正的咖啡但不是实物……一切都被允许，你可以享受一切——只要它被剥夺了使其危险的实质。”（齐泽克, 38）\n这种对虚拟的概念，即享受无后果的乐趣或去除物体本质的欲望，是我们迄今为止探讨的超现实和虚构概念的核心。向虚构的运动反映了一种沉浸在符号的吸引世界中的愿望，在那里理想可以不受阻碍地生存，超现实的城市空间同样反映了一种欲望，即将城市中任何不愉快或危险的因素剥离。然而，超现实倾向于那些不仅使我们与超现实之外的现实疏离，而且间接地与他者疏离的系统。这导致了对现实的共同感知的削弱。那些在70年代末和80年代开发的超现实空间充当了当代虚拟空间扩散的原型。虚拟现实和超现实仍然保持各自的领域，但技术的整体趋势指向政府和私营部门积极努力将数字实用性与物理空间整合（智能手机与城市的互动是一个很好的例子；例如Uber，甚至约会服务如Tinder）。超现实中反映的虚拟渴望与从70年代末到现在的视频游戏的加速增长和流行密切相关。然而，如果这些空间使某种行为或某种消费关系得以实现，大泽会将其定义为转向虚构的行为，但它们并不一定决定这种行为。大泽关于御宅族的论点揭示了沉浸在超现实中的欲望如何反映出一种快乐的享乐主义，但也可以反映出对世界的深层次怨恨，迅速转变为病态的虚无主义。\n虚构的负面逆转 超现实世界的主要问题在于，虽然它充满了符号和物质上的享受，但却缺乏意义。对当代整体情况常见的情感反应是讽刺、玩世不恭和刻意的冷漠。另一种常见反应是制定复杂且高度综合的新世纪信仰体系。这些信仰体系鼓励信徒完全服从一种彻底另类的世界观，通常看起来像科幻小说或幻想作品一样刻意。在这个意义上，它是虚构时代最有力的象征。这些信仰体系通常强调世界的虚假和无意义。因此，围绕新世纪信仰体系组织的邪教往往核心是一个末世论叙事，要么寻求逃避当前形式的世界，要么寻求其毁灭。在社会学家岛园嗣的研究中，指出新世纪邪教成员的两个关键特点：一是成员主要来自相对富裕或中产阶级背景；二是加入邪教的主要原因是世界的虚假、虚幻或无意义 (田中, 48)。这两个特点似乎概括了问题的核心。尽管这些人生活舒适，物质上得到满足，但这种满足并不能填补当代生活中某种根本性的意义空虚。\n对于大泽来说，虚构时代（1972-1995）的主要象征是奥姆真理教。他认为这个组织是御宅族的极端表现。这在字面上是部分正确的。众所周知，麻原彰晃和他的追随者是漫画和动漫的狂热爱好者，这些虚构的内容直接融入了他们的综合信仰体系中，包括诺斯替基督教、吠陀神秘主义、阴谋论和超自然伪科学。一个小例子是“宇宙清洁器”，这是一个大型空调单元，麻原声称可以净化外界毒素的空气（大泽, 50）。这个名字直接取自流行动漫《宇宙战舰大和号》，其叙事围绕人类试图修复被敌对外星人辐射污染的地球。此外，该邪教还通过身体和精神上远离外界，建立了一个名为莲花村的公社，作为他们的新乌托邦时代的诺亚方舟，并称之为香巴拉，这是从藏传佛教中借用的天堂概念。通过隐退，他们得以完全封闭在自己设计的世界中。莲花村是他们尝试创建的超真实空间，在这里他们可以用新的虚构符号包裹自己。全面探讨他们所有的宗教实践在这里是不可能的，但简而言之，像“宇宙清洁器”这样的遗物、麻原的秘传布道、能量转移仪式如夏克提巴特，以及电击疗法和在黑暗房间里度过数天的极端宗教训练，都是他们沉浸在自己的超真实中的一部分。\n麻原彰晃将许多阴谋论作为他们神话的一部分。他们认为日本政府是一个由恶意的全球犹太阴谋（共济会）操纵的傀儡，实际上控制了世界。他们认为美国政府在共济会的影响下开发了一种地震机器，导致了1995年的神户地震。在他们看来，世界是不可救药的，受恶意力量的控制。他们甚至认为自己的公社莲花村里充满了共济会间谍，这导致了一个秘密内圈的形成，最终负责毒气袭击。在奥姆未能在1990年获得政治职位后，大泽指出，麻原在该团体内部刊物中的言辞变得越来越末日论和对日本政府的敌意。甚至有证据表明，在1995年之前有几次失败的毒气袭击（奥尔森, 413 - 416）。未能当选相当于外界对其虚构的拒绝，这对他们来说是不可容忍的侮辱，促使进一步的神秘启示和更多的阴谋论，以巩固他们的信仰。\n奥姆还标志着日本社会状况与《黑暗之魂》系列之间的第一个接触点。在每个游戏中，总是存在着在已坍塌王国废墟中仍在运作的敌对、神秘的亡灵邪教。这在第三部作品中特别明显，几乎整个游戏过程中都可以看到亡灵邪教的证据。这些无法理解的信仰实践者代表了有组织社会的最后残余，他们一见到玩家就完全致力于消灭你。正如奥姆的一些成员甚至对其实践和目标也感到模糊一样，《黑暗之魂》中的亡灵邪教的实践和目标也是如此。只有他们作为玩家威胁的存在是明确的。这重现了许多人对奥姆的恐惧和焦虑，他们只是一个威胁和神秘的实体。\n大泽认为，像奥姆真理教这样的新宗教与基督教等旧的千禧年传统不同之处在于，他们通过退缩故意脱离与“贫病争”的斗争。佐证岛园的论点，他指出这种退缩的主要动机是“生活的空虚”（生活の空虚）（大泽, 35）。他将新信仰与旧信仰进行对比。例如，基督教在《圣经》中包含一个末世论叙事，涉及物质与神圣最终完美结合（《启示录》实际上是麻原的主要灵感来源之一）。然而，大多数形式的基督教在通过慈善等努力积极参与与“贫病争”的斗争。换句话说，他们不通过退缩来拒绝现实的严酷，而是积极努力通过各种可能的途径消除它。这使得它们在经典意义上是意识形态的。令人惊讶的是，许多在日常生活中与贫困和疾病作斗争的人往往是宗教信徒。如果我们看一下像天主教会这样的机构，大多数教区居民来自第三世界，如南美洲、非洲甚至贫困水平较高的亚洲。相比之下，属于虚构时代的宗教如奥姆真理教明确拒绝世界，通常渴望世界的终结或其他形式的毁灭。在我们的文化中，人民圣殿教（乔恩斯顿大屠杀）33和天堂之门34是两个虚构取向而非意识形态取向的宗教的好例子。\n岛园对加入像奥姆真理教这样的团体的动机的研究似乎表明，现代经验中出现的某种缺失需要被填补。这是从意识形态转向虚构的根源，在面对当代的模糊、混乱和意识形态的空虚时对意义的真诚渴望。虚构就像是在这混乱中的生命线，但一个人越深入这领域，病态行为的潜力就越高。如果沉迷于自己最喜欢的系列神话的御宅族是对虚构和超真实的“积极”异化，那么实行恐怖主义的末日邪教则是无法容忍其虚构界限之外世界的“消极”异化。奥姆对其自创虚构的痴迷，以及他们完全退隐至莲花村——他们自己设计的超真实空间的尝试——使他们无法接受任何与其虚构相矛盾的存在。这是对虚构的依恋导致对世界虚无主义拒绝的关键点。在后现代性的背景下——即宏大叙事不再起作用的世界——现实无法维持这种虚构中潜在的理想，往往会导致认为现实本身某种程度上是被污染的结论。\n第二章：受苦之魔力圈 未实现的道路 文学解释充满了模棱两可，因为一个文本可以有无数种解读。这一点在电子游戏中更为显著，因为其“游戏性”（或游戏特质）和叙事结构之间存在根本性的张力。传统的文学解释依赖于文本的某种稳定性，以便提取出一种“解读”。在《了不起的盖茨比》中，读者只能通过一个“路径”来进行叙事。威尔逊总是射杀盖茨比，而这一叙事事件的描述对所有读者来说都是相同的。虽然可能有许多解释方式——例如，我们可以将其解读为对资本主义意识形态如何使无产阶级自相残杀的马克思主义批判——但这种解释只有在基于菲茨杰拉德的原始作品《了不起的盖茨比》的基础上才有效。\n如果我们将电子游戏，特别是RPG（角色扮演游戏）类型，视为一种文本，它们更像是一个选择你自己的冒险小说，其中玩家的自主性决定了事件的进程。从叙事角度来看，这种思维方式有助于分析《黑暗之魂》，因为它的叙事结构大致是线性的。它有一个开始，并有几个决定结局的叙事选择，而这些点之间有限的叙事内容是由“作者”（设计师）设定的。然而，即便在这里也存在问题，因为游戏作为美学艺术品并不主要在于通过叙事来前进，推动玩家想知道接下来会发生什么。游戏的体验在于游戏本身，这种游戏形式可能与叙事或其中所出现的虚构世界有松散甚至完全没有实质性的联系。例如，想象一下，你只能在完成一场5公里跑步比赛且时间在六分钟以内的情况下从第九章继续到第十章。在文学中，这些活动之间没有联系，但在电子游戏中，“跑步比赛”的体验非常重要，并直接影响我们对叙事的解读。在像《黑暗之魂》这样的游戏中，完成游戏大约需要40个小时，而阅读、观看过场动画或听对话的时间可能只有30分钟。\n大多数电子游戏是困难且繁琐的，即使对那些熟悉这一媒介的人来说也是如此。对于那些没有所需数字素养和基本操作游戏设备技能的人来说，它们简直是不可能的。正是这种繁琐和挑战性，导致电子游戏学者Espen Aarseth称电子游戏为“需耗费精力的文学”（ergodic literature），即“需要付出巨大努力才能让玩家穿越游戏文本”（Aarseth，第2页）。“ergodic”这个词来源于希腊词语ergon和hodos，分别意为“工作”和“路径”。这个概念出现在Aarseth的开创性作品《Cybertext: Perspectives on Ergodic Literature》中，成为这一新领域的核心理论工具。这个概念的核心是玩家在游戏中拥有的自主性，这种自主性是书籍读者或电影观众所不具备的：\n读者，即使强烈地参与到叙事的展开中，也无能为力。就像足球比赛的观众，他可以推测、推断、外推，甚至大声咒骂，但他不是比赛的参与者。就像火车上的乘客，他可以研究和解释不断变化的风景，可以随意休息眼睛，甚至拉下紧急刹车并下车，但他不能自由地改变轨道方向。他无法拥有玩家的影响乐趣：“让我们看看我这样做会发生什么。”读者的乐趣是偷窥的乐趣。安全但无能为力。（Aarseth，第2页）\n然而，除了“影响的乐趣”——即通过游戏系统选择自己的“路径”的乐趣之外，还存在其负面反转的未探索可能性。在另一篇题为“定义现实”（Define Real）的文章中，他写道：\n\u0026hellip;玩家意识到他们体验的部分性质，众多策略和未走的路径，以及游戏中可能存在他们永远不会遇到的谜团，超出他们技能水平的解决方案\u0026hellip;你可能永远不会知道你的选择的确切结果；也就是说，你到底错过了什么（Aarseth，第3页）。\n在文学中，没有只有在特定条件下才会显现的秘密章节。当我们从头到尾阅读《了不起的盖茨比》时，我们确信已经读完了整部作品。当然，多次阅读会揭示多种解释，但我们从不会为是否仍有大量未发现内容而感到焦虑。从形式上、游戏设计角度以及文本/电影的角度来看，《黑暗之魂》是一款推动这种感觉的游戏，有时这种感觉令人不安、疲惫和疏远。应对这种感觉是游戏作为一个偶然性系统运作的关键方面。在对第一款《黑暗之魂》游戏的分析中，Daniel Vella将这种焦虑称为“需耗费精力的讽刺”（ergodic irony）（Vella，第16页），以表示我们的自主性如何可以削弱我们对游戏“完成”或“掌握”的驱动力。\n除了“需耗费精力的讽刺”中潜在的焦虑之外，还有由游戏行为产生的不稳定心理模式的问题。尽管被称为“游戏”，但在这个领域仍有相当大的争论，即电子游戏是否应该被视为游戏。这并不难理解，因为电子游戏通常同时既是一个故事又是一个具有规则和程序的游戏。当我们踏上篮球场时，我们进入了一个特定的心理框架；所有的行动都是通过一个基本的目标来理解的，即在一个内化的任意限制（例如，不携带球、不击打其他球员等）下将球投入篮筐。\n实际上，正是这种框架使人成为篮球运动员。这正是荷兰社会学家Johan Huizinga所说的“游戏的魔法圈”（magic circle of play）（Huizinga，第32页）。它是指游戏划定了一个空间，在这个空间内只能采用某种心理框架。篮球场是一个“魔法圈”；它允许篮球运动的发生，但只有在篮球游戏本身的心理框架下才能使用。如果做其他事情，就会排除游戏的可能性。篮球场也可以用作高中舞会的场地，此时“圈”的魔法处于休眠状态。小说也是一种魔法圈，因为它是以某种心理框架为前提而创作的。当我们阅读小说时，通常会暂停许多其他阅读方式，以便欣赏故事。文学评论家、历史学家和文学爱好者不会以相同的方式阅读小说，尽管他们可能是同一个人。然而，所有这些框架都是允许的，并且不会削弱作品的基本存在。\n此外，阅读小说的行为通常并不是围绕着完成一个任意目标进行的，而阅读的“规则”并不是基于封闭的一套理性公理。电子游戏会在你无法理解或处理游戏作为一个规则和程序系统时让叙事停滞不前。电子游戏，特别是RPG类型，要求玩家在最基本的层面上通过多种心理模式进行转换。玩家必须随时准备成为电影观众、读者、统计数据的解释者以及复杂运动任务的执行者，所有这些都在几分钟之内完成。\n从这个意义上讲，魔法圈的概念开始崩溃，因为很明显，电子游戏是一个可以同时存在多个圈并要求不同心理框架的空间，而不会削弱电子游戏作为互动艺术品的功能。更好的理解电子游戏的方式是将其视为模拟，其中传统意义上的游戏要么被直接纳入，要么可以在设计师意图之外自发地出现。此外，尽管电子游戏通常将虚构作为体验的核心方面，但严格来说，它们与虚构并不完全相同。引用游戏学者Jesper Juul的话，电子游戏是“半真实的”：\n电子游戏是现实的，因为它们由玩家实际互动的真实规则组成，赢得或输掉游戏是一个真实事件。然而，通过杀死一条龙赢得游戏时，龙并不是真实的龙，而是虚构的。玩电子游戏因此是与真实规则互动，同时想象一个虚构世界，电子游戏是规则和虚构世界的结合。（Juul，第1页）\n然而，在“真实”与“虚构”龙的问题上，还有另一个重要的观点。Espen Aarseth认为，像《魔戒》这样的幻想作品中的龙和像《无尽的任务》（Sony Online Entertainment，1999）这样的幻想RPG游戏中的龙具有截然不同的本体论性质。即使是同一条龙，如《霍比特人》小说中的Smaug和《霍比特人》电子游戏改编中的Smaug，也是如此。区别在于虚构与模拟之间的差异。在题为“门与感知：游戏中的虚构与模拟”（Doors and Perceptions: Fiction vs Simulation in Games）的文章中，Aarseth写道：\n一条龙显然是虚构的，但另一条是模拟的。一条龙是供阅读或在电视或电影屏幕上观看的，另一条龙是供玩耍的。一条龙完全由符号构成，另一条由符号和动态模型构成，这个动态模型将指定其行为并响应我们的输入。正是这种模型行为使其与虚构不同，因为我们可以比了解虚构更亲密地了解模拟。虚构很少甚至从来都不是个人化的，而模拟通过体验可以成为个人化的。模拟允许我们测试其极限、理解因果关系、制定策略并产生变化，这些在虚构中被明确拒绝，但在现实中却非常相似。（Aarseth，第35页）\n然而，如果我们将游戏视为模拟，它们到底在模拟什么呢？如果模拟的是一些现实世界的活动，如驾驶飞机或汽车，这个问题的答案就很简单。在电子游戏行业本身，“模拟器”一词指的是一种试图在世界中再现实际、有时是非常平凡的体验的游戏。模拟可以是低保真或高保真的，但它们的参照物是显而易见的。\n以虚构为导向的游戏，本质上是将那种虚构作为一个数字世界的模拟。当我们考虑电子游戏与传统虚构中的既定类型的关系时，这一点最为明显。科幻电子游戏《光晕：战斗进化》（Bungie，2001）似乎直接借鉴了几部科幻作品，并将它们拼凑在一起。游戏发生的巨大的环形太空栖息地（即标题中提到的“光晕”）让人联想到Larry Niven的《环形世界》系列，而主角Master Chief穿着的“Mjolnir Powered Assault Armor”似乎暗示了John Steakley的《装甲》一书，该书的情节也围绕着穿着动力外骨骼与外星威胁作战的士兵展开。可以几乎无限地以这种方式继续下去，将光晕神话中的某些方面孤立出来，并试图从科幻经典作品中挖掘出影响。这种拼凑是类型小说的基本特征。不同的是，当这些元素被重新构建为一个虚拟的“现实”时。\n设计师不像作家那样，必须回答一些困难的问题，例如，等离子步枪的感觉和声音如何？它的射速有多快？它能穿透坦克的外壳吗？作家可以简单地依靠读者自己想象这些体验细节。以这种方式，《光晕》就像是对构成该类型的符号集合的模拟：模拟模拟物。然而，电子游戏并不是由影响其美学的虚构类型定义的，而是由游戏玩法的惯例定义的。《光晕》的虚构可能源自科幻，但它首先是一款第一人称射击游戏。因此，作为一种体验，它与《孤岛惊魂：原始杀戮》（Ubisoft Montreal，2016）——一款发生在人类原始的穴居人过去的“射击”游戏（标枪、弓箭等）——相比，具有更多的共同点，而不是与《幽浮》这款科幻游戏进行比较，尽管《幽浮》也涉及人类与外星人之间的冲突，但它是一款策略游戏，其原则更类似于国际象棋或Risk这样的棋盘游戏。\n然而，电子游戏不仅仅模拟作为美学集合的类型，或甚至是作为与外星人战斗的太空陆战队员的幻想，尽管它们在这些方面做得相当令人信服。它们还模拟人类存在的模式，或者换句话说，它们模拟文化原型。它们几乎是作为这些原型在古今虚构作品中表现的逻辑延伸来模拟的。\n在其作品《千面英雄》中，美国神话学家Joseph Campbell首次提出了“英雄之旅”的概念，这是一种在不同文化和时代中可见的叙事模式。他描述了基本模式如下：\n一个英雄从日常世界出发，进入一个充满超自然奇迹的区域：在那里遇到令人惊叹的力量，并赢得决定性的胜利：英雄从这个神秘的冒险中回来，拥有了为同伴带来恩惠的力量。（Campbell，第23页）\n正是这种模式的认知使我们能够看到《星球大战》中的卢克·天行者几乎与《伊利亚特》中的奥德修斯扮演了完全相同的文化功能。RPG类型作为一个整体几乎完全围绕这种模式在叙事和游戏设计中进行结构化。在这些游戏中，几乎总是有一个任务，一次跨越许多土地的旅程，一个成长的过程（例如，升级，解锁能力和获得强大的物品），以及一个英雄式的结局，一个王国，或者宇宙本身得救。《黑暗之魂》与其RPG前辈不同之处在于一个关键的类别：英雄式的结局。英雄的方面不仅被模糊和故意含糊不清，而且甚至没有提供一个真正的结局，像卢克自我实现为绝地武士并推翻邪恶帝国的那种方式。这是使《黑暗之魂》作为作品独特的关键方面，因为它模拟了英雄之旅，同时又颠覆了构成其核心价值观的基本结构。\n电子游戏之现象学 如果电子游戏是一种对虚构类型和文学/文化原型的模拟，而不是简单的虚构再现，那么我们该如何解释它们的意义呢？游戏的高度开放性和“能动性”特质（ergodic）在试图对某一作品进行严谨理解时带来了挑战。这一问题在游戏学者中广泛讨论，但一种广泛应用的解决方案是采用现象学方法，即Edmund Husserl和Martin Heidegger等思想家所提倡的在研究游戏体验的基本特征时所用的方法。简而言之，现象学是指通过经验调查现实，而不是单纯依赖外部的、理性的（主要是隐含的）公理体系来证明我们的知识。\n从根本上说，游戏的现象学是一种“第一人称”的分析方法，它不会忽视学者在与游戏这种物质系统互动时所产生的变化和解释框架。这种方法并不排除其他传统的文学解释方法，也不排除社会学、人类学或历史等其他研究模式，而是将这些模式纳入研究者的心理整体中。这样，评论家可以关注游戏过程中相对于具体文本和电影元素所出现的多种心理模式。毕竟，电子游戏不仅仅是叙事，也不仅仅是一组抽象的程序和规则。它们是两者的结合。玩家通常将这些元素作为一个整体来体验，仅仅关注叙事或游戏玩法中的任何一个都会忽略一些至关重要的方面。只有通过严格的自我反思过程，游戏评论家才能提出关于这种全新媒介中出现的意义类型的连贯论点。\n之前，我提到过Johan Huizinga对游戏的定义，即“魔力圈”，其中划定了一个需要特定心理框架的空间，才能使游戏存在。由于游戏在每一刻都引发多种心理模式，电子游戏理论家Dominic Arsenault和Bernard Perron借用了Huizinga的概念，并将魔力圈重新定义为“魔法循环”（magic cycle）（Arsenault，Perron 109）。这一术语指的是玩家与游戏系统之间的反馈循环，玩家通过探测系统来推进游戏，系统则产生新的游戏状态，激发玩家对游戏世界的不同理解，促使玩家采取进一步行动。在《黑暗之魂》系列中，玩家探索世界以获取材料，这些材料可以用来升级武器，使他们能够打败更强大的敌人，从而探索更多的世界，获得更多的武器和材料，依此类推。在这个过程中，他们将看到、阅读和体验到改变他们对自己活动看法并激发新行动的事物。\nArsenault和Perron的魔法循环概念在游戏研究中广泛传播，但游戏设计师早已意识到反馈循环对其媒介的重要性。作为《光环》的首席设计师，Jaime Griesmer曾在一次采访中说：\n在《光环1》中，大概有30秒的乐趣反复出现。如果你能找到30秒的乐趣，你基本上就能把它延伸成整个游戏。（Kietzmann，web）\n由于《光环》在游戏历史中的重要地位，这句话已成为商业领域的设计信条。然而，Griesmer在几年后的另一次采访中对此进行了重要补充：\n在Vidoc（视频纪录片）中被删掉的那句后半部分我谈到了如何在不同的环境中，以不同的武器、不同的载具、对抗不同的敌人、不同组合的敌人，有时对抗彼此战斗的敌人来进行那30秒的乐趣。《光环》的每30秒都不会重复；任务不断改变你所处的环境。（Kietzmann）\n这揭示了Arsenault和Perron意识到但其术语未能充分表达的魔法循环的重要方面。游戏玩法不是一个循环，而是一个不断扩展的螺旋，叙事和游戏元素交织在一起，创造出对游戏世界作为虚构空间和系统的不断演变的理解。\n在下一章中，我将对我在《黑暗之魂III》中遇到的一个隐藏区域进行现象学描述，该区域是在玩了大约30小时后发现的。角色和地点的名字将同时给出英文本地化和日文原版。这些本地化版本相对忠实但可能与原版有显著偏差。这是因为本地化过程优先考虑的是游戏的市场性和销售，而不是文本的忠实度。在原版日文和本地化版本之间有显著差异的地方，我将提供自己的翻译。这将在文本引用中注明。我将采用现象学方法来传达在魔法循环中发现的变化心理模式，这些模式不仅是整个系列的特征，而且可以在游戏的任何特定部分中浓缩。尽管从叙事角度来看，描述中会有许多看似晦涩的部分，但这种晦涩是故意构建在体验中的。只有当我们检查魔法循环的轮廓时，才能正确地将这些散落在这段短暂但强有力的体验中的叙事片段置于上下文中。这里提供的《黑暗之魂》系列的解释将展示叙事框架如何与游戏元素交织在一起，创造出必须整体分析的连贯体验。\n第三章：末法、死亡叙事与可怖他者 审判者古达，失败的英雄古达 在洛斯里克城堡的地下墓穴深处，有一座早已被遗弃的陵墓。这个房间曾经看起来像是一个礼拜的地方。房间中央矗立着一个巨大的石质圣杯，仿佛一个洗礼池。在它下面，一个身穿16世纪马西米连式板甲的骑士盘腿而坐，呈莲花座姿势。他在冥想吗？不，他早已死去，但人们不禁想知道他是否已经摆脱了这个充满幻觉、欲望和轮回的短暂世界。或许他在这个被遗弃世界的凉爽而孤寂的角落里，达到了那著名的般涅槃境界。\n凝视着他平静的身影，我不禁想起浮世绘版画中那幽默的拟态（見立て）。我回想起铃木春信（1725-1770）的一幅作品，画中一位身穿鲜红长袍的花魁在一片巨大的叶子上航行，这是对菩提达摩从印度抵达日本的幽默指涉（詹金斯，第100页；附图1）。江户时代的有识之士和富裕阶层会为这样一个将高僧与吉原的女孩混同在一起的形象感到兴奋。我们的骑士——安详地在这个洗礼池下休息的形象，不正如同释迦牟尼在菩提树下成道的拟态吗？这是开发者对玩家的巧妙玩笑吗？我们无从得知，但没有理由停留在无法解答的谜题上。当游戏本能占据上风时，这个房间就变成了一个需要搜刮宝物的地方。\n房间后部有一个箱子。我打开它，发现了一片龙鳞（顿时一阵快感涌上心头；我现在有足够的鳞片来升级一件特殊武器了），但箱子后面的墙壁有些奇怪。它的颜色与周围环境不匹配，看起来过于黑暗，仿佛这个部分的图像纹理有些瑕疵。这种不协调感令人无法忽视，而且地板上还刻着其他玩家留下的信息。我不需要特意去读它们就能感觉到这面墙后面有什么东西。我用剑击打墙壁，墙壁消失了——不过是个幻象。取而代之的是一个洞穴的入口。向洞穴迈出一步，屏幕上闪现出粗体文字：无主墓地（無縁墓地）。我感到一阵兴奋。寒意通过我的身体，汗毛竖起。我发现了一个秘密区域。带着忐忑，我穿过狭窄的通道，但走了几码后，我发现自己竟然在户外。头顶上没有天花板，只有无尽的黑暗，仿佛洞穴的屋顶高达数百英尺。我在这狭窄的峡谷中穿行，斩杀可怕的生物，它们扭曲的身躯以恐怖的速度前行，每个都残缺不全，陷入疯狂。\n然而这里有些东西让人感到不对劲，与这些畸形怪物的恐怖无关。某种潜移默化的既视感开始渗入我的脑海。当我穿过峡谷时，一条临崖的小路出现了。既视感愈发强烈。这里有更多的怪物，我很快将它们击败，但当我转过弯时，一座巨大的石门出现在视野中，那挥之不去的感觉变成了顿悟。我以前来过这里；这是通往传火祭祀场（火継ぎの祭祀場）的路，与我在游戏开始时的地方一模一样。这是正常游戏世界的黑暗翻版吗？是游戏虚构世界的一部分吗？我们还在叙事空间内吗？还是这是开发者在这庞大作品中隐藏的彩蛋：一种打破第四面墙的暗示，让玩家知道毕竟这只是一款游戏？\n但这个地方带来的感觉更像是恐惧，而不是内部笑话。上面的世界，即使在这秘密区域之外，已经是破碎和折磨的了，但这里更黑暗，更可怕，更堕落，完全没有希望。这无疑是一个回收利用的区域，使用了相同的数字艺术资产，但以某种方式，它与我在这些游戏中体验的世界并不矛盾。我是被困在时间循环中吗？另一个维度？平行世界？穿过石门的拱门，我可以看到院子里蹲着的审判者古达（灰の審判者グンダ）的身影。与游戏开始时的灰烬墓地（灰の墓場）一模一样（附图2）。我怀着忐忑的心情迈过大门，他抬起巨大的身躯，是我的三倍高，拿起他的巨大长柄战斧冲向我，跃起数十英尺，然后让他的全部重量砸在石头上。我勉强躲开。Boss战开始了，他的生命条出现在屏幕底部，但这次显示的名字不同。这次是：英雄古达（英雄グンダ）（附图3）。他的外貌也变了。他的眼睛闪着红光，动作更凶猛狂野，攻击模式更变化多端，难以预测，毫不留情。\n与第一次相比，这场战斗明显更加黑暗和残暴。难度也高了一个数量级。经过大约一分钟的奔跑，努力在他追击我时找准方位，我误判了他的攻击模式，他用长柄战斧的残酷重量击碎了我的角色。屏幕上出现了“你死了”的信息。我的角色在离我惨死地最近的篝火处复活。我感觉到这将是一场艰难的战斗。《黑暗之魂》系列中的Boss战很难，通常需要八九次死亡才能克服挑战。它们的难点在于识别Boss的攻击模式，让玩家能够系统地躲避攻击和利用空隙。耐心、观察和计划会得到回报，急躁和贪婪则会受到严厉惩罚。需要一种禅意的超然态度。我在精神上准备好要死很多次，直到掌握古达的攻击模式。\n我不想浪费时间击败古达和我之间的所有怪物。那太麻烦了。我冲过那些恐怖和畸形怪物，举着盾牌像人形冲撞车一样，只杀掉那些无法绕过的怪物。探索模式的兴奋感已经消失。我对我在哪里、为什么在这里、在这里意味着什么不再感兴趣。我完全专注于击败古达这个任务。这个空间曾经是恐惧和奇迹的地方，现在只是一个需要尽快穿越的地方。回到门前，现在入口处有一层薄雾在旋转。这是一个屏障，一个只有我能通过的封闭区域，其他怪物无法跟随。它是一个亲密的空间。薄雾对我来说意味着院子现在与游戏世界的其余部分隔离开来，在那之后，只有古达的挑战在等待。当古达被击败时，薄雾会消失。穿过薄雾，战斗开始，我在一系列时机不当的闪避后被迅速肢解。这开始了一个死亡、复活和冲回院子的循环。\n起初，我在无尽的死亡中保持冷静。每次死亡只是一次试探性的任务，以进一步了解我的对手。每次尝试，我都能更好地识别他的动作，更一致地躲避攻击，在不受惩罚的情况下偷袭他。我每次都离击败他更近一点，但在大约第20次死亡后，挫败感开始显现。每次失误都引发咒骂和愤怒的嘟囔。我的挫败感让我玩得更糟，进展开始倒退。在这苦难的最低谷，一个来自另一个世界的恶意玩家入侵了我的游戏，在我与凶残的亡灵攻击犬搏斗时，从背后刺杀了我。这导致我失去了一个珍贵的东西，一个人形余烬（残り火），用于在死亡后恢复角色的全部潜力。挫败感不断积累。\n最终，古达的攻击过于狂野，方向变化多端，节奏既慢又快。我对这个系列很有经验，期待它会很难，并且享受挑战，但我遇到了瓶颈。我感到一丝受挫的骄傲，但我拿起笔记本电脑，向更聪明的玩家寻求策略来解决我的问题。看了几个视频后，我对古达的攻击模式有了新的见解：我应该使用的武器，应该等待的时机，攻击的时机，躲避的时机，以及无数微小的细节都会对我有帮助。战斗仍然困难，死亡不止，但我现在清楚地看到了前进的道路。这只是一个我是否有足够技能去执行的问题。\n第十次尝试，带着这些新的策略，我感受到了。这就是那次。必须是那次。带着坚定的决心，我全力以赴，每次闪避都准确无误，等待合适的时机挥剑，抵制住过度攻击的冲动。在削减了他的生命条并躲避无数疯狂的攻击后，古达被击倒在地。我看到屏幕上出现提示，表示可以执行特殊的终结一击。我按下正确的按钮，我的角色用剑刺穿了对手的身体。他发出雷鸣般的野兽般的吼叫，他的身体在一片灰烬中消失。屏幕上闪现出胜利的信息：“火的继承者被消灭了。”一切都结束了，我胜利了。我长舒一口气，全身充满了满足感和兴奋的强烈混合。但我到底得到了什么？这场战斗残酷、令人沮丧、让人意志消沉，但最终，击败Boss的快乐只来自于我学会了他的攻击模式。而且我还需要借助互联网的指导。这不是一次完全的失败，但也不是一次完全的胜利。我感觉到在这次经历之外还有更深的奥秘，但现在还不是我发现它们的时候。我关闭了游戏机，休息眼睛，思考。那次经历是什么？它意味着什么？\n破碎的叙事 上面的现象学描述展示了在游戏过程中不断变化的心理模式。这些模式从寻宝到敬畏的探索，从文本分析到视觉解读，从理论思考到实际操作，从挫折到狂喜，以及这两者之间的一切。游戏的整体流程在与世界的具体挑战进行身体上的互动和对所见所闻产生的好奇之间不断切换。总体而言，游戏系统的推动和拉动作用使玩家始终处于悬念之中，不仅因为环境的挑战，还因为游戏中的真相从未以连贯的方式揭示。游戏的呈现极其丰富和暗示性，但总是留给玩家更多的问题而不是答案。要理解这一系列游戏如何作为一个整体运作，有必要勾勒出基本的游戏机制与反复出现的叙事主题的关系，从而赋予游戏整体体验一种统一的逻辑。\nDark Souls系列在RPG类型的其他游戏中独树一帜，因为它几乎没有向玩家提供任何叙事说明。此外，它也没有给玩家一种续集之间有任何关系的确定感。将该系列联系在一起并使其被认作续集的是游戏设计的连续性、有限叙事中的概念主题以及某些情感特征，这些都是该系列的标志。从这个意义上讲，该系列非常符合东浩纪的数据库理论，因为传统意义上的叙事几乎完全不存在。现有的叙事说明——无论是电影“过场动画”、对话还是沿途找到的文字碎片——都以一种抽象和神话创造的方式运作，玩家很容易忽略。对游戏世界的明确理解最终并不是享受游戏的必要部分，尽管对某些玩家来说可能很有吸引力，因此被简化为体验的外围方面。\n每款游戏都发生在一个不同名字的王国中，这些王国处于后末日的破败状态。这种破败状态的原因不明，但总是与“不死的诅咒”有关，这种诅咒使居民无法永久死亡（他们不断转生），最终变成疯狂和怪物化的样子。这被称为“空心者”（hollow），而玩家在游戏中创造的化身也受到这种诅咒。这种诅咒以黑暗标记（ダークリング）表示，一个框住黑暗虚空的闪烁火环（见附图4）。系列中暗示，只有通过猎杀他人以收集“灵魂”，才能抵抗空心化的影响并最终避免发疯。在每款游戏中，玩家的任务是“链接火焰”（火を継ぐ），即复活死寂世界的过程。这涉及到击败五个强大的实体——在黄金时代的堕落王国的始祖和领主——并收集他们的灵魂，以便用作催化这种重燃的燃料。一旦玩家将这些伟大的灵魂吸收到自己体内，他们也必须牺牲自己作为新纪元火焰的燃料。\n乍一看，将所有三款Dark Souls游戏联系在一起的概念主题似乎只是对无数西方文明神话的另一种演绎，这些神话围绕年轻一代为了振兴传统而做出牺牲。然而，Dark Souls系列通过对其有效性的细微质疑并削弱个人能动性的概念，复杂化了这种典型的英雄公式。Dark Souls系列展示了这个循环不仅是社会通过代际生存的必要过程，而是一种对自然秩序的绝望斗争，因而是一个收益递减的循环。在第三款游戏的结尾，重燃过程已经退化到世界无法修复的地步。玩家的任务不过是在一系列逐渐退化的现实循环中的最后阶段。\n灵魂的概念是叙事和游戏玩法中的另一个重要概念主题。在每个游戏世界中，只有少数几个角色尚未变成空心者，你可以与他们交易物品。你通过杀死空心者和遍布世界的怪物获得的灵魂是你用来与这些角色交易的货币。这些角色可以成为你战斗中的盟友，但在游戏过程中，许多角色最终会变成空心者并攻击你。从叙事的角度来看，这在那些仍保持理智的人之间营造了一种不信任的氛围，因为他们可能只是因为他们是掠食者。这一概念也从叙事中渗透到游戏中。游戏内置的在线功能意味着几乎在任何时候，其他玩家都可以侵入你的世界，杀死你并夺取你身上的灵魂供自己使用。这反映了村上春树和大泽的诡异他者概念。你的敌人本质上与你相似；因此，在Dark Souls的世界里，无论是从叙事还是游戏角度，你都不能真正信任任何人。\n灵魂也是你角色变得更强大的主要方式。当你获得灵魂时，可以用它们来增强和升级你的角色和你拥有的武器。这对于探索世界更危险的部分至关重要。然而，当你变得更强时，角色的升级成本呈指数增长，而收益却是递增的。这需要进一步探索世界的危险区域以寻找更强大的灵魂。与灵魂任务相关的重要游戏机制在玩家探索世界时会产生一种持续的紧张和危险感。当你的化身被杀死时，所有未使用的累积灵魂都会掉落在他们死去的地方，但化身本身会在最近的“篝火”（见附图5）处复活。这些篝火是标志着你进度的安全港湾。它们之间间隔极远，必须由玩家“点燃”才能使用。玩家可以在篝火处休息而不必担心攻击，甚至可以用它们传送到其他已经点燃的篝火。通过篝火，玩家得以探索世界。当玩家的化身在篝火处重生时，他们有一次机会回到死去的地方并找回他们的灵魂，灵魂以一个绿色的旋转粒子球体悬浮在地面上。如果玩家在找回这些灵魂之前再次死亡，灵魂将永远丢失。因此，玩家在篝火之间的危险旅程中总是面临巨大的风险。除了作为安全港湾外，篝火还是玩家补充化身健康和物资的地方。然而，这可能是双刃剑。当敌人被杀死时，他们会无限期地保持死亡状态，但每当玩家在篝火处休息时，他们会复活。在这些破碎的诅咒王国中，没有“免费的午餐”。所有进展都是艰难获得的，并充满风险。\n环境叙事 尽管在《黑暗之魂》系列中故事情节被弱化，但它并非完全不存在。理解游戏世界的神话主要通过解释性的循环，这种循环由丰富的视觉信息和散布在世界各地的物品附加说明文字驱动。整个系列传达的主要氛围显然是后末日的，第三部作品更是将这种美学推向极致。在名为洛斯里克高墙的区域，玩家探索一座完全荒废的梦魇般的哥特式城堡。灰白皮肤、眼窝空洞的可怜人跪在地上，双手合十祈祷，崇拜着巨龙的尸体和似乎正在变成细长树木的人类尸体。看起来这里被某种邪教占据。这些人通常无视玩家，但他们由士兵看守，这些士兵一看到玩家就会恐怖地尖叫，召唤同伴来迎战。这里的基调无疑是后末日的，但没有任何解释。\n这种叙事风格通常被评论家和设计师称为环境叙事。在游戏的任何时刻，玩家在《黑暗之魂》系列中不断自问的中心问题是：这里发生了什么？自然，解释会有所不同，但发现过程是激发《黑暗之魂》游戏魅力循环的一个重要部分。在2010年的游戏开发者大会上，Arkane Studios的设计师Harvey Smith称赞了这种叙事风格的重要性，认为这是视频游戏作为一种媒介所独有的机会：\n“……环境叙事是一种主动的叙事方式。瑞士心理学家Jean Piaget表明，游戏、发现和互动是学习的关键。这种主动的学习方式创造了参与感，进而产生投入感。学生和玩家都会带着自己的经验，因此解释的行为具有个人意义……这一概念背后的理论是封闭法则。作为人类，我们有一种天生的需要，将视觉元素分类并纳入更大的框架。为此，我们得出结论。Scott McCloud在《理解漫画》中将这一概念应用于视觉叙事：‘重要的是在面板之间发生了什么。’” (Harvey)\n因此，在上述现象学描述中，我们在遇到古达时看到的略微打开的石棺，通过人类连接符号点的欲望联系在一起。Harvey认为，这导致了一种深刻的沉浸感，使一款精心制作的游戏充满了自发的突现意义。尽管这种方法在许多游戏中很常见，但《黑暗之魂》系列将这一概念推向极致，常被认为是这种世界设计的高水准标杆。\n玩家在《黑暗之魂》中通过文字、视觉和动作建立的联系跨越了大量的时间和续作。在第二部游戏中，玩家来到了一座显然是战场的城堡。巨人般、树状的尸体到处都是，这些尸体像树一样长出了根，完全占据了整个城堡，打破了厚重的石墙和护墙。最终，玩家会找到一部电梯，将他们带到城堡的下层，他们将在那里第一次与一个仍然活着的巨人boss战斗，尽管这个巨人像针垫一样被各种剑和矛刺穿。一旦boss战开始，屏幕底部会出现一个显示boss角色“生命值”的条。玩家对boss造成的每次打击都会让生命条减少，向玩家传达他们在战斗中的进展信息。虽然这个条的主要功能是信息性的，但它也执行了一个微妙的叙事功能，通过命名对手来反映其叙事意义。在这种情况下，boss的名字出现在生命条上方，称为最后的巨人，反映了它的叙事重要性。尽管在此之前看到无数与这个boss角色相似的尸体，这是唯一提供任何当前情况信息的地方。显然，这个巨人是城堡内部某次冲突的最后幸存者。一旦这个巨人被击败，它的灵魂会自动添加到玩家的库存中。附加在灵魂上的说明文字如下：\n巨人の森の地下に縛られていた／生き残りの巨人のソウル／王国を蹂躙しつくした巨人たちの长は、／名もしれぬ英雄によって倒されたという／长は砦の地下に繋がれ、封じられたが、それは何もかもが滅び去ったあとだった\n被困在巨人森林地下的巨人灵魂/这个王国的摧毁者之一/一个无名英雄打败了这个巨人首领/他被绑在堡垒地下，被封印，但一切都已经被毁。 (FromSoftware, Dark Souls II; 我的翻译)\n这里有很多信息，但它提出的问题远比回答的多。我们知道巨人是入侵者，这解释了城堡的状态和无数的尸体。我们知道这个特定的巨人是巨人中的一个领导者，我们也知道他被打败并被俘虏，这就是我们找到他现在这种状态的原因。但他们为什么要入侵？这发生在多久以前？玩家知道了发生了什么，但并没有更多信息。这种不断的神秘感是玩家如何解释他们在游戏世界中看到、做和体验的一个重要方面。随着他们继续在游戏中前进，其他带有说明文字的物品将为整体画面添加更多信息，但有时是矛盾的。每次披露都会带来新的隐藏。这些巨人的谜团在我们在第三部游戏的开始遇到其中一个尸体时更加复杂。洛斯里克（第三部）和德兰尼格（第二部）之间是否存在连续性，还是这仅仅是一个“彩蛋”，是对系列长期粉丝的一个小惊喜？这是不可能知道的。\n这种叙事风格催生了无数的论坛帖子和YouTube视频，致力于研究分散的说明文字和环境信息之间的联系，并以此为证据提供关于世界的连贯解释。这些视频中的一些非常受欢迎，获得了数百万的观看。YouTuber VaatiVidya制作了无数视频，基于游戏内的证据创建了关于游戏背景故事的理论。然而，他不仅止步于此，还通过挖掘游戏代码并检索通常在游戏的正常商业版本中无法访问的信息片段（音频文件、缺失的场景等）“揭示”叙事内容。这需要特殊的工具和代码知识来发掘这些片段，指向了一种完全不同的消费虚构作品的模式。VaatiVidya的许多视频经常超过一百万次观看，他通过对游戏神话的个人解释成功地将其职业化。这仅仅是因为游戏本身提供的信息非常少。在游戏设计师在游戏内提供大量虚构历史的情况下，例如流行的西方RPG《上古卷轴V：天际》（Bethesda Softworks，2011），对游戏神话的理论研究几乎没有意义。显然，这些理论在粉丝中引起了激烈的争论，因为游戏中内置的证据实在太少，无法得出定论。\n有趣的是，虽然在英语世界中存在数百甚至数千个这样的视频，但在日语网络区域几乎不存在这种内容。YouTube上有成千上万来自日本内容创作者的关于《黑暗之魂》的视频，但他们很少处理从叙事片段中解构神话。显然，这种做法在日本的系列粉丝中不太普遍，他们似乎更喜欢制作分析游戏系统的内容（教程、指南）或制作实况视频。这似乎证实了东浩纪的观点，即新一代御宅族对重建作品中潜在的大叙事不感兴趣。对于他们来说，《黑暗之魂》丰富的情感特征数据库已经足够了。\n第四章: 后现代意识与末法意识 末法 正如前一章所述，“点燃火焰”的命令是驱动《黑暗之魂》系列的核心主题；它构成了推动玩家前进并赋予游戏进展意义的主要目标。点燃火焰带有许多传统西方神话的意味，集中在神灵和英雄展开宏大的任务，以恢复王国或领域的正当状态。在许多方面，RPG类型可以被视为围绕这一设想的一系列模拟游戏。从表面上看，《黑暗之魂》似乎没有什么不同，只是氛围更加暗黑，表现更加抽象。然而，当我们审视这一概念在整个系列中的发展时，很明显在《黑暗之魂》中，点燃火焰实际上是走向消亡的下坡路。点燃火焰——就像古老谚语“传递火炬”——代表了社会及其结构价值观的延续。因此，它大致类似于意识形态在我们社会中所扮演的角色，即通过构建我们对世界的体验的宏大叙事将价值观从一代传递到另一代。《黑暗之魂》的基本结构质疑这一过程的价值，暗示其中存在深刻的腐败，并且一代又一代试图维持微弱火焰的努力不过是人类虚荣心的表现。正是在这种点燃火焰的隐喻中，我们看到了通过佛教形而上学反映的大泽和东浩纪对日本文化景观的后现代评估。\n末法（まっぽう）的概念是佛教早期的一种古老的末世论概念，但直到镰仓时代（1185-1333）才在日本受到广泛关注。据推测，末法是在印度受到希腊人入侵期间发展起来的，但直到6世纪传入中国后才具体出现：\n“当这种思想传入中国时，在南北朝和隋朝建立期间渗透进了大众意识。重要的是574年周武帝对佛教的迫害。”（Bloom，第145页）\n末法思想，像其他类型的启示性思想一样，往往在过渡、冲突和不确定的背景下出现。从南北朝到隋朝的过渡标志着从长期的政治混乱到统一的中国帝国的转变。镰仓时代也反映了一个政治混乱的时期，武士家族篡夺了京都名义上的中央政府。在这些时期，末法概念在日本佛教机构的神学话语中变得弥散，产生了许多独特的日本佛教形式，包括净土宗和日莲宗35——这些佛教形式至今仍然流行。这个词，可以字面翻译为“法的终结”，指的是佛陀教义中包含的真理随着时间的推移会失去其相关性，直到它们在世界上不再发挥任何功能或目的。\n总的来说，根据这种模式，佛教有三个时代。佛陀去世后最初的500年被称为正法时代（しょうほう）。在这个时代，佛陀的教义按照应有的方式被实践，佛陀教义的精髓对所有人开放。接下来的500年被称为像法时代（ぞうほう），尽管佛陀的教义以各种形式和仪式形式实施，但它们已经失去了法的精髓。像法时代之后的10,000年被称为末法，在这个时代，形式和精髓都已经衰退，通过圣贤或个人努力实现觉悟的可能性完全为零。在这个时代，佛教本身最终会被遗忘，痛苦和纷争将持续不减。\n从基本视觉层面来看，《黑暗之魂》是末世氛围的。此外，每次重新点燃火焰时都会逐渐消逝的火焰主题以及法的传递越来越弱的启示性观念，像一场漫长的电话游戏，直到信息完全丢失，都有着强烈的概念平行。这甚至与大泽的三种意识形态、虚构和后虚构（动物）时代之间存在平行。大泽的论点基于这样一个观点：宏大叙事变得越来越弱和腐败，直到没有什么能够支撑它们。历史上有趣的平行现象将后现代主义和末法思想以意想不到的方式联系在一起。\n尽管在镰仓时期末法一词广泛流传，但解释却相当多样。然而，这个词在日本宗教生活中的起源通常与一个名为《末法灯要记》的文献的出现有关。这个文献通常归因于天台宗的创始人最澄（767-822），但专家对此争论不休。许多人认为这只是一个净土宗僧人的伪作。不容置疑的是，它对当时主要佛教思想家的明显影响，包括法然、荣西、道元、亲鸾和日莲。比起宗教文献，《末法灯要记》决定性地具有政治色彩。最澄在其中为忽视传统佛教戒律的僧侣的做法辩护，反对政府的批评。宗教学者Michele Marra解释了支持最澄论点的逻辑：\n“……政府在批评中忘记了这些僧侣生活在末法时代，因此，他们不能适用为生活在真理理想时期的僧侣制定的规则。由于在末法时代只有口头教义存在，而实践不存在，觉悟不可达成，戒律也随之消失，因此，坚持僧侣违反戒律是毫无意义的。不存在的东西如何被破坏？同样的原因，戒律也不能被遵守。”（Marra，第287页）\n然而，《末法灯要记》在反驳中并没有止步于此：\n“《末法灯要记》暗示那些努力遵守戒律的僧侣，因此屈从于政府要求的僧侣，表现出对佛教的形式态度，忘记了其宗教的人性意义。因此，他们被比作摧毁国家的蝗虫……”（288页）\n该论著的最终结论是，那些“名义上的僧侣”，即至少表面上扮演角色的僧侣，应受到敬畏和尊重，因为他们代表了在这种情况下可能达到的最高精神成就。因此，他们应该被视为珍贵的，就像在一个没有银和金的世界里，铜被视为珍贵一样。东浩纪对“动物主义”的默认支持在某种程度上与最澄的论点有相似之处。在一个意义无法存活的时代，除了成为一个御宅族并将自己困在只有你渴望的情感特点的毛绒世界中，还有什么其他选择呢？暗示中，依附于旧式意识形态信仰的人是错觉的，甚至是危险的。这是涵盖在后现代主义范畴下的哲学广泛持有的信念。\n尽管《末法灯要记》在日本主要佛教思想家中广泛流传，但在关于末法的形而上学状况下应该做些什么的解释却十分多样。然而，绑定这些不同解释的往往是对天台宗佛教的拒绝。事实上，法然、道元、荣西、日莲和亲鸾都曾接受过天台宗僧侣的训练 36，后来他们得出结论认为该机构已经失去了对真正法的把握。这最终导致每个人都与这个强大的机构决裂，创立了自己的传统。天台宗自最澄时代以来一直是平安朝廷支持的官方宗派。在藤原氏等强大支持者以及其他重要贵族家族的支持下，它兴盛并成为日本的主要佛教形式。其与平安贵族的关系如此紧密，以至于它几乎成为一种类似于拜占庭皇帝与早期东正教会关系的国教。这里可以画出的另一个平行现象是，天台宗试图通过将其在中国遇到的许多异端佛教传统综合为一种大师解释的方式来塑造其信仰：\n“日本天台宗的第一个特征是倡导一种综合佛教，即所谓的‘一大圆满教’的理想……所有佛陀的教义最终没有矛盾，可以统一为一个综合和完美的系统。”（Hazama，第102页）\n从这个角度来看，接受末法概念的传统拒绝了天台宗的中央权威。Thomas Kasulis写到亲鸾对此的特殊反应：\n“对亲鸾来说，平安世界观的权威机构已经不再相关。在比叡山，天台宗的中心，亲鸾年轻时曾在那里学习和修行，他们全面教授所有形式的知识，无论是显教还是密教。每个僧侣都可以利用各种修行方法，突破魔罗的幻觉军队，直面现实。\n整个企业得到了平安贵族的社会、经济、文化和政治支持。然而，尽管在山上有那么多的见识和实践，镰仓日本在山谷中的世界似乎正在崩溃。政府是军事政变和几十年公开战争的结果；疾病和自然灾害广泛发生；个人为自己的解放而内省，但发现自己被内部冲突分心和困扰，这些冲突与外部世界的情况一样真实和令人沮丧。在这种情况下，圣贤之道，天台（和真言）的承诺，即与现实和自身和谐相处，只会加剧人们对真正发生了什么以及如何应对的不知所措感。这种对世界和自我的深刻不可理解和失控的感觉就是末法意识的本质。”（Kasulis，第20页）\nKasulis所说的末法意识是一种认为现有秩序无法拯救的感觉。除了Kasulis，许多学者还将末法思想的出现与异常数量的饥荒、自然灾害、军事冲突和政治斗争联系起来。然而，有理由相信镰仓时代在这些事件的实际数量上并不与日本历史的其他时代不同，但在宗教思想家感知和解释这些事件的方式上可能存在质的差异。不可否认的是，镰仓时代标志着日本文化和政治中心的巨大转变。这是从京都贵族向镰仓和东部地区的地方武士家族的转变。动荡的政治秩序无疑对天台宗观点和实践的合法性构成了挑战。从这个角度来看，末法意识是一种情感反应，回应了一个结构社会的叙事似乎无法拯救的时代。向过去的激进转变变得必要。\n毫无疑问，在我们自己的时代，我们也生活在同样动荡和过渡的时期。国家权力在全球经济体系面前已经削弱，战争已变成在国际政治边缘运作的分裂组织之间的冲突。公司从民主结构中夺取权力，不再需要在国家层面运作。即使是苹果，这个美国企业精神的象征，也在中国制造其产品，在库比蒂诺设有办公室，并在爱尔兰注册以避美国税率。在我们自己的国家，特朗普总统的政治口号“让美国再次伟大”反映了对事情正在分崩离析并需要拯救的恐惧。数字技术以深刻模棱两可的方式改变了人类互动的基本体验。如果我们接受宗教学者的总体分析，即末法意识在动荡和过渡时期出现，那么东浩纪和大泽作品中所倡导的后现代主义似乎也反映了一种新的末法意识。后现代思想主要围绕真理之死和叙事之死展开，当以这种方式看待时，它似乎相当启示性。这是对工业和国家现代时代成长的回应，转而进入信息时代和新兴全球秩序的动荡模糊中。\n以类似的方式，《黑暗之魂》系列属于这种来自生活在这种变动中的个体的末法意识情感反应的范畴。《黑暗之魂》系列的显著之处在于它在一个西方外壳和西方媒介中传达了一种传统佛教的启示性思维。然而，末法和后现代意识形态之间有一个重要区别：在镰仓时代对末法做出回应的人们是真正有兴趣通过重新概念化指导其信仰的超验价值来追求一个解决方案。对亲鸾来说，或许是最具后现代色彩的末法思想家之一，人们只有通过放弃自己的自主力量并服从于阿弥陀佛愿力的慈爱，才能逃避不可避免的退化。对日莲来说，他的解决方案是崇敬《法华经》并念诵题目。这些本质上是以不可否认的衰退为背景的精神解决方案。相比之下，后现代思想缺乏信仰成分，简化为对以往价值结构的简单否定。这成为其自身倒置的教条；无叙事的教条，无真理的教条。《黑暗之魂》传达了末法的符号学和传统，但它倡导的是一种更符合后现代思想的更为阴暗的观点。没有对抗末法形而上学轨迹的阴暗预后的超验原则。在这方面，《黑暗之魂》是一部充满日本过去，无论是现代还是古代的感性作品，但植根于对日本当今轨迹的阴郁思考。\n第一火焰：欲望之源 通过末法意识和后现代主义的解释框架，我们可以将连接火焰这一核心主题解读为跨代社会叙事的恶化，以及日本本土末世论范式的重构。虽然游戏采用了西方美学，但其设计和美学却充满了佛教形而上学影响下的独特日本感性。西方的外在形式也反映了日本战后社会和现代日本的整体情况。尽管日本国家的形成在很大程度上是由本土精英自主完成的，但毫无疑问，日本的法律、教育、政治甚至文化机构的核心构造是一系列源自19世纪和20世纪欧洲社会的概念嫁接。自1868年成为现代国家以来，日本一直是组合（組み合わせ）的杰出典范，即通过巧妙地组合现有元素创造出新的事物。\n明治政府在构建政府时，既借鉴了德国的法律体系，也吸取了英国的政治经济哲学。二战后，日本战败后麦克阿瑟推动的宪法改革进一步加剧了日本国家的拼凑性质。尽管这部宪法在公众中得到了广泛接受（尽管近来有修改的尝试，但仍在继续维护），但它仍然是少数西方人撰写的外来文件。这份文件构成了战后日本叙事的基础——这个永远和平、永远繁荣、永远服务于全球进步秩序的国家——仍然是日本国家的核心。但这种外来性并没有抹去日本的文化或历史。宪法只是提供了一个框架，真正的核心是数百年积累的文化，这些文化构成了日常生活的基础。现代日本人的生活与西方同行非常相似，但充满了源自悠久历史的感性和行为，这些历史与民主或经济自由主义没有必然联系。如果东浩纪和大泽真幸所描绘的是日本社会叙事的崩塌，那么这种崩塌主要表现为那些从欧洲继承的进步、自由和平等观念的瓦解。如果这些叙事正在衰退，那么这种衰退自然会被表现为一个崩塌的西方王国。这就像日本的西方性如死皮般剥落。如何更好地表现这一点呢？通过一幅充满幽灵和变异尸群的哥特式大教堂画面。\n尽管《黑暗之魂》系列偏重于环境叙事，但并不意味着它完全没有传统的叙事展现。然而，这种展现风格更接近于前现代的神话诗意传统，而非现代的奇幻作品。这两者的区别大致可以概括为理性和直觉原则在叙事中的区别。主要由于J.R.R.托尔金的《魔戒》三部曲的影响，大多数现代奇幻作品试图创造一个全新的世界，这个世界有着完整的虚构历史，充满了虚构的种族、语言，以及一套部分透明的公理来支配作品的内部现实。当一个作品不仅仅是一本书，而是一个跨越多个媒介和数十个单独作品的系列时，这可能会变得相当复杂。通常，这些元虚构信息的主体是以一种可以通过因果关系的理性原则来解释的方式构建和呈现的。这允许粉丝基于系列中的“证据”对他们喜欢的作品进行“理性”论证（历史、社会、物理、生物等）。当创作者创作的新内容不符合先前确立的虚构宇宙公理时，粉丝们甚至会批评他们。例如，在《哈利波特》系列中，咒语只能用魔杖施放。如果在一个《哈利波特》的衍生作品中，一个角色不用魔杖就施放了咒语，这将与先前确立的公理逻辑不一致。为了解决这个矛盾，需要建立一些额外的公理来包含先前的公理（即，这个角色可以不用魔杖施放咒语，因为他们拥有独角兽的血液，这赋予他们对魔法的更深连接）。这些公理不断演变以适应新作品，但也为了在世界构建过程中保持完整性，并避免粉丝的责难。\n相比之下，前现代的神话诗意作品几乎不尝试用理性公理来支撑其虚构现实。它们的功能是象征性或情感性的，而非字面的，因此从现代角度来看，它们似乎充满了矛盾。为什么宙斯可以变成公牛或天鹅？为什么神明可以受伤或被杀害而他们却是神？在传统神话中，发生的事情就是发生了；没有对底层公理的诉求。《黑暗之魂》几乎没有提供理性原则，也几乎没有提供全面的历史，因此其叙事风格更像传统神话。称之为完全相同可能有些牵强，但它顽固拒绝现代奇幻及其庞大元叙事的理性主义是其美学的关键方面。唯一的反驳是电子游戏本身是理性、数学的系统，装饰着叙事。因此，在这种媒介中总是存在一种奇怪的游戏与叙事之间的冲突。《黑暗之魂》通过将其机制概念化为游戏世界困扰的表达来避开这个问题，但保持细节故意模糊，以避免对元虚构进行正式和严格的理解。\n三部游戏的开头都有一个简短的电影，让玩家对他们进入的世界有一个模糊但高度暗示的框架。我们将分别考察每个游戏，作为美学演变的序列，但我们将详细分析第一款游戏，追踪其完整的叙事弧。这是因为对第二和第三款游戏中的选择的理解依赖于第一款游戏中确立的美学原则。在我们开始分析第一款游戏的介绍电影之前，重要的是要注意，尽管《黑暗之魂》是一款日本游戏，但原版中没有日语配音。换句话说，游戏中的英语配音不是本地化的结果，而是开发者为营造某种氛围而做出的美学选择。不懂英语的日本玩家必须依靠字幕来理解游戏中的对话，这强化了沉浸在异域世界中的感觉。还值得一提的是，配音演员都带有英国口音，这反映了奇幻类型跨作品和媒介长期以来的传统。这只是《黑暗之魂》西方外衣总体情感数据库的一个部分。英文音频和日文文本大致相当，但有时在重要方面有所不同。在以下引用中，我将保留原文英文音频：\n古い時代／世界はまだわかたれず、霧に覆われ／灰色の岩と大樹と、朽ちぬ古竜ばかりがあった／だが、いつかはじめての火がおこり／火と共に差异がもたらされた／熱と冷たさと／生と死と／そして光と闇と／そして、闇より生まれた幾匹かが／火に惹かれ、王のソウルを見出した／最初の死者、ニト／イザリスの魔女と、混沌の娘たち／太陽の光の王グウィンと、彼の騎士たち／そして誰もしらぬ小人／それらは王の力を得、古竜に戦いを挑んだ／グウィンの雷が、岩のウロコを貫き／魔女の炎は嵐となり／死の瘴气がニトによって解き放たれた／そしてウロコのない白竜、シースの裏切りにより／遂に古竜は敗れた。／火の時代の始まり／だが、やがて火是将灭，暗闇だけが残る／今や、火はまさに消えかけ／人の世には届かず、夜ばかり続き／人の中に、呪われたダークリングが现れはじめていた\n在古老的时代，世界尚未形成，被雾笼罩／一个灰色岩石、大树和永恒巨龙的土地／但随后有了火焰，随着火焰的出现，差异也随之而来／热与冷／生与死，以及当然，光与暗／然后从黑暗中，他们来了，并在火焰中找到了王之灵魂／最初的死者尼特／伊扎里斯的女巫及其混沌之女们／太阳之光之王格温及其忠实的骑士们／还有那不为人知的矮子／凭借王者的力量，他们向龙发起挑战／格温强大的雷霆撕裂了它们的石鳞／女巫编织了巨大的火焰风暴／尼特释放出死亡和疾病的瘴气／而无鳞白龙席斯背叛了自己的同类，龙族不复存在／于是火焰的时代开始了／但很快火焰将熄灭，只剩下黑暗／即使现在只剩下余烬，人类看不到光，只看到无尽的黑夜／在活人中出现了被诅咒的黑暗印记。是的，的确如此。黑暗印记标记了亡者。在这个土地上，亡者被驱赶到北方，被关在等待世界末日的地方\u0026hellip;（Farz; 视频片段）\n这一简短片段的音乐显然属于恐怖或悬疑范畴。开头是极简主义的；情绪化的弦乐在背景中幽幽作响，竖琴添加了不和谐的点缀，使画面充满了神秘和不安。火焰被描述为生命的起源和现实基本二元性的起源，例如生与死（0:30）。在许多西方神话中，火或光通常用来代表神圣的创造源泉。这在许多现代奇幻作品中也适用，因此“光”在许多文化和神话中都具有强烈的积极意义。然而，这种隐含的情感滤镜将火焰呈现为某种险恶和危险的东西。在观众遇到这火焰之前，镜头将我们带入地球的深处。在那里，火焰像地狱般的舌头在一个巨大的洞穴张开的嘴巴中燃烧。无论是视觉效果还是音乐，都没有什么鼓励我们将火焰视为神圣的生命源泉。它更像是可憎的生命源泉。火焰出现时低音提琴和铜管的引入表明它既可怕又强大（0:50）。整个片段在不和谐程度上接近挽歌风格，特别是弦乐部分。尼特的出现伴随着图瓦喉音歌手的引入，他们在背景中凶恶地低吟，进一步加剧了恐惧感（1:15）。这些图瓦歌手在介绍剩下的三位神祇时继续吟唱：伊扎里斯的女巫，格温大人，以及隐秘的矮子（1:15-1:46）。这些喉音歌手虽然是微妙的补充，但为传统的西方管弦乐增添了“东方”的神秘感，突出了故事中的神秘色彩。\n这种投射在火焰上的恐惧滤镜与佛教形而上学和隐喻语言一致。在巴利语经典中，《火焰经》（Adittapariyana Sutra），也称为《火焰讲经》，使用火焰作为隐喻来代表由欲望引起的苦（dukkha）。传统认为佛陀向火崇拜的苦行者讲授这部经文，以便将他们转化为他的精神实践：\n比丘们，一切皆燃烧。什么在燃烧？比丘们，眼在燃烧，可见形式在燃烧，视觉意识在燃烧，视觉印象在燃烧，任何因视觉印象而产生的感受，愉快的、痛苦的、既不愉快也不痛苦的，都在燃烧。燃烧着什么？燃烧着欲火，燃烧着恨火，燃烧着愚昧火；我说它燃烧着生、老、死，燃烧着悲伤、哀悼、痛苦、忧愁和绝望。（Thanisarro）\n在这段经文中，火与我们对感知的执着所带来的痛苦混为一谈，同时也是现实基本二元性的一个方面，如生/死和快乐/痛苦。这与《黑暗之魂》神话中火作为差异起源的概念相平行。当我们在电影中看到地球深处的翻滚火焰时，它并没有呈现为神圣的创造之光，而是作为混沌的、原始的欲望引擎。从这种角度来看，恐惧的情感滤镜与佛教隐喻语言密切吻合。此外，随着这种火焰的出现，令人恐惧、可怜的僵尸般的剪影从黑暗中浮现。他们愚蠢地摇摇晃晃地走向这火焰，身体姿态笨拙，暗示着粗糙和未形成的心理。他们没有圣经传统中高贵原始人的尊严。这些蹒跚而行的可怜虫将被火焰的力量转变为如格温大人那样的崇高个体，但这种英雄转变有些污秽和怪异。\n格温大人的美学显然让人想起宙斯、奥丁、沃坦或因陀罗般的神祇，因为他是一个统治光明和掌握雷霆的众神之王。然而，我们对他的第一印象却是一个疲惫的老人（1:34）。火焰在他面前燃烧，但他的眼睛浑浊，他的头发狂野、凌乱，看起来像稻草一样干燥，仿佛被长时间暴露在热中所损坏。他似乎没有传统神话中父亲形象的活力或智慧。此外，他身后的骑士军团与典型的西方骑士形象几乎没有共同之处。没有高贵、勇敢或个人英雄主义的符号。这些骑士是无脸、诡异的存在，过于纤细和高挑，具有昆虫般的特质，因为他们的角盔略微让人联想到钳子。他们在一个巨大的洞穴檐下整齐地站成无尽的队列，静如雕像。这些被火焰转化的可怜虫——即被欲望转化的——成为了一个小型的神祇团。\n有一个父神（格温），一个混沌母亲/生育神（伊扎里斯的女巫），和一个冥界神（尼特）。然而，“隐秘的矮子”的存在打破了这个神祇团的连贯性。他被称为这些王者之一，但他却不参与斗争。他那扭曲的小小身影贪婪地蹲在火焰旁边——就像佛教神话中的饿鬼（APPX. 图6）——对这些伟大神祇的阴谋漠不关心，专注于他手中那小小的火焰在他烧焦的手掌间跳动（1:40-1:52）。这一形象进一步加深了火焰吸引可怜生物的嫉妒，即使它对其持有者造成伤害的印象。确实，尽管伊扎里斯的女巫拥有更为尊贵的形象，她的手看起来也像矮子一样烧焦了（1:28）。其他神祇也是如此，每个人都在他们面前握着一团火焰，凝视着它。这是火焰时代的真正起源，那些摇摇晃晃的实体以王者自居的盲目欲望。\n许多西方神话和奇幻的经典特征在这里得到应用，但它们由与火焰相关的恐惧滤镜定义。即使在火焰时代介绍时，这种滤镜也没有消失。我们看到一个美丽的王国，但光是暗红色的，暗示一个已经在黄昏的时代。当与龙族的冲突中使用低音提琴、合唱团和铜管乐器时，表示战争的能量和恐惧，伴随和平王国的音乐则回到了开头部分的悬念和预感模式。总体而言，火焰时代的特点是静止、惰性和预感。这部介绍电影的整体重点不在于世界的起源，而在于其当前的衰退状态及其看似污秽的起源。抛开佛教形而上学，这部介绍电影牢牢确立了系列的末世氛围。亡者的诅咒，通过黑暗印记表现，也与火焰联系在一起：一个环绕空洞深渊的燃烧圆圈。这与早期的原始火焰展示相平行。它也是一个在广阔黑暗中的微弱火焰。通过这个标记，火焰本身与亡者的诅咒联系在一起。在佛教形而上学中，燃烧的欲望火焰引发了黑暗印记，这是驱动轮回的能量。在这一点上，黑暗印记在游戏的符号学与电影中遇到的世界神话概述之间创建了一个有趣的接触点。\n如前所述，那些受到这种诅咒困扰的人无法死亡。如果他们被杀，他们只是转世。连续的转世导致角色“空心化”，意味着他们失去了理智。在游戏中，这是通过视觉表现的。那些变得空心的人变成了可怕的僵尸般的实体，与介绍电影中的蹒跚求火者非常相似。这也符合佛教形而上学，因为逃离无尽的轮回单调是该传统的主要目标。佛教中的最高精神成就是达到涅槃，这也依赖于与火相关的隐喻。这个词的词源字面意思是“熄灭”，就像吹灭蜡烛一样。末法意识叠加在这个概念之上的是人类制度中的某种精神退化，使人们无法熄灭保持他们在越来越堕落的轮回中的欲望之火。人们无法达到涅槃所允许的真正死亡。这与亡者的诅咒类似，通过一个无法熄灭的火圈标志。这让你一次又一次地复活，不论你被亡者、变异体还是统治这个世界的怪物杀死多少次。这个世界的一切都被这个诅咒的影响所驱动。\n这一大约三分钟的序列是玩家用来理解系列第一款游戏前十几个小时的主要叙事框架。比起叙事内容本身，这部简短电影建立的整体基调和氛围简洁地总结了游戏的全部内容。虽然介绍中出现的角色在第二款游戏中不会回归，但他们在第三款游戏中会以一种间接且诱人的方式被提及。因此，这部电影作为魔法循环的温床，当玩家渴望“连点成线”时，这个循环就会出现。下一章将回到现象学角度，讲述这个开场电影如何在玩家的脑海中保留并在完成《黑暗之魂》第一款游戏的大约40小时内发生变化。我们不会以这种方式看待第一或第三款游戏，但会追踪第一款游戏中建立的叙事和游戏主题的发展。这将表明，连接火焰的主要任务是一个无意义的活动，导致“火之时代”越来越堕落的轮回。\n第五章：成为英雄的意义是什么？ 葛温，薪王 终于，在穿过一个充满恶臭的变异食人族棚户区，跋涉过浓密的毒沼，击败一个会喷吐熔岩的半女巫半蜘蛛的恐怖存在之后，我在地下大教堂塔楼的深处找到了钟。一个愤世嫉俗、心碎的骑士告诉我关于这个钟的信息，但没有解释我为何要寻找它。他说几乎不可能找到，还嘲笑了我，但并未说明其用途。此时，我已在游戏中花费了二十小时，找到它几乎是偶然。我一直在这个可怕的荒原中游荡，无数次死亡，但获得了武器，通过吸收强大的灵魂来增强自己的力量。钟旁有一个杠杆，我必须去调查一下。果然，它不仅仅是装饰；当我操作我的角色站在它前面时，屏幕上出现了一个消息框。我可以拉动它，于是我照做了。这个杠杆可拉动这一事实几乎是一种命令。钟声响起，进入了一个过场动画。在远处，一个无脸巨人，身体像被火烧焦了一样斑驳的灰黑色，听到了钟声，拉动了一条巨大的链条。这使得一座似乎建在悬崖侧面的堡垒的大门升起。我不确定这是在哪里发生的，也不明白为什么，但显然世界的一部分对我开放了。我可以继续穿过大教堂，深入被遗忘的深处，但我被一种强烈的欲望所驱使，想回到地表，回到传火祭祀场（火継ぎの祭祀場），这个破碎世界中唯一的避难所。\n回到那里，我注意到有些东西变了。整个神殿的石墙上回荡着一种奇怪的咔哒声。顺着声音，我走到了篝火旁边的破旧礼拜堂般的建筑里。在那里，我发现一个巨大的蛇状生物从深处冒了出来。原本礼拜堂里的石地板现在变成了深渊，这条蛇从这黑暗的空洞中探出头来，身体的其余部分延伸到下面的深处。它全身黑色，眼睛巨大、鼓胀，橙色的眼睛有蛇一样的瞳孔，上唇上挂着奇怪的肉囊，类似胡须。他有一个鹰钩鼻和巨大的牙齿，块状，从血红色的牙龈中凸出，不停地咬合——这是咔哒声的来源。从这个角度看，他几乎像一匹马。他的外表确实非常怪异，但他并不敌对。当我接近这个生物时，出现了一个对话选项。我按下控制器上的X键开始了互动，他用一种完全与外表不符的老者声音说：\nおお、お主か／目覚ましの鐘を鳴らしたのは／わしは世界の蛇、王の探索者フラムト／大王グウィンの親友じゃ／目覚しの鐘を鳴らした、不死人の勇者よ／お主に、不死の使命を伝えたい／よいかな？\n“啊，是你吗？你是那个敲响觉醒之钟的人吗？我是始祖蛇，寻王者弗拉姆特，大王葛温的亲密朋友。敲响觉醒之钟的不死勇者，我想告诉你你的命运。你愿意接受启示吗？”\n我的头有点晕。敲钟的目的是为了见这个奇怪的蛇？我真的要相信他是我在开场动画中看到的那个人的朋友吗？这些钟是某种测试吗？尽管有这些疑问，这却是游戏中很长一段时间以来第一个明确的叙事发展。我很好奇，也没有理由忽略他。我接受了：\nよかろう。ならば伝えよう／不死人の勇者よ／お主の使命は…大王グウィンを継ぐことじゃ／かの王を継ぎ、再び火を熾し、闇をはらい、不死の徴をはらうことじゃ／そのためには、まず王都アノール・ロンドで王の器を手に入れねばならぬ\n“很好。那么我很高兴与你分享。不死勇者。你的命运是…继承大王葛温。为了重新点燃火焰，驱散黑暗，解除不死的诅咒。为此，你必须前往亚诺尔隆德，获得王之器。”\n这是我第一次直接接受一个具体任务的明确指示。没有真正拒绝的理由，从某种意义上说，也无法拒绝。我可以按自己的方式继续探索这个世界，但到了某个时候，我知道我会耗尽探索的地方。毕竟这是一个游戏，它是有限的。只要我有意愿玩这个游戏——这基本上意味着探索更多的世界，收集更多的物品，并通过吸收灵魂来增强力量——最终我会找到他所寻找的这个器皿。在没有其他事情可做的情况下，真的有什么选择吗？\n弗拉姆特建立了一个关于继承和从世界瘟疫中救赎的叙事，但这个叙事本身就非常暧昧。在经过更多艰苦的试炼，前往游戏世界的遥远区域后，我获得了这个形状巨大的圣杯。我再次带着它来到蛇面前，他带我到地底深处的一个房间。他称之为传火祭祀场，并告诉我它是为继承大王葛温的继承者准备的。这个房间只是一个平台，坐落在一对巨大的石门前。他指示我将器皿放在门前，并告诉我作为“王的继承者”的职责。他告诉我，我必须用与葛温的灵魂同等力量的大灵魂填满王器。他列举了这些灵魂：墓王尼特，伊扎里斯的女巫，新伦多的四王，他们继承了葛温的灵魂碎片，以及白龙希斯。除了四王之外，这些“王”都被称为火之时代的英雄和始祖——那个没有不死诅咒的黄金时代。我感觉如果我用这些灵魂填满器皿，门就会打开。我按照他的指示，杀死了尼特，伊扎里斯的女巫和白龙。他们没有向我透露任何信息。当我遇到他们时，他们只是攻击我。最终，在击败新伦多的四王并获得其灵魂后，另一个与弗拉姆特一模一样的蛇出现了，用完全相同的声音提出了一个反提案：\n…ようこそ、不死の勇者よ／我は、世界の蛇、闇撫でのカアス／貴公ら人を導き、真実を伝える者だ／では、我は隠さず真実を語ろう／かつて火のはじまり、貴公ら人の先祖は／古い王たちの後に、四つ目のソウルを見出した／闇のソウルだ／貴公らの人の先祖は、闇のソウルを得て、火の後を待った／やがて火は消え、闇ばかりが残る／さすれば、貴公ら人、闇の時代だ／…だが／王グウィンは、闇を恐れた／火の終わりを恐れ、闇の者たる人を恐れ／人の间から生まれるであろう、闇の王を恐れ／世界の理を恐れた／だから奴は、火を継ぎ、自らの息子たちに、火を率い、縛らせた／貴公ら人が、すべて忘れ、呆け、闇の王が生まれぬように／…我は世界の蛇／正しい時代を、王を探すもの／だがもう一人の蛇、フラムトは、理を忘れ、王グウィンの友に堕した／よいか、不死の勇者よ／我カアスが、貴公に、正しい使命を伝えよう／理に返して火を継ぎ、今や消えかけの王グウィンを杀し／そして、四人目の王となり、闇の时代をもたらすのだ\n“我将毫不留情地分享真相/在火焰的开始，古代王者发现了三种灵魂/但你的祖先发现了第四种独特的灵魂/黑暗灵魂/你的祖先夺取了黑暗灵魂并等待火焰熄灭/很快，火焰消失，只剩下黑暗/于是开始了人类的时代，即黑暗时代/然而…葛温大王在黑暗面前颤抖/他紧紧抓住他的火焰时代，极度恐惧人类/以及将来会在他们中诞生的黑暗王者/葛温大王违背自然法则/通过牺牲自己来延续火焰，并命令他的子女引导人类/葛温模糊了你的过去，以防止黑暗王的诞生/我是始祖蛇/我寻求纠正过去的错误，发现我们真正的王/但另一条蛇弗拉姆特失去了理智，成为了葛温大王的朋友/不死的勇者，我们站在十字路口/只有我知道你的命运真相/你必须摧毁那正在消逝的葛温大王，他依附于火焰，违抗自然/并成为第四位王者，从而开启黑暗时代！”\n卡斯提供的关于这个世界的历史和形而上学基础的简略草图并不清楚。人类时代是黑暗时代？当他说我的祖先时，他指的是开场动画中的那个不起眼的小矮人吗？小矮人是“人类”，而其他人不是吗？“黑暗灵魂”究竟是什么？这些任务发布者，弗拉姆特和卡斯，他们的外表怪异而阴险，似乎有着完全不透明的动机。重新链接火焰——就像寻王者弗拉姆特希望的那样——以迎来没有不死者的另一个火焰时代，这难道不是一件好事吗？从幻想题材的普遍惯例来看，黑暗时代似乎是需要避免的东西。任何倡导黑暗时代的人，肯定是“坏人”，但我对这个世界以及发生了什么和当前正在发生的事情了解太少。这不是有可能吗？卡斯所说的是真的？葛温，紧紧抓住火焰，拒绝了世界的自然循环，带来了一场灾难？在游戏的上下文中，无法最终验证他的陈述是否真实。无论我相信哪条蛇，我的任务实际路径似乎都没有改变。此时，这只是我个人的解释问题。我已经用必要的灵魂填满了王器，我打算打开通往传火祭祀场的门。这是游戏的逻辑。这也是探索的逻辑。我只是必须知道一旦我执行这些任务会发生什么。我想看看游戏会向我揭示什么。\n我回到传火祭祀场，将最后一个大灵魂释放到王器中，厚重的石门在我面前打开，露出一个纯白的空洞，中间有一个墨黑的斑点。这似乎是一条通道。走过白色空洞，朝着黑色斑点走去，鬼魅般的白色骑士在我面前行进并消失。它们是某些过去事件的残影吗？空洞让位于一个巨大的塔楼的痛苦景象，在昏暗而病态的黄色天空中耸立。我无法确定这是晨光还是余晖。感觉就像我进入了一个停滞的状态。当我走过一些烧焦的柱子时，游戏提示我进入了“The Kiln of the First Flame”（最初的火的炉）。地板完全覆盖着灰白的灰烬，就像在沙丘中行走。有某种爆炸吗？\n在与穿着黑色盔甲的骑士战斗后（它是黑色的因为它像其他一切一样被烧焦了吗？），我在一个充满灰烬和中央有一个闪烁篝火的房间里与葛温大王对峙。然而，当我与他对峙时，他有些不对劲。在开场动画中，他似乎是父神的典型形象，但现在他看起来像个畸形的怪物。他已经空洞了。挥舞着一把燃烧的剑，他的眼睛是黑洞，肉体像木炭一样烧黑了。他一直在这里，守护着世界的最后一块燃烧的余烬，紧紧抓住火焰时代的遗迹。然而，这让他变成了一个无意识的怪物。他的头衔也变了。当我进入房间并看到他的生命条出现在屏幕底部，象征着另一个Boss战时，他的名字变成了薪の王（Lord of Cinder）。看来他作为太阳神的显赫地位已经沦为仅仅是一个燃烧的余烬。薪的意思是什么？我应该把它理解为火种吗？这就是寻王者弗拉姆特所说的继承葛温的意思吗？我必须杀死这个国王，继承他的称号，成为薪之王吗？我将自己变成火种来燃烧这个破碎的世界吗？这个国王的意义，他的意图，以及我在做什么都非常不清楚。\n然而，清晰的是一种悲剧感。与其他二十五个Boss战的音乐通常是轰鸣、黑暗和充满活力的，象征着挑战的严峻、恐怖和刺激不同，这段音乐孤独而悲伤。一架孤独的钢琴在小调中演奏着悲伤的曲调，我与这位曾经伟大的王者的疯狂躯壳搏斗。这种感觉奇异地感人但也神秘。音乐似乎暗示着这种冲突是不可避免的，是一种悲剧。但这是为什么呢？我不是来驱散黑暗并复兴火焰时代的吗？它似乎暗示所有自称为王者和王国保护者的命运是多么可悲。\n在我击败葛温大王后，我走到炉的中央，那里有篝火。当你接近时，会出现一个消息框，允许你按控制器上的X键在世界中启动一个动作。但这次出现的不是通常我接近未点燃的篝火时出现的消息（篝火を灯す），而是一个新选项：火を継ぐ。在这个时候，我可以链接火焰，接着又开始了一个过场动画。我的角色伸手进入火焰，火焰慢慢蔓延到他们的身体，吞噬他们并蔓延到整个炉子，然后爆发成一片火海。竖琴开始演奏，一个孤独的女人的声音开始唱歌，字幕开始滚动。大概这意味着一个新的火焰时代已经开始，但在此之后没有进一步的叙述或图像播放。音乐并没有暗示或确认任何胜利的感觉，而是更多的悲伤和神秘，仿佛整个40小时的游戏过程只是一个很久以前的神话的演绎。\n在玩家击败葛温之后，游戏还提供了另一个选择。这完全不明显，但我偶然从观看其他玩家的视频中了解到。如果玩家从炉中徘徊并返回传火祭祀场，会开始另一个过场动画，弗拉姆特和卡斯与众多其他蛇一起出现，宣告玩家的角色为新黑暗之王。他们从一开始就串通好了吗？如果是这样，为什么？为什么一条蛇敦促我链接火焰，而另一条蛇试图劝阻我，如果最后他们都在玩家角色面前一起鞠躬？没有答案，任何选择的意义都非常模糊。链接火焰是忠于大多数RPG试图模拟的典型英雄身份。然而，蛇形任务发布者的缺乏答案、氛围和模棱两可的动机与我拯救王国的感觉相悖。如果有的话，感觉我被操纵成了一个牺牲的羔羊，一个火种之王。\n在随后的两款游戏中，链接火焰的主题最终将被揭示为不那么英雄的，但这无法从第一款游戏中具体看出。这只是通过游戏世界的符号学和游戏行为所感受到的。要汲取的主要思想是，葛温紧紧抓住生命之火，拒绝让它熄灭，并沦为一个无意识、不死的怪物。在佛教的隐喻语言中，必须放弃燃烧的欲望之火，以逃离无尽轮回的痛苦。无尽地活着就是在轮回的业火中燃烧和燃烧。\n名为“自我”的炙热余烬 我们不会深入探讨第二款游戏，但简要回顾一下“连接火焰”这一主题的发展还是值得的。第一款游戏中的所有概念主题在这里也都存在：有一个不死的诅咒，一个象征它的黑暗标志，篝火，一个获取强大灵魂的命令，连接火焰并接替早已成灰的国王，但仅此而已。这是一个新的王国，带有新的谜团。在这款游戏中，玩家必须坐在一个被称为“渴望王座”（渇望の玉座）的王座上来连接火焰，而这个王座无疑是一个巨大的窑炉，这与第一款游戏有着间接的联系。这种连接火焰和坐在渴望王座之间的直接联系，使火焰作为佛教欲望隐喻的关系更加具体化，这种欲望引发了苦难并推动了轮回的循环。它还表明了欲望如何赋予生命以动力。与第一款游戏不同的是，玩家没有选择是否坐在王座上的权利。一旦击败最终Boss，一段旁白会开始，角色的化身坐在王座上，窑炉的门将角色封闭在内：\n火を継ぐ者、呪いをその身に引き受ける者…／貴方が火を継げば、再びソウルは育ち、同じことが繰り返される／それを望むも、拒むも…貴方が決めることです／王たるものよ、王座へ／その先は、貴方にしか見えないのです “你，连接火焰的你，你，承受诅咒的你…/一旦火焰被连接，灵魂将重新繁荣，这一切将再次上演/这是你选择接受或拒绝的事情/伟大的君主，请坐上你的王座/前方的道路只有你能看见。”\n到第二款游戏结束时，我们完全无法感觉到第一款游戏的事件是否与其续集有任何联系，但叙述者的讲述清楚地表明，“连接火焰”只是循环的一部分。值得注意的是，游戏的创意控制从FromSoftware的首席设计师宫崎英高（Hidetaka Miyazaki）转移到了年轻的下属Tomohiro Shibuya。因此，游戏在基调和风格上有许多有趣的变化也就不足为奇了。这种差异在第三款游戏中最为明显，因为导演控制权又回到了宫崎英高，第一款游戏的联系也更加明显。无论如何，在接受日本著名游戏出版物Famitsu采访时，Shibuya表示，第二款游戏确实与第一款游戏有联系，但在叙事上并不完全如此：\n“我不能完全回答这个问题，但两个设定确实是有联系的，”他说。“然而，就故事而言，我不会说有直接的联系。游戏设定在同一个星球的不同部分——换句话说，如果第一款游戏设定在北极，这款游戏就设定在南极；是那种对比。‘时间’是我们在创作时牢记的一个核心关键词。我现在不能给出具体细节，所以希望你能用你的想象力来理解。”\nShibuya对时间的强调在游戏中通过一个流浪的魔法师Straid of Olaphis的角色得到了呼应，他通过出售魔法来帮助你：\nこの地には、かの国以前にも／多くの国が存在しておったらしい／国は栄え、しかしいずれ衰えていく／あたかも火の燃えあがり、消えるが如く／繰り返し繰り返し／しかしのォ、消えかけた火はやがて蘇るのよ／そして再び国が栄える、その姿を変えながら全ては呪いよ！／ヒェヒェヒェ！／オヌシの如き呪われ人こそが、火を引き受けるのよ ヒェヒェヒェ… “在这个地方，在那个国家之前，/有许多国家曾经存在/国家繁荣，但终将衰落/就像火焰燃烧，最终熄灭/一遍又一遍/但消逝的火焰最终会复活/然后新的国家会再度繁荣，换上新的面貌/这一切都是诅咒！嘿嘿嘿！/像你这样的被诅咒之人，将承受火焰。嘿嘿嘿…”\n这种长时间周期的主题，王国在不同形式中兴衰，与佛教的末世观美学相比基督教的末世观更为相符。在基督教的末世中，耶稣会回来进行最后的审判，将人类带入永恒的天堂。这里的重点是永恒和对世间问题的最终解决。在高度异质的佛教传统中，类似的叙事也存在，但它们总是基于劫（kalpic cycles）的理念，即整个现实旋转的千禧年的缓慢转变。\n除了欲望和时间，游戏还更强调了空虚过程。这在角色Lucatiel of Mirrah身上得到了最清楚的体现。Lucatiel是一个你遇到的流浪骑士，她会偶尔在你的任务中帮助你。随着你的进展，你会在世界的不同地点遇到她，但在每次相遇中，她都会因不死的诅咒而失去更多的记忆。这让她感到恐惧，她最终向你坦白：\n私は、失うことを恐れている／記憶を、私自身を／もし、お前を殺せば／この呪いが解けると言われたら…／私はためらうことなく、剣を抜くのだろう／私は、生き続けたい 私であり続けたいのだ／そのためなら…何を犠牲にしても…／何と醜く、浅ましいことか… “失去让我无比恐惧。失去记忆，失去自我。/如果有人告诉我，杀了你就能解除这个诅咒…/我会毫不犹豫地拔剑。/我不想死，我想存在。/为了这一点，我愿意牺牲任何东西，任何东西。/这让我感到羞耻，但这是事实。有时，我觉得自己沉迷于这个叫做‘自我’的小东西。/但即便如此，我还是迫切想要保护它。/我这样感觉错了吗？如果你是我，你也会这样做吧？也许我们从出生起就被诅咒了。”\n最终，接近游戏末尾时，Lucatiel变得空虚并会攻击玩家的化身。Lucatiel的感受和不死诅咒可以与佛教的无我（Anatta）教义联系起来。这一理念是构成佛教实践的主要形而上学原则之一。该术语指的是人类内部没有构成自我的永久的、根本的物质。对这一教义的确切解释在各宗派、神学家和学者之间存在争议，但这一理念在佛教传统中的核心地位相当于苦（dukkha）和无常（anicca）。总的来说，无我教义断言构成“自我”的只是意识中的现象流，这只是自我的错觉。对这种所谓的“自我”的执着是一种主要的苦难来源，因此是宗教实践中需要克服的主要障碍之一。作为一个角色，Lucatiel体现了当我们拼命抓住我们的存在，抓住所谓的“自我”时产生的痛苦。这赋予黑暗标志之火一种略有不同的意义。它标志着玩家的化身被困在轮回的循环中，永无止境地燃烧。\n薪王，火之继承者 虽然整个《黑暗之魂》系列贯穿着许多佛教主题，但在第三部游戏的结尾，末法的联系变得尤为明显。在第三部游戏中，系列核心概念中的隐喻成熟并凝聚成一种对旧制度无效努力的毁灭性批判。这不仅体现了佛教末法的思想，还展示了一种荒凉的后现代视角，揭示了旨在推动世界前进的传统和循环。在第三部游戏中，末法意识与后现代主义相融合，形成了一种双重视角。相应地，第三部游戏的开场动画比第一部更加末日化：\nそうさね、そこはロスリック／火を継いだ、薪の王たちの故郷が、流れ着く場所さね／だから巡礼者たちは北に向かい／そして、予言の意味を知るのさ／「火は陰り」／「王たちに玉座なし」／継ぎ火が絶えるとき、鐘が響き渡り／古い薪の王たちが、棺より呼び起こされるだろう／深みの聖者、エルドリッチ／ファランの不死队、深淵の监视者たち／そして、罪の都の孤独な王／巨人のヨーム／けれどね／きっと王たちは、玉座を捨てるだろう／そして、火の无き灰たちがやってくる／名もなく、薪にもなれなんだ、呪われた不死／けれど、だからこそ／灰はのこり火を求めるのさね\n\u0026ldquo;Yes, indeed / It is called Lothric / where the transitory lands of the Lords of Cinder converge / In venturing north, the pilgrims discovered the truth of the old words: / \u0026lsquo;The fire fades and the lords go without thrones\u0026rsquo; / When the link of the fire is threatened, the bell tolls / unearthing the old Lords of Cinders from their graves\u0026hellip;Aldrich, Saint of the Deep / Farron\u0026rsquo;s Undead Legion the Abyss Watchers / The reclusive lord of the Profaned Capital, Yhorm the Giant / Only, in truth / the Lords will abandon their thrones / And the Unkindled will rise / Nameless, accursed Undead, unfit even to be cinder / And so it is, that ash seeketh embers.\u0026rdquo;\n与第一部游戏不同，这里没有起源故事，没有时间黎明时的原始场景，没有新旧神之间的战斗，只有一个正在沉入沙土中的破败王国。可怕的“朝圣者”背上绑着巨石，倒在沙地里死去，这里的神已经耗尽腐化，被钟声重新唤醒为薪之王。父神完全缺席，但他在上一部游戏中的头衔依然存在。正如葛温大人在最终BOSS战中被称为薪之王，现在这个称号变成了复数形式。几个王被点名，这也起到了预示作用。这些是需要被打败的敌人，他们拥有巨大的灵魂，将被用来重新点燃火焰。确实，当你击败这些命名实体时，不再像第一部游戏那样在屏幕上出现“YOU DEFEATED”（你打败了）字样，而是在打败一个次要BOSS时会出现“HEIR OF FIRE DESTROYED”（火的继承者被摧毁），最终击败这些命名实体时，则会出现“LORD OF CINDER FALLEN”（薪之王陨落）。\n在第一部游戏中，当玩家第一次遇到葛温大人时，他的生命条上方出现的名字在英文本地化中被称为薪之王，而在日文原版中为薪の王。这里有一个概念问题需要解决，因为游戏将日文术语“takigi”与英文术语“cinder”联系起来，虽然这些术语相关，但它们在重要方面有所不同，复杂了点燃火焰的隐喻。很容易将这一差异视为英文本地化团队对细微差别的草率忽略，但第三部游戏将这一差异加以规范。开场动画中的英文配音和击败BOSS后出现的新信息是游戏日文原版的一部分，因此必须将“cinder”和“takigi”两个词一起解释。\n“Cinder”可以科学地指火山岩，或者在更松散的意义上指炭或煤的余烬。在游戏背景下，“cinder”显然是指后者，因为它支持“点燃火焰”这一核心隐喻。当火焰熄灭时，木炭余烬仍在白灰下燃烧。可以通过揭开这些余烬并在其上放置新的引火物来重新点燃火焰。余烬在火熄灭后可以长时间保持燃烧，并已知会引发森林火灾和其他事故。当我们将其与第一部游戏的事件联系起来时，“cinder”这一隐喻似乎有非常明确的关联。在第一部游戏中，作为“被选中的不死者”，你的任务是找到死去世界灰烬下仍在发光的余烬（四个伟大的灵魂），并用它们重新点燃世界的火焰。另一方面，“takigi”意为火焰的燃料，但特指通过窑炉加工成木炭的木材。\n在这里也许可以找到与日本自身对木炭依赖的历史共鸣。木炭作为燃料的依赖是日本前现代历史上砍伐森林的主要原因。在江户时期，木材的过度依赖达到了危机点，最终导致严重的经济和政治问题。这促使幕府制定了复杂的林业政策和新的造林技术。木炭作为燃料是前现代日本社会的一个重要组成部分，因为它燃烧得更有效率，更容易控制，并且产生更高温的火焰。要制作木炭，必须将木材放在窑中，通过燃烧普通木材来加热窑。这意味着用来制作这种燃料的普通木材消耗成倍增加。木炭的巨大效用是可以获得的回报，因为未经处理的木材燃烧温度不足以冶炼钢铁或其他重要金属。例如，制造东大寺大佛像需要16.3万立方英尺的木炭。因此，木炭的生产具有重要的文明意义。然而，文明越发展，这种生产越无法维持。最终，它会留下荒芜的废地，短缺会给依赖这种燃料的社会带来严重问题。聚集燃料以保持我们这个时代的火焰愈加明亮会耗尽世界的活力，导致灾难的观点在《黑暗之魂》中显然存在。这与我们自己的时代密切相关。这种叙述在当代环境问题（如全球变暖或石油峰值）中很常见，也带有末日色彩。在日本的情况下，能源消耗的双刃性质在福岛事件后关于核能的左右翼激烈辩论中有所体现。\n第二个赋予“takigi”这个术语特殊意义的观点是，为使其成为燃料，必须通过火进行处理。每个游戏就像一个过程，玩家的化身像木炭一样被准备好，通过玩家必须面对的考验，以及点燃人类心灵的欲望之火的过程。从叙述角度看（即你的角色作为“被诅咒的不死者”渴望灵魂），也是如此，从游戏设计的角度看也是如此。实际上，为使游戏作为作品取得成功，它必须通过设计成功激发玩家继续玩的欲望之火。\n只有通过不断发展玩家化身的内在火焰，化身才准备好用作新时代的燃料。将“takigi”解读为余烬，即隐藏在死去时代灰烬下的热余烬，以及经过特殊处理以为新时代创造更强大火焰的木炭，对玩家在整个系列中的行为提供了一种有趣的解释。在每个游戏中，玩家的任务是通过收集隐藏在死去世界灰烬下的余烬（腐化的旧王灵魂），用自己作为特别准备的燃料重新点燃世界。\n在第一部游戏中，我们首次见到葛温大人时，他被介绍为“太阳的王”（太陽の王），但在我们遇到他那令人厌恶的空心状态时，他的头衔已变为薪之王（薪の王）。作为火焰时代的主要创始人，很容易将他代表为火焰的余烬，过去的影子，必须被利用来重新点燃世界。然而，我们也可以将他不愿放弃火焰以及他在巨大窑炉中的长期隔离，视为一种自我枯竭。他的存在在几个世纪里在窑中被准备好，作为新火的催化剂。蛇要求你继承他的王位，如果你这样做，那正是发生的事情。\n你的考验使你准备好作为木炭，作为你收集的所有引火物的催化剂，即你积累的所有灵魂。然而，准备木炭总是意味着为更强大的火焰牺牲大量材料。当我们将“takigi”一词的双重含义解读为余烬（过去）/木炭（未来）时，就出现了一个循环，但这是一个回报递减的循环。每次重新链接火焰都会消耗越来越少的资源，因此每次王国的转世（新名字和新王）都只是一个退化的复制品。如果在第一和第二部游戏中这只是暗示，那么在第三部游戏中这被巩固了。也许第一部游戏仍然可以按照传统西方神话来解读，即通过新的血液复兴旧制度。然而，第三部游戏的结局只能通过东浩纪的后现代主义和末法来理解，即不断减少的循环。\n这种对游戏的解读在我们比较第一部游戏与第三部游戏的最终BOSS战时更加复杂。一旦玩家收集了所有薪之王的头颅并将其放在他们的宝座上，又一个通往最初的火之炉（最初の火の炉）的路径打开了。这是第一部游戏中与葛温对峙的地方，但这个区域看起来更像是千百个过去时代的噩梦废墟，而不是巨大的窑炉。在高高的天空中，一个燃烧的圆圈框住了黑暗的深渊，像是一个地狱般的日食。它向地平线以外的某个地方倾泻下火流。你周围是巨大的城堡，堆积在一起，形成一个庞大的破碎堆，螺旋状地高耸入云。它们似乎是所有前世“王国”化身的废墟：Lothric、Londor、Drangleic，以及无数无名的时代。然而，这次炉中等待的是谁？不像你击败的那些王，它没有名字，只是“薪之王的化身”（王たちの化身）。这里的本地化实际上是与日文原版有很大不同。更合适的翻译应该是“诸王的化身”或“国王的化身”。“化身”一词（keshin）一般意为化身，但在日本佛教传统中也特指佛陀的化现。\n最后的BOSS战与玩家在这个世界中创造的化身并无不同。它也是一个与世界没有任何有意义关系的化身，只是某种外在意志的载体。它只是那些连接和重新连接火焰以维持时代衰退火焰的所有英雄的象征，但却是一个没有实质的怪物。它只是一个空的盔甲，一个连接火焰仪式的傀儡。这通过它拥有的能力和攻击模式得到了加强。游戏中的其他BOSS完全不同于玩家角色。它们的力量、能力和美学完全不同，但诸王的化身使用的技术和能力模仿你的。它的攻击模式反映了玩家在游戏中发展角色时可以采取的不同路径：巫师、敏捷的盗贼、坚定的骑士、混乱的火焰法师等。从这个意义上说，它是“迷宫讽刺”的终极体现，因为它将所有未走的路径、所有可能成为英雄的路径混杂成一个空洞的怪物。\n当这个无面实体、牺牲的英雄的集合体被击败时，你可以像过去的游戏一样选择连接火焰。第一部游戏只有两个不同的结局，现在有四个，每个结局比上一个更加末日。这里没有“好”结局。第一个结局是玩家按照指示连接火焰。就像第一部游戏一样，玩家的化身伸手进入篝火，他的手点燃了。但这次火焰没有蔓延到他的全身，导致一场巨大的火灾，而只是包裹在化身上，像死灰中的余烬一样微弱地闪烁。似乎每次重新链接火焰都会产生越来越弱的火焰，在这一系列的最终篇章中，仪式本身似乎无效。当火焰包裹住玩家的化身时，他沮丧地坐在篝火旁休息。这个火焰甚至没有力量消耗链接它的人。这个结局明显与第一部游戏中看似英雄的“好”结局形成鲜明对比，巩固了游戏与末法意识的联系。这个时代已经太过退化，无法让这个英雄仪式有任何目的或意义。在第三部游戏中，我们已经远远超过了像法（外表的时代），因为仪式甚至看起来都不像。\n其他三个结局在本质上没有不同。在第二个结局中，玩家可以召唤开火者（firekeeper）——在游戏开始时遇到的角色——到火炉中，让她熄灭火焰。在第三个结局中，通过某种晦涩难懂的仪式，玩家将这个黄昏时代固定下来，成为不死之王。这个结局特别难以达成，因为它要求你完成一系列复杂的秘密任务，几乎不可能在没有借助互联网的情况下自己发现。第四个结局特别神秘。它开始时与第二个结局一样，但当开火者去熄灭火焰时，你可以击打她。如果你这样做，一段过场动画会开始，角色的化身将开火者击倒在地，把脚放在她的头上，从她的手中取出燃烧的余烬。当这一切发生时，一直在三部游戏开场动画中担任旁白的老妇人说道：\n名も無く、薪にもなれなんだ、呪われた不死／けれど、だからこそ／灰は残り火を求めるのさね。 \u0026ldquo;名不见经传的被诅咒的不死者，不配称为薪／因此灰烬才会寻求火星\u0026rdquo;\n这句话重复了开场的一句话，其中角色被称为不配称为薪的被诅咒的不死者。这也反映了游戏核心主题的进一步退化，因为你在第一部游戏中被称为“被选中的不死者”。在这种不可理喻的残忍行为之后，你的化身将偷来的余烬举向倾泻的火流，仿佛在献祭。旁白的言辞似乎在暗示，正是因为玩家角色作为“灰烬”的不配，才使他们渴望“火星”。\n正如这一媒介和系列创作者的本性，没有一个结局是标准结局。这与游戏中的后现代意识相吻合，或许也适用于游戏中的普遍情况，因为多结局是这一媒介的常态。最终分析中，无法从游戏本身的背景中得出具体的叙述解释。每个结局都只是暗示性的，而不是决定性的。它的意义几乎完全取决于我们对其少量具体文本元素及其情感特征的感知：它的外观、声音、感觉等。第四个结局中化身对开火者的残忍行为意味着什么？并不清楚。通过手势和整体语气显然表明这些角色之间正在发生某种侵犯行为。在四个结局中，你的重连火焰之旅和消除不死诅咒的目标没有一个结局暗示这一目标已经实现。也许这个游戏世界最具后现代特色的就是这些“选择”及其完全不透明的意义。当然，无法选择任何一个结局作为标准结局，即使我们能做到，其意义也是不可解读的。这个系列唯一具体的方面是一系列情感特征、主题和游戏设计元素，使其可识别为一个系列。这个星座指向未来的无望、过去的罪恶和生活在现在的痛苦。出现的模式是，旨在复兴世界的英雄仪式被揭示为不过是一个空洞的循环，绝望的灵魂紧握着即将熄灭的余烬，进一步混淆了现实的结构。赋予这一仪式最初意义的宏大叙述是如此模糊，以至于已无法被察觉。\n结论：黑暗之魂与后现代意识 在这篇文章中，我论证了《黑暗之魂》系列，特别是第三部作品，是当代日本社会后现代意识的文化反映。大泽和东浩纪等思想家提出的后现代反叙事、极右翼意识形态的复兴（“日本的重振”），以及极端社会退隐现象（“蛰居族”和“草食男子”）等现象，都反映了一种由内部恐怖活动（如奥姆真理教）、出生率下降、福利系统恶化以及基础设施不稳定（如神户、福岛）引发的深层次焦虑。当我们所依赖的基础，无论是物质上的还是社会上的，似乎有消失的风险时，这种后现代意识便会产生。《黑暗之魂》系列也是这种焦虑的体现，它可能是当代焦虑最有力的文化表达。它的巨大成功和作为有史以来最伟大游戏系列之一的地位，尽管其不遵循行业最佳实践，似乎表明其美学和设计触动了众多游戏玩家的共同感受。\n那么，我们如何总结日本的后现代意识，这在许多方面似乎是正在整个后工业化西方蔓延的一种意识？可以说，后现代意识只是一种悲观情绪。这种情绪让人感觉我们的抱负将毫无意义，现代化的项目已经失败，个人采取有意义步骤去实现理想的观念，更不用说整个人类，是一个悲哀的笑话。这是对当代生活在某种程度上不如过去，甚至可能很可悲的恐惧。事实上，社会在某处进步的观念现在被视为一种极不时尚的想法。批判现代化抱负为危险的天真，已经成为几乎所有哲学或文学批评的固定部分。除了努力支持我的解释外，我还希望——即使只是初步地——表明后现代意识本身也是循环的。它只是社会在向陌生的新时期过渡时表现出的不稳定症状。这种悲观情绪，或者说是世界末日的情绪，就像当新社会组织模式在旧秩序下挣扎着出现时的成长痛苦。然而，我还想指出，我所标记为后现代意识的这种悲观情绪，仅仅是一种情绪。它的现实取决于我们在多大程度上愿意沉溺于它。\n有鉴于此，我认真对待大泽和东浩纪对当今日本社会心理或精神问题的诊断。无论现实如何，人们的感觉都能驱使他们走向自毁行为。这对整个社会来说可能会有非常严重的后果，即使这种想法仅仅被少数人接受。奥姆真理教的行动是由一个小团体实施的，但它们仍然设法在日本社会的核心造成了损害。然而，我拒绝后现代的预后——特别是东浩纪的预后——认为流行文化中传统叙事的转变是人们普遍放弃理想的证据，我们注定要退缩到技术享乐主义中，所有人都成为自己癖好的奴隶。\n这只是某些人正在走的一条道路，甚至这一点也是有争议的。与漫画和轻小说等其他流行媒介相比，电子游戏的核心在于要求解决一系列问题。无论这种需求与日常生活多么人为和遥远，它依然是愿意经历困难并克服挑战的表现。在一个极其基本的层面上，愿意经历困难去解决特定问题或克服特定挑战，支撑着所有人类的努力。叙述中的绝望与完成游戏所需的耐心和技巧之间，有一种奇怪的脱节。\n在电子游戏中，《黑暗之魂》系列代表了一组特别具有挑战性的问题。它提出了一个问题：如果没有对你努力的确认，为什么要经历这样一系列艰难的挑战？答案只能是过程本身是值得的，游戏本身的行为是其精神上的滋养来源。然而，玩游戏比单纯地享受乐趣要复杂得多。正如 Aarseth 等人指出的，ergos，也就是说“工作”，是电子游戏媒介的本质。《黑暗之魂》当然是一款将 ergos 和 ludos 紧密结合在一起的游戏。当然，人们玩《黑暗之魂》不是为了工作，以谋生（除了一些创业的 YouTuber）。然而，说玩《黑暗之魂》只是为了乐趣，这抹去了关于游戏体验的某些绝对关键的东西。《黑暗之魂》中所谓的“乐趣”是那种与爬山、跑马拉松或任何需要长时间持续努力的活动联系在一起的：痛苦、困难，只在结束时短暂满足，然后人们又心甘情愿地回到同样的挑战中。我们不称这些活动为乐趣，而是说它们令人满意，这正是克服《黑暗之魂》中的挑战的感觉。\n社会学家 Roger Caillois 认为，游戏是培养文化反射和习惯的熔炉。如果是这样的话，玩像《黑暗之魂》这样的游戏会培养出什么样的文化反射呢？这个问题的答案可能超出了本文的范围，但可以肯定的是，《黑暗之魂》鼓励我们接受挑战，以便我们可以获得与地狱般的壮丽景象同样令人惊叹的回报。这可能是推动玩家前进的最重要的回报：获得某种美丽景象的回报。尽管其黑暗和怪诞，每一部《黑暗之魂》系列作品在视觉呈现上都独具美感。\n《黑暗之魂》是一款极其复杂和综合性的游戏，它汲取了日本的现在和过去，但这一切都是为了表达对当人们开始质疑支撑其社会的主要观念时，自我实现、进步和社区可能性的深切焦虑。游戏玩法、叙事和美学的复杂交织共同形成了一种强烈的后现代意识表达，在这种意识中，角色在一个衰败的世界里独自面对充满敌意的他者，处于一个他们无法理解的情境中。游戏中包含的佛教形而上学进一步暗示，通过进行祭祀和复兴的仪式来纠正这种情况的追求，最终是毫无意义甚至腐败的。在这层意义上，《黑暗之魂》直接触及了后现代主义的巨大恐惧：无论我们如何努力避免湮灭，最终，这可能超出了我们的掌控。\n然而，游戏中也反映出一种尼采式的自我超越承诺——通过激烈的斗争实现自我超越。我认真对待后现代的诊断，即传统社会叙事的恶化造成了令人不安的自毁行为模式，但我不同意他们的预后。我也不同意他们关于历史独特性甚至传统信仰、信条和叙事不能更新或演变以满足文化需求的说法。我认为日本以前也经历过这样的情况。后现代意识可能只是一种精神压力——尽管是严重的——人们在社会经历重大结构转变和旧结构的叙事失去连贯性时经历的。它注定会在新的形式定型时循环回到一种乐观的情绪中。事物很少长时间保持不变——无论好坏——事实上，无论我们身处何地，没有人真正知道接下来会发生什么。这就是未来的运作方式。它是未知的，只有意识形态的教条主义才试图将其固定在某个位置，不变得像过去一样。我们必须有勇气对接下来发生的事情保持开放态度。\n夏目漱石。日本近代文学巨匠，被誉为“日本现代文学之父”，其作品探讨了人与社会、个人内心世界等深刻主题，代表作有《我是猫》、《心》、《明暗》等。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n三岛由纪夫。日本著名作家、剧作家和政治活动家，以其充满美学与哲学思考的作品著称，代表作有《金阁寺》、《春雪》、《海与毒药》等。他的作品往往探讨人性、荣誉、死亡等主题。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n或翻译成“新的媒介在大学里常常遇到困难，因为每一种媒介都必须通过那些把关“高雅文化”的权威人士的审查。”\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n沟口健二（1898-1956）是日本著名电影导演，以精湛的拍摄技巧和深刻的社会洞察力闻名。其代表作包括《雨月物语》和《山椒大夫》，他擅长于通过细腻的叙事手法展现人性的复杂。沟口被视为日本电影史上的大师之一，对后世电影影响深远。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n指代一种源自捷克作家弗朗茨·卡夫卡（Franz Kafka）作品风格的情境，通常描述一种充满荒诞、绝望和无助感的氛围。在这种情境中，个体往往陷入与无情且不可理解的官僚体系或命运的斗争中，感受到无力改变自身处境的痛苦和迷茫感。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n大泽真幸 Masachi Ōsawa（1958-）是日本当代著名的社会学家、哲学家和评论家，专注于社会理论、文化批评和历史哲学。研究焦点包括现代日本社会的结构性问题及后现代思想在日本的应用。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n东浩纪 Hiroki Azuma（1971-），日本文化评论家和哲学家，专注于后现代主义、信息社会理论及日本流行文化的研究。他的代表作《动物化的后现代》探讨了当代日本动漫、游戏等亚文化现象，并提出了“数据库消费”等独特概念。东浩纪在日本思想界和文化评论领域具有重要影响力，尤其在分析现代社会和文化变化方面贡献卓著。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n田中真纪子（Makiko Tanaka），日本文学学者，研究方向包括现代日本文学及文化，她的研究涉及后现代思想对日本文学的影响。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n村上春树（Murakami Haruki）是日本著名小说家，以其独特的风格和对梦幻与现实交织的描绘而闻名。他的代表作包括《挪威的森林》、《海边的卡夫卡》和《1Q84》，这些作品探讨了孤独、爱情、以及人类存在的意义。村上春树的作品广受国际读者喜爱，并对全球文学产生了深远影响。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n弗朗索瓦·利奥塔 Francois Lyotard（1924-1998），法国哲学家，以其对后现代主义的研究著称。他在1979年出版的《后现代状况》一书中首次提出了“后现代”一词，主张大叙事（如宗教、政治意识形态）的破裂和小叙事的兴起。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n奥姆真理教 日本的极端宗教团体，创立于1984年，因其在1995年东京地铁沙林毒气袭击事件中的恐怖行为而广为人知。该教派结合了多种宗教和神秘主义信仰，曾声称能够提供终极真理。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n联合赤军事件（日本语：連合赤軍事件）是指1971年至1972年间，由日本极左激进组织联合赤军（連合赤軍）发动的一系列暴力事件。联合赤军由“赤军派”和“京滨安保共斗”两派极端左翼组织合并而成，其成员信奉极端左翼思想，试图通过暴力推翻政府。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEspen Aarseth 挪威学者，游戏研究领域的开创者之一，以其对电子游戏叙事和游戏性分析的贡献著称。著有《Cybertext: Perspectives on Ergodic Literature》（《赛博文本：互动文学视角》），提出了“互动文学”的概念，强调玩家在游戏中的互动和参与对于理解游戏文本的重要性。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n佛教末法概念 佛教教义中的一个概念，指佛法逐渐衰微的时代，教义的力量减弱，人们无法通过修行获得解脱。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n“安倍经济学”是指日本首相安倍晋三（Shinzō Abe）自2012年开始推行的一系列经济政策。这些政策包括所谓的“三支箭”策略：大胆的货币政策、灵活的财政政策和促进投资的增长战略。安倍经济学的目标是通过刺激经济增长、提高通货膨胀率来摆脱长期的通货紧缩和经济停滞状态。这些政策在日本和国际上都引起了广泛关注和讨论，但也引发了对其效果和可持续性的质疑。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n草食男子（日语：草食(そうしょく)系男子(けいだんし)，sōshoku danshi）是日本的一种社会现象，指那些对事业、恋爱和结婚不感兴趣，生活态度温和、不争、不抢的男性。这个词最早由日本作家深泽真纪在2006年提出，反映了日本社会中一些年轻男性的生活态度和行为模式的变化。这些男性通常不追求传统意义上的男性气概和社会成就，反而更注重个人兴趣和生活质量。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n尼特族 （NEET，Not in Education, Employment, or Training）是指那些既不在学、也不在职、也不接受职业培训的年轻人。这个词源自英国，但在日本也广泛使用。尼特族的出现反映了现代社会中青年失业率高、就业压力大以及社会结构变化等问题。这一群体在日本引起了社会关注，因为他们的经济依赖性和社会疏离感对家庭和社会结构带来了挑战。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n隐蔽青年 （日语：引(ひ)き籠(こも)り，hikikomori）是指那些因社会压力、精神疾病或其他原因而长期闭门不出、与社会隔绝的年轻人。这种现象在日本尤为突出，被认为是社会压力、竞争激烈以及家庭结构变化等多重因素共同作用的结果。隐蔽青年通常在家中长时间不出门，不上学、不工作，依赖父母或家庭成员的支持。这个现象不仅影响到个人的心理健康和生活质量，也对家庭和社会产生了深远的影响。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n見田宗介 是日本著名社会学家，曾任东京大学名誉教授，是日本社会学界的重要人物之一。他的研究领域广泛，涵盖现代社会理论、文化社会学以及日本社会的独特发展轨迹。峰崎的代表作《现代社会的理论》（『現代社会の理論』）对日本社会现代性的转型和结构做了深刻分析，被认为是社会学研究的重要文献。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n约翰·多尔 是一位美国历史学家和作家，以研究日本历史和美日关系闻名。他的著作《拥抱失败：日本在美国的阴影下》（Embracing Defeat: Japan in the Wake of World War II）通过详细的历史分析和丰富的文献资料，探讨了二战后日本社会的变化和重建过程。多尔的研究不仅涉及政治和经济层面，还深入探讨了社会文化的转变，特别是日本人对美国模式的接受和适应。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n泛泛女孩（panpan girls）是指二战后日本被美国占领时期，一些日本女性与驻日美军士兵交往的现象。这些女性通常通过与美军士兵建立关系，获得他们带来的物资和经济利益。泛泛女孩现象反映了战后日本社会的贫困与物质匮乏，以及人们对物质富裕和更好生活的渴望。二战后，日本遭受了巨大的物质和经济损失，许多人生活在极度贫困之中。占领日本的美军士兵带来了大量的物资和财富，使得美军的生活条件远优于普通日本人的生活水平。泛泛女孩们通过与美军士兵的交往，获得了食品、酒类、香烟、糖果、化妆品等在当时极为稀缺的物品。泛泛女孩现象不仅仅是一个物质交换的过程，它还反映了当时日本社会对美国文化和生活方式的向往。对许多日本人来说，美国的富裕和舒适的生活条件成为他们追求的目标，这种对美国模式的向往也在一定程度上推动了战后日本的现代化和经济复苏。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n貧病争 ひんびょうそう是一个源自佛教的概念，指的是“世间的烦恼”，具体包括贫穷、疾病和争斗。这三个方面代表了人类在世俗生活中不可避免的痛苦和困扰。以下是对每个方面的解释: 贫穷（ひん），指物质上的匮乏和经济上的贫困，贫穷会导致人们为了生计而不断奋斗，成为生活中的一大烦恼；疾病（びょう），指身体上的疾病和健康问题，疾病的存在使得人们不断追求健康和医治；争斗（そう），指人际之间的冲突和社会中的斗争，这包括个人之间的争执、家庭内部的冲突、社会中的暴力和战争等，争斗使得人们生活在不安和紧张的环境中。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n新人类（しんじんるい）是20世纪80年代日本的一代年轻人，他们在思想、行为和文化上与之前的世代有显著的不同。这一群体的出现标志着日本社会的深刻转型，影响了当时的社会文化和经济发展。通过对新人类的研究，可以更好地理解日本意识形态在20世纪80年代的变化和发展。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n御宅族 通常用于描述对某一特定兴趣（如动漫、漫画、电子游戏等）有着极端热情和深入了解的人群。这个词汇最早出现在20世纪80年代，最初带有一定的负面意味，指那些沉迷于兴趣爱好、常常在家里闭门不出、不太参与社会活动的年轻人。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n全学联合（日语：全学連，Zengakuren）是“全日本学生自治会总联合”（全日本学生自治会総連合）的简称，成立于1948年，是日本历史上重要的学生运动组织。全学联合主要由日本各大学的学生自治会组成，代表学生在政治、社会问题上发声。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n田中元子 是一位研究日本战后政治运动的学者，特别关注20世纪60年代的学生运动，如安保运动（Anpo）和全共斗运动（Zenkyoto）。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n全共斗运动 （全学共闘会議，Zenkyōtō）是20世纪60年代末至70年代初，日本大学生和左翼组织发起的激进学生运动，旨在反对政府的教育政策、经济措施以及与美国的安保条约。这个运动的特点是学生自发组织、没有固定的领导层，通过激烈的抗议和占领校园来表达政治诉求。全共斗的行动在日本社会引起了广泛关注，成为那个时代反抗精神的象征。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n联合赤军事件（Rengō Akagun jiken）是指1972年日本联合赤军组织进行的一系列激进和暴力事件。联合赤军是由极左翼的日本学生运动组织合并而成的激进组织，他们在长野县浅间山庄劫持了人质，导致与警方的对峙长达10天。最终，日本警方采取了强攻行动，事件导致人质获救、部分赤军成员被捕或死亡，引发了日本社会对极端左翼运动的广泛批判。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n通过博尔赫斯的《科学的准确性》作为寓言，他断言地图作为表征取代了领土，最终成为需要创建新地图的领土本身： 来自于阿根廷作家豪尔赫·路易斯·博尔赫斯（Jorge Luis Borges）的一篇短篇小说《精确的地图》（也译作《科学的准确性》）。在这个故事中，博尔赫斯描绘了一个极端的情况：地图变得如此精确，以至于它与现实世界（领土）完全重叠，最后，地图的细节变得如此复杂，以至于它不再是现实世界的象征，而是成为了一个替代现实的东西。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n弗朗索瓦·李奥塔（François Lyotard，1924-1998）是法国著名的哲学家和文学批评家，以其在后现代主义领域的开创性研究而闻名。他的代表性著作《后现代状况》（La Condition Postmoderne，1979年）对20世纪末的思想产生了深远影响。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n山谷是东京台东区和荒川区附近的一个地区，以前被认为是日工、无家可归者和社会底层人员聚集的地方。在这个地区，贫困和社会问题较为突出。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n釜崎是大阪市西成区的一个地区，类似于东京的山谷，这里也有大量的日工和无家可归者。如今，这个区域的正式地名为”爱邻地区”（あいりんちく，Airin Chiku），但釜崎的称呼仍然流行。这一地区长期以来是社会底层人员的聚集地，经济落后，社会问题严重。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n人民圣殿教是美国的一个新宗教团体，由吉姆·琼斯（Jim Jones）于1950年代创立。该教团以其强烈的社会平等和共产主义色彩著称，特别强调种族平等与社会正义。然而，这一组织在1978年因乔恩斯镇大屠杀（Jonestown Massacre）而闻名。当时，吉姆·琼斯带领900多名信徒在南美圭亚那的乔恩斯镇集体自杀，成为现代宗教历史上最惨烈的悲剧之一。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n天堂之门是一个美国的新宗教团体，由马歇尔·阿普尔怀特（Marshall Applewhite）和邦妮·内托尔斯（Bonnie Nettles）于1970年代创立。这个教团以其独特的末世论思想和对外星生命的信仰而著称。教义核心是认为地球将被净化，信徒的灵魂需要通过离开身体（即自杀）以进入一艘外星飞船，从而到达更高的存在层次。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n**净土宗：**净土宗是日本佛教的一大宗派，起源于中国的净土思想，传入日本后由法然（1133-1212）创立。净土宗的核心教义是通过专一称念“南无阿弥陀佛”来获得往生西方极乐净土的保证。净土宗的实践重点在于简化修行，通过称念佛号（念仏），普通人也能获得解脱，而不必追求复杂的禅修或其他高深的佛教修行。**日莲宗：**日莲宗由日莲（1222-1282）在日本创立，主张《法华经》是释迦牟尼佛教法的究竟表达，因此对末法时代的唯一正法是称念“南无妙法莲华经”。日莲宗带有强烈的社会关怀意识，认为末法时代的混乱与个人、社会的正法失落有关，因此通过弘扬法华经，信众不仅能拯救自己，还能影响社会，带来和平与繁荣。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n法然（ほうねん，1133–1212）：日本净土宗的创始人，法然从天台宗的修行体系中转向单一的念佛法门，提倡通过专念“南无阿弥陀佛”来获得往生净土；道元（どうげん，1200–1253）：日本曹洞宗的创始人，他从天台宗的基础出发，前往中国学习禅宗，并将其带回日本。他的教义强调只管打坐这一直接的禅修实践；荣西（えいさい，1141–1215）：日本临济宗禅宗的创始人，他同样来自天台宗的传统，后来前往中国，学习禅宗并带回日本。他在日本还推广了茶道，被称为日本禅茶文化的先驱；日莲（にちれん，1222–1282）：日莲宗的创始人，日莲主张《法华经》是佛法的究竟表达，强调通过唱念“南无妙法莲华经”来获得救度，并积极参与社会、政治事务，呼吁社会改革；亲鸾（しんらん，1173–1263）：净土真宗的创始人，法然的弟子，他进一步发展了法然的念佛思想，主张即使是最普通的人通过称念阿弥陀佛也能获得救度。他强调阿弥陀佛的救度是不依赖个人修行的。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://niraya666.github.io/essay/%E5%90%91%E4%B8%8B%E8%9E%BA%E6%97%8B%E9%BB%91%E6%9A%97%E4%B9%8B%E9%AD%82%E7%B3%BB%E5%88%97%E6%B8%B8%E6%88%8F%E4%B8%AD%E7%9A%84%E5%90%8E%E7%8E%B0%E4%BB%A3%E6%84%8F%E8%AF%86%E4%B8%8E%E4%BD%9B%E6%95%99%E5%BD%A2%E8%80%8C%E4%B8%8A%E5%AD%A6/","summary":"\u003ch1 id=\"摘要\"\u003e摘要\u003c/h1\u003e\n\u003cp\u003e本文探讨了“黑暗之魂”系列游戏在当代日本社会中的意义定位。我认为，这款游戏可以被看作是当今文化潮流的象征，就像有人可能会把杰克·凯鲁亚克的《达摩流浪者》视为60年代反文化的象征一样。\u003cstrong\u003e我主张，“黑暗之魂”系列通过寓言的方式表达了人们在一个日常行为和社会本身的意义都变得极不稳定的时代中生活的焦虑\u003c/strong\u003e。游戏采用碎片化的叙事方式，融合了佛教的形而上学思想，并以描绘一个曾经辉煌的王国在最后时刻挣扎的阴森哥特式美学为背景。这种对当代社会焦虑的表达，与日本的后现代主义话语密切相关。通过将这些游戏视为文本、环境和游戏系统之间的反馈回路，我把这些游戏的主要概念主题与大泽真幸提出的“后虚构时代”概念，以及东浩纪对御宅族的定义联系起来。\u003c/p\u003e\n\u003ch1 id=\"前言\"\u003e前言\u003c/h1\u003e\n\u003cp\u003e在人文学科这个领域，我们认为艺术和文学不仅仅是艺术鉴赏。当我们阅读夏目漱石\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e或三岛由纪夫\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e的作品时，教授和学生不仅仅像粉丝那样陶醉于他们优美的文笔，而是作为评论家，从中挑出深刻的思想。通过这种方式阅读足够多的作品，我们会发现一种更宏大的东西：\u003cstrong\u003e一个跨越时代和文化的思想洪流，在这个洪流中，生活的神秘、美丽、恐怖和悲剧汇聚成我们人类经验的漩涡和流动\u003c/strong\u003e。文学是指南，就像老话说的那样，是通向美好生活的指南：它是一面镜子，反映我们的位置，也是我们漫步时的地图。简而言之，伟大的作品让我们变得更强大。它们让我们清晰地面对生活的矛盾，并有勇气承受其重压。我们学习文学是为了找到人类经验中的共性，并将其内化。这至少是人文学科的理想和创立原则。\u003c/p\u003e\n\u003cp\u003e但如果这是正确的，我们能说这种深刻的体验只是文学独有的吗？书面文字是否有某种独特的力量，能够以其他媒介无法企及的方式激发反思？最终，文学只是一个个故事，但故事并不局限于一种媒介。故事是跨媒介的。它们可以口头讲述，可以印刷，可以通过舞蹈、图像，甚至可能通过尚未构想的方式来讲述。这是因为故事首先存在于人类心灵的深层结构中，不同的媒介让这些结构的不同方面显现出来。\u003cstrong\u003e故事是人类生活的核心，它们赋予我们的社会和个人生活以连贯性和意义。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e故事是个人身份的基石，人类将经验转化为故事的能力可能与我们感知时间的能力有关。\u003cstrong\u003e毕竟，故事是什么？它是以有意义的方式组织和编辑时间\u003c/strong\u003e。简而言之，通过研究故事，特别是那些在社会想象中占据重要地位的故事，我们可以进入人类心灵的最深处。当我们接近这一神秘领域时，我们更接近自己，也许会找到一些我们遗忘的，对我们至关重要的东西，它像火药桶上的火花一样在我们脚下点燃，在这场大火中我们的世界观重生。\u003c/p\u003e\n\u003cp\u003e新的媒介在大学里常常面临艰难，因为每种媒介都必须越过高文化裁决者的障碍\u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e。这在二十世纪初的电影和摄影上是如此，在今天的漫画、电视和视频游戏上也是如此。但如果我们仅因为这些作品属于错误的媒介而忽视了沟口健二\u003csup id=\"fnref:4\"\u003e\u003ca href=\"#fn:4\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e4\u003c/a\u003e\u003c/sup\u003e的作品，人文学科会变得多么贫乏？偏重研究一种媒介而忽视其他媒介有什么好处？这种偏见是最糟糕的，我们都因这种武断的判断而变得贫乏。我们切断了自己探索那些激发我们深层结构的新视角的机会。故事在新的媒介中同样存在，此外，对那些在这些新媒介中成长的人来说，发现其中的故事是引人入胜、动人且深具意义的。视频游戏中的故事体验与其他媒介有着根本的不同，正是这种不同使得研究它们变得如此重要。它反映了一种新的世界观和价值观。我们不再生活在一个技术只是工具的世界里；技术是我们生活的环境。电影和电视是工业时代的本土媒介，而视频游戏是数字时代的本土媒介。视频游戏不是小众的。这个行业在全球产生的收入大大超过了电影和印刷品。这本身就使得研究它们成为紧迫的事情。\u003c/p\u003e\n\u003cp\u003e话虽如此，我们必须认识到，视频游戏是一种新兴的媒介。就像早期的电影只是基本现象的再现——火车向屏幕疾驰或马在慢动作中奔跑——视频游戏的媒介中无疑有着尚未开发的巨大潜力。此外，我们还不能像理解文学那样全面理解这一媒介。我们还没有足够的时间去理解视频游戏在文化中可能扮演的角色以及它们对塑造我们的价值观和性格的影响。我不会在这里主张创建一个新的经典目录。现在还为时过早，而且流行经典化的过程早已在进行中。本文研究的游戏《黑暗之魂》系列已经被这样经典化了。它享有一种地位，其他同类游戏以它为标准，而那些共享其设计原则的游戏被称为“魂类游戏（Soul-like）”，这可能类似于许多文学或电影作品被描述为“卡夫卡式的”\u003csup id=\"fnref:5\"\u003e\u003ca href=\"#fn:5\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e5\u003c/a\u003e\u003c/sup\u003e。然而，我不会试图将这款游戏作为一部伟大作品来评估，以便将研究这一系列游戏制度化。我认为这些游戏被经典化不仅仅是因为它们“有趣”，而是因为它们直接处理了当代日本及其年轻一代面临的问题、焦虑和挑战。这是我们将要问的问题：\u003cstrong\u003e这些游戏中反映了什么，使其在跨文化范围内以及在粉丝和评论家中产生如此深刻的共鸣？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我将在这里主要讨论日本，但我相信在研究这款游戏时得出的教训具有全球意义。目前，这些意义将保持原样。本质上，为了故事而玩游戏是一件矛盾的事情。游戏的内部组件，作为一个具象化的代码系统和作为不同类型叙事（文本、视觉、听觉）的载体，对玩家提出了一系列相互竞争的需求。这种矛盾在《黑暗之魂》中和几乎所有其他游戏中一样没有解决，但该系列在这些相互竞争的元素之间达到了罕见的一致性，可能直接反映了日常生活中数字世界的体验。我希望我在这里的分析，即使只是初步和不完整的，也能成为反思社会走向、新的价值结构的出现以及文学解释或在这种情况下的游戏解释可以对这些问题有所启示的机会。\u003c/p\u003e\n\u003ch1 id=\"第一章引言\"\u003e\u003cstrong\u003e第一章：引言\u003c/strong\u003e\u003c/h1\u003e\n\u003cp\u003e本文旨在探讨“黑暗之魂”系列游戏与当代日本社会状况之间的关系。我认为，“黑暗之魂”系列通过寓言形式表达了在一个日常行为意义甚至社会本身都变得不稳定的时代生活的焦虑。这一表达通过破碎的叙事方式实现，这种方式结合了佛教形而上学，并以描绘一个昔日伟大王国最后挣扎的阴暗哥特风格为背景。这种寓言中的焦虑与日本后现代性讨论密切相关，特别是现代性项目失败和进步叙事腐败的观点。在我的论文中，我认为这种讨论在“黑暗之魂”中通过模拟经典英雄之旅得以体现，但最终通过剥夺玩家的英雄成就感并用深深的模糊和不确定性取而代之，颠覆了这一旅程。\u003c/p\u003e\n\u003cp\u003e“黑暗之魂”系列是一款第三人称动作RPG，其核心机制围绕探索一个破败的世界展开。该系列由著名日本游戏公司FromSoftware在总裁宫崎英高的指导下开发。第一款游戏于2011年9月发布，第三款于2016年4月发布。这是一款难度极高的游戏，设定在一个末世奇幻世界，要求玩家克服许多复杂的运动任务。游戏的一大特点是其缺乏具体的叙事阐述。然而，有一些概念性主题将这些游戏联系在一起。游戏中总是有一个被“不死诅咒”摧毁的王国，并且总是有神秘人物指示玩家杀死旧神并使用他们的灵魂来“连接火焰”。这个过程在第一款游戏中被解读为一个世界复兴过程，但在第二和第三款游戏中被揭示为不可避免的衰败螺旋。\u003c/p\u003e\n\u003cp\u003e全球销量数百万，三部作品在国外几乎普遍获得好评，赢得了众多“年度游戏”称号和大量其他行业奖项。它对当代游戏设计产生了深远的影响，许多采用类似设计的游戏经常被称为“魂类”或“魂风格”。这已成为一种陈词滥调，类似于带有超现实或存在主义色彩的文学作品被描述为“卡夫卡式”。我认为其地位的原因并非游戏的“有趣”，而是它有一些关于我们今天所处世界的强有力表达，这些表达与那些对现代性的后现代批评观点一致的人产生共鸣。\u003c/p\u003e\n\u003cp\u003e本文的核心论点是，“黑暗之魂”系列体现了具有后现代意识的生活体验。这个术语“后现代意识”是我用来总结后现代思想的一个总称。然而，我特别关注日本分支，引用了社会学家大泽真幸\u003csup id=\"fnref:6\"\u003e\u003ca href=\"#fn:6\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e6\u003c/a\u003e\u003c/sup\u003e、文化评论家东浩纪\u003csup id=\"fnref:7\"\u003e\u003ca href=\"#fn:7\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e7\u003c/a\u003e\u003c/sup\u003e、文学学者田中真纪子\u003csup id=\"fnref:8\"\u003e\u003ca href=\"#fn:8\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e8\u003c/a\u003e\u003c/sup\u003e和小说家村上春树\u003csup id=\"fnref:9\"\u003e\u003ca href=\"#fn:9\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e9\u003c/a\u003e\u003c/sup\u003e的著作。\u003cstrong\u003e从弗朗索瓦·利奥塔\u003csup id=\"fnref:10\"\u003e\u003ca href=\"#fn:10\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e10\u003c/a\u003e\u003c/sup\u003e（Francois Lyotard）开始——他首次提出“后现代”一词——后现代思想的不同分支的核心主张是，曾经用来指导社会的“大叙事”已经无可救药地破裂并且无法修复\u003c/strong\u003e。大泽和其他思想家拾起了这条思路，并将其应用到具体的日本背景。他们认为，日本战后时期的大叙事的破裂在年轻一代中引发了虚无主义行为，这种行为\u003cu\u003e表现为从政治原因和社区参与转向过度消费主义和一种表现为御宅族形象的媒体崇拜\u003c/u\u003e。在一些极端情况下，这种御宅族主义可能导致病态行为，如奥姆真理教\u003csup id=\"fnref:11\"\u003e\u003ca href=\"#fn:11\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e11\u003c/a\u003e\u003c/sup\u003e的恐怖主义，但需要注意的是，这些思想家将这种暴力行为视为御宅族行为连续体的最外端，而不是在类别上有所不同。从大泽和东浩纪等后现代思想家那里，\u003cstrong\u003e我将后现代意识提炼为两个基本特征：1. 拒绝或无法接受宏大叙事和意识形态作为意义的来源 2. 对“他者”的日益焦虑和敌意\u003c/strong\u003e。在这种情况下，他者指的是主体与他者之间的经典哲学二元关系；换句话说，就是自我与世界上所有其他自我之间的关系。\u003cu\u003e大叙事的破裂削弱了依赖这些叙事来维系和稳定的社区纽带和同胞感\u003c/u\u003e。这种意识是“黑暗之魂”系列设计和叙事的主要当代文化元素。\u003c/p\u003e\n\u003cp\u003e然而，后现代意识在日本确实广泛传播，这并不是显而易见的。出于这个原因，我在第一章中追溯了大叙事在日本历史中逐渐瓦解的确切方式，从战后时期开始一直到现在。这使得我们能够看到后现代意识的发展及其在日本社会和“黑暗之魂”系列中的表达。没有这一步骤，就不可能识别贯穿这个系列的后现代意识。\u003c/p\u003e\n\u003cp\u003e为了挖掘日本后现代意识的文化根源，我采用了大泽的文化时代精神理论，\u003cstrong\u003e将战后时期分为三个阶段：意识形态时代（1945 - 1972），虚构时代（1972 - 1995）和后虚构时代（1995 - 现在）\u003c/strong\u003e。大泽在其作品中提出的基本观点是，意识形态的死亡——本质上是他对“宏大叙事”的术语——刺激了新的形式，这些形式最终使他们脱离了日本战后社会的意识形态基础。从1972年的联合赤军事件\u003csup id=\"fnref:12\"\u003e\u003ca href=\"#fn:12\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e12\u003c/a\u003e\u003c/sup\u003e开始，激进的左翼政治让位于非政治的消费享乐主义。这导致了围绕显著消费形式尤其是时尚的亚文化的繁荣。然而，对一些人来说，对更深层意义的渴望仍然存在，这最终催生了新时代的邪教，即奥姆真理教，它们同样从传统宗教和动漫中汲取力量来满足这种需求。\u003c/p\u003e\n\u003cp\u003e奥姆真理教的重要性在于他们既标志着传统信仰和意识形态的弱化，也标志着对任何被他们视为“他者”的事物的日益不容忍。他们还标志着一种对远在天边但又近在咫尺的敌对他者的偏执。例如，他们认为日本政府被全球犹太共济会阴谋控制，而他们自己的莲花团体则充满了双重间谍。他们在1995年对这个被认为是犹太人的他者的恐怖袭击，具有讽刺意味的是，传播了这种对奥姆真理教妖魔的偏执，这些妖魔潜伏在学校、企业甚至政府中。这种怪异他者的概念在“黑暗之魂”中得到了有力的表达，因为它向玩家展示了一个充满敌对个体和群体的世界——这些实体是玩家角色的他者——他们的目标和实践是难以理解的。这也通过一种系统得到了加强，即玩家始终连接到互联网，并且开放给其他玩家入侵。\u003c/p\u003e\n\u003cp\u003e东浩纪采纳了大泽的时代精神，并提出了一种“动物化”理论。他指出，由于后现代时代缺乏大叙事，人们失去了理想和抱负。\u003cstrong\u003e因此，他们退缩到一个以收集符号为中心的世界，这些符号被添加到一个巨大的符号数据库中并被重新利用\u003c/strong\u003e。 他的主要证据是，当今的御宅族不再对叙事感兴趣。相反，他们只是享受识别、重新混合和扩展数据库的组件。他的预测是，御宅族的活动——他们无休止地收集符号——是大文化的先锋，后续几代人将在自己的领域中变得越来越像御宅族。东浩纪所指出的这一流行文化趋势在“黑暗之魂”中体现为深深的模糊和稀疏的叙事。\u003c/p\u003e\n\u003cp\u003e那么“黑暗之魂”究竟如何通过游戏玩法表达后现代意识呢？我认为它通过为我们提供一个任务和一个王国来模拟传统的英雄之旅，但剥夺了我们理解这个任务意义的任何连贯方式。游戏提供了一个视觉细节丰富的世界，但完全缺乏具体的阐述，将玩家置于考古学家和法医科学家的角色中。然而，从未有任何可靠的解释；只有更多的线索和片段，有些是矛盾的。这被称为“环境叙事”，它创造了游戏与后现代思想之间最关键的接触点；即它对主叙事的拒绝。有“拯救王国”的建议，但仅仅是建议，主要是通过类型的惯例传达的，而不是叙事。你所做事情的意义及其服务的目的从未完全清楚。\u003c/p\u003e\n\u003cp\u003e重要的是要记住，虽然可以从传统的文学解释视角来解释“黑暗之魂”系列的叙事，但当试图将游戏机制解释为寓意时，会遇到许多实际和理论问题。出于这个原因，我在第二章中对当代游戏研究的批判理论进行了文献综述。利用Espen Aarseth\u003csup id=\"fnref:13\"\u003e\u003ca href=\"#fn:13\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e13\u003c/a\u003e\u003c/sup\u003e和其他奠定该领域基础的思想家的论点，我认为需要结合“第一人称”现象学方法和更传统的文学分析方法，才能正确评估视频游戏中潜在的潜在意义。这样做是为了建立一种分析方式，通过与游戏系统的斗争，让玩家体验到我上面概述的后现代意识的两个基本特征。我在第三章中将这种现象学方法付诸实践，探索了一种特别有效的文本叙事、环境叙事和游戏玩法的融合，捕捉到游戏作为一个统一体验的本质。\u003c/p\u003e\n\u003cp\u003e除了后现代主义，还有另一股影响游戏的力量，那就是佛教末法概念\u003csup id=\"fnref:14\"\u003e\u003ca href=\"#fn:14\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e14\u003c/a\u003e\u003c/sup\u003e。这两种影响力在有趣的方式上重叠，并产生了惊人的相似之处。末法在镰仓时代是一个极具影响力的概念，正如我们的时代一样，那是一个深刻的社会转型时期。末法指的是佛教教义失去其效力，人们无法再依靠自己的努力来获得启示。\u003cstrong\u003e随之而来的是僧侣和寺庙变得不可否认的腐败，人们因此无法离开轮回，被困在一系列日益退化的转世中\u003c/strong\u003e。我在第四章中分析了末法的哲学核心，并展示了它如何与大泽和东浩纪的后现代话语一致。此外，我认为，只要“黑暗之魂”系列表达了后现代意识，它主要是通过采用这个佛教末世论概念来表达的。\u003cstrong\u003e后现代思想和末法都表达了一种恐惧，即事情只会变得更糟，人类的努力无法改变结果\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e在第五章中，我回到现象学和文学分析的混合方法，展示末法概念以及佛教形而上学的混合如何作为构建游戏虚拟世界的核心要素，尽管游戏的美学显然源于中世纪的欧洲奇幻调色板。这些佛教元素共同揭示了游戏世界被困在一个日益退化的轮回中，玩家的任务基本上是一种徒劳的行为，只会推动这个痛苦的循环。我认为佛教形而上学的融合最终表达了东浩纪的结论，即后现代世界及其死去的叙事和怪异他者无可避免地导致社会整体的“动物化”。尽管“黑暗之魂”是一款美学显然源于中世纪欧洲奇幻风格的游戏，但它充满了末法的逻辑，因此游戏深受异教影响，通过采用和改造佛教形而上学，在阴暗的骑士在破败的城堡中冒险的表面下表达了一种后现代情感。\u003c/p\u003e\n\u003ch2 id=\"衰败叙事\"\u003e\u003cstrong\u003e衰败叙事\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e过去几十年，日本几乎成了停滞的代名词。这在很大程度上归因于日本在1970年代到1980年代经历的“奇迹”，以及他们令人震惊的衰落，自那以后，国家似乎一直处于无所事事的状态。在美国，当《纽约时报》或《华尔街日报》等出版物提到日本时，往往很少有积极的报道，而是集中在一小部分话题：人口老龄化，年轻人自杀；货币贬值，索尼、丰田和东芝等企业巨头被更精简的竞争对手击败；核燃料仍在福岛渗入地下水，但无人承担责任，等等，每一个预言都比前一个更严峻。在西方，日本作为一个正在衰败的帝国的叙述已经流传已久。这种衰败的印象如此强烈，似乎只有惯性才能维持一切运作，以至于人们忘记了日本仍然是世界上最富有、最富裕和技术最先进的国家之一，仍然领先于许多西欧国家。这种停滞的叙述也存在于日本。正如现任首相安倍晋三在2012年选举中的口号所示：“日本を取り戻す”（取回日本）。从谁那里取回？取回到哪里？凭借他的“安倍经济学”\u003csup id=\"fnref:15\"\u003e\u003ca href=\"#fn:15\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e15\u003c/a\u003e\u003c/sup\u003e议程中的“三支箭”，他将从日本自己的“萎缩心态”中拯救日本（Sharp）。\u003cstrong\u003e如果说1980年代的代表是那些狂热工作、渴望企业晋升的上班族，那么近年来这种原型被更为无力的角色所取代：草食男子\u003c/strong\u003e\u003csup id=\"fnref:16\"\u003e\u003ca href=\"#fn:16\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e16\u003c/a\u003e\u003c/sup\u003e\u003cstrong\u003e（sōshoku danshi）、尼特族\u003c/strong\u003e\u003csup id=\"fnref:17\"\u003e\u003ca href=\"#fn:17\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e17\u003c/a\u003e\u003c/sup\u003e\u003cstrong\u003e（NEET，指不在职或不在学的年轻人）、隐蔽青年\u003c/strong\u003e\u003csup id=\"fnref:18\"\u003e\u003ca href=\"#fn:18\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e18\u003c/a\u003e\u003c/sup\u003e\u003cstrong\u003e（hikikomori，指社会隐士）和其他贬损的称呼\u003c/strong\u003e。诚然，日本的经济和文化问题与其他任何国家一样真实存在，但这种叙述的力量已经超越了现实，成为一种独立的存在。\u003c/p\u003e\n\u003cp\u003e这种“萎缩”的心态和随之而来的文化表达，我将称之为后现代意识。这种意识必须与正统的后现代哲学区分开来，因为哲学本身只是对围绕日本的整体衰败叙述的众多情感反应之一。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e后现代意识的核心是一种源于对人类社会已经达到不可否认的衰退点的感知——无论是有意识还是无意识的——的焦虑\u003c/strong\u003e。鉴于上面概述的围绕日本经济和文化衰退的广泛文化讨论，后现代意识在日本文化心理中占据了中心地位。因此，这些源自后现代意识的停滞叙述在日本的流行媒体中也找到了强大而多样的表达。虽然有许多例子可以引用，但游戏《黑暗之魂》及其所有续集，是这种“萎缩”心态的卓越典范。要理解它如何以这种方式运作，我们不仅要看叙述，还要看《黑暗之魂》相对于同类游戏的存在。《黑暗之魂》属于一种被称为角色扮演游戏（RPG）的游戏类型。RPG通常是一个开放式的幻想世界模拟，玩家可以探索领土、收集宝物和击败怪物。通常，玩家创建一个角色——一个在游戏世界中的化身——并以此角色进行任务，其最终目标通常涉及拯救某物（王国、存在平面、公主等）免于毁灭。另一个RPG的基本特征是成长概念。尽管有许多设计模式和隐喻用于模拟成长过程，通常玩家的化身通过击败怪物获得经验值，并通过积累这些点数“升级”。通过升级过程，玩家解锁能力，他们的化身变得更强大。总的来说，RPG往往是许多文化神话中常见的英雄之旅模式的模拟：年轻、未成型的人必须离开家园的安全区域，面对未知的危险，克服它们，培养他们潜在的能力，并以强大和完全实现的人的身份返回，无论是字面上还是象征性地。\u003c/p\u003e\n\u003cp\u003e在其基本设计中，《黑暗之魂》作为RPG是相当传统的。然而，它有许多叙述和游戏设计选择，颠覆了这个几十年旧的类型的许多传统。作为一个叙述，它可以被解读为一种政治和文化的寓言，++直接反映了生活在一个意识形态叙述失去吸引力和连贯性的衰败文明中的经验++。它也是一种新兴新类型的前沿：后末日幻想。\u003cstrong\u003e在这款游戏中，王国被占领，英雄们都死了或堕落了，没有人可以拯救，而你存在的最大威胁是那些与你在废墟中一起生存的人\u003c/strong\u003e。社区是不可能的。基本的本体状态是无休止的失败，而“英雄”只是注定要忍受它。甚至死亡也不能免除角色的负担，而你被赋予的任务的意义和目标是模糊和不明确的。叙述几乎不存在。当游戏开始时，玩家被简单地放在一个被怪物和不死者占领的废弃王国中，没有明确的理由说明为何事情会如此，或者他们应该怎么做。仅有的叙述存在于零碎的文本中，只提供诱人但最终不完整或矛盾的关于世界的信息。所有这些叙述元素都对已建立的类型惯例提出了严重挑战，因此将其与衰退的讨论联系起来。\u003c/p\u003e\n\u003cp\u003e在游戏设计方面，《黑暗之魂》有两个突出的特点。第一个是游戏被有意设计得异常困难。这实际上是其吸引力的主要来源之一。该系列在西方的广告标语是“准备去死”（Prepare To Die），而在日本，该系列被认为是しにがみ（死亡之神）的主要例子，暗示玩家在与远比玩家创建的化身强大的巨大、恐怖的怪物斗争时必然会经历无数次死亡。另一个特点是，尽管游戏主要设计为单人体验——也是RPG类型的一个既定惯例——玩家始终连接到互联网。这被视频游戏评论家广泛赞誉为该类型的重要创新。在实践中，这创造了一种紧张的局势，玩家总是暴露在其他玩家的“入侵”之中，这些玩家会试图杀死该玩家。这种互动中内置了一个复杂的风险/回报系统，入侵者通过杀死其他玩家可以获得很多，但如果失败则会失去很多。\u003c/p\u003e\n\u003cp\u003e实际上，始终连接到互联网使得游戏世界充满了偏执和危险。其他玩家是玩家在游戏中可能面对的最危险和不可预测的怪物。入侵玩家经常会潜伏在一个不合适的时机突然袭击，玩家无法自卫，从而逆转他们不幸的受害者辛苦获得的进展。我们将详细探讨叙述和游戏系统，但这一系列游戏的基本概况引出了一个问题：在一个没有希望拯救王国，并且异常困难常常到不公平地步的游戏中，怎么会有如此大的吸引力？但事实上，这款游戏在日本、欧洲和北美都极具吸引力。\u003cstrong\u003e这也指出了游戏的设计和叙述如何与在无聊时代生活的年轻一代的经验产生共鸣\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e日本文化领域的停滞叙述需要进一步澄清。我认为《黑暗之魂》可以被解读为对当代日本状况的政治和文化寓言。这是一种后现代的英雄之旅的颠倒：一种被污染的神话碎片的模拟。\u003cstrong\u003e它直接反映了许多年轻日本人今天试图在庞大、失修的机构中航行时所经历的无聊和徒劳的感觉，这些机构至多对他们的存在漠不关心，至多直接敌对。然而，这种寓言不仅仅是关于生活在1980年代“奇迹”之后的经济问题。它同样涉及生活在一个国家、政治和文化叙述已经失去了大部分意义和连贯性的社会中的社会和心理成本，这些叙述曾经作为一种心理基石——为个人和社区身份提供稳定\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e催化这一恶化的事件起源于1995年，那一年发生了神户地震和沙林毒气袭击。在西方媒体中，关于这些事件的文化或政治意义的讨论通常不多，但在许多日本知识分子中，这些事件似乎标志着现代性的决定性破裂。在著名小说家村上春树的书《地下：东京毒气袭击和日本心理》中，对沙林毒气袭击幸存者的一系列采访，并得出结论，这一事件的后果不可逆转地揭示了日本社会的所有矛盾、缺陷和内在不稳定性：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“神户地震和1995年1月和3月的东京毒气袭击是日本战后历史上两起最严重的悲剧。毫不夸张地说，这些事件前后的日本意识发生了显著变化。这两次灾难将作为我们生活中的两个里程碑，永远铭刻在我们的心灵中。如此灾难性的事件接连发生是令人震惊的，也是巧合的。然而，当日本的“泡沫经济”破裂，标志着那些泛滥成灾的时代结束时，这些事件带来了对日本国家根本根源的批判性审视。就像这些事件一直在等待伏击我们。两者共有的是压倒性的暴力元素：\u003cstrong\u003e一个是不可避免的自然灾难，另一个是可以避免的人为灾难。\u003c/strong\u003e”（村上，237页）\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e通过村上等许多知识分子的工作，1995年已成为一个单一且不可改变的地位：\u003cstrong\u003e通往破碎和功能失调时代的门户\u003c/strong\u003e。这里分析的主要理论家——东浩纪、大泽真幸和田中基子——都\u003cstrong\u003e将1995年视为进入反乌托邦现状的起点\u003c/strong\u003e。这些思想家的语调本身就有一种微妙的后末日色彩，仿佛我们生活在一个无法拯救的被污染时代。这也是衰败讨论的一部分。这些思想家有一种确定的末世论信念，将他们与这一讨论联系起来。\u003c/p\u003e\n\u003cp\u003e无论如何，这些灾难比任何经济灾难都更可能是现任首相希望根除的“萎缩”心态的原因。尽管已经过去几十年，1995年的事件作为焦虑和无助感的触发点，在《黑暗之魂》的寓言中找到了源头。经济的持续低迷、老龄化人口、年轻一代的就业前景减少以及福岛等灾难，只是加剧了这些灾难在1995年最初引发的负面情绪。福岛等事件只帮助在日本意识中创造了一种遗产。近年来，右翼极端民族主义政治的重新出现和尼特族及隐蔽青年的社会退缩，形成了对这一相同的文化病态的极端和相反的情感反应。右翼试图通过与其真实和感知的对手（韩国、中国、朝鲜）进行公开的对抗来复兴“大和”帝国的活力，试图通过历史修正主义抹去日本帝国的暴力和道德可憎之处，并试图通过修改宪法（第9条）恢复战争作为国家主权权利。而尼特族和隐蔽青年则将自己沉溺于网络和其他形式的私人数字享乐中。他们没有叙述可供复兴，没有事业可供加入，甚至没有可以参与的兴趣小组。\u003cstrong\u003e与他人沟通实在是太困难了，在他们看来，也太危险了。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e我的观点不是《黑暗之魂》系列是这些问题的根源，甚至不是它们的贡献，而是它是对在公众意识中循环的深层社会焦虑，特别是对视频游戏作为熟悉媒介的年轻一代的一种特别有力的表达。《黑暗之魂》系列的持续流行，作为一种社会腐化的象征，反映了人们在日常生活中的感觉。但这些焦虑到底是什么，它们如何在《黑暗之魂》中表现出来？另一种问这个问题的方法是，后现代意识的基本要素是什么？定义1995年后时代的有两个主要元素。\u003cstrong\u003e1. 对构建战后秩序的政治和社会叙述的拒绝；2. 一种对他者的弥漫性焦虑，侵蚀了对社会过程的信任和信心\u003c/strong\u003e。他者的概念是指自我与世界上遇到的所有其他自我之间的二元关系的一半。这一概念的延伸是文化他者，即一种感觉某些人与自己相似，另一些人则是异类。日本社会通常被认为具有非常同质的国家认同感，彼此之间有相同的文化、种族和相似的价值观。这反过来又创造了强烈的信任和社区感，但这种亲近的逆向效应是，外来者被认为比在美国、英国或法国等文化多样性更大的国家中更为陌生。大泽真幸的论点是，奥姆真理教的恐怖活动将潜在威胁引入了公众。这种恐惧是一种诡异的他者的恐惧，这种他者会突然出现，以一种深刻的方式扰乱你的生活，有时甚至是致命的。社会结构中的这种破裂从未真正修复，并继续受到挑战，直到现在。关于诡异他者的偏执是定义《黑暗之魂》的氛围和叙述的主要特征之一，也是其游戏机制，尤其是其在线组件。\u003c/p\u003e\n\u003cp\u003e要理解《黑暗之魂》如何作为一种描述后现代意识的寓言运作，我们必须追踪战后日本社会状况的衰退轨迹。\u003cstrong\u003e这根本上是一个现代进步叙述——本质上是从西方继承的——首先在1960年代末引发了激烈的意识形态斗争，然后在1980年代变成一种无政治的享乐主义，最后，最终在五个正义的宗教狂热者用雨伞尖端戳破装满沙林毒气的袋子的时刻，被一种微妙的虚无主义彻底摧毁\u003c/strong\u003e。为此，我们将研究社会学家大泽真幸的工作。大泽花费了相当多的职业生涯试图回答奥姆为什么会做他们所做的事情。\u003cstrong\u003e在他的书《虚构时代的终结》中，他认为答案涉及意识形态本身的致命缺陷：一种危险而空洞的思维模式，导致在一个自我设计的世界中越来越高的疏离感。\u003c/strong\u003e\u003c/p\u003e\n\u003ch2 id=\"理性时代\"\u003e理性时代\u003c/h2\u003e\n\u003cp\u003e借用社会学家見田宗介\u003csup id=\"fnref:19\"\u003e\u003ca href=\"#fn:19\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e19\u003c/a\u003e\u003c/sup\u003e（Mita Munesuke）的观点，大泽真幸将战后时代分为两个不同的阶段。第一个阶段他称为“理想的时代（理想の時代，risō no jidai）”，第二个阶段他称为“虚构的时代（虚構の時代，kyokō no jidai）”。理想的时代始于20世纪60年代，结束于1972年，虚构的时代从1972年开始，一直持续到1995年。大泽将“理想”和“虚构”描述为“可能世界（可能の世界 kanōsei no sekai）”，因为它们都反映了我们对世界的感知以及我们认为世界应该如何。然而，尽管这两个概念在根本层面上是相关的，但它们在几个重要方面是不同的。\u003cstrong\u003e大泽认为，理想与现实世界密切相关，而虚构则完全脱离现实世界\u003c/strong\u003e：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e理想是一个在未来有望或期待在现实中实现的可能世界。因此，理想必须存在于现实的因果延伸之上。从这个意义上讲，理想不是一个纯粹的可能世界，而是广义现实世界的一个方面。相反，虚构是一个可以在现实中实现与否无关的可能世界，因此是纯粹的反现实。（大泽，41页）\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e理想は、未来において現実に着地することが予期（期待）されているような可能世界である。だから、理想は、現実の因果的な延長上になくてならない。その意味では、理想は、純粋な可能世界ではなく、むしろ広義の現実世界の一局面である。それにたいして、虚構は現実への着地ということについてさしあたって無関連ありうる可能世界であり、それゆえ純粋な反現実である。(Osawa, 41)\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e暂且不讨论虚构如何将我们与现实疏离，日本的理想时代很大程度上受到冷战阴影的笼罩。当亚洲大部分地区处于苏联的保护伞下时，日本则在美国的庇护下，因而在意识形态上致力于民主和经济自由主义。在20世纪60年代，日本在这些条件下几乎在各个方面都得到了繁荣：科学、基础设施、经济、文化等。大泽将20世纪60年代称为理想的黄金时代，并指出家用电器是赋予大众理想的物质形式：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e理想时代在大众层面的黄金期是20世纪60年代。当然，这与日本的高速增长期相吻合。在此期间，例如，受到国民绝大多数人广泛需求的家电产品赋予了大众理想物质的表达……经济增长和科学技术的进步并不是因为理想而被接受的，相反，正因为理想作为可能的现实在广泛（全球范围内）被信奉，经济才能够增长，科学和技术才能进步。（大泽，44页）\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e理想の時代の、大衆的な水準で黄金期は、1960年代である。もちろん、これは、高度成長期にあたる。この時期、たとえば、国民の圧倒的な大多数によって広範に欲求された家電製品が、大衆的理想に物質的な表現を与えた\u0026hellip;経済成長や科学・技術の進歩があったから理想が抱かれたのではなく、逆に、理想が可能的現実として広く（世界規模で）信憑されたがゆえに、経済が成長することができ、また科学や技術進歩していると感受されたのである。(Osawa, 44)\u003c/strong\u003e\u003c/p\u003e","title":"翻译｜向下螺旋：《黑暗之魂》系列游戏中的后现代意识与佛教形而上学"},{"content":" If you want to make a good RAG tool that uses your documentation, you should start by making a search engine over those documents that would be good enough for a human to use themselves. This is likely something your organization has considered before, and if it doesn’t exist it’s because building a good search engine has traditionally been a significant undertaking.\n— from Build a search engine, not a vector DB\n一个优秀的RAG背后， 一定有一个优秀的搜索引擎；\n很多时候，在针对通用场景下， 如果能够调用常见的搜索引擎，如google 或者bing， RAG的效果一般不会太差；\n但，当考虑到一些垂直场景， 我们需要构造属于自己的“搜索引擎”，而往往根据特定的场景，在索引构建上会有特殊处理；可以参考devv，在针对代码场景下， 对RAG的检索部份也做了不少的工作和设计；\n很显然， 检索不是仅仅使用向量匹配和向量库就能搞定的事情；\n考虑到前LLM时代的NLP检索（甚至是图像检索），或者是推荐系统， 其实会发现， 这些东西并没有什么太大的变化，思路和技术依旧是可以复用的。\nvector-search is not all you need 纯粹基于向量匹配实现起来很简单，但不是万能的\n其问题来源有：\nembedding模型一般在通用预料上做训练， 在特定领域下， 其效果并不会太好，很多时候需要在特定领域语料上再做微调；\n语义匹配不见得是万能的，对于一些特定场景，其局限性尤为明显。例如，当用户询问一个具体的名词时，就会发现单纯使用向量匹配只能匹配到大致的相似度，对于具体的关键词是无能为力的。 这种情况下，语义匹配往往难以捕捉到用户提问中的精确细节。例如，用户可能询问特定型号的苹果电脑（如“MacBook Pro 2021”），但语义匹配算法可能会返回类似类型或年份的苹果电脑，而不是确切的型号。此时语义匹配的效果并不会太好。\nembedding模型计算的是输入的两个文本（A和B）的相似度。然而，在实际应用中，输入的是一个问句（query），需要匹配的是一段文字。在这种情况下，我们关注的重点是文本之间的相关性而非简单的相似性。因此，通常在使用embedding模型后，还需要一个reranking模型，根据相关性对结果进行排序，以确保返回最相关的答案。\n对于组合的问题无效；如果query是一些复杂的需要一些推理的问题（如多跳），使用vector- search显然不是好办法；这类问题通常涉及多个子问题，每个子问题的答案都是解答下一个问题的基础， 举例来说，回答“谁是发明电话的人的孙子在2020年的职业是什么？”需要知道发明电话的人是谁，接着找出他的孙子，然后查询这个孙子的职业。面对需要多步推理的复杂问题时，向量搜索的能力有限，原因在于它不可能进行复杂的逻辑推理和多步信息整合。在这样的场景下，需要的是Agent将query进行分解，然后分别调用工具（搜索引擎）；\n其实我们可能过于迷信向量搜索。事实上，对于一些简单的场景，基于倒排索引的关键词匹配效果更好、更加简单且成本更低。倒排索引是一种高效的文本检索方法，通过建立关键词到文档的映射，可以快速找到包含特定关键词的文档。对于不需要复杂推理的简单查询，倒排索引可以提供快速且准确的搜索结果。\n不止只有向量检索 稀疏向量（Sparse）和稠密向量（Dense）是通过不同的算法计算的。稀疏向量主要由零值组成，只有少数几个非零值，而稠密向量则主要包含非零值。稀疏嵌入由算法如BM25和SPLADE生成，而稠密嵌入则由机器学习模型如GloVe和Transformers生成。\nTF-IDF(Term-Frequency Inverse-Document Frequency)是一种用于评估文本中一个词对一个文档的重要程度的统计方法。其原理基于两个指标：词频（TF）和逆文档频率（IDF）。\n词频（TF）：表示某个词在文档中出现的频率，计算公式为：\n$$ \\text{TF}(t,d) = \\frac{\\text{词t在文档d中出现的次数}}{\\text{文档d中的总词数}} $$\n逆文档频率（IDF）：衡量某词在整个文档集合中重要性的指标。公式为：\n$$ \\text{IDF}(t) = \\log\\left(\\frac{\\text{总文档数}}{\\text{包含词t的文档数} + 1}\\right) $$\nTF-IDF值通过将词频和逆文档频率相乘计算得到：\n$$ \\text{TF-IDF}(t,d) = \\text{TF}(t,d) \\times \\text{IDF}(t) $$\nBM25（Best Matching 25）是一种基于概率模型的文本检索算法，它在TF-IDF（词频-逆文档频率）的基础上进行改进。BM25通过引入二元独立模型，并添加归一化惩罚来计算文档长度相对于数据库中所有文档平均长度的权重。\nBM25的核心公式如下：\n$$ \\text{BM25}(q, D) = \\sum_{i=1}^{n} \\text{IDF}(q_i) \\cdot \\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}})} $$\n其中：\nq 代表查询\nD 代表文档\n$q_i$ 是查询中的第i个词\n$f(q_i, D)$ 是词 ($q_i$) 在文档 (D) 中的词频\n|D| 是文档 (D) 的长度（以词计）\n$\\text{avgdl}$ 是集合中所有文档的平均长度\n$k_1$ 和 b 是调节参数，通常 $k_1$ 在1.2到2之间，b 取0.75\n$\\text{IDF}(q_i)$是词 $q_i$ 的逆文档频率\nDense vector 使用稠密向量表示存储在数据库中的信息，包括文本、图像和其他类型的数据，。这些嵌入由机器学习模型生成，将数据转换为向量。也就是最近两年大家常说的向量检索。\n如何提升检索效果：\n自然而然的想法，不再使用单一的向量检索， 而是采用多种检索方式混合的方式，不论是混合不同的embedding模型的检索还是Sparse-vector和Dense-vector混合使用以获得二者的优势。通常来说，稠密向量擅长理解查询的上下文，而稀疏向量则擅长关键词匹配。\n那么需要将二者合并，but how？\nReciprocal Rank Fusion (RRF) 其核心思想是通过计算每个文档在不同排名列表中的倒数排名之和来确定最终排名。这样，排名较高的文档会得到更高的分数，而排名较低的文档会受到惩罚。\nRRF的计算公式如下：\n$$ \\text{RRF}(d) = \\sum{i=1}^{N} \\frac{1}{k + r_{i}(d)} $$\n其中：\n(d) 代表文档\n(N) 是排名列表的数量\n(k) 是一个常数，用于平滑处理，通常取值为60\n($r_{i}(d)$) 是文档 (d) 在第 (i) 个排名列表中的排名\n通过这个公式，每个文档的最终RRF分数是其在所有排名列表中的倒数排名之和，分数越高，排名越靠前。\n在langchain **ensemble-retriever**的源码中可以看到其具体的思想逻辑：\ndef weighted_reciprocal_rank( self, doc_lists: List[List[Document]] ) -\u0026gt; List[Document]: \u0026#34;\u0026#34;\u0026#34; Perform weighted Reciprocal Rank Fusion on multiple rank lists. You can find more details about RRF here: https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf Args: doc_lists: A list of rank lists, where each rank list contains unique items. Returns: list: The final aggregated list of items sorted by their weighted RRF scores in descending order. \u0026#34;\u0026#34;\u0026#34; if len(doc_lists) != len(self.weights): raise ValueError( \u0026#34;Number of rank lists must be equal to the number of weights.\u0026#34; ) # Associate each doc\u0026#39;s content with its RRF score for later sorting by it # Duplicated contents across retrievers are collapsed \u0026amp; scored cumulatively rrf_score: Dict[str, float] = defaultdict(float) for doc_list, weight in zip(doc_lists, self.weights): for rank, doc in enumerate(doc_list, start=1): rrf_score[ doc.page_content if self.id_key is None else doc.metadata[self.id_key] ] += weight / (rank + self.c) # Docs are deduplicated by their contents then sorted by their scores all_docs = chain.from_iterable(doc_lists) sorted_docs = sorted( unique_by_key( all_docs, lambda doc: doc.page_content if self.id_key is None else doc.metadata[self.id_key], ), reverse=True, key=lambda doc: rrf_score[ doc.page_content if self.id_key is None else doc.metadata[self.id_key] ], ) return sorted_docs 排序模型 在信息检索和问答系统中，处理用户查询通常分为两个步骤：召回（retrieval）和重排序（reranking）。\n召回的目标是用非常短的时间在海量数据中找到一定范围的备选项。这一过程的精度可能不会特别高，但可以将候选项从千万量级压缩到百量级。（这一过程涉及ANN也就是Approximate Nearest Neighbor， 在本文的后段会提及）\n重排序阶段，需要从召回阶段的备选项中选择符合需要的选项。由于候选项数量已经大幅减少，可以采用精度较高但相对计算时间较长的算法对这些备选项进行重新排序，以提高最终结果的准确性。\n重排序阶段场景的模型如`BAAI/bge 系列，从其huggingface仓库中的config.json可以发现：\n\u0026#34;_name_or_path\u0026#34;: \u0026#34;BAAI/bge-m3\u0026#34;, \u0026#34;architectures\u0026#34;: [ \u0026#34;XLMRobertaForSequenceClassification\u0026#34; ], 其本质是基于**XLM-RoBERTa**的序列分类模型。在下游任务中，对于序列分类任务，XLMRobertaForSequenceClassification 在 XLM-RoBERTa 的基础上添加了一个分类层（一个全连接层）来进行分类；简单来说，对于信息检索或问答系统中，输入用户问题（query），和匹配到的doc，通过合并query和doc形成一个sequence（[CLS]query[SEP]doc[SEP]），通过XLMRobertaForSequenceClassification 可以计算出二者的相关性分数，遍历候选集中的doc（一般在百数量级左右），即可得到query同候选集相关性分数。\n一些新的工作 Matryoshka Representation Learning（MRL） 来源于OpenAI 的embedding 技术：New embedding models and API updates\n和NeurIPS 2022发表的论文：Matryoshka Representation Learning\nMotivation：现有的深度学习模型通常学习固定维度的表示，无法灵活适应任务需求；表示维度的难以确定；表示维度缺乏粗到细（coarse-to-fine）的粒度；\nMRL旨在学习具有不同粒度的表示，允许单个embedding适应下游任务的计算约束。其设计思想是为了在不同的embedding维度上使用损失函数，从而训练一个模型，使其在不同的embedding维度上都能保持良好的性能\n训练过程：MRL 在多个嵌套的维度上训练模型，使得每个低维度的表示都能作为数据点的有用表示。这样，模型在不同的任务和计算约束下都能表现良好。\n推理过程：在推理过程中，MRL 可以根据需要使用不同维度的嵌入。对于分类任务，可以从低维度开始，逐步使用更高维度的表示。对于检索任务，可以先使用低维度表示进行初步筛选，然后使用高维度表示进行精细排序。\n（具体可以参考论文和sentence_transformers中所实现的MatryoshkaLoss）\nbge-m3 paper\ngithub\nm3—即Multi-Linguality 支持多语言， Multi-Functionality 支持多种检索方式（Dense-retrieval，Sparse-Retrieval， Multi-Vec Retrieval），以及Multi-Granularity 支持多粒度的检索（sentence-level，Passage-level，和Doc-level）\npip install -U FlagEmbedding Dense Embedding from FlagEmbedding import BGEM3FlagModel model = BGEM3FlagModel(\u0026#39;BAAI/bge-m3\u0026#39;, use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation sentences_1 = [\u0026#34;What is BGE M3?\u0026#34;, \u0026#34;Defination of BM25\u0026#34;] model.encode(sentences_1) print(model.encode(sentences_1)[\u0026#39;dense_vecs\u0026#39;].shape) # (2, 1024) Sparse Embedding (Lexical Weight) output_1 = model.encode(sentences_1, return_dense=True, return_sparse=True, return_colbert_vecs=False) output_1 \u0026#34;\u0026#34;\u0026#34; {\u0026#39;dense_vecs\u0026#39;: array([[-0.03412 , -0.04706 , -0.0009317, ..., 0.0483 , 0.007576 , -0.02959 ], [-0.01026 , -0.0449 , -0.02432 , ..., -0.00828 , 0.01502 , 0.011086 ]], dtype=float16), \u0026#39;lexical_weights\u0026#39;: [defaultdict(int, {\u0026#39;4865\u0026#39;: 0.0836, \u0026#39;83\u0026#39;: 0.0814, \u0026#39;335\u0026#39;: 0.1295, \u0026#39;11679\u0026#39;: 0.252, \u0026#39;276\u0026#39;: 0.17, \u0026#39;363\u0026#39;: 0.2695, \u0026#39;32\u0026#39;: 0.04083}), defaultdict(int, {\u0026#39;262\u0026#39;: 0.04996, \u0026#39;5983\u0026#39;: 0.1367, \u0026#39;2320\u0026#39;: 0.04483, \u0026#39;111\u0026#39;: 0.06335, \u0026#39;90017\u0026#39;: 0.2517, \u0026#39;2588\u0026#39;: 0.3335})], \u0026#39;colbert_vecs\u0026#39;: None} \u0026#34;\u0026#34;\u0026#34; # you can see the weight for each token: print(model.convert_id_to_token(output_1[\u0026#39;lexical_weights\u0026#39;])) # [{\u0026#39;What\u0026#39;: 0.08356, \u0026#39;is\u0026#39;: 0.0814, \u0026#39;B\u0026#39;: 0.1296, \u0026#39;GE\u0026#39;: 0.252, \u0026#39;M\u0026#39;: 0.1702, \u0026#39;3\u0026#39;: 0.2695, \u0026#39;?\u0026#39;: 0.04092}, # {\u0026#39;De\u0026#39;: 0.05005, \u0026#39;fin\u0026#39;: 0.1368, \u0026#39;ation\u0026#39;: 0.04498, \u0026#39;of\u0026#39;: 0.0633, \u0026#39;BM\u0026#39;: 0.2515, \u0026#39;25\u0026#39;: 0.3335}] # compute the scores via lexical mathcing print(model.compute_lexical_matching_score(output_1[\u0026#39;lexical_weights\u0026#39;][0], output_1[\u0026#39;lexical_weights\u0026#39;][1])) # 0 Multi-Vector (ColBERT) sentences_1 = [\u0026#34;What is BGE M3?\u0026#34;, \u0026#34;Defination of BM25\u0026#34;] output_1 = model.encode(sentences_1, return_dense=True, return_sparse=True, return_colbert_vecs=False) print(output_1[\u0026#39;colbert_vecs\u0026#39;][0].shape) # (8, 1024) print(model.colbert_score(output_1[\u0026#39;colbert_vecs\u0026#39;][0], output_1[\u0026#39;colbert_vecs\u0026#39;][1])) # tensor(0.4768) ColBERT score： 在计算完查询和文档之间的相似度矩阵后，对每个查询token选择与文档中token的最大相似度，将所有最大相似度累加，得到最终的colbert_score。\n基于LLM实现embedding 几个代表模型：\nAlibaba-NLP/gte-Qwen2-7B-instruct\nintfloat/e5-mistral-7b-instruct\ne5-mistral-7b-instruct论文：Improving Text Embeddings with Large Language Models\nconfig.json:\n{ \u0026#34;_name_or_path\u0026#34;: \u0026#34;mistralai/Mistral-7B-v0.1\u0026#34;, \u0026#34;architectures\u0026#34;: [ \u0026#34;MistralModel\u0026#34; ], \u0026#34;bos_token_id\u0026#34;: 1, \u0026#34;eos_token_id\u0026#34;: 2, \u0026#34;hidden_act\u0026#34;: \u0026#34;silu\u0026#34;, \u0026#34;hidden_size\u0026#34;: 4096, \u0026#34;initializer_range\u0026#34;: 0.02, \u0026#34;intermediate_size\u0026#34;: 14336, \u0026#34;max_position_embeddings\u0026#34;: 32768, ... 通过LLM生成数据（合成数据）， 采用对比学习微调Mistral-7B；\nGiven a pretrained LLM, we append an [EOS] token to the end of the query and document, and then feed them into the LLM to obtain the query and document embeddings $(h_{q_{inst}^+}, h_d^+)$, by taking the last layer [EOS] vector.\n附录 如何找到合适的embedding模型和reranker模型 首先推荐从 huggingface MTEB Leaderboard上选择排名靠前的模型\n其次，实验！根据自己的场景构造测试集验证，才能选择出适合自己场景的embedding模型和reranker模型；\nembedding模型和reranker模型的注意事项 上下文长度限制。 这些模型大多本质是Bert-based 模型， 而Bert的上下文长度限制一般是512，具体可以在huggingface中的config.json中查看；以BAAI/bge-base-en-v1.5 为例\n{ \u0026#34;_name_or_path\u0026#34;: \u0026#34;/root/.cache/torch/sentence_transformers/BAAI_bge-base-en/\u0026#34;, \u0026#34;architectures\u0026#34;: [ \u0026#34;BertModel\u0026#34; ], \u0026#34;attention_probs_dropout_prob\u0026#34;: 0.1, \u0026#34;classifier_dropout\u0026#34;: null, \u0026#34;gradient_checkpointing\u0026#34;: false, \u0026#34;hidden_act\u0026#34;: \u0026#34;gelu\u0026#34;, \u0026#34;hidden_dropout_prob\u0026#34;: 0.1, \u0026#34;hidden_size\u0026#34;: 768, \u0026#34;id2label\u0026#34;: { \u0026#34;0\u0026#34;: \u0026#34;LABEL_0\u0026#34; }, \u0026#34;initializer_range\u0026#34;: 0.02, \u0026#34;intermediate_size\u0026#34;: 3072, \u0026#34;label2id\u0026#34;: { \u0026#34;LABEL_0\u0026#34;: 0 }, \u0026#34;layer_norm_eps\u0026#34;: 1e-12, \u0026#34;max_position_embeddings\u0026#34;: 512, \u0026#34;model_type\u0026#34;: \u0026#34;bert\u0026#34;, \u0026#34;num_attention_heads\u0026#34;: 12, \u0026#34;num_hidden_layers\u0026#34;: 12, \u0026#34;pad_token_id\u0026#34;: 0, \u0026#34;position_embedding_type\u0026#34;: \u0026#34;absolute\u0026#34;, \u0026#34;torch_dtype\u0026#34;: \u0026#34;float32\u0026#34;, \u0026#34;transformers_version\u0026#34;: \u0026#34;4.30.0\u0026#34;, \u0026#34;type_vocab_size\u0026#34;: 2, \u0026#34;use_cache\u0026#34;: true, \u0026#34;vocab_size\u0026#34;: 30522 } 其中`\u0026quot;max_position_embeddings\u0026quot;: 512, 也就是它的上下文长度，但输入sequence长度超过512个token，则模型只看到了最前面的512个token；\n向量维度\n微调\n如何微调embedding 模型 采用FlagEmbedding，参考：How to fine-tune bge embedding model?\n微调Sentence Transformer，参考：Training Overview\n还有哪些类型的reranker模型 根据ColBert文章\n作者将query-document matching 任务（reranking）分类成：\nRepresentation-based Similarity, 双塔，独立对查询和文档进行编码，然后通过计算它们的向量相似度进行匹配， 但query和doc间无更精细的交互。\nQuery-Document interaction： 在查询和文档之间直接进行交互，通常使用CNN来捕捉查询和文档之间的交互特征， 但交互计算复杂度较高，尤其是当查询和文档长度较长时。\nAll-to-All Interaction，基于Bert 的Cross-encoder结构， 查询和文档的每个词与对方的每个词进行全连接交互。这种方式可以捕捉细粒度的交互信息，通常需要较高的计算资源。\nLate Interaction， 迟交互型，在对查询和文档的每个词进行独立编码后，再进行交互计算。通常使用最大池化（MaxSim）来选择最相关的词进行匹配，从而结合了高效性和细粒度交互的优点。\n此外， 当然也有基于LLMs的reranker，参考：llm_reranker\n以 BAAI/bge-reranker-v2-gemma 为例， 只是做这样一件事\nprompt = \u0026#34;Given a query A and a passage B, determine whether the passage contains an answer to the query by providing a prediction of either \u0026#39;Yes\u0026#39; or \u0026#39;No\u0026#39;.\u0026#34; 以输出“Yes” 的logit 作为相关分数\n对比学习 在之前不断提到了embedding，当然， 和transformer中的embedding层不是一个东西；\n这里所指的embedding是通过对比学习的方式，将语义相近的文本映射到高维参数空间中的相近位置，使它们的距离尽可能短。相反，语义差别大的文本则被映射到参数空间中远离的位置。类似地，这种方法也可以应用于图像（相似图像检索）以及文本和图像的多模态语义匹配（如CLIP）。那么，对比学习有三个核心：loss function，网络架构和采样。\n对比学习有三个核心要素：网络架构、损失函数（loss function）和采样策略。\n常见的损失函数有contrastive loss、triplet loss，以及N-pair loss。\n网络架构方面,对比学习通常采用双塔(siamese network)或者三塔(triplet)结构。双塔结构包含两个相同或相似的编码器,分别用于处理正样本对;三塔结构则增加了一个用于处理负样本的编码器。这些编码器可以是各种深度学习模型,如CNN、RNN或Transformer等,具体选择取决于任务域和数据类型。这一步将原始较为复杂的数据类型，通过深度学习的方法降到相对较低的维度便于之后的计算。\n对于双塔结构， 一般采用Contrastive Loss， 其用于度量两个样本之间的相似度。其公式为：\n$$ L = \\frac{1}{2N} \\sum_{i=1}^N (y_i d_i^2 + (1 - y_i) \\max(0, m - d_i)^2) $$\n其中：\n$d_i$是样本对$(x_i, x_j)$ 的欧几里得距离。\n$y_i$ 是样本对的标签，1 表示正样本对，0 表示负样本对。\nm 是一个超参数，表示负样本对之间的最小距离，也称margin。\nTriplet Loss则使用于triplet-network结构, 其通过构造三元组 ( anchor, positive, negative) 来训练模型，使得正样本（positive）与锚点（anchor）的距离小于负样本（negative）与锚点的距离。其公式为：\n$$ L = \\sum_{i=1}^N \\left[ |f(x_i^a) - f(x_i^p)|_2^2 - |f(x_i^a) - f(x_i^n)|_2^2 + \\alpha \\right] $$\n其中：\n$f(x)$ 表示样本 x 的特征向量。\n$\\alpha$是一个超参数，表示正负样本对之间的最小距离差。\nN-pair Loss 是 Triplet Loss 的推广，通过引入多个负样本来提升训练效果。\n$$ L = \\sum_{i=1}^N \\log \\left( 1 + \\sum_{j \\neq i} \\exp \\left( f(x_i)^\\top f(x_j^n) - f(x_i)^\\top f(x_i^p) \\right) \\right) $$\n在训练过程中， 采样策略则很关键；但运气不好， 选择的样本都是Easy Negative mining，也就是$d(a,p)+margin\u0026lt;d(a,n)$，则模型能够很快收敛，但什么也没有学会，相反在另一个极端中， 采用的多是hard negative mining，也就是$d(a,n)\u0026lt;d(a,p)$的情况，此时模型训练将很难收敛；实际情况中， 往往采用semi-hard 或者是distance-weighted sampling 来寻找难度适中的负样本,以避免模型过于关注极端情况。而由于在高维空间下， 因为高维空间中大部分体积都集中在高维球壳上，所以随机采样得到的点之间的距离往往非常接近，这也是不采用随机采样的策略的原因（Sampling Matters in Deep Embedding Learning）。\n向量库是个什么东西 向量库不是“库”，但也是“库”；\n考虑到传统关系型数据库， 数据以表格形式存储， 但在AI时代， 大量非结构化数据的存储和查询，以表格形式存在这不太合理了；因为数据维度高， 需要一些特殊的查询方式；\n不同于传统数据库的精确匹配查询,向量库主要用于相似性搜索。这种搜索基于向量间的距离,通常使用欧几里得距离或余弦相似度。以暴力遍历的最近邻查询为例(Nearest neighbor search),假设我们有n个d维向量,查询复杂度为$O(nd)$。当n和d都很大时,这种方法变得非常耗时。\n而近似最近邻搜索(Approximate Nearest Neighbor search, ANN)则能将时间复杂度降低到亚线性,通常为$O(log n)$或更优。\n常见的ANN算法：\n基于树的：k-D树(k-D tree):将空间递归地划分为子空间,适用于低维数据。\n基于哈希的：局部敏感哈希(LSH, Locality-Sensitive Hashing):将相似的向量映射到相同的\u0026quot;桶\u0026quot;中。\n乘积量化(Product Quantization):将高维向量分解为低维子向量,并对每个子向量进行量化。\n基于Graph的：分层可导航小世界图(HNSW, Hierarchical Navigable Small World):构建多层图结构,在图上进行快速导航搜索。\n而以上算法的思路都可以归介于—将相似的样本放在一起（减少搜索空间）， 和构建高效的搜索结构。\n参考 Build a search engine, not a vector DB\nHybrid Search Explained\n再谈大模型RAG问答中的三个现实问题：兼看RAG-Fusion多query融合策略、回答引文生成策略及相关数据集概述\nLLM - RAG文档应用处理与召回经验之谈\n[RAG] BGE M3-Embedding | 什么？我的RAG底座模型又要换了？\nColBERT: A complete guide\n搜索引擎技术\nUtilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges\nColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\nLLM4IR-Survey\nFine-Tuning LLaMA for Multi-Stage Text Retrieval\n","permalink":"https://niraya666.github.io/posts/rag%E6%A3%80%E7%B4%A2/","summary":"\u003cblockquote\u003e\n\u003cp\u003eIf you want to make a good RAG tool that uses your documentation, you should start by making a search engine over those documents that would be good enough for a human to use themselves. This is likely something your organization has considered before, and if it doesn’t exist it’s because building a good search engine has traditionally been a significant undertaking.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e— from \u003ca href=\"https://blog.elicit.com/search-vs-vector-db/\"\u003eBuild a search engine, not a vector DB\u003c/a\u003e\u003c/p\u003e","title":"RAG工具箱：检索"},{"content":"本文将简单介绍如何评价LLM的tool-using 能力。\n引言 在工具使用评估方面，过去的研究主要有以下几种思路：\n对比工具使用和纯LLM在基准测试上的分数：例如Toolformer和LATM。\n在Toolformer研究中，通过下游任务如语言模型评估基准测试、数学推理任务和问答任务来验证工具使用的有效性。\nLATM则采用了来自BigBench的六个数据集进行评估。\n测试工具使用的准确率和响应质量：例如API-Bank。\n在评估过程中，首先初始化评估系统，确保每个API的数据库包含默认值。然后，将预测的API调用与手动标注的API调用进行比较，以确定它们的一致性。响应评估则使用ROUGE-L指标。 利用LLM对工具使用的效果进行评价：例如Tool-bench。\ntwo evaluation metrics:\nPass Rate: Calculates the proportion of successfully completing an instruction within limited OpenAI API calls.\nPreference: Measured by comparing two answers (action sequences) for a given instruction.We pre-define a set of criteria for a better answer, which are organized as prompts for ChatGPT.\n构造虚拟运行环境，测试代理与环境的交互结果：例如ToolAlpaca。\n利用LLM模拟环境（用户代理和助手代理），并使用GPT-4对ToolAlpaca模型进行机器评估，评估其使用各种未见工具的能力。 对于绝大多数企业和垂直场景下， 其中思路1需要构建额外的测试集成本比较高（但还是有必要的）， 而思路4构造虚拟运行环境实际上并不现实； 所以还是选择思路2，外加通过思路3辅助判断；换句话说， 根据场景，构造工具列表和工具调用的ground-truth（包括函数名， 和传入参数） ，在存在歧义时，采用ROUGE评价响应质量， 或者使用LLM判断响应结果并评价。\n顺带提一下Langchain 项目中有关Agent的tool-using能力测试的内容， 不过由于Langchain项目又臭又长，且有很大的局限性， 这里只讨论其思路。\n在 Benchmarking Agent Tool Use 一文中，提出了4种指标用于评价Agent 的tool-using 能力：\nCorrectness 即通过LLM判断工具调用结果是否同ground truth 相同；\nCorrect final state 即检查agent 所交互环境的最终状态是否同预期相同；\nIntermediate step correctness 除了最终状态， 也可以检查中间状态；\nRatio of steps taken to the expected steps 即实际步骤与预期步骤的比例。\n在LangChain Benchmarks 项目提供了4个（3个）任务用于测试tool-using， 本质上也是一种构造虚拟环境并与之交互。\nMultiverse Math 任务 ： 要求模型使用提供的工具来解决数学问题。为了确保模型不依赖于内在知识，数学运算被修改以产生不同于预期的结果。例如，乘法和加法的结果会有所不同，但仍保留某些数学性质。 任务示例包括基本的加减乘除运算、幂运算、对数运算等。\ncode \u0026#34;\u0026#34;\u0026#34;Solve basic math question using the provided tools. Must use the provided tools to solve the math question. To make sure that innate knowledge is not used, the math operations have been altered to yield different results than expected. The modified operations should yield different results, but still retain appropriate properties. For example, the modified multiplication operation should still be commutative. Please note that the modified operations are not guaranteed to even make sense in the real world since not all properties will be retained (e.g., distributive property). For example, I ate 1 apple and 2 oranges every day for 7 days. How many fruits did I eat? One would expect the answer to be 21, but in this universe, the answer is 32.34. In addition, it depends on how the operations are grouped: (1 + 2) * 7 = 32.34 But: 1 * 7 + 2 * 7 = 24.3 Due to these changes certain questions are not allowed as inputs as they would yield different results if evaluated in different ways. For example, \u0026#34;convert 15 degrees to radians\u0026#34; is not allowed as an input as it could be interpreted as either: divide(multiply(15, pi()), 180) or multiply(divide(15, 180), pi()) \u0026#34;\u0026#34;\u0026#34; Relational Data任务 ：要求模型使用提供的工具来回答关于关系数据的问题。环境中包含关于用户及其位置和喜好食物的虚假数据，模型需要使用工具查询这些数据以回答问题。 任务示例包括查询用户的位置信息、喜好食物等\ncode \u0026#34;\u0026#34;\u0026#34;Answer questions about relational data using the provided tools. The environment contains fake data about users and their locations and favorite foods. The environment provides a set of tools that can be used to query the data. All questions can be answered by using the provided tools. The answers include the expected result as well as the most efficient way to answer the question using the tools. \u0026#34;\u0026#34;\u0026#34; Typewriter(single-tool, 26-tools): 要求模型使用工具逐字打印给定的字符串。模型需要调用工具来模拟打字机的行为，每次打印一个字符，直到完成整个字符串。 任务示例包括打印特定的句子或段落。\ncode ```python \u0026quot;\u0026quot;\u0026quot;A task where the agent must type a given string one letter at a time. In this variation of the task, the agent is given a single function, that takes a letter as an argument. \u0026quot;\u0026quot;\u0026quot; ``` 根据综述文章《What Are Tools Anyway? A Survey from the Language Model Perspective》，在验证代理或模型的工具使用能力时，可以关注以下指标：\nTask completion：任务完成度，或pass-ratio 这是一个相对宏观的指标， 工具调用的最核心目的就是为了完成任务， 任务的成功与否表征了工具调用的最终结果。\nTool selection： 如何在众多工具中挑选到最合适的工具，这考验了模型在特定场景下对任务的理解和最优化的工具选择；\nTool reusability： 指的是一个工具在不同情境下或解决不同问题时能够被多次使用的能力， 不过往往和工具生成（tool-marking）相关， 不在这次的讨论范围中。\n方法论 综合以上讨论， tool-using 的测试可以简单分为：\n单轮简单测试 在这种测试中，主要测试function_name 和传入参数。关注的指标是pass-rate 和 Preference。具体方法是不需要使用LLM进行判断，只需将返回的function_name 和 function_arguments 与ground-truth进行比对，确认是否一致。最终使用pass-ratio 评价测试结果。\nJson-mode验证 由于并非所有模型都能严格按要求输出所需要的json格式，考虑到这种情况，可以进行Json-mode的验证，以确保输出格式的正确性。\n优化版本\n通过ROUGE判断function_arguments\n目的：避免严格一致所带来的问题。 通过LLM辅助判断function_arguments\n优点：准确率更高。\n缺点：成本也更高。\n多轮调用 以上单轮tool-using测试在复杂场景下不太适用。\n在一些复杂场景中，如代码生成与执行、SQL生成并执行等，需要按照一定顺序调用多个tools。这些场景需要LLM根据前几次tool-using的结果反馈，调整function_arguments 或 function_name。\n这些场景无外乎都需要LLM根据前几次tool-using的结果反馈， 修改function_arguments 或者是function_name；\n将tool-using的过程抽象为强化学习中agent同环境(env)的交互过程。目标是减少agent与环境的交互次数，从而降低成本，并争取一次或者几次就能做对，避免重复错误。可以借用langchain中的思想，增加对中间和最终状态的检查，并比对实际交互次数和预期交互次数。这类测试需要额外构建虚拟环境，超出此次讨论范围。\n测试集 NousResearch/func-calling-eval-glaive\nNousResearch/func-calling-eval-singleturn\nNousResearch/func-calling-eval\n上手：测试LLM的tool-using 能力 这里，选择最简单的tool-using用于演示， 即直接调用OpenAI 的tool-using API\n环境 import os # os.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] = \u0026#34;...\u0026#34; from openai import OpenAI import json client = OpenAI() 定义工具函数 考虑了一个简单的医疗场景，共4个工具；\ntools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_medical_definition\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the definition of a medical term\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;term\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The medical term to define\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;term\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_treatment_options\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get treatment options for a disease\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;disease\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The disease to get treatment options for\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;disease\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_medication_side_effects\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the potential side effects of a medication\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;medication\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The name of the medication\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;medication\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_disease_symptoms\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the symptoms associated with a specific disease\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;disease\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The disease to get symptoms for\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;disease\u0026#34;] } } } ] 定义测试用例 创建测试用例数据集，每个测试用例包含查询、预期函数调用及其参数、以及期望的响应。\n使用GPT-4构建。\ntest_cases = [ { \u0026#34;query\u0026#34;: \u0026#34;What are the symptoms of influenza?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_disease_symptoms\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;disease\u0026#34;: \u0026#34;influenza\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Symptoms of influenza include fever, chills, muscle aches, cough, congestion, runny nose, headaches, and fatigue.\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;What is the definition of asthma?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_medical_definition\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;term\u0026#34;: \u0026#34;asthma\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Asthma is a condition in which your airways narrow and swell and may produce extra mucus, making breathing difficult and triggering coughing, wheezing, and shortness of breath.\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;What treatments are available for rheumatoid arthritis?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_treatment_options\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;disease\u0026#34;: \u0026#34;rheumatoid arthritis\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Treatment options for rheumatoid arthritis include medications such as NSAIDs, steroids, DMARDs, and biologics, as well as physical therapy and lifestyle changes.\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;What are the side effects of metformin?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_medication_side_effects\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;medication\u0026#34;: \u0026#34;metformin\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Common side effects of metformin include gastrointestinal issues such as diarrhea, nausea, and abdominal discomfort, as well as lactic acidosis in rare cases.\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;What symptoms are associated with hypothyroidism?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_disease_symptoms\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;disease\u0026#34;: \u0026#34;hypothyroidism\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Symptoms of hypothyroidism include fatigue, weight gain, cold intolerance, dry skin, constipation, and depression.\u0026#34; }, ... ] 定义测试metrics 自定义了pass-ratio，即function_name, function_arguments 严格一致为pass。\n运行测试并验证响应 def call_openai_tool(model, prompt, tools): response = client.chat.completions.create( model=model, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: prompt} ], tools=tools, tool_choice=\u0026#34;auto\u0026#34; ) return response def run_tests(test_cases, model=deployment_name): passed_tests = 0 failed_tests = 0 for case in test_cases: response = call_openai_tool(model, case[\u0026#39;query\u0026#39;], tools) if case[\u0026#39;expected_function\u0026#39;] and case[\u0026#39;function_arguments\u0026#39;]: if response.choices[0].message.tool_calls: tool_calls = response.choices[0].message.tool_calls # 验证函数调用名称和参数 try: assert tool_calls[0].function.name == case[\u0026#39;expected_function\u0026#39;], f\u0026#34;Expected function {case[\u0026#39;expected_function\u0026#39;]}, but got {tool_calls[0].function.name}\u0026#34; assert json.loads(tool_calls[0].function.arguments) == case[\u0026#39;function_arguments\u0026#39;], f\u0026#34;Expected arguments {case[\u0026#39;function_arguments\u0026#39;]}, but got {tool_calls[0].function.arguments}\u0026#34; print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 except AssertionError as e: print(e) print(f\u0026#34;Test failed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test failed for query (no tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: # # 验证响应内容 # response_text = response.choices[0].message.content.strip() # 验证没有调用工具 if response.choices[0].message.tool_calls: print(f\u0026#34;Test failed for query (unexpected tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 total_tests = passed_tests + failed_tests accuracy = (passed_tests / total_tests) * 100 if total_tests \u0026gt; 0 else 0 print(f\u0026#34;Total tests: {total_tests}, Passed: {passed_tests}, Failed: {failed_tests}, Accuracy: {accuracy:.2f}%\u0026#34;) run_tests(test_cases) 结果：\nTest passed for query: What are the symptoms of chronic kidney disease? Test passed for query: What does the medical term \u0026#39;bipolar disorder\u0026#39; mean? Expected arguments {\u0026#39;disease\u0026#39;: \u0026#39;chronic obstructive pulmonary disease\u0026#39;}, but got { \u0026#34;disease\u0026#34;: \u0026#34;COPD\u0026#34; } Test failed for query: What are the treatment options for chronic obstructive pulmonary disease (COPD)? Test passed for query: What side effects are associated with the use of aspirin? Test passed for query: Tell me a joke. Test passed for query: What is the capital of France? Total tests: 22, Passed: 21, Failed: 1, Accuracy: 95.45% 对于test failed case， 这只是个模凌两可的错误。\n如果采用LLM作为裁判是可以避免的。\n基于ROUGE的响应判断 环境\n! pip install rouge-score --quiet from rouge_score import rouge_scorer def calculate_rouge_l(predicted, expected): scorer = rouge_scorer.RougeScorer([\u0026#39;rougeL\u0026#39;], use_stemmer=True) scores = scorer.score(predicted, expected) return scores[\u0026#39;rougeL\u0026#39;].fmeasure def run_tests_with_rouge(test_cases, model=deployment_name, rouge_l_threshold=0.8): passed_tests = 0 failed_tests = 0 for case in test_cases: response = call_openai_tool(model, case[\u0026#39;query\u0026#39;], tools) if case[\u0026#39;expected_function\u0026#39;] and case[\u0026#39;function_arguments\u0026#39;]: if response.choices[0].message.tool_calls: tool_calls = response.choices[0].message.tool_calls # 验证函数调用名称和参数 try: assert tool_calls[0].function.name == case[\u0026#39;expected_function\u0026#39;], f\u0026#34;Expected function {case[\u0026#39;expected_function\u0026#39;]}, but got {tool_calls[0].function.name}\u0026#34; predicted_arguments = json.loads(tool_calls[0].function.arguments) # 计算ROUGE-L分数 rouge_l_score = calculate_rouge_l(json.dumps(predicted_arguments), json.dumps(case[\u0026#39;function_arguments\u0026#39;])) assert rouge_l_score \u0026gt;= rouge_l_threshold, f\u0026#34;ROUGE-L score {rouge_l_score} is less than threshold {rouge_l_threshold}\u0026#34; print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 except AssertionError as e: print(e) print(f\u0026#34;Test failed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test failed for query (no tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: # 验证没有调用工具 if response.choices[0].message.tool_calls: print(f\u0026#34;Test failed for query (unexpected tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 total_tests = passed_tests + failed_tests accuracy = (passed_tests / total_tests) * 100 if total_tests \u0026gt; 0 else 0 print(f\u0026#34;Total tests: {total_tests}, Passed: {passed_tests}, Failed: {failed_tests}, Accuracy: {accuracy:.2f}%\u0026#34;) 使用ROUGE-L 计算function_arguments 同预期的差距，若大于一定阈值，则判断失败。\n基于LLM验证和判断 def chat_completion_request(messages, tools=None, tool_choice=None, model=deployment_name, json_mode=False): try: params = { \u0026#39;model\u0026#39;: model, \u0026#39;messages\u0026#39;: messages, \u0026#39;tools\u0026#39;: tools, \u0026#39;tool_choice\u0026#39;: tool_choice } if json_mode: params[\u0026#39;response_format\u0026#39;] = { \u0026#34;type\u0026#34;: \u0026#34;json_object\u0026#34; } response = client.chat.completions.create(**params) return response except Exception as e: print(\u0026#34;Unable to generate ChatCompletion response\u0026#34;) print(f\u0026#34;Exception: {e}\u0026#34;) return e def evaluate_with_llm(predicted_arguments, expected_arguments, model, tools): prompt = f\u0026#34;\u0026#34;\u0026#34; Compare the following predicted arguments and expected arguments for a function call. Predicted Arguments: {json.dumps(predicted_arguments, indent=2)} Expected Arguments: {json.dumps(expected_arguments, indent=2)} Evaluate if the predicted arguments sufficiently match the expected arguments, considering minor differences acceptable. Respond with a JSON object containing a single key \u0026#34;match\u0026#34; with a boolean value indicating if they match. Example response: {{ \u0026#34;match\u0026#34;: true }} \u0026#34;\u0026#34;\u0026#34; response = chat_completion_request(messages=[{\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: prompt}],model = model, json_mode=True) json_response = json.loads(response.choices[0].message.content) return json_response.get(\u0026#34;match\u0026#34;, False) def run_tests_with_llm(test_cases, model=deployment_name, rouge_l_threshold=0.8): passed_tests = 0 failed_tests = 0 for case in test_cases: response = call_openai_tool(model, case[\u0026#39;query\u0026#39;], tools) if case[\u0026#39;expected_function\u0026#39;] and case[\u0026#39;function_arguments\u0026#39;]: if response.choices[0].message.tool_calls: tool_calls = response.choices[0].message.tool_calls # 验证函数调用名称和参数 try: assert tool_calls[0].function.name == case[\u0026#39;expected_function\u0026#39;], f\u0026#34;Expected function {case[\u0026#39;expected_function\u0026#39;]}, but got {tool_calls[0].function.name}\u0026#34; predicted_arguments = json.loads(tool_calls[0].function.arguments) # 使用 LLM 来判断参数匹配 match = evaluate_with_llm(predicted_arguments, case[\u0026#39;function_arguments\u0026#39;], model, tools) assert match, \u0026#34;LLM evaluation determined the arguments do not match\u0026#34; print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 except AssertionError as e: print(e) print(f\u0026#34;Test failed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test failed for query (no tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: # 验证没有调用工具 if response.choices[0].message.tool_calls: print(f\u0026#34;Test failed for query (unexpected tool call): {case[\u0026#39;query\u0026#39;]}\u0026#34;) failed_tests += 1 else: print(f\u0026#34;Test passed for query: {case[\u0026#39;query\u0026#39;]}\u0026#34;) passed_tests += 1 total_tests = passed_tests + failed_tests accuracy = (passed_tests / total_tests) * 100 if total_tests \u0026gt; 0 else 0 print(f\u0026#34;Total tests: {total_tests}, Passed: {passed_tests}, Failed: {failed_tests}, Accuracy: {accuracy:.2f}%\u0026#34;) 附: prompt 生成示例 def chat_completion_request(messages, tools=None, tool_choice=None, model=deployment_name, json_mode=False): try: params = { \u0026#39;model\u0026#39;: model, \u0026#39;messages\u0026#39;: messages, \u0026#39;tools\u0026#39;: tools, \u0026#39;tool_choice\u0026#39;: tool_choice } if json_mode: params[\u0026#39;response_format\u0026#39;] = { \u0026#34;type\u0026#34;: \u0026#34;json_object\u0026#34; } response = client.chat.completions.create(**params) return response except Exception as e: print(\u0026#34;Unable to generate ChatCompletion response\u0026#34;) print(f\u0026#34;Exception: {e}\u0026#34;) return e def generate_test_cases_from_tools(tools, examples): tools_descriptions = \u0026#34;\\n\u0026#34;.join([ f\u0026#34;- {tool[\u0026#39;function\u0026#39;][\u0026#39;name\u0026#39;]}: {tool[\u0026#39;function\u0026#39;][\u0026#39;description\u0026#39;]} (Parameters: {\u0026#39;, \u0026#39;.join(tool[\u0026#39;function\u0026#39;][\u0026#39;parameters\u0026#39;][\u0026#39;properties\u0026#39;].keys())})\u0026#34; for tool in tools ]) prompt = f\u0026#34;\u0026#34;\u0026#34; Create a series of test cases for evaluating the tool-using capabilities of a language model. The test cases should be relevant to the domain and should utilize the provided tools. Each test case should include the following fields: - query: A question or request related to the domain. - expected_function: The function that should be called to answer the query. - function_arguments: The arguments that should be passed to the function. - expected_response: The expected response from the function. The available tools are: {tools_descriptions} Here are some examples to follow: {examples} Now, generate 10 more test cases in the same format utilizing the provided tools. Make sure the output format is JSON and enclose the result in triple backticks (```): \u0026#34;\u0026#34;\u0026#34; return prompt # Example usage tools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_medical_definition\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the definition of a medical term\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;term\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The medical term to define\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;term\u0026#34;] } } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_treatment_options\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get treatment options for a disease\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;disease\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The disease to get treatment options for\u0026#34;} }, \u0026#34;required\u0026#34;: [\u0026#34;disease\u0026#34;] } } } ] examples = \u0026#34;\u0026#34;\u0026#34; [ { \u0026#34;query\u0026#34;: \u0026#34;What is diabetes?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_medical_definition\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;term\u0026#34;: \u0026#34;diabetes\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Diabetes is a chronic condition that affects the way the body processes blood sugar (glucose).\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;How can hypertension be treated?\u0026#34;, \u0026#34;expected_function\u0026#34;: \u0026#34;get_treatment_options\u0026#34;, \u0026#34;function_arguments\u0026#34;: {\u0026#34;disease\u0026#34;: \u0026#34;hypertension\u0026#34;}, \u0026#34;expected_response\u0026#34;: \u0026#34;Treatment options for hypertension include lifestyle changes, such as diet and exercise, and medications like ACE inhibitors, beta-blockers, and diuretics.\u0026#34; } ] \u0026#34;\u0026#34;\u0026#34; sys_prompt = generate_test_cases_from_tools(tools, examples) messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: sys_prompt} ] resp = chat_completion_request(messages, json_mode=True) test_cases = eval(resp.choices[0].message.content) 参考 Function-calling \u0026amp; JSON-mode Evaluation\nBenchmarking Agent Tool Use\nWhat Are Tools Anyway? A Survey from the Language Model Perspective\nBerkeley Function Calling Leaderboard\nToolformer\nLATM\nAPI-Bank\nTool-bench\nToolAlpaca\n","permalink":"https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/","summary":"\u003cp\u003e本文将简单介绍如何评价LLM的tool-using 能力。\u003c/p\u003e\n\u003ch2 id=\"引言\"\u003e引言\u003c/h2\u003e\n\u003cp\u003e在工具使用评估方面，过去的研究主要有以下几种思路：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e对比工具使用和纯LLM在基准测试上的分数\u003c/strong\u003e：例如\u003ca href=\"https://arxiv.org/abs/2302.04761\"\u003eToolformer\u003c/a\u003e和\u003ca href=\"https://arxiv.org/abs/2305.17126\"\u003eLATM\u003c/a\u003e。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e在Toolformer研究中，通过下游任务如语言模型评估基准测试、数学推理任务和问答任务来验证工具使用的有效性。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLATM则采用了来自BigBench的六个数据集进行评估。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e测试工具使用的准确率和响应质量\u003c/strong\u003e：例如\u003ca href=\"https://arxiv.org/abs/2304.08244\"\u003eAPI-Bank\u003c/a\u003e。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e在评估过程中，首先初始化评估系统，确保每个API的数据库包含默认值。然后，将预测的API调用与手动标注的API调用进行比较，以确定它们的一致性。响应评估则使用ROUGE-L指标。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e利用LLM对工具使用的效果进行评价\u003c/strong\u003e：例如Tool-bench。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003etwo evaluation metrics:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePass Rate\u003c/strong\u003e: Calculates the proportion of successfully completing an instruction within limited OpenAI API calls.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePreference\u003c/strong\u003e: Measured by comparing two answers (action sequences) for a given instruction.We pre-define a set of criteria for a better answer, which are organized as prompts for ChatGPT.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e构造虚拟运行环境，测试代理与环境的交互结果\u003c/strong\u003e：例如ToolAlpaca。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e利用LLM模拟环境（用户代理和助手代理），并使用GPT-4对ToolAlpaca模型进行机器评估，评估其使用各种未见工具的能力。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e对于绝大多数企业和垂直场景下， 其中思路1需要构建额外的测试集成本比较高（但还是有必要的）， 而思路4构造虚拟运行环境实际上并不现实； 所以还是选择思路2，外加通过思路3辅助判断；换句话说， 根据场景，构造工具列表和工具调用的ground-truth（包括函数名， 和传入参数）  ，在存在歧义时，采用ROUGE评价响应质量， 或者使用LLM判断响应结果并评价。\u003c/p\u003e\n\u003cp\u003e顺带提一下Langchain 项目中有关Agent的tool-using能力测试的内容， 不过由于Langchain项目又臭又长，且有很大的局限性， 这里只讨论其思路。\u003c/p\u003e","title":"Agent学习笔记： 如何验证模型的tool-using能力"},{"content":"上周看了《坂本龙一：Opus》，特别喜欢其中有一首未收录在之前作品中的曲目《for Johann》\n第一反应是这首曲子可能是献给已故的冰岛作曲家Johann Johannsson，也是我最喜欢的音乐人之一\n不过，我找不到确切的证据\n万一是巴赫（Johann Sebastian Bach） 也有可能\n总觉得这首歌的旋律走向和Johann Johannsson的作品有某种神似，也有可能是我的错觉罢了吧\n试着弹一下这首歌， 顺带用AnthemScore扒了下谱子 可能有些小错误，但我希望能将这份音乐传递下去\n希望大家喜欢\nHe’s gone, but the music remains.\nありがとうございます\n感谢教授的最后礼物， 也感谢同样被迫包场的另两位陌生人\n","permalink":"https://niraya666.github.io/musik/for_johann/","summary":"\u003cp\u003e上周看了《坂本龙一：Opus》，特别喜欢其中有一首未收录在之前作品中的曲目《for Johann》\u003c/p\u003e\n\u003cp\u003e第一反应是这首曲子可能是献给已故的冰岛作曲家Johann Johannsson，也是我最喜欢的音乐人之一\u003c/p\u003e\n\u003cp\u003e不过，我找不到确切的证据\u003c/p\u003e\n\u003cp\u003e万一是巴赫（Johann Sebastian Bach） 也有可能\u003c/p\u003e\n\u003cp\u003e总觉得这首歌的旋律走向和Johann Johannsson的作品有某种神似，也有可能是我的错觉罢了吧\u003c/p\u003e\n\u003cp\u003e试着弹一下这首歌， 顺带用AnthemScore扒了下谱子\n可能有些小错误，但我希望能将这份音乐传递下去\u003c/p\u003e\n\u003cp\u003e希望大家喜欢\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/music/for_johnann/1.png\" alt=\"\"  /\u003e\n\n\u003cimg loading=\"lazy\" src=\"/img/music/for_johnann/2.png\" alt=\"\"  /\u003e\n\n\u003cimg loading=\"lazy\" src=\"/img/music/for_johnann/3.png\" alt=\"\"  /\u003e\n\n\u003cimg loading=\"lazy\" src=\"/img/music/for_johnann/4.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eHe’s gone, but the music remains.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eありがとうございます\u003c/p\u003e\n\u003cp\u003e感谢教授的最后礼物， 也感谢同样被迫包场的另两位陌生人\u003c/p\u003e","title":"【钢琴谱分享】坂本龙一《for Johann》"},{"content":"2024年 夏\n这是我第一次踏上泉州这片土地，虽然我是厦门人，已经快三十岁了，却一直没有机会来这座近在咫尺的城市。\n泉州在我想象中，是一座充满历史韵味的地方，同时也被一些暴发户的繁荣所点缀。几年前，这座城市成功申遗，从此逐渐成为小众旅游的热门选择。泉州的古老街区、传统建筑和浓厚的文化氛围，让人忍不住想一探究竟。\n大学时，我有一位好友家在泉州。我们是班里唯二的福建人，因此自然成了很好的朋友。每次听他讲起泉州的美食、风景，总让我心生向往。\n这次借着回家的机会，我终于决定亲自走一趟泉州。\n泉州，我来了！\n初印象 初到泉州，路上穿梭的电动车给我留下了深刻的第一印象。这些电动车在街头巷尾自由穿行，让我一度产生了身处越南的错觉。或许，这正是泉州的独特之处——在传统与现代之间，在历史与现实之中，找到一种和谐的平衡。\n作为古城，鲤城区似乎尽可能地保留着过去的模样。漫步在古城，却能产生一种记忆中的故乡的错觉，这一切似乎都太像了。\n那些熟悉的景象和气息，让人倍感亲切。有人说过，“离开了，故乡才称之为故乡。”庆幸的是，故乡以另一种形式呈现在我的面前，尽管这不是我的故乡。\n在鲤城区，街头的小贩、古早风格的便利店、上了年纪的理发店，无时无刻不把我拉回到记忆的深处。\n人 历史离不开人，特别是一个个普通人\n正是这些普通人，构成了这座城市的血脉与灵魂。他们的日常琐事，他们的勤劳与坚韧，使得这座古老的城市充满了生机与活力。在他们的身上，我看到了泉州的过去、现在和未来。\n宗教 泉州作为海上丝绸之路的起点，在那辉煌的历史长河中，不仅是贸易和文化交流的中心，也吸引了大量的外来文化和宗教。佛教、道教、伊斯兰教、基督教等多种宗教在这里交汇融合，形成了独特的宗教文化景观。经过千年的融合与发展，这些宗教在泉州和谐共存，互相尊重，不分彼此。\n吃 牛肉店 阿秋牛排馆\n牛排并不是传统意义上的steak，而是采用香料和咖喱炖煮而成的牛排骨。招牌牛排非常推荐，炖得非常软烂，入口即化，肉质瞬间脱骨。咖喱的香气与牛肉的原汁原味相得益彰，不会掩盖肉本身的美味。用汤汁拌饭，可谓是一绝。\n不过，对于从小习惯了晋江牛肉店的闽南人来说，阿秋牛排馆的汤味道可能稍显清淡，不够浓郁，因此未必合所有人的口味。此外，这家店的价格也比其他店稍高一些。\n除此之外，我的收藏夹里还有几家值得尝试的牛排店：\n阿波牛肉店\n天财牛肉店\n阿泉全牛馆\n面线糊 平阿面线糊\n我去的这家平阿面线糊，在周末早上8点左右已经挤满了人，足见其受欢迎程度。\n与厦门地区加入了猪血、虾米的面线糊相比，泉州的面线糊更多地呈现出字面上的意思——就是很单纯的面线糊。所用的面线更加细碎，完全不用担心吃太慢会坨，因为这甚至可以用面线汤来形容。但喝上一口汤，你会发现这绝不是一碗普通的面线汤，在汤头上，店家一定是下足了功夫的。\n食客可以根据自己的喜好添加额外的食材，这种模式在闽南地区基本相同。在泉州，根据我对本地食客的观察，基本上必加的食材有：醋肉、卤大肠、套肠、豆干等等，当然绝对不能忘了加一根油条。\n除了平阿面线糊，我还收藏了几家值得一试的面线糊店：\n水门国仔老店\n后城面线糊\n文啊面线糊\n烧肉粽 东街肉粽店\n“烧”在闽南语中的含义既包含了特定的烹饪方法，也体现了食物的热度（与“烫”同音）。在“烧肉粽”中，“烧”不仅指将肉粽通过炖、煮、蒸等方式烹饪至入味，还强调了粽子食用时热乎的特质。\n与在厦门吃的肉粽不同，除了甜辣酱外，泉州的肉粽更喜欢加入花生酱，增添了一份独特的香气和口感。\n原本计划去侯阿婆烧肉粽，但可惜饭点人太多，只能临时改变计划，选择了不远处的东街肉粽店。不过这家感觉有些失望，对粽子没有太多感觉，店里的海蛎煎下的油太多，实在无法恭维。\n可惜这次时间有限，还有很多地方想去但没来得及去， 有很多想吃的没吃上\n下次再来\n","permalink":"https://niraya666.github.io/travel/%E6%B3%89%E5%B7%9E%E8%A1%8C%E8%AE%B0%E5%8F%A4%E5%9F%8E%E6%BC%AB%E6%AD%A5%E4%B8%8E%E5%91%B3%E8%95%BE%E4%B9%8B%E6%97%85/","summary":"\u003cp\u003e2024年 夏\u003c/p\u003e\n\u003cp\u003e这是我第一次踏上泉州这片土地，虽然我是厦门人，已经快三十岁了，却一直没有机会来这座近在咫尺的城市。\u003c/p\u003e\n\u003cp\u003e泉州在我想象中，是一座充满历史韵味的地方，同时也被一些暴发户的繁荣所点缀。几年前，这座城市成功申遗，从此逐渐成为小众旅游的热门选择。泉州的古老街区、传统建筑和浓厚的文化氛围，让人忍不住想一探究竟。\u003c/p\u003e\n\u003cp\u003e大学时，我有一位好友家在泉州。我们是班里唯二的福建人，因此自然成了很好的朋友。每次听他讲起泉州的美食、风景，总让我心生向往。\u003c/p\u003e\n\u003cp\u003e这次借着回家的机会，我终于决定亲自走一趟泉州。\u003c/p\u003e\n\u003cp\u003e泉州，我来了！\u003c/p\u003e\n\u003ch2 id=\"初印象\"\u003e初印象\u003c/h2\u003e\n\u003cp\u003e初到泉州，路上穿梭的电动车给我留下了深刻的第一印象。这些电动车在街头巷尾自由穿行，让我一度产生了身处越南的错觉。或许，这正是泉州的独特之处——在传统与现代之间，在历史与现实之中，找到一种和谐的平衡。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/50F93B5D-5373-486C-A785-4BB341FD0679_1_105_c.jpeg\" alt=\"50F93B5D-5373-486C-A785-4BB341FD0679_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e作为古城，鲤城区似乎尽可能地保留着过去的模样。漫步在古城，却能产生一种记忆中的故乡的错觉，这一切似乎都太像了。\u003c/p\u003e\n\u003cp\u003e那些熟悉的景象和气息，让人倍感亲切。有人说过，“离开了，故乡才称之为故乡。”庆幸的是，故乡以另一种形式呈现在我的面前，尽管这不是我的故乡。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/458F4F0B-B35C-4AC9-A447-0A38E69CC35D_1_105_c.jpeg\" alt=\"458F4F0B-B35C-4AC9-A447-0A38E69CC35D_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e在鲤城区，街头的小贩、古早风格的便利店、上了年纪的理发店，无时无刻不把我拉回到记忆的深处。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/218DC3D6-D630-49FE-9796-64202907D7E3_1_105_c.jpeg\" alt=\"218DC3D6-D630-49FE-9796-64202907D7E3_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"人\"\u003e人 \u003c/h2\u003e\n\u003cp\u003e历史离不开人，特别是一个个普通人\u003c/p\u003e\n\u003cp\u003e正是这些普通人，构成了这座城市的血脉与灵魂。他们的日常琐事，他们的勤劳与坚韧，使得这座古老的城市充满了生机与活力。在他们的身上，我看到了泉州的过去、现在和未来。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/E5CBBA91-C9A6-4F93-853D-009FD2D568C5_1_105_c.jpeg\" alt=\"E5CBBA91-C9A6-4F93-853D-009FD2D568C5_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/BC390CC0-02B4-45A6-9266-1C7638C75D76_1_105_c.jpeg\" alt=\"BC390CC0-02B4-45A6-9266-1C7638C75D76_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/3F165220-A99D-4E4F-92AB-94F572A0B231_1_105_c.jpeg\" alt=\"3F165220-A99D-4E4F-92AB-94F572A0B231_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/0DA901A1-F620-4B8A-A722-63E95EDAA536_1_105_c.jpeg\" alt=\"0DA901A1-F620-4B8A-A722-63E95EDAA536_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/46A3B7FB-2306-4661-8B47-7DEDB3FF20AE_1_105_c.jpeg\" alt=\"46A3B7FB-2306-4661-8B47-7DEDB3FF20AE_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"宗教\"\u003e宗教\u003c/h2\u003e\n\u003cp\u003e泉州作为海上丝绸之路的起点，在那辉煌的历史长河中，不仅是贸易和文化交流的中心，也吸引了大量的外来文化和宗教。佛教、道教、伊斯兰教、基督教等多种宗教在这里交汇融合，形成了独特的宗教文化景观。经过千年的融合与发展，这些宗教在泉州和谐共存，互相尊重，不分彼此。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/22205648-89A8-41BE-B99C-56850A28D252_1_105_c.jpeg\" alt=\"22205648-89A8-41BE-B99C-56850A28D252_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/BB0999F1-EDEA-4AA2-BA72-D6954CD12BA8_1_105_c.jpeg\" alt=\"BB0999F1-EDEA-4AA2-BA72-D6954CD12BA8_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/5A6D2D91-D86E-4BBA-9248-272095117CE9_1_105_c.jpeg\" alt=\"5A6D2D91-D86E-4BBA-9248-272095117CE9_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"吃\"\u003e吃\u003c/h2\u003e\n\u003ch3 id=\"牛肉店\"\u003e牛肉店\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/FEA7D1E0-80AD-45BC-B2F9-E3BF31A1130A_1_201_a.jpg\" alt=\"FEA7D1E0-80AD-45BC-B2F9-E3BF31A1130A_1_201_a.jpg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e阿秋牛排馆\u003c/p\u003e\n\u003cp\u003e牛排并不是传统意义上的steak，而是采用香料和咖喱炖煮而成的牛排骨。招牌牛排非常推荐，炖得非常软烂，入口即化，肉质瞬间脱骨。咖喱的香气与牛肉的原汁原味相得益彰，不会掩盖肉本身的美味。用汤汁拌饭，可谓是一绝。\u003c/p\u003e\n\u003cp\u003e不过，对于从小习惯了晋江牛肉店的闽南人来说，阿秋牛排馆的汤味道可能稍显清淡，不够浓郁，因此未必合所有人的口味。此外，这家店的价格也比其他店稍高一些。\u003c/p\u003e\n\u003cp\u003e除此之外，我的收藏夹里还有几家值得尝试的牛排店：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e阿波牛肉店\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e天财牛肉店\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e阿泉全牛馆\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"面线糊\"\u003e面线糊\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/FC2DD610-927E-4E1E-829A-420ACD1A0418_1_105_c.jpeg\" alt=\"FC2DD610-927E-4E1E-829A-420ACD1A0418_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e平阿面线糊\u003c/p\u003e\n\u003cp\u003e我去的这家平阿面线糊，在周末早上8点左右已经挤满了人，足见其受欢迎程度。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/0615C07D-8BA9-484A-BBFC-FF59E764955B_1_201_a.jpg\" alt=\"0615C07D-8BA9-484A-BBFC-FF59E764955B_1_201_a.jpg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e与厦门地区加入了猪血、虾米的面线糊相比，泉州的面线糊更多地呈现出字面上的意思——就是很单纯的面线糊。所用的面线更加细碎，完全不用担心吃太慢会坨，因为这甚至可以用面线汤来形容。但喝上一口汤，你会发现这绝不是一碗普通的面线汤，在汤头上，店家一定是下足了功夫的。\u003c/p\u003e\n\u003cp\u003e食客可以根据自己的喜好添加额外的食材，这种模式在闽南地区基本相同。在泉州，根据我对本地食客的观察，基本上必加的食材有：醋肉、卤大肠、套肠、豆干等等，当然绝对不能忘了加一根油条。\u003c/p\u003e\n\u003cp\u003e除了平阿面线糊，我还收藏了几家值得一试的面线糊店：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e水门国仔老店\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e后城面线糊\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e文啊面线糊\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"烧肉粽\"\u003e烧肉粽\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e6%b3%89%e5%b7%9e%e8%a1%8c%e8%ae%b0%ef%bc%9a%e5%8f%a4%e5%9f%8e%e6%bc%ab%e6%ad%a5%e4%b8%8e%e5%91%b3%e8%95%be%e4%b9%8b%e6%97%85-assets/F2CA54E0-ADE3-42B7-A243-D90C9B559D7B_1_105_c.jpeg\" alt=\"F2CA54E0-ADE3-42B7-A243-D90C9B559D7B_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e东街肉粽店\u003c/p\u003e\n\u003cp\u003e“烧”在闽南语中的含义既包含了特定的烹饪方法，也体现了食物的热度（与“烫”同音）。在“烧肉粽”中，“烧”不仅指将肉粽通过炖、煮、蒸等方式烹饪至入味，还强调了粽子食用时热乎的特质。\u003c/p\u003e\n\u003cp\u003e与在厦门吃的肉粽不同，除了甜辣酱外，泉州的肉粽更喜欢加入花生酱，增添了一份独特的香气和口感。\u003c/p\u003e\n\u003cp\u003e原本计划去侯阿婆烧肉粽，但可惜饭点人太多，只能临时改变计划，选择了不远处的东街肉粽店。不过这家感觉有些失望，对粽子没有太多感觉，店里的海蛎煎下的油太多，实在无法恭维。\u003c/p\u003e","title":"泉州行记：古城漫步与味蕾之旅"},{"content":"2024-春夏之交 大阪\n旅行时间2天3夜\n在多邻国上学了快一年的散装日语，受到了看大河剧、日本电影和玩日本游戏的影响，我决定利用刚获得的三年多次入境签证，以及51假期的空闲时间，去日本看看。考虑到时间限制，我选择了关西的交通枢纽和经济中心——大阪，作为这次日本之行的第一站。\n对于日本，尤其是大阪，我的第一印象是热门景区和场所人非常多。这主要是因为赶上了日本的10天黄金周，同时由于日元汇率低迷，大量外国人涌入日本消费和旅游。然而，在居民区，特别是我所住的浪速区，情况则大为不同，晚上和清晨几乎见不到几个人，给人一种非常萧条的感觉。中国人会说，这叫做“缺乏人气”。此外，随处可见的大乌鸦加深了这种萧条感。或许这也可能是宫崎英高在《黑魂》系列中乌鸦的灵感来源吧。在日本，乌鸦似乎被视为吉祥的象征。\n游玩篇 出了民宿，我的第一站是不远处的难波八阪神社。这里以其狮子头形状的大狮子殿闻名，成为了一处热门的打卡地点。据说，这个狮子头具有驱除灾难和带来好运的力量。\n经过两站地下铁，即可到达动物园前站， 这里是新世界的入口。\n新世界，曾是日本向西方看齐、力图“脱亚入欧”时的产物。在20世纪初，日本大量吸纳西方文化元素，并在大阪建立了这一街区。然而时光流转，21世纪的今天，这里更像是一个保存良好的“旧世界”。街区内充满昭和时代的气息，从游戏厅、炸串店到浮夸的店面招牌，甚至粉红色影院，处处透露出时代的印记。\n作为泡沫经济时期产物， 粉红影院现在主要吸引了一部分中老年男性和非传统性别的人士。影院的“学生半价”标志显得有些讽刺，同时也透露出一种时代变迁的哀愁。鉴于这类场所的特殊性，不推荐旅行者单独前往。\n新世界的标志性建筑通天阁，则见证了区域的多重历史。这座铁塔最初在1912年仿照巴黎的埃菲尔铁塔建造，但在二战中因为“献纳”政策而被拆除，用其材料支持军工。通天阁的现代版本建于1956年，为了迎接万博会而重建，塔身醒目地印有日立的广告，成为了大阪的新地标。\n西成区，与新世界仅一路之隔，是大阪的旧城区。这个区域以较复杂的治安情况、流浪汉的较高出现率，以及成人娱乐业而知名。其中，著名的酒吧一条街和在中文互联网上广为人知的飞田新地均位于此地。游客在此区域应特别小心，避免随意使用手机或拍照，以尊重当地文化和增加个人安全。\n往新世界东北边走， 则能到达天王寺车站，商圈，以及以此命名此地的四天王寺。这里的天王寺车站作为从关西机场到大阪市区的两条主要电车线路之一JR西日本的终点站，同前面走过的西成区和新世界相比， 自然非常繁华。\n天王寺站前\nJR西日本机场线之HARUKA， 以Hello- Kitty涂装著称。\n日本的许多古迹因二战的轰炸和历史上的大地震而稀少，多数是在原址上修复或重建的。四天王寺就是这样的例子，它是日本历史悠久的寺庙之一，最初由飞鸟时期的圣德太子创建。虽然历经多次战火，我们今天所见的四天王寺主要是1957年后的重建。\n前往天王寺途中，偶遇的一心寺。\n在天王寺附近，我意外地发现了一个旧书集市。在那里，我用400日元买到了一本1994年的旧书。虽然还有很多书我想买想看，但考虑到海关的限制和行李空间的限制，我只能忍痛放弃。\n不可免俗的道顿堀格利高小人\n蟹道乐\n夜幕降临， 抵达梅田，乘坐hep five摩天轮，体验大阪夜景。\nhep five摩天轮\n第二天，前往大阪历史博物馆和大阪城， 以及shooping。\n大阪城\n大阪城始建于1583年，由丰臣秀吉下令建造。大阪城的天守阁如今是博物馆，展示了丰臣秀吉的生平、战国时期的武器和铠甲，以及大阪城的历史变迁。\n如果对于历史感兴趣的小伙伴， 大阪城公园边上的大阪历史博物馆也值得逛一逛。 大阪历史博物馆展示了古代大阪作为日本重要商业城市的发展过程，以及现代大阪的城市化进程。参观路线从10楼一路到7楼，6楼为特别展。\n日式连锁中餐王将的碳水加碳水再加碳水的定食\n剩下的shopping时间，逛了堂吉柯德，在西斋心桥发现一家二手唱片店\n位于 Big Step 大楼的地下一层，可惜根据网友的评论，似乎店面越来越小，东西越来越少了。\n似乎在日本不同城市，优衣库会有限定的特别款式， 在大阪则是御好烧（大阪烧）和章鱼烧的图案。\n美国村边上的小自由女神像\n攻略篇 入境 Visit Japan Web （VJW）为了替代入境卡而设计的， 需要在入境前提前申报，在入境时扫码即可。和纸质入境卡相比， 至少从我的观察而言， 使用VJW会更加快速，而没有存在需要排队的情况。\n交通 在大阪，从关西机场到市区有两条主要的铁路线路，南海电铁和JR西日本。两条线路隶属于不同的公司运营，在使用购票机购票时需要注意区分。平均时间在半个小时到一个小时不等， 票价在970到1800日元间，取决于所乘坐车次和制定席与否。除了特急列车（Rapi:t \u0026amp; HARUKA）,均和国内乘坐地铁没有太大差别。\n对于特急列车， 可以在网上买票，通过扫二维码进站，或者是在自助购票机上操作，以及通过刷西瓜卡进站，在候车处附近的机器上购买特急券。理论上有售票员会查票。\n赶了6:00的第一班Rapi:t alpha\n吃 居酒屋会在刚入座上小菜，也叫お通し（o-to-shi）,这部分一般是按人头收费，价格在330日元左右，一般是强制收取不给退的。\n日本餐厅一般是不提供打包服务的， 因为内用和外带属于不同执照，并且会因为害怕顾客吃坏肚子店家要负责任， 所以在日本餐厅，店家对于打包吃剩的食物十分抗拒。\n点餐时， 特别在旅游城市， 一般都会有多国语言版本或者是带图片版本的菜单， 有的店家甚至有扫码点单，可谓是非常友好的。所以， 只需要会几个日语单词即可，如\n日语单词 意思 罗马音 注文 点单 chūmon 会計 结账 kaikei メニュー 菜单 menyū 一つ 一个 hitotsu 二つ 两个 futatsu 三つ 三个 mittsu 少々 少量 shōshō 大盛り 大份 ōmori おすすめ 推荐 osusume トイレ 洗手间 toire 在便利店消费时，有几个常用的日语单词和表达可以帮助你更方便地交流。例如，店员可能会询问你是否需要袋子（ふくろ，fukuro）或加热食物（温め，atatame）。在不需要这些服务时，可以回答“大丈夫”（daijōbu，没关系）。\n在7-11一般是又店员负责扫码和年龄检查（买烟酒时），扫完后，有顾客在旁边的一台机器上选择付款方式并付款。当然，也可以直接出示Alipay 给店员， 店员会帮你操作的。\n大阪周游卡（Osaka Amazing Pass） or 大阪乐游券（Osaka e-Pass） 目前周游卡已停售(二日券)，一日券购买有效期截止到2024年6月30日。\n其中大阪周游卡需要购买后兑换成实体卡，兑换位置可查看 售票及换票点；而大阪乐游券直接展示二维码即可。二者都支持在Klook上购买。周游卡价格在¥3300包括了市区地铁随意乘坐， 乐游券价格为¥2400，只包括景点。\n用GPT-4 整理了一个周游卡和乐游券差异的表格（不能保证100%正确）：\n地点 (日本語) 地点 (中文) Location Regular fee Osaka Amazing Pass Osaka e-Pass 梅田スカイビル空中庭園展望台 梅田天空大厦空中庭园观景台 梅田 ¥ 1500 ✔️ ✔️ 梅田スカイビル・衣川邦彦天空美術館 梅田天空大厦衣川邦彦天空美术馆 梅田 ¥ 1000 ✔️ ✔️ HEP FIVE観覧車 HEP FIVE摩天轮 梅田 ¥ 600 ✔️ ✔️ 通天閣 通天阁 新世界 ¥ 1000 ✔️ ✔️ 通天閣タワースライダー 通天阁塔滑梯 新世界 ¥ 1000 ✔️ ✔️ 四天王寺 (中心伽藍・本坊庭園) 四天王寺（中心伽蓝、本坊庭园） 四天王寺 ¥ 300 ✔️ ✔️ とんぼりリバークルーズ 道顿堀河巡航 道顿堀 ¥ 1200 ✔️ ✔️ 天王寺動物園 天王寺动物园 四天王寺 ¥ 500 ✔️ ❌ 中之島川クルーズ 中之岛河巡航 北区中之岛 ¥ 1500 ✔️ ✔️ 大阪国立国際美術館 大阪国立国际美术馆 北区中之岛 ¥ 430 ✔️ ❌ 道頓堀ZAZA 道顿堀ZAZA 道顿堀 ¥ 800 ✔️ ✔️ 上方浮世絵館 上方浮世绘馆 难波 ¥ 700 ✔️ ✔️ 大阪歴史博物館 大阪历史博物馆 大阪城 ¥ 600 ✔️ ❌ 大阪平和の殿堂 大阪和平馆 大阪城 ¥ 250 ✔️ ✔️ 大阪城天守閣 大阪城天守阁 大阪城 ¥ 600 ✔️ ❌ ワンダークルーズ 奇迹巡航 ¥ 1200 ✔️ ✔️ 大阪くらしの今昔館 大阪生活今昔馆 天神橋 ¥ 600 ✔️ ✔️ 天保山大観覧車 天保山大观览车 天保山 ¥ 1200 ✔️ ❌ グリオンミュージアム GLION博物馆 天保山 ¥ 1200 ✔️ ✔️ サンタマリア日帰りクルーズ 圣玛丽亚日游巡航 ¥ 1800 ✔️ ✔️ サンタマリア夜景クルーズ 圣玛丽亚夜景巡航 ¥ 2300 ✔️ ✔️ キャプテンライン 队长线 ¥ 1500 ✔️ ✔️ レゴランド・ディスカバリー・センター大阪 大阪乐高探索中心 ¥2800～¥3000 ✔️ ✔️ 咲洲コスモタワー展望台 咲洲宇宙塔展望台 ¥1000 ✔️ ✔️ ボートレース住之江 住之江赛艇 ¥ 1500 ✔️ ✔️ 大阪水上バスアクアライナー 大阪水上巴士Aqua-Liner ¥ 1800 ✔️ ✔️ 桜川お花見クルーズ 樱川赏花巡航 ¥ 1200 ✔️ ✔️ 夕日クルーズ「寄道」 夕阳巡航“YORIMICHI” ¥ 1500 ✔️ ✔️ 大阪城御座船 大阪城御座船 ¥ 1500 ✔️ ✔️ エンタープライズイノベーションミュージアム 创业创新博物馈 ¥ 300 ✔️ ✔️ 大阪城重要文化財櫓 大阪城重要文化财瞭 ¥ 800 ✔️ ❌ 大阪城西の丸庭園 大阪城西之丸庭园 ¥ 200 ✔️ ❌ 咲くやこの花館 咲く家这花馆 ¥ 500 ✔️ ❌ 長居植物園 长居植物园 ¥ 200 ✔️ ❌ 大阪市立自然史博物館 大阪市立自然历史博物馆 ¥ 300 ✔️ ❌ 堺利晶の杜 堺利晶之森 ¥ 300 ✔️ ❌ 堺市博物館 堺市博物馆 ¥ 200 ✔️ ❌ 万博記念公園（自然文化園、日本庭園） 万博纪念公园（自然文化园、日本庭园） ¥ 260 ✔️ ❌ OSAKA WHEEL（日本最大の観覧車） 大阪摩天轮（日本最大） 天保山 ¥ 1000 ✔️ ✔️ 大阪科学館 大阪科学馆 ¥ 400 ✔️ ❌ 桂陵園 桂陵园 ¥ 150 ✔️ ❌ 日向の湯 日向温泉 ¥ 800 ❌ ✔️ 海洋堂ホビーランド 海洋堂模型乐园 ¥ 1000 ❌ ✔️ 忍者トリックハウス（エディオン難波本店） 忍者特技屋（EDION难波本店） ¥ 1000 ❌ ✔️ 道頓堀ミュージアムなみき座 道顿堀剧场 ❌ ✔️ 更多的攻略建议参考：小气少年的部落格 这是我所发现的最完整的日本旅行攻略，成功解决了我的旅行前焦虑。 此外，在推荐一本书：《日本點餐完全圖解》，这本书详细介绍了在日本点餐的注意事项，甚至教会你怎么吃。\n感受篇 在这次的旅途中，我在网上上结识了两位旅游搭子，分别各搭了一天。\nA是一位出生于1998年的年轻人，帅气的外表下藏着近期感情伤痕的痛楚。他独自一人前来关西，试图通过旅行洗涤感情上的创伤。尽管我不愿轻易给人贴上标签，诸如“渣男”之类的称呼，但A的行为难免让人费解：他同时与四五名女生保持联系，不断在Tinder上寻找新的可能，对每一个路过的女性都有自己的评价。然而，从他的话语中，我逐渐感知到他背后隐藏的故事——那些使他变得如此的伤痕累累。通过他，我也间接了解了日本的一些风俗业及他的个人感受体验。\nR则是一位三十多岁的体制内员工，表面上看似普通，内心却充满了对现状的不满和对自由的渴望。他的思想深受那个时代的河殇文化与十年前“意林”文学的影响。在他的眼中，日本社会的方方面面几乎都是模范，而国内的绝大多数则恰恰相反。他甚至考虑过一个大胆的想法：辞去体制内的工作，“润”到日本。用互联网上的用语形容他的思想就是妥妥“反贼”和“润人”，但又何妨。R还是个爱酒如命的人。\n日本人究竟相信什么？道德伦理？法律？还是抽象的社会潜规则 事实上，日本社会的一个显著特点是高度的循规蹈矩。人们极其重视集体，与社会脱节被视为所能想到的最严酷的惩罚之一。也许正是因为日本人对意识形态和教条缺乏关注，他们格外重视外在形象，注重符合各种场合的姿态，因为“面子”比“里子”更重要。这演化成了一种行为模式，即在私下里怎么搞都行，但在公众面前一定要维护自己的“形象”。这意味着日本人本质上追求的是集体认同，极度避免被社会边缘化。\n“日本的情况则不同，原始信仰从未遭到更精致的官方律条的碾压。尽管不同宗教之间的区分不甚清晰，尤其是在最广泛的层面上，但佛寺和神社仍然共存并立。两种教派的仪式人们都参与，尽管不一定同时同地。这或许是因为日本人对意识形态和教条缺乏关注，却格外重视外在，重视符合各种场合的姿态，因为“面子”比“里子”更重要。”\n在这种文化氛围下，个人行为被严格的社会规范和集体利益所约束。脱离集体，被视为严重的社会惩罚，比法律制裁更为严酷。社会关系和集体认同对个人生活至关重要，因此日本人普遍面临巨大的心理压力，必须时刻注意自己的行为是否符合社会期望，以避免被边缘化。\n这种面子文化强调外在形象的维护。日本人非常重视在各种场合的表现和形象管理，不论是在公共场合的礼仪，还是在工作中的表现，维护良好的外在形象是必不可少的。在私下场合，日本人可能会表现出更大的灵活性和自由度，但在公开场合，他们会极力维护自己的公众形象，遵守社会规范和礼仪，以获得集体的认可和尊重。\n不论是飞田新地的挂羊头卖狗肉，还是游戏厅的老虎机，日本人总是有能力绕过所谓的规则，显示出一种极强的变通能力；但在公共区域场合下， 日本人又总能展现出一种死板地对于规则的严格遵守。\n日本社会的这种双重性在于，私下和公开行为的巨大反差。这种现象可以通过对集体认同和避免边缘化的强烈需求来解释。正如《日本之镜：日本文化中的英雄与恶人》一书中所提到的，“制约日本人行为的不是社会规则，而是一套抽象的道德教训。”\n然而，这种“抽象的道德”在中文语境下显得陌生。中国古代追求的是儒家的仁义道德，而日本的道德观念更多来源于神道教的泛神信仰，强调避免在社会上出丑。例如，须佐之男被放逐的故事就是一种道德教训，提醒人们避免类似的羞辱。日本人常说，只要不被逮个正着，避免在社会上出丑，就能够为所欲为，不必担心后果。\n","permalink":"https://niraya666.github.io/travel/%E5%A4%A7%E9%98%AA%E6%B8%B8%E8%AE%B0%E6%97%B6%E5%85%89%E4%BA%A4%E9%94%99%E4%B8%8B%E7%9A%84%E6%97%A5%E6%9C%AC%E6%8E%A2%E7%B4%A2/","summary":"\u003cp\u003e2024-春夏之交 大阪\u003c/p\u003e\n\u003cp\u003e旅行时间2天3夜\u003c/p\u003e\n\u003cp\u003e在多邻国上学了快一年的散装日语，受到了看大河剧、日本电影和玩日本游戏的影响，我决定利用刚获得的三年多次入境签证，以及51假期的空闲时间，去日本看看。考虑到时间限制，我选择了关西的交通枢纽和经济中心——大阪，作为这次日本之行的第一站。\u003c/p\u003e\n\u003cp\u003e对于日本，尤其是大阪，我的第一印象是热门景区和场所人非常多。这主要是因为赶上了日本的10天黄金周，同时由于日元汇率低迷，大量外国人涌入日本消费和旅游。然而，在居民区，特别是我所住的浪速区，情况则大为不同，晚上和清晨几乎见不到几个人，给人一种非常萧条的感觉。中国人会说，这叫做“缺乏人气”。此外，随处可见的大乌鸦加深了这种萧条感。或许这也可能是宫崎英高在《黑魂》系列中乌鸦的灵感来源吧。在日本，乌鸦似乎被视为吉祥的象征。\u003c/p\u003e\n\u003ch2 id=\"游玩篇\"\u003e游玩篇\u003c/h2\u003e\n\u003cp\u003e出了民宿，我的第一站是不远处的难波八阪神社。这里以其狮子头形状的大狮子殿闻名，成为了一处热门的打卡地点。据说，这个狮子头具有驱除灾难和带来好运的力量。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/D22F4C9A-23D6-472A-B359-5A9DC656DE03_1_201_a.jpeg\" alt=\"D22F4C9A-23D6-472A-B359-5A9DC656DE03_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e经过两站地下铁，即可到达动物园前站， 这里是新世界的入口。\u003c/p\u003e\n\u003cp\u003e新世界，曾是日本向西方看齐、力图“脱亚入欧”时的产物。在20世纪初，日本大量吸纳西方文化元素，并在大阪建立了这一街区。然而时光流转，21世纪的今天，这里更像是一个保存良好的“旧世界”。街区内充满昭和时代的气息，从游戏厅、炸串店到浮夸的店面招牌，甚至粉红色影院，处处透露出时代的印记。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/6DA5908E-2DB7-48B0-9254-7B189FB7848A_1_201_a.jpeg\" alt=\"6DA5908E-2DB7-48B0-9254-7B189FB7848A_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/AF7FD137-8145-4DE2-91D7-116908DC6985_1_201_a.jpeg\" alt=\"AF7FD137-8145-4DE2-91D7-116908DC6985_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e作为泡沫经济时期产物， 粉红影院现在主要吸引了一部分中老年男性和非传统性别的人士。影院的“学生半价”标志显得有些讽刺，同时也透露出一种时代变迁的哀愁。鉴于这类场所的特殊性，不推荐旅行者单独前往。\u003c/p\u003e\n\u003cp\u003e新世界的标志性建筑通天阁，则见证了区域的多重历史。这座铁塔最初在1912年仿照巴黎的埃菲尔铁塔建造，但在二战中因为“献纳”政策而被拆除，用其材料支持军工。通天阁的现代版本建于1956年，为了迎接万博会而重建，塔身醒目地印有日立的广告，成为了大阪的新地标。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/6C8F7905-91AC-46AA-BEC9-79AF3A362781_1_105_c.jpeg\" alt=\"6C8F7905-91AC-46AA-BEC9-79AF3A362781_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/0B1EA1C4-DFF3-4FDA-ACF8-EFDB75E7A3C0_1_201_a.jpeg\" alt=\"0B1EA1C4-DFF3-4FDA-ACF8-EFDB75E7A3C0_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e西成区，与新世界仅一路之隔，是大阪的旧城区。这个区域以较复杂的治安情况、流浪汉的较高出现率，以及成人娱乐业而知名。其中，著名的酒吧一条街和在中文互联网上广为人知的飞田新地均位于此地。游客在此区域应特别小心，避免随意使用手机或拍照，以尊重当地文化和增加个人安全。\u003c/p\u003e\n\u003cp\u003e往新世界东北边走， 则能到达天王寺车站，商圈，以及以此命名此地的四天王寺。这里的天王寺车站作为从关西机场到大阪市区的两条主要电车线路之一JR西日本的终点站，同前面走过的西成区和新世界相比， 自然非常繁华。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/2E815B2C-F25B-4CB4-A8FB-8D993265A540_1_105_c.jpeg\" alt=\"2E815B2C-F25B-4CB4-A8FB-8D993265A540_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e天王寺站前\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/42E69559-0A2E-4F15-8B70-C4CD15948641_1_201_a.jpeg\" alt=\"42E69559-0A2E-4F15-8B70-C4CD15948641_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eJR西日本机场线之HARUKA， 以Hello- Kitty涂装著称。\u003c/p\u003e\n\u003cp\u003e日本的许多古迹因二战的轰炸和历史上的大地震而稀少，多数是在原址上修复或重建的。四天王寺就是这样的例子，它是日本历史悠久的寺庙之一，最初由飞鸟时期的圣德太子创建。虽然历经多次战火，我们今天所见的四天王寺主要是1957年后的重建。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/C316DC6A-106E-494C-9926-6F5ED52B11E3_1_105_c.jpeg\" alt=\"C316DC6A-106E-494C-9926-6F5ED52B11E3_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/30F7FC2C-4BFA-494F-A0EC-1C07AEBA1A5E_1_105_c.jpeg\" alt=\"30F7FC2C-4BFA-494F-A0EC-1C07AEBA1A5E_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/3BFFEA31-F958-4239-99FD-23B5D8F91CFF_1_105_c.jpeg\" alt=\"3BFFEA31-F958-4239-99FD-23B5D8F91CFF_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e前往天王寺途中，偶遇的一心寺。\u003c/p\u003e\n\u003cp\u003e在天王寺附近，我意外地发现了一个旧书集市。在那里，我用400日元买到了一本1994年的旧书。虽然还有很多书我想买想看，但考虑到海关的限制和行李空间的限制，我只能忍痛放弃。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/A0D7A507-9B4F-44D5-AA9C-6B771FA520D2_1_201_a.jpeg\" alt=\"A0D7A507-9B4F-44D5-AA9C-6B771FA520D2_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/96FA58A9-C223-40F4-9BC8-33B6A50D4BF0_1_105_c.jpeg\" alt=\"96FA58A9-C223-40F4-9BC8-33B6A50D4BF0_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e不可免俗的道顿堀格利高小人\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/17DC7E7D-8CD2-4FCD-A19E-EC4BCE661FF1_1_105_c.jpeg\" alt=\"17DC7E7D-8CD2-4FCD-A19E-EC4BCE661FF1_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e蟹道乐\u003c/p\u003e\n\u003cp\u003e夜幕降临， 抵达梅田，乘坐hep five摩天轮，体验大阪夜景。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/90FE62D5-F899-43B8-BBB7-D44B242C2CEB_1_201_a.jpeg\" alt=\"90FE62D5-F899-43B8-BBB7-D44B242C2CEB_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003ehep five摩天轮\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/5C716546-81DE-4FE8-BEAF-EA239F27DAB4_1_201_a.jpeg\" alt=\"5C716546-81DE-4FE8-BEAF-EA239F27DAB4_1_201_a.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e第二天，前往大阪历史博物馆和大阪城， 以及shooping。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%a4%a7%e9%98%aa%e6%b8%b8%e8%ae%b0/FDCCBE76-D57A-4EC6-8D79-D19D9066390F_1_105_c.jpeg\" alt=\"FDCCBE76-D57A-4EC6-8D79-D19D9066390F_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e大阪城\u003c/p\u003e\n\u003cp\u003e大阪城始建于1583年，由丰臣秀吉下令建造。大阪城的天守阁如今是博物馆，展示了丰臣秀吉的生平、战国时期的武器和铠甲，以及大阪城的历史变迁。\u003c/p\u003e\n\u003cp\u003e如果对于历史感兴趣的小伙伴， 大阪城公园边上的大阪历史博物馆也值得逛一逛。 大阪历史博物馆展示了古代大阪作为日本重要商业城市的发展过程，以及现代大阪的城市化进程。参观路线从10楼一路到7楼，6楼为特别展。\u003c/p\u003e","title":"大阪游记：时光交错下的日本探索"},{"content":"为什么要进行文本分块？ 大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。\n如何进行文本分块 **块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。\n文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：\n句子分割（Sentence Splitting） 这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。\ntext = \u0026#34;...\u0026#34; # 你的文本 from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter( separator = \u0026#34;\\n\\n\u0026#34;, chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 递归字符文本分割（Recursive Character Text Splitting） 这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。\ntext = \u0026#34;...\u0026#34; # 你的文本 from langchain.text_splitter import RecursiveCharacterTextSplitter text_splitter = RecursiveCharacterTextSplitter( chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 根据langchain 的默认分隔条件 [\u0026quot;\\n\\n\u0026quot;, \u0026quot;\\n\u0026quot;, \u0026quot; \u0026quot;, \u0026quot;\u0026quot;] ,也就是会将text根据该分割条件的顺序（两个换行-\u0026gt;一个换行-\u0026gt;空格）将文本进行递归分割。\n针对特定文档的分割方法（Document Specific Splitting） 例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。\nlangchain 提供了一些常见文档的分割方法：\nmardown的分割逻辑\n[ # First, try to split along Markdown headings (starting with level 2) \u0026#34;\\n#{1,6} \u0026#34;, # Note the alternative syntax for headings (below) is not handled here # Heading level 2 # --------------- # End of code block \u0026#34;```\\n\u0026#34;, # Horizontal lines \u0026#34;\\n\\\\*\\\\*\\\\*+\\n\u0026#34;, \u0026#34;\\n---+\\n\u0026#34;, \u0026#34;\\n___+\\n\u0026#34;, # Note that this splitter doesn\u0026#39;t handle horizontal lines defined # by *three or more* of ***, ---, or ___, but this is not handled \u0026#34;\\n\\n\u0026#34;, \u0026#34;\\n\u0026#34;, \u0026#34; \u0026#34;, \u0026#34;\u0026#34;, ] python的分割逻辑：\n[ # First, try to split along class definitions \u0026#34;\\nclass \u0026#34;, \u0026#34;\\ndef \u0026#34;, \u0026#34;\\n\\tdef \u0026#34;, # Now split by the normal type of lines \u0026#34;\\n\\n\u0026#34;, \u0026#34;\\n\u0026#34;, \u0026#34; \u0026#34;, \u0026#34;\u0026#34;, ] 表格 重点提示： 后来在我们对数据块进行语义搜索时，直接从表格中匹配嵌入可能会比较困难。开发者常用的做法是，在提取了表格之后，对其进行关键信息提取。然后对这些关键信息的总结进行嵌入。如果这个总结的嵌入与你的搜索目标匹配，那么就可以把原始表格交给你的大语言模型处理。\n语义分块 目前的文本分块方法大多基于结构或字符数量，忽视了文本的实际语义内容。有效的语义分块应当确保内容上相似的数据被归类在一起，这样不仅有助于数据的组织，还能提升后续处理的效率和准确性。\n根据Greg的做法：寻找连续句子间的分割点， 即从第一句话开始，获取其嵌入，然后与第二句进行比较，以此类推。在寻找嵌入距离较大的“分割点”。如果距离超过了一定阈值，就认为这标志着新的语义段落的开始。\n可以通过以下步骤来进行语义分块：\n文档初始处理：首先将你的文档分割成句子，每个句子通常包含关于一个主题的单一观点。\n句子嵌入：利用语言模型获取每个句子的嵌入表示。\n句子比较与分块：从第一句话开始，逐句比较嵌入的相似度。当相邻句子之间的嵌入距离超过预设的阈值时，标记为新的语义段落的开始。\n聚类相似句子：将语义上接近的句子聚集成块，同时保持句子的原始顺序。\n伪代码示例\narticle = \u0026#34;你的完整文章\u0026#34; chunks = [article[:1]] # 默认第一部分为一个独立分块 # 文章逐句审查 for sentence in article[1:]: if is_similar(sentence, chunks[-1][-1]): chunks[-1].append(sentence) # 如果新句子与当前块的最后一个句子相似，则加入当前块 else: chunks.append([sentence]) # 如果不相似，则创建新的分块 # 持续这个过程直至文章末尾 # 在这种方法中，is_similar 函数需要定义为比较句子嵌入之间的距离，并判断它们是否足够接近。 特殊分块以及后处理 不见得一定要在召回后，返回原始的chunks。\nSummary(摘要) 处理和存储大量文档的原始数据块往往不是最高效的方法。通过为每个文档创建摘要并进行嵌入，我们不仅可以减少处理的数据量，还能提高检索的速度和准确性。\nhttps://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector#summary\ncreate a summary for each document, embed that along with (or instead of) the document.\nimport uuid from langchain_core.documents import Document from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import ChatPromptTemplate from langchain_openai import ChatOpenAI chain = ( {\u0026#34;doc\u0026#34;: lambda x: x.page_content} | ChatPromptTemplate.from_template(\u0026#34;Summarize the following document:\\n\\n{doc}\u0026#34;) | ChatOpenAI(max_retries=0) | StrOutputParser() ) summaries = chain.batch(docs, {\u0026#34;max_concurrency\u0026#34;: 5}) # The vectorstore to use to index the child chunks vectorstore = Chroma(collection_name=\u0026#34;summaries\u0026#34;, embedding_function=OpenAIEmbeddings()) # The storage layer for the parent documents store = InMemoryByteStore() id_key = \u0026#34;doc_id\u0026#34; # The retriever (empty to start) retriever = MultiVectorRetriever( vectorstore=vectorstore, byte_store=store, id_key=id_key, ) doc_ids = [str(uuid.uuid4()) for _ in docs] summary_docs = [ Document(page_content=s, metadata={id_key: doc_ids[i]}) for i, s in enumerate(summaries) ] retriever.vectorstore.add_documents(summary_docs) retriever.docstore.mset(list(zip(doc_ids, docs))) Hypothetical questions HyDE\nhypothetical_document_embeddings\nHyDE (Hypothetical Document Embeddings)\nHyDE（Hypothetical Document Embeddings，假设性文档嵌入），通过生成假设性的答案并对这些生成的文档进行嵌入，而非嵌入原始文本。这种方法特别适用于用户问题简短且与需要查找的原始文本在语义上相似度不高的情况。\n当用户的问题与知识库中的原始文本在语义上相差较大时，传统的文档检索方法可能无法有效地匹配到相关内容。HyDE通过使用大型语言模型（LLMs）根据用户问题生成格式上类似于知识库中文本的假设性答案，从而提升匹配的准确率。\n尽管HyDE可以提升检索的准确性，但这种方法也会一定程度上增加检索的耗时。为了平衡检索准确率和响应速度，可以考虑使用更强大的重排模型（reranking models）。这些模型能够在检索后的阶段进一步优化结果，通过精准地评估和排序生成的假设性答案，以提供最相关的回答。\nParent Document Retriever (PDR) from Advanced RAG Techniques: an Illustrated Overview\nA.K.A Multi-size-chunks(Parent Document Retriever/ parent-child chunks retriever/ Auto Merging Retriever)\n核心思想是，尽管小片段的数据更容易在语义上与短小的用户查询匹配，但这些小片段往往缺乏提供全面回答所需的足够上下文。PDR的解决方案是在检索时优先获取这些小片段，然后识别并返回包含这些小片段的更大父文档，以此为基础进行问题的回答。\n在使用embedding模型召回时，尽可能的将对应文本拆成句子级别，因为往往人的问题都是比较短的句子，这样在语义匹配上能够较好的匹配上；但是在使用LLM做回答时，由需要足够的上下文让模型能够有足够多的背景进行回答；因此在召回的时候倾向于使用small-chunks用于匹配，再通过某些聚合方式合并成一个具备相对完整上下文的较大chunks用作模型回答之背景；\n在Langchain中提供了Parent Document Retriever这一方法。\nDuring retrieval, it first fetches the small chunks but then looks up the parent ids for those chunks and returns those larger documents.\n使用方法：\nfrom langchain.retrievers import ParentDocumentRetriever from langchain.storage import InMemoryStore from langchain.text_splitter import RecursiveCharacterTextSplitter # Retrieving larger chunks # This text splitter is used to create the parent documents parent_splitter = RecursiveCharacterTextSplitter(separators=\u0026#34;\\n\u0026#34;,chunk_size=2000) # This text splitter is used to create the child documents # It should create documents smaller than the parent child_splitter = RecursiveCharacterTextSplitter(separators=\u0026#34;\\n\u0026#34;,chunk_size=400) # define your docs = embeddings, and vectorstore # docs = loader.load(...) # emebeddings = OpenAIEmbeddings(...) # vectorstore = Chroma(...) # The storage layer for the parent documents store = InMemoryStore() retriever = ParentDocumentRetriever( vectorstore=vectorstore, docstore=store, child_splitter=child_splitter, parent_splitter=parent_splitter, ) retriever.add_documents(docs) 而在llama_index中也提供了类似的方法。\n# 创建较小的子块 from llama_index.schema import IndexNode sub_chunk_sizes = [256, 512, 864] sub_node_parsers = [ SimpleNodeParser.from_defaults(chunk_size=c) for c in sub_chunk_sizes ] all_nodes = [] for base_node in base_nodes: for n in sub_node_parsers: sub_nodes = n.get_nodes_from_documents([base_node]) sub_inodes = [IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes] all_nodes.extend(sub_inodes) original_node = IndexNode.from_text_node(base_node, base_node.node_id) all_nodes.append(original_node) all_nodes_dict = {n.node_id: n for n in all_nodes} # 创建索引、检索器和查询引擎 vector_index_chunk = VectorStoreIndex( all_nodes, service_context=service_context ) vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2) retriever_chunk = RecursiveRetriever( \u0026#34;vector\u0026#34;, retriever_dict={\u0026#34;vector\u0026#34;: vector_retriever_chunk}, node_dict=all_nodes_dict, verbose=True, ) query_engine_chunk = RetrieverQueryEngine.from_args( retriever_chunk, service_context=service_context ) response = query_engine_chunk.query( \u0026#34;Can you tell me about the key concepts for safety finetuning\u0026#34; ) print(str(response)) Sentence Window Retrieval 为了更好地分析找到的语境，我们在检索到的最相关单句之前后各扩展 k 个句子，然后把这个扩展后的语境送给 LLM 进行推理\nfrom Advanced RAG Techniques: an Illustrated Overview\n分块可视化小工具 推荐一个可视化chunk-spliting 工具chunkviz\n推荐阅读 Text splitting (chunking) for RAG applications\n5_Levels_Of_Text_Splitting\nlangchain:Semantic Chunking\nChunking Strategies for LLM Applications\nAdvanced RAG Techniques: an Illustrated Overview\nRAG系列05：基于语义的Chunk分割\n","permalink":"https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97/","summary":"\u003ch2 id=\"为什么要进行文本分块\"\u003e\u003cstrong\u003e为什么要进行文本分块？\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。\u003c/p\u003e\n\u003ch2 id=\"如何进行文本分块\"\u003e\u003cstrong\u003e如何进行文本分块\u003c/strong\u003e\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e**块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：\u003c/p\u003e\n\u003ch3 id=\"句子分割sentence-splitting\"\u003e\u003cstrong\u003e句子分割（Sentence Splitting）\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etext\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;...\u0026#34;\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 你的文本\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003elangchain.text_splitter\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eCharacterTextSplitter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etext_splitter\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eCharacterTextSplitter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eseparator\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003echunk_size\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e256\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003echunk_overlap\u003c/span\u003e  \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e20\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edocs\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etext_splitter\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_documents\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003etext\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"递归字符文本分割recursive-character-text-splitting\"\u003e\u003cstrong\u003e递归字符文本分割（Recursive Character Text Splitting）\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etext\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;...\u0026#34;\u003c/span\u003e \u003cspan class=\"c1\"\u003e# 你的文本\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003elangchain.text_splitter\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eRecursiveCharacterTextSplitter\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003etext_splitter\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eRecursiveCharacterTextSplitter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003echunk_size\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e256\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003echunk_overlap\u003c/span\u003e  \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e20\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edocs\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etext_splitter\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecreate_documents\u003c/span\u003e\u003cspan class=\"p\"\u003e([\u003c/span\u003e\u003cspan class=\"n\"\u003etext\u003c/span\u003e\u003cspan class=\"p\"\u003e])\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e根据langchain 的\u003ca href=\"https://github.com/langchain-ai/langchain/blob/9ef2feb6747f5a69d186bd623b569ad722829a5e/libs/langchain/langchain/text_splitter.py#L842\"\u003e默认分隔条件\u003c/a\u003e \u003ccode\u003e[\u0026quot;\\n\\n\u0026quot;, \u0026quot;\\n\u0026quot;, \u0026quot; \u0026quot;, \u0026quot;\u0026quot;]\u003c/code\u003e ,也就是会将text根据该分割条件的顺序（两个换行-\u0026gt;一个换行-\u0026gt;空格）将文本进行递归分割。\u003c/p\u003e\n\u003ch3 id=\"针对特定文档的分割方法document-specific-splitting\"\u003e\u003cstrong\u003e针对特定文档的分割方法（Document Specific Splitting）\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。\u003c/p\u003e\n\u003cp\u003elangchain 提供了一些常见文档的分割方法：\u003c/p\u003e\n\u003cp\u003emardown的分割逻辑\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-py\" data-lang=\"py\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# First, try to split along Markdown headings (starting with level 2)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e#{1,6} \u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# Note the alternative syntax for headings (below) is not handled here\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# Heading level 2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# ---------------\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# End of code block\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;```\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# Horizontal lines\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\\\\\u003c/span\u003e\u003cspan class=\"s2\"\u003e*\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s2\"\u003e*\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s2\"\u003e*+\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e---+\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e___+\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# Note that this splitter doesn\u0026#39;t handle horizontal lines defined\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"c1\"\u003e# by *three or more* of ***, ---, or ___, but this is not handled\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"se\"\u003e\\n\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34; \u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003epython的分割逻辑：\u003c/p\u003e","title":"RAG工具箱：文本分块"},{"content":"写在开头 本文是基于最近组内技术交流的文字稿整理。\nWhat is Agent？ 在探讨复杂的人工智能技术之前，让我们先回顾一下生活中的一个简单例子：扫地机器人。这种智能设备在房间中自主导航，避开障碍物，寻找最有效的清洁路径。它就是一个现实生活中的Agent——一个可以自主决策和行动的实体。\n在人工智能领域，Agent指的是任何可以感知其环境并根据感知结果做出决策的实体。这些决策旨在完成某些任务或达成特定的目标。Agent的行为可以简单如游戏里的机器人，也可以复杂如自动驾驶汽车。\n开始于强化学习 在强化学习中， 我们往往能见到agent的概念。强化学习是一种机器学习方法，它教导Agent通过试错法找到最佳行动路径。就像训练小狗一样，我们通过奖励来引导Agent做出正确的决策。Agent的目标是在与环境的交互中寻找最优策略。理想情况下，如果Agent能够获取足够多的真实环境数据，它就能找到最佳解决方案。然而，由于真实环境的复杂性，完全模拟真实世界是不现实的。\n目前，强化学习主要适用于环境简单、问题定义明确的场景，如围棋或视频游戏。这种方法在虚拟环境中通过大量试错来探索解决方案，这种方法虽然有效，但缺乏灵活性和高效性。与人类学习新技能的方式相比，强化学习的效率远低。人们通常通过少量的尝试就能迅速掌握新技能，而强化学习可能需要成千上万次的试错。\n这时候，如果agent具有大脑就好了。\n将LLMs作为大脑: 赋能智能Agent的关键技术 相较于基于强化学习的Agent，人类的优势在于我们天生具备的记忆能力和逻辑判断能力，甚至包括反思和从经验中学习的能力。这些能力使得我们能够通过极少的试错迅速适应和掌握新技能。\n语言模型（LLMs）为AI领域带来了革命性的变化。LLMs通过其深度学习的新范式，以及在思维链和自然语言理解方面的强大能力，预示着Agent将拥有更强大的学习和迁移能力。这种能力的提升将使得创建广泛应用且实用的Agent成为可能。\n虽然LLM是否真正具备了推理能力仍然存疑，但LLM的出现无疑改变了很多。以COT（Chain of Thought）为例，这种模型通过打印解题的中间步骤，加强了在数学和逻辑推理方面的能力，减少了幻觉的出现。这一突破性的工作揭示了LLM在不同场景下的强大\u0026quot;in-context learning\u0026quot;能力，以及其在未经微调的情况下的泛化能力。\n将LLM视为AI Agent的大脑，为自动化系统提供了一种全新的构思方式。这种基于LLM的agent系统综合了规划、记忆、工具使用和行动的能力，通过API调用与外部世界互动，显示出了前所未有的灵活性和效率。\n根据LLM Powered Autonomous Agents一文对LLM-based agent系统的定义， agent需要具备的基本能力：规划+记忆+工具+行动。\n规划能力：将复杂的任务分解成小任务， 并管理每一个子任务的目标， 并从过去的失败中反思，以吸取经验。\n记忆：LLM的上下文长度有限， 通过额外的记忆系统以提升LLM作为大脑的能力。\n工具调用\u0026amp;行动：LLM通过API调用的方式，执行任务， 与外界交互，而不是只是输出文字。\n探索AI代理的独特能力：人类与单一LLM无法比拟 AI系统的主要优势在于它们的规模和效率。这些系统能够执行以下任务，超越人类能力：\n大规模数据处理：AI能够高效地分析和处理超出人类理解范围的数据量。\n无需休息的持续操作：AI系统可以不间断地运行，而无需像人类那样休息和恢复。\n超快速计算：AI可以迅速执行复杂的计算，处理速度和效率远超人类。\nAI代理与单一LLM的不同:\n根据Andrew Ng在讲座中分享的内容，使用相对“简单”模型的代理工作流程（例如GPT-3.5）在实际应用中往往能够超越使用“智能”模型（如GPT-4）的零次提示。这说明在特定场景下，选择适当的AI模型和策略可能比单一的高级模型更有效。\nAI代理在决策制定中的应用也显示出其独特的优势。它们可以在没有情感偏见的情况下，基于大量数据做出快速且精确的决策。这种能力在需要快速响应和高精确度的领域尤为重要，如金融交易和紧急响应系统。\nAgent的规划和思维过程 AI Agent在处理复杂任务时，通过将大任务分解成小任务来提高效率。此外，自我反思能力允许Agent从过去的行动中学习，通过评估过去的决策来改善未来的表现。\nCoT，Chain of Thought， Wei et al. 2022。 即“思维链”，是一种使Agent逐步思考的方法。它通过要求模型展示解决问题的中间步骤来加强其逻辑推理能力，从而提高决策的质量和准确性。\nTree of Thoughts， ToT (Yao et al. 2023)\n尽管语言模型在许多领域表现出色，但在需要复杂规划和全局决策的任务上，它们的能力受到了限制。ToT框架应运而生，旨在通过一个结构化的思考和评估过程来弥补这一缺陷。\nToT框架借鉴了人类心理学中的双系统决策理论，通过整合快速直觉判断和慢速深思熟虑的决策过程，极大地提升了模型的决策能力。这一框架通过自我评估的方式，允许模型在面对多种可能的决策路径时，能够进行有效的选择和全局优化。\nToT框架旨在克服现有语言模型在处理需要复杂规划或搜索任务的局限。它通过结构化的思想树来探索和评估不同的决策路径。ToT允许模型在考虑多个推理路径时自我评估其选择，以做出最佳的决策。此外，ToT结合了语言生成和搜索算法（如BFS和DFS），使模型能够在进行决策时前瞻和回溯，以实现全局最优选择。\nprompt example：\ncot_prompt = \u0026#39;\u0026#39;\u0026#39; Write a coherent passage of 4 short paragraphs. The end sentence of each paragraph must be: {input} Make a plan then write. Your output should be of the following format: Plan: Your plan here. Passage: Your passage here. \u0026#39;\u0026#39;\u0026#39; vote_prompt = \u0026#39;\u0026#39;\u0026#39;Given an instruction and several choices, decide which choice is most promising. Analyze each choice in detail, then conclude in the last line \u0026#34;The best choice is {s}\u0026#34;, where s the integer id of the choice. \u0026#39;\u0026#39;\u0026#39; compare_prompt = \u0026#39;\u0026#39;\u0026#39;Briefly analyze the coherency of the following two passages. Conclude in the last line \u0026#34;The more coherent passage is 1\u0026#34;, \u0026#34;The more coherent passage is 2\u0026#34;, or \u0026#34;The two passages are similarly coherent\u0026#34;. \u0026#39;\u0026#39;\u0026#39; score_prompt = \u0026#39;\u0026#39;\u0026#39;Analyze the following passage, then at the last line conclude \u0026#34;Thus the coherency score is {s}\u0026#34;, where s is an integer from 1 to 10. \u0026#39;\u0026#39;\u0026#39; GoT， Graph of Thoughts，\nhttps://arxiv.org/abs/2308.09687\nhttps://arxiv.org/abs/2401.14295\nGoT（Graph of Thoughts）是在ToT（Tree of Thoughts）基础上的一种进阶，它通过引入图状结构，增强了模型处理复杂推理任务的能力。这种结构允许在生成的思考中进行更为灵活的图状转换，如合并多个思考或在思考间进行循环。\nGoT的核心特点在于其灵活的图状结构，这使得它能够通过合并和循环不同的思考节点来模拟更复杂的推理过程。每个思考节点可以从多个父节点聚合信息，也可以向多个子节点扩展，形成一个密集的思考网络。这种结构特别适合处理那些传统树状模型难以解决的复杂推理和决策任务。\nGoT设计之初就为了处理比ToT更为复杂的推理任务。通过允许广泛的依赖关系和中间步骤的聚合，GoT能够更有效地解决那些需要非线性思考路径的问题。例如，在处理涉及多个相互关联子问题的任务时，GoT的图状结构提供了一种比传统线性或树状结构更为有效的解决方案。\nXoT, Everything of Thoughts, https://arxiv.org/abs/2311.04254\nXoT代表了在AI领域中对复杂思考和决策过程的一次显著革新，它通过结合蒙特卡洛树搜索（MCTS）和大型语言模型求解器（LLM solver）来优化决策路径。\nXoT框架包含以下几个关键步骤和组件：\n预训练的MCTS模块：该模块通过在特定任务上的预训练，获得了有效导航复杂思考路径的能力。\n动态思考搜索：在实际应用中，MCTS模块继续利用其策略和价值网络来探索和优化潜在的思考轨迹。\n思考修正与优化：LLM评估并修正MCTS的输出，确保思考路径的逻辑严密性和有效性。\n决策执行：修正后的思考路径被送回LLM，用于解决具体的问题和挑战。\nReAct (Reason to Act) 是由 Yao et al. 2023 提出的一种新颖的提示框架，旨在通过交错的思考、行动和观察步骤，提高大型语言模型（LLM）的动态推理和计划调整能力。\nReAct通过“思考-行动-观察”结构，使LLM能够生成口头推理迹线和与任务相关的行动。这种结构允许模型动态地创建、维护并调整高层次的行动计划，同时与外部环境（如Wikipedia）互动，引入额外信息以丰富推理。\nReAct的独特特点\n直观且易于设计：ReAct的设计直观，易于实现，并能快速适应不同的应用场景。\n通用性与灵活性：适用于多种任务，能够灵活处理复杂的情境。\n高性能与鲁棒性：提供稳定且有效的推理输出。\n与人类行为一致且可控：增强了模型的可控性，与人类的推理和行动方式更为一致。\nReAct与CoT的对比\n相对于CoT（Chain of Thought），ReAct通过交错的思考、行动和观察步骤，改进了模型的根据性和可信度。然而，这种结构在提高模型实地操作的同时，也略微降低了在推理步骤制定的灵活性。此外，ReAct的有效性很大程度上依赖于成功检索到信息丰富的知识。\nThought: ... Action: ... Observation: ... ... (Repeated many times) Reflexion是由Shinn \u0026amp; Labash 2023提出的一种创新的决策支持框架。它包括三个核心模块：Actor（行动模块）、Evaluator（评估模块）、和Self-Reflection（自我反思模块），旨在通过增强的语言模型反馈机制提升任务处理效率和质量。\n框架组成与工作机制\nActor模块：负责生成针对特定任务的行动指令和文本。\nEvaluator模块：评估Actor的输出，保证行动的适宜性和效果。\nSelf-Reflection模块：反馈生成部分，通过深入分析和总结Actor的表现，指导未来的改进。\nReflexion框架的轻量级设计和对详细反馈的处理能力使其在多个高级任务中表现优异，包括编程、推理和复杂决策。实际应用显示，该框架能显著提升任务处理的正确率和效率。\n思考的快与慢。 在《思考，快与慢》一书中，丹尼尔·卡尼曼提出了人类思考的两种模式：“系统1”和“系统2”。系统1是快速、本能和情感性的，而系统2则更为缓慢、深思熟虑和逻辑性。这两种系统在处理不同类型的记忆和决策时发挥着不同的作用。\nAgent记忆 记忆是人类认知功能的核心，使我们能够从经验中学习并避免重复错误。在人工智能领域，尤其是在开发智能代理（Agent）时，构建有效的记忆系统也显得尤为重要。\nAI系统，尤其是依赖于大型语言模型的Agent，常面临有限的上下文记忆容量问题。这限制了它们在处理持续对话和复杂任务中的表现。这些系统通常受到有限上下文长度的制约，这限制了它们在处理连续对话或复杂任务时的效率。例如，一个没有有效记忆机制的Agent可能会重复犯同样的错误，或者忘记初始的任务目标。\n尽管现代LLMs的上下文长度已经可以处理超过100,000个标记，试图将所有对话历史和相关记忆直接置于模型的上下文中既不经济也不高效。因此，开发一个专门的记忆系统，如检索增强生成（Retrieval-Augmented Generation, RAG）成为提升Agent性能的有效手段。\n如果要为AI构建高效的记忆系统，借鉴和参考人类的记忆系统是必不可少的。人类的记忆系统包含多种类型的记忆，每种记忆都有其独特的生物学基础和功能，这些记忆类型不仅支持我们的日常活动，还是我们进行复杂决策和学习的基础。\n通过了解人类记忆的工作原理，我们可以设计出能够更好地模拟人类认知过程的AI系统。这不仅可以提高机器的任务执行能力，还可以使机器更加自主地适应复杂的环境和需求。\n根据维基百科的定义，人类的记忆系统可细分成：\n工作记忆：支持我们处理日常任务和进行决策。\n工具记忆：帮助我们形成习惯和自动化反应。\n语义记忆：允许我们累积知识和理解世界。\n情节记忆：使我们能够回忆过去的经历和事件。\n动作记忆：通过练习改善我们的物理技能和运动。\n遗忘的机制和认知卸载。记忆的形成经历过滤、压缩、遗忘和重组等环节。在这个过程中，大脑会删除大部分接收到的信息，只保留对当前活动或未来决策最关键的部分。\n建议阅读：\nA Survey on the Memory Mechanism of Large Language Model based Agents\nAgent的工具调用 我们更希望能帮助我们干活的agent 而不是一个只会说话的LLMs。换句话说人实际上并不需要一个聊天的对象，而是帮助解决问题的助手\n如何让LLMs具备工具调用的能力。 根据当前的主要工作， 主要是以openAI 的tool-using 的工作为主（也就是之前的function calling）。\n一句话解释：function calling从本质上并不是严格的工具调用， 而是作为工具调用的前奏，它通过更加结构化的方式指导LLM输出，为在本地执行具体函数提供了参数，铺平了道路。\n具体来说，function calling允许LLM在执行过程中通过指定的参数来调用并执行一个特定的函数。这种方式不仅实现了代码的重用和模块化处理，而且能够从模型中获取更可靠的结构化数据回应。在API调用过程中，开发者可以描述想要执行的功能，并让模型智能地选择输出包含所需参数的JSON对象。这个过程中，Chat Completions API本身不直接执行任何函数调用，而是生成了可以在开发者代码中实现函数调用的JSON。\n更详细的tool-using内容，可以查看之前的博文：Agent学习笔记：OpenAI Function Calling完全指南\n除了tool-using意外， 比较重要的工具还有：code interpreter， 在代码开发的场景下， code interpreter充当了RL中的Env角色，让agent能够根据环境的反馈做出对应决策，而不只是生成代码。 除了openAI所提供的code interpreter外， 还有一些开源的code interpreter，如Open Interpreter 可以使用。\n从单Agent到多agent协作 来自斯坦福的虚拟小镇，因其独特的话题性而被广泛讨论。\nGenerative Agents: Interactive Simulacra of Human Behavior\nMetaGPT 在MetaGPT看来，可以将智能体想象成环境中的数字人，其中\n智能体 = 大语言模型（LLM） + 观察 + 思考 + 行动 + 记忆\n多智能体系统可以视为一个智能体社会，其中\n多智能体 = 智能体 + 环境 + 标准流程（SOP） + 通信 + 经济\nCode = SOP(Team) 是核心哲学。我们将SOP具象化，并且用于LLM构成的团队\n一些讨论 LLMs真的具备逻辑推理能力吗 何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；**推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。**LLMs的推理能力似乎是”涌现“的结果，而非专门针对性训练，所以LLMs是否真正具备推理能力？从一些结果表明，LLMs似乎是在背答案而非真正的推理。\n在 Can Large Language Models Reason? 这篇文章中作者认为CoT过程中LLM可能是在背答案：\nGPT-4 solved 10 out of 10 problems that had been published before 2021 (GPT-4’s pre-training cutoff date) and zero out of 10 problems that had been published after 2021. 不过，我还是持保留意见的， 作者所观察到的现象和人类很像，更擅长在自己熟悉的领域，因为存在大量的记忆，记忆间存在大量“近道”（shortcut）用于加速推导过程，甚至直接给出答案；所要做的让LLMs去执行“慢思考”而不是“快思考”。\n如果从transformer 的原理上讨论， 一个自回归的模型本身是和推理，逻辑甚至是智能无缘的。\n但人类的语言中， 天生具备了逻辑，或者人类的语言中融入的人类本身的逻辑。那么通过模拟语言的生成，一定程度也能恢复出语言背后的逻辑。\nAgent真的只是商业上的吹捧或者泡沫吗 泡沫的成份一定是有点。但也是未来十年值得做的东西。\n如果把LLM类比成CPU的话， 一个完整的计算机系统，除了CPU以外， 还需要内存，控制，输入输出等组件。不可能让LLM实现所有功能，这并不现实。但通过一定合理的架构，工作流的编排，能够大大提升LLM的准确性，进而加快落地实现。\n传统行业要如何在agent上发力 所有公司都有SOP，和大量存在在员工脑子中的“隐性知识”。 这些“知识”只有转换成agent的工作流（思维方式），或者是LLM的system prompt，才会变得更有价值和意义。现阶段有很多公司在做所谓的知识管理， 本质上是用公司的内部文本作为RAG系统而已，但一个问答系统很难量化出收益，并且对于使用者的要求挺高的。 实际上我认为，发力点应该是将内部人类可使用的工具逐渐API化，标准化以方便agent的工具调用，然后定义智能代理在各种业务场景中的具体任务和行动。这包括从简单的数据检索到复杂的决策制定\nAgent应该从事简单重复劳动还是具有创造性的探索工作 这题让GPT-4来回答吧：\n关于“Agent应该从事简单重复劳动还是具有创造性的探索工作”的问题，我们可以从多个角度进行分析：\n经济效益：从经济角度考虑，如果简单重复的劳动可以被自动化或由机器人执行，这将大幅度降低成本，并提高效率。企业通常会选择自动化这类工作以减少人力成本。然而，对于创造性的探索工作，由于需要不断地创新和解决新问题，这种类型的工作更可能需要人类智能的参与，因此，这种工作对于推动技术进步和经济增长具有重要价值。\n技术发展：随着AI和机器学习技术的发展，越来越多的简单劳动可以被智能系统所取代。例如，数据输入、监控等任务已被自动化系统广泛接管。然而，对于需要高度创造性和判断力的工作，如科学研究、艺术创作、复杂决策制定等，目前的技术还无法完全替代人类。\n人类福祉：从心理学的角度来看，长期从事简单重复的劳动可能导致工作满意度下降，影响心理健康。相反，创造性工作通常能带来更高的个人成就感和职业满意度。因此，鼓励Agent从事创造性探索工作可能更有助于提升整体福祉。\n社会需求和未来趋势：社会对创新和创造的需求日益增加，这种趋势推动了对创造性职业的需求。例如，新兴技术、可持续发展解决方案和个性化产品等领域，都需要大量的创新思维和创造力。因此，社会和市场需求可能更倾向于从事具有创造性的探索工作。\n综上所述，虽然从事简单重复的劳动在某些情况下具有其经济和效率上的优势，但从长远和全面的角度来看，鼓励Agent从事具有创造性的探索工作似乎更具前瞻性和可持续性。这不仅有助于经济和技术的发展，还能改善工作者的心理福祉和职业满意度。\nAgent在制造业良率分析上如何应用 以Yield分析和提升为例，在进行Yield提升和案例分析时，存在大量重复的分析和判断工作，这些可以通过AI进行加速和辅助，而不需人工逐一检查。\n工程师每天可能需要处理超过100个与良率相关的预警。其中约40%可能是由于测试问题、设备故障或是之前已经标注过的案例。这些都需要工程师逐一检查。由于人力有限，他们只能优先审查良率特别低的情况，可能会错过一些潜在的问题。通过使用特定规则和AI Agent，可以自动检查这些数据并作出判断。\n在处理实际案例时，工程师通常会根据案例特征在知识库中查询处理方法，这一过程也可以由Agent自动完成，并缩小后续检查的范围。如果需要进一步分析，工程师会调用不同的工具用于检查，这些分析也可以通过Agent来执行。如果仍无法找到问题，可以提醒人工介入。当Agent成功分析出结果时，还会将分析过程和结果整理成图文并茂的报告，供工程师检查和使用。一旦这些分析被人工审核并采用，它们就会成为高质量的知识，自动加入知识库中供下次使用。\nReading LLM Powered Autonomous Agents\nA busy person’s Intro to AI Agents\n基于大语言模型的AI Agents—Part 1\nChain of Thought\nTree of Thoughts\nGraph of Thoughts\nReAct\nReflexion\nMetaGPT: Meta Programming for Multi-Agent Collaborative Framework\nGenerative Agents: Interactive Simulacra of Human Behavior\nLLM Agents Papers\nAI Agent \u0026amp; 大模型经典论文推荐\nAI Agents are disrupting automation: Current approaches, market solutions and recommendations\nAGI-Edgerunners-LLM-Agents-Papers\nThe Rise and Potential of Large Language Model Based Agents: A Survey\nAwesome AI Agents\nLarge Language Model based Multi-Agents: A Survey of Progress and Challenges\nThe Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey\n","permalink":"https://niraya666.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84-agent%E7%A7%91%E6%99%AE%E5%90%91/","summary":"\u003ch2 id=\"写在开头\"\u003e写在开头\u003c/h2\u003e\n\u003cp\u003e本文是基于最近组内技术交流的文字稿整理。\u003c/p\u003e\n\u003ch2 id=\"what-is-agent\"\u003eWhat is Agent？\u003c/h2\u003e\n\u003cp\u003e在探讨复杂的人工智能技术之前，让我们先回顾一下生活中的一个简单例子：扫地机器人。这种智能设备在房间中自主导航，避开障碍物，寻找最有效的清洁路径。它就是一个现实生活中的Agent——一个可以自主决策和行动的实体。\u003c/p\u003e\n\u003cp\u003e在人工智能领域，Agent指的是任何可以感知其环境并根据感知结果做出决策的实体。这些决策旨在完成某些任务或达成特定的目标。Agent的行为可以简单如游戏里的机器人，也可以复杂如自动驾驶汽车。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/Pasted%202024-05-10-14-58-28.webp\" alt=\"Pasted 2024-05-10-14-58-28.webp\"  /\u003e\n\u003c/p\u003e\n\u003ch3 id=\"开始于强化学习\"\u003e开始于强化学习\u003c/h3\u003e\n\u003cp\u003e在强化学习中， 我们往往能见到agent的概念。强化学习是一种机器学习方法，它教导Agent通过试错法找到最佳行动路径。就像训练小狗一样，我们通过奖励来引导Agent做出正确的决策。Agent的目标是在与环境的交互中寻找最优策略。理想情况下，如果Agent能够获取足够多的真实环境数据，它就能找到最佳解决方案。然而，由于真实环境的复杂性，完全模拟真实世界是不现实的。\u003c/p\u003e\n\u003cp\u003e目前，强化学习主要适用于环境简单、问题定义明确的场景，如围棋或视频游戏。这种方法在虚拟环境中通过大量试错来探索解决方案，这种方法虽然有效，但缺乏灵活性和高效性。与人类学习新技能的方式相比，强化学习的效率远低。人们通常通过少量的尝试就能迅速掌握新技能，而强化学习可能需要成千上万次的试错。\u003c/p\u003e\n\u003cp\u003e这时候，如果agent具有大脑就好了。\u003c/p\u003e\n\u003ch3 id=\"将llms作为大脑-赋能智能agent的关键技术\"\u003e将LLMs作为大脑: \u003cstrong\u003e赋能智能Agent的关键技术\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e相较于基于强化学习的Agent，人类的优势在于我们天生具备的记忆能力和逻辑判断能力，甚至包括反思和从经验中学习的能力。这些能力使得我们能够通过极少的试错迅速适应和掌握新技能。\u003c/p\u003e\n\u003cp\u003e语言模型（LLMs）为AI领域带来了革命性的变化。LLMs通过其深度学习的新范式，以及在思维链和自然语言理解方面的强大能力，预示着Agent将拥有更强大的学习和迁移能力。这种能力的提升将使得创建广泛应用且实用的Agent成为可能。\u003c/p\u003e\n\u003cp\u003e虽然LLM是否真正具备了推理能力仍然存疑，但LLM的出现无疑改变了很多。以COT（Chain of Thought）为例，这种模型通过打印解题的中间步骤，加强了在数学和逻辑推理方面的能力，减少了幻觉的出现。这一突破性的工作揭示了LLM在不同场景下的强大\u0026quot;in-context learning\u0026quot;能力，以及其在未经微调的情况下的泛化能力。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png\" alt=\"截屏2024-05-08 15.37.21.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e将LLM视为AI Agent的大脑，为自动化系统提供了一种全新的构思方式。这种基于LLM的agent系统综合了规划、记忆、工具使用和行动的能力，通过API调用与外部世界互动，显示出了前所未有的灵活性和效率。\u003c/p\u003e\n\u003cp\u003e根据\u003ca href=\"https://lilianweng.github.io/posts/2023-06-23-agent/\"\u003eLLM Powered Autonomous Agents\u003c/a\u003e一文对LLM-based agent系统的定义， agent需要具备的基本能力：规划+记忆+工具+行动。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e规划能力\u003c/strong\u003e：将复杂的任务分解成小任务， 并管理每一个子任务的目标， 并从过去的失败中反思，以吸取经验。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e记忆\u003c/strong\u003e：LLM的上下文长度有限， 通过额外的记忆系统以提升LLM作为大脑的能力。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e工具调用\u0026amp;行动\u003c/strong\u003e：LLM通过API调用的方式，执行任务， 与外界交互，而不是只是输出文字。\u003c/p\u003e\n\u003ch3 id=\"探索ai代理的独特能力人类与单一llm无法比拟\"\u003e\u003cstrong\u003e探索AI代理的独特能力：人类与单一LLM无法比拟\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eAI系统的主要优势在于它们的规模和效率。这些系统能够执行以下任务，超越人类能力：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e大规模数据处理\u003c/strong\u003e：AI能够高效地分析和处理超出人类理解范围的数据量。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e无需休息的持续操作\u003c/strong\u003e：AI系统可以不间断地运行，而无需像人类那样休息和恢复。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e超快速计算\u003c/strong\u003e：AI可以迅速执行复杂的计算，处理速度和效率远超人类。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eAI代理与单一LLM的不同:\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e根据Andrew Ng在讲座中分享的内容，使用相对“简单”模型的代理工作流程（例如GPT-3.5）在实际应用中往往能够超越使用“智能”模型（如GPT-4）的零次提示。这说明在特定场景下，选择适当的AI模型和策略可能比单一的高级模型更有效。\u003c/p\u003e\n\u003cp\u003eAI代理在决策制定中的应用也显示出其独特的优势。它们可以在没有情感偏见的情况下，基于大量数据做出快速且精确的决策。这种能力在需要快速响应和高精确度的领域尤为重要，如金融交易和紧急响应系统。\u003c/p\u003e\n\u003ch2 id=\"agent的规划和思维过程\"\u003e\u003cstrong\u003eAgent的规划和思维过程\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eAI Agent在处理复杂任务时，通过将大任务分解成小任务来提高效率。此外，自我反思能力允许Agent从过去的行动中学习，通过评估过去的决策来改善未来的表现。\u003c/p\u003e\n\u003cp\u003eCoT，Chain of Thought， \u003ca href=\"https://arxiv.org/abs/2201.11903\"\u003eWei et al. 2022\u003c/a\u003e。 即“思维链”，是一种使Agent逐步思考的方法。它通过要求模型展示解决问题的中间步骤来加强其逻辑推理能力，从而提高决策的质量和准确性。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png\" alt=\"截屏2024-05-08 15.37.21.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTree of Thoughts， ToT\u003c/strong\u003e  (\u003ca href=\"https://arxiv.org/abs/2305.10601\"\u003eYao et al. 2023\u003c/a\u003e)\u003c/p\u003e","title":"基于大语言模型的 Agent：科普向"},{"content":"写在最开始 当我们在讨论基于大型语言模型（LLM-based）的智能代理（agent）时，我们究竟在谈论什么？根据Lilian W在其文章《LLM Powered Autonomous Agents》中的讨论，一个智能代理需要具备几个核心能力：规划（Planning）、记忆（Memory）、以及工具使用（Tool use）。特别地，工具使用方面的进展，得益于OpenAI在API中提供的function calling功能，为我们开启了新的可能性。\nOpenAI function calling，作为智能代理与外部工具交互的基本方式，对于每位从业者来说都是必备技能。随着技术的发展，我们期望的不只是能与我们对话的LLM，而是能够辅助我们使用各种工具、做出决策的智能伙伴。\n不过需要特别指出的是，最近OpenAI在Chat Completions API中已经废弃了“函数（function）”的使用，转而采用“工具（tool）”。这一变更旨在拓宽LLM集成的功能范围，为更复杂的交互模式铺平道路，如构建能够相互作用的多代理系统。\n尽管如此，由于语言习惯的原因，本文中仍然会使用function calling的术语来描述OpenAI的tool using功能，因为“function calling”的说法已经深入人心了。\n核心内容概览\nFunction Calling的定义：解释什么是function calling，以及它在智能代理工作中的作用。\nOpenAI Cookbook示例：提供实际的function calling示例，帮助读者理解其在实际应用中的用途。\n开源LLM的Tool Using：探索如何在开源大型语言模型中实现工具使用，以及LLM在tool using的时候经历了什么。\n评价与训练：讨论如何评价开源模型的工具使用能力，以及如何训练LLM进行有效的工具使用。\n鉴于整理笔记的速度远赶不上更新的速度， 会将第四部份作为单独的部分整理。\n何为function calling 一句话解释：function calling从本质上并不是严格的工具调用， 而是作为工具调用的前奏，它通过更加结构化的方式指导LLM输出，为在本地执行具体函数提供了参数，铺平了道路。\n具体来说，function calling允许LLM在执行过程中通过指定的参数来调用并执行一个特定的函数。这种方式不仅实现了代码的重用和模块化处理，而且能够从模型中获取更可靠的结构化数据回应。在API调用过程中，开发者可以描述想要执行的功能，并让模型智能地选择输出包含所需参数的JSON对象。这个过程中，Chat Completions API本身不直接执行任何函数调用，而是生成了可以在开发者代码中实现函数调用的JSON。\nfunction calling的应用范围广泛，如\n创建智能助手：通过调用外部API回答问题。\n转换指令：将自然语言指令转换成API调用指令。\n数据提取：从文本中提取结构化数据。\nfunction calling的过程涵盖了从定义函数集、通过模型生成遵循自定义模式的JSON对象字符串，到在代码中解析这个字符串并调用相应函数的全过程。这一连串操作不仅自动化了交互过程，还确保了执行操作的安全性和准确性。\n一些常见的问题 JSON mode json mode 和tool-using 有什么关系？有了json mode 还需要用到tool-using吗？\n从json mode 的本质， 更多的是在system prompt 增加一句类似“请以json格式输出”之类的话，然后在LLM输出时增加json结果检查和格式转换。在使用时只需要在client.chat.completions.create 中 增加response_format={ \u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot; } 即可。\n那么json mode 什么时候会用到呢？一般在做文本提取，内容提取时可以使用；以RAG场景为例， 当我们希望LLM能够帮我们对用户的query进行改写时，我们肯定是希望模型能够返回干净的json格式改写结果，这样的结果可以直接使用，而不是在模型输出一些内容后，如：\n\u0026#34;\u0026#34;\u0026#34; 好的，以下是我的改写内容： ``` real-rewrite-query ``` \u0026#34;\u0026#34;\u0026#34; 其中包含了一些模型喜欢输出的客套话，此时我们需要通过正则匹配等方法将真正希望使用内容提取出来。而这时候json mode可以直接输出需要的内容， 而跳过了额外的提取步骤。在json mode 出现之前，这样的处理我们也尝试使用过tool-using 的模式，但有点大材小用了。\n很显然， tool-using的真正强大之处并不只是对输出格式进行处理， 而是能够让模型从提供的多个tools中选择需要使用的。\n如何使用OpenAI function calling 天气查询的简单示例 环境配置\n首先，我们需要安装一些必要的Python库。这些库将帮助我们与OpenAI的API进行交互，以及完成一些辅助功能。\n!pip install scipy --quiet !pip install tenacity --quiet !pip install tiktoken --quiet !pip install termcolor --quiet !pip install openai --quiet os.environ[\u0026#34;OPENAI_API_KEY\u0026#34;] = \u0026#34;...\u0026#34; from openai import OpenAI from tenacity import retry, wait_random_exponential, stop_after_attempt from termcolor import colored client = OpenAI() 工具函数定义\n接下来，我们定义一些实用函数，这些函数旨在方便我们向Chat Completions API发送请求，并管理与跟踪对话状态。\n@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3)) def chat_completion_request(messages, tools=None, tool_choice=None, model=\u0026#34;gpt-3.5-turbo\u0026#34;): try: response = client.chat.completions.create( model=model, messages=messages, tools=tools, tool_choice=tool_choice, ) return response except Exception as e: print(\u0026#34;Unable to generate ChatCompletion response\u0026#34;) print(f\u0026#34;Exception: {e}\u0026#34;) return e def pretty_print_conversation(messages): role_to_color = { \u0026#34;system\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;user\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;assistant\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;function\u0026#34;: \u0026#34;magenta\u0026#34;, } for message in messages: if message[\u0026#34;role\u0026#34;] == \u0026#34;system\u0026#34;: print(colored(f\u0026#34;system: {message[\u0026#39;content\u0026#39;]}\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]])) elif message[\u0026#34;role\u0026#34;] == \u0026#34;user\u0026#34;: print(colored(f\u0026#34;user: {message[\u0026#39;content\u0026#39;]}\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]])) elif message[\u0026#34;role\u0026#34;] == \u0026#34;assistant\u0026#34; and message.get(\u0026#34;function_call\u0026#34;): print(colored(f\u0026#34;assistant: {message[\u0026#39;function_call\u0026#39;]}\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]])) elif message[\u0026#34;role\u0026#34;] == \u0026#34;assistant\u0026#34; and not message.get(\u0026#34;function_call\u0026#34;): print(colored(f\u0026#34;assistant: {message[\u0026#39;content\u0026#39;]}\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]])) elif message[\u0026#34;role\u0026#34;] == \u0026#34;function\u0026#34;: print(colored(f\u0026#34;function ({message[\u0026#39;name\u0026#39;]}): {message[\u0026#39;content\u0026#39;]}\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]])) 函数规范定义\n我们还需要创建一些函数规范，以接口化与假设的天气API的交互。\ntools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the current weather\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;format\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;celsius\u0026#34;, \u0026#34;fahrenheit\u0026#34;], \u0026#34;description\u0026#34;: \u0026#34;The temperature unit to use. Infer this from the users location.\u0026#34;, }, }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;, \u0026#34;format\u0026#34;], }, } }, { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_n_day_weather_forecast\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get an N-day weather forecast\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;format\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;celsius\u0026#34;, \u0026#34;fahrenheit\u0026#34;], \u0026#34;description\u0026#34;: \u0026#34;The temperature unit to use. Infer this from the users location.\u0026#34;, }, \u0026#34;num_days\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The number of days to forecast\u0026#34;, } }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;, \u0026#34;format\u0026#34;, \u0026#34;num_days\u0026#34;] }, } }, ] 对话示例\n当我们请求当前天气时， LLM会要求澄清问题，如地址等参数信息：\nmessages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Don\u0026#39;t make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What\u0026#39;s the weather like today\u0026#34;}) chat_response = chat_completion_request( messages, tools=tools ) assistant_message = chat_response.choices[0].message messages.append(assistant_message) assistant_message output:\nChatCompletionMessage(content=\u0026#39;Sure, may I know your current location?\u0026#39;, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=None) 当补充缺失的信息后， LLM将生成适当的函数参数\nmessages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;I\u0026#39;m in Shanghai, China.\u0026#34;}) chat_response = chat_completion_request( messages, tools=tools ) assistant_message = chat_response.choices[0].message messages.append(assistant_message) assistant_message output:\nChatCompletionMessage(content=None, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=\u0026#39;call_VdqOOMp9pagf5ho39Y2HmYV4\u0026#39;, function=Function(arguments=\u0026#39;{\\n \u0026#34;location\u0026#34;: \u0026#34;San Francisco, CA\u0026#34;,\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;,\\n \u0026#34;num_days\u0026#34;: 4\\n}\u0026#39;, name=\u0026#39;get_n_day_weather_forecast\u0026#39;), type=\u0026#39;function\u0026#39;)]) 完整流程如下：\nmessages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Don\u0026#39;t make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;what is the weather going to be like in Glasgow, Scotland over the next x days\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;in 5 days\u0026#34;}) chat_response = chat_completion_request( messages, tools=tools ) assistant_message = chat_response.choices[0].message messages.append(assistant_message) assistant_message 当然， 我们也可以强制要求使用特定的函数\nmessages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Don\u0026#39;t make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Give me a weather report for Toronto, Canada.\u0026#34;}) chat_response = chat_completion_request( messages, tools=tools, tool_choice={\u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: {\u0026#34;name\u0026#34;: \u0026#34;get_n_day_weather_forecast\u0026#34;}} ) chat_response.choices[0].message output:\nChatCompletionMessage(content=None, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=\u0026#39;call_0ldecDpV8Vdq8mGPoUewlue3\u0026#39;, function=Function(arguments=\u0026#39;{\\n \u0026#34;location\u0026#34;: \u0026#34;Toronto, Canada\u0026#34;,\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;,\\n \u0026#34;num_days\u0026#34;: 1\\n}\u0026#39;, name=\u0026#39;get_n_day_weather_forecast\u0026#39;), type=\u0026#39;function\u0026#39;)]) 并行函数调用\n对于一些特定模型，如**gpt-4-turbo-preview**, gpt-4-0125-preview, gpt-4-1106-preview, gpt-3.5-turbo-0125, and **gpt-3.5-turbo-1106**支持并行函数调用， 允许我们在单个回合中调用多个函数。\nmessages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Don\u0026#39;t make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;what is the weather going to be like in San Francisco and Glasgow over the next 4 days\u0026#34;}) chat_response = chat_completion_request( messages, tools=tools ) assistant_message = chat_response.choices[0].message.tool_calls assistant_message output:\n[ChatCompletionMessageToolCall(id=\u0026#39;call_tfl8eTCW64sHvHjiiatoYzku\u0026#39;, function=Function(arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;San Francisco, CA\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;fahrenheit\u0026#34;, \u0026#34;num_days\u0026#34;: 4}\u0026#39;, name=\u0026#39;get_n_day_weather_forecast\u0026#39;), type=\u0026#39;function\u0026#39;), ChatCompletionMessageToolCall(id=\u0026#39;call_bAqj55RygP2Y1T85RHqgskku\u0026#39;, function=Function(arguments=\u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Glasgow, UK\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;, \u0026#34;num_days\u0026#34;: 4}\u0026#39;, name=\u0026#39;get_n_day_weather_forecast\u0026#39;), type=\u0026#39;function\u0026#39;)] 实现本地函数调用\n首先我们需要构造两个用于演示的假function\nimport json def get_current_weather(location, format=\u0026#34;fahrenheit\u0026#34;): \u0026#34;\u0026#34;\u0026#34; Simulates getting the current weather for a given location. The response is hardcoded for demonstration purposes. Args: location (str): The city and state, e.g., San Francisco, CA. format (str, optional): The temperature unit to use. Defaults to \u0026#34;fahrenheit\u0026#34;. Returns: str: JSON string with the current weather data. \u0026#34;\u0026#34;\u0026#34; if \u0026#34;tokyo\u0026#34; in location.lower(): return json.dumps({\u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Partly Cloudy\u0026#34;}) elif \u0026#34;san francisco\u0026#34; in location.lower(): return json.dumps({\u0026#34;location\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;72\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Sunny\u0026#34;}) elif \u0026#34;paris\u0026#34; in location.lower(): return json.dumps({\u0026#34;location\u0026#34;: \u0026#34;Paris\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Rainy\u0026#34;}) else: return json.dumps({\u0026#34;location\u0026#34;: location, \u0026#34;temperature\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Data Unavailable\u0026#34;}) def get_n_day_weather_forecast(location, num_days, format=\u0026#34;fahrenheit\u0026#34;): \u0026#34;\u0026#34;\u0026#34; Simulates getting an N-day weather forecast for a given location. The response is hardcoded for demonstration purposes. Args: location (str): The city and state, e.g., San Francisco, CA. num_days (int): The number of days to forecast. format (str, optional): The temperature unit to use. Defaults to \u0026#34;fahrenheit\u0026#34;. Returns: str: JSON string with the N-day weather forecast data. \u0026#34;\u0026#34;\u0026#34; # This example just returns a fixed response regardless of the input. # In a real scenario, the response would depend on the location, num_days, and format. forecast = [ {\u0026#34;day\u0026#34;: 1, \u0026#34;temperature\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Sunny\u0026#34;}, {\u0026#34;day\u0026#34;: 2, \u0026#34;temperature\u0026#34;: \u0026#34;18\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Cloudy\u0026#34;}, {\u0026#34;day\u0026#34;: 3, \u0026#34;temperature\u0026#34;: \u0026#34;15\u0026#34;, \u0026#34;format\u0026#34;: format, \u0026#34;description\u0026#34;: \u0026#34;Rainy\u0026#34;} ] # Return only the forecast for the requested number of days. return json.dumps(forecast[:num_days]) available_functions = { \u0026#34;get_current_weather\u0026#34;: get_current_weather, \u0026#34;get_n_day_weather_forecast\u0026#34;: get_n_day_weather_forecast, } 尝试请求天气\nmessages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What\u0026#39;s the weather like in Tokyo!\u0026#34;}) chat_response = chat_completion_request(messages, tools=tools, tool_choice=\u0026#34;auto\u0026#34;) assistant_message = chat_response.choices[0].message assistant_message = json.loads(assistant_message.model_dump_json()) assistant_message[\u0026#34;content\u0026#34;] = str(assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;function\u0026#34;]) #a temporary patch but this should be handled differently # remove \u0026#34;function_call\u0026#34; from assistant message del assistant_message[\u0026#34;function_call\u0026#34;] assistant_message \u0026#34;\u0026#34;\u0026#34; {\u0026#39;content\u0026#39;: \u0026#39;{\\\u0026#39;arguments\\\u0026#39;: \\\u0026#39;{\\\\n \u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;,\\\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;\\\\n}\\\u0026#39;, \\\u0026#39;name\\\u0026#39;: \\\u0026#39;get_current_weather\\\u0026#39;}\u0026#39;, \u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;tool_calls\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;call_Tz8S1HgvnaBzf6CFZP1u4d1J\u0026#39;, \u0026#39;function\u0026#39;: {\u0026#39;arguments\u0026#39;: \u0026#39;{\\n \u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;,\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;\\n}\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;get_current_weather\u0026#39;}, \u0026#39;type\u0026#39;: \u0026#39;function\u0026#39;}]} \u0026#34;\u0026#34;\u0026#34; messages.append(assistant_message) 可以看到，LLM返回了json格式的参数信息（其实是str）以及需要调用的function名称， 拥有这些信息之后就可以调用之前定义的函数了\n# get the weather information to pass back to the model function_name_to_call = assistant_message[\u0026#39;tool_calls\u0026#39;][0][\u0026#39;function\u0026#39;][\u0026#39;name\u0026#39;] function_arguments = assistant_message[\u0026#39;tool_calls\u0026#39;][0][\u0026#39;function\u0026#39;][\u0026#39;arguments\u0026#39;] weather = available_functions[function_name_to_call](function_arguments) 将函数执行结果和对话历史返回给LLM\nmessages.append({\u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;id\u0026#34;], \u0026#34;name\u0026#34;: assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;function\u0026#34;][\u0026#34;name\u0026#34;], \u0026#34;content\u0026#34;: weather}) messages \u0026#34;\u0026#34;\u0026#34; [{\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#34;What\u0026#39;s the weather like in Tokyo!\u0026#34;}, {\u0026#39;content\u0026#39;: \u0026#39;{\\\u0026#39;arguments\\\u0026#39;: \\\u0026#39;{\\\\n \u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;,\\\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;\\\\n}\\\u0026#39;, \\\u0026#39;name\\\u0026#39;: \\\u0026#39;get_current_weather\\\u0026#39;}\u0026#39;, \u0026#39;role\u0026#39;: \u0026#39;assistant\u0026#39;, \u0026#39;tool_calls\u0026#39;: [{\u0026#39;id\u0026#39;: \u0026#39;call_Tz8S1HgvnaBzf6CFZP1u4d1J\u0026#39;, \u0026#39;function\u0026#39;: {\u0026#39;arguments\u0026#39;: \u0026#39;{\\n \u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;,\\n \u0026#34;format\u0026#34;: \u0026#34;celsius\u0026#34;\\n}\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;get_current_weather\u0026#39;}, \u0026#39;type\u0026#39;: \u0026#39;function\u0026#39;}]}, {\u0026#39;role\u0026#39;: \u0026#39;tool\u0026#39;, \u0026#39;tool_call_id\u0026#39;: \u0026#39;call_Tz8S1HgvnaBzf6CFZP1u4d1J\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;get_current_weather\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;{\u0026#34;location\u0026#34;: \u0026#34;Tokyo\u0026#34;, \u0026#34;temperature\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;fahrenheit\u0026#34;}\u0026#39;}] \u0026#34;\u0026#34;\u0026#34; 最终输出结果（for user）\nfinal_response = chat_completion_request(messages, tools=tools) final_response.choices[0].message.content output：\n\u0026#39;The current weather in Tokyo is partly cloudy with a temperature of 10°C (50°F).\u0026#39; 通过function calling 实现sql执行 下载演示所用的sqlite数据\n!wget https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip -O chinook.zip !unzip chinook.zip 连接数据库，和定义一些function\nimport sqlite3 conn = sqlite3.connect(\u0026#34;/content/chinook.db\u0026#34;) print(\u0026#34;Opened database successfully\u0026#34;) def get_table_names(conn): \u0026#34;\u0026#34;\u0026#34;Return a list of table names.\u0026#34;\u0026#34;\u0026#34; table_names = [] tables = conn.execute(\u0026#34;SELECT name FROM sqlite_master WHERE type=\u0026#39;table\u0026#39;;\u0026#34;) for table in tables.fetchall(): table_names.append(table[0]) return table_names def get_column_names(conn, table_name): \u0026#34;\u0026#34;\u0026#34;Return a list of column names.\u0026#34;\u0026#34;\u0026#34; column_names = [] columns = conn.execute(f\u0026#34;PRAGMA table_info(\u0026#39;{table_name}\u0026#39;);\u0026#34;).fetchall() for col in columns: column_names.append(col[1]) return column_names def get_database_info(conn): \u0026#34;\u0026#34;\u0026#34;Return a list of dicts containing the table name and columns for each table in the database.\u0026#34;\u0026#34;\u0026#34; table_dicts = [] for table_name in get_table_names(conn): columns_names = get_column_names(conn, table_name) table_dicts.append({\u0026#34;table_name\u0026#34;: table_name, \u0026#34;column_names\u0026#34;: columns_names}) return table_dicts 获取db 的schema\ndatabase_schema_dict = get_database_info(conn) database_schema_string = \u0026#34;\\n\u0026#34;.join( [ f\u0026#34;Table: {table[\u0026#39;table_name\u0026#39;]}\\nColumns: {\u0026#39;, \u0026#39;.join(table[\u0026#39;column_names\u0026#39;])}\u0026#34; for table in database_schema_dict ] ) 定义tools工具列表\ntools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ask_database\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Use this function to answer user questions about music. Input should be a fully formed SQL query.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;\u0026#34;\u0026#34; SQL query extracting info to answer the user\u0026#39;s question. SQL should be written using this database schema: {database_schema_string} The query should be returned in plain text, not in JSON. \u0026#34;\u0026#34;\u0026#34;, } }, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;], }, } } ] 定义用于执行sql的function\ndef ask_database(conn, query): \u0026#34;\u0026#34;\u0026#34;Function to query SQLite database with a provided SQL query.\u0026#34;\u0026#34;\u0026#34; try: results = str(conn.execute(query).fetchall()) except Exception as e: results = f\u0026#34;query failed with error: {e}\u0026#34; return results def execute_function_call(message): if message.tool_calls[0].function.name == \u0026#34;ask_database\u0026#34;: query = json.loads(message.tool_calls[0].function.arguments)[\u0026#34;query\u0026#34;] results = ask_database(conn, query) else: results = f\u0026#34;Error: function {message.tool_calls[0].function.name} does not exist\u0026#34; return results messages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Answer user questions by generating SQL queries against the Chinook Music Database.\u0026#34;}) messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Hi, who are the top 5 artists by number of tracks?\u0026#34;}) chat_response = chat_completion_request(messages, tools) assistant_message = chat_response.choices[0].message messages.append(assistant_message) if assistant_message.tool_calls: results = execute_function_call(assistant_message) messages.append({\u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: assistant_message.tool_calls[0].id, \u0026#34;name\u0026#34;: assistant_message.tool_calls[0].function.name, \u0026#34;content\u0026#34;: results}) 此时的messages\n[{\u0026#39;role\u0026#39;: \u0026#39;system\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;Answer user questions by generating SQL queries against the Chinook Music Database.\u0026#39;}, {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: \u0026#39;Hi, who are the top 5 artists by number of tracks?\u0026#39;}, ChatCompletionMessage(content=\u0026#39;Function(arguments=\\\u0026#39;{\\\\n \u0026#34;query\u0026#34;: \u0026#34;SELECT artists.Name, COUNT(tracks.TrackId) AS num_tracks FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.ArtistId ORDER BY num_tracks DESC LIMIT 5\u0026#34;\\\\n}\\\u0026#39;, name=\\\u0026#39;ask_database\\\u0026#39;)\u0026#39;, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=\u0026#39;call_vSLysEQncbGvMgXGhttIow6v\u0026#39;, function=Function(arguments=\u0026#39;{\\n \u0026#34;query\u0026#34;: \u0026#34;SELECT artists.Name, COUNT(tracks.TrackId) AS num_tracks FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.ArtistId ORDER BY num_tracks DESC LIMIT 5\u0026#34;\\n}\u0026#39;, name=\u0026#39;ask_database\u0026#39;), type=\u0026#39;function\u0026#39;)]), {\u0026#39;role\u0026#39;: \u0026#39;tool\u0026#39;, \u0026#39;tool_call_id\u0026#39;: \u0026#39;call_vSLysEQncbGvMgXGhttIow6v\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;ask_database\u0026#39;, \u0026#39;content\u0026#39;: \u0026#34;[(\u0026#39;Iron Maiden\u0026#39;, 213), (\u0026#39;U2\u0026#39;, 135), (\u0026#39;Led Zeppelin\u0026#39;, 114), (\u0026#39;Metallica\u0026#39;, 112), (\u0026#39;Deep Purple\u0026#39;, 92)]\u0026#34;}] 最终输出：\nfinal_response = chat_completion_request(messages, tools=tools) final_response.choices[0].message.content # output \u0026#34;\u0026#34;\u0026#34; The top 5 artists by number of tracks are: 1. Iron Maiden - 213 tracks 2. U2 - 135 tracks 3. Led Zeppelin - 114 tracks 4. Metallica - 112 tracks 5. Deep Purple - 92 tracks \u0026#34;\u0026#34;\u0026#34; 基于function calling构建智能代理：自动获取与深度解析arXiv学术文章 在这一节中将介绍如何构建一个能够从arXiv上查找论文， 下载分析并总结学术论文的Agent。这个Agent不仅可以帮助用户快速了解特定领域的最新研究动态，而且还能深入分析和总结选定文章的核心内容。\nAgent核心功能\n获取arXiv文章 get_articles 代理通过**arxiv**库搜索关于特定主题的文章，为用户提供简要的文章摘要和链接。\n阅读并总结文章 read_article_and_summarize 利用**PyPDF2**库读取选中文章的PDF文件，代理能够提炼出文章的主要论点、支撑证据和结论。\n环境配置\n!pip install scipy --quiet !pip install tenacity --quiet !pip install tiktoken==0.3.3 --quiet !pip install termcolor --quiet !pip install openai --quiet !pip install arxiv --quiet !pip install pandas --quiet !pip install PyPDF2 --quiet !pip install tqdm --quiet import os import arxiv import ast import concurrent import json import os import pandas as pd import tiktoken from csv import writer from IPython.display import display, Markdown, Latex from openai import OpenAI from PyPDF2 import PdfReader from scipy import spatial from tenacity import retry, wait_random_exponential, stop_after_attempt from tqdm import tqdm from termcolor import colored GPT_MODEL = \u0026#34;gpt-3.5-turbo-0613\u0026#34; EMBEDDING_MODEL = \u0026#34;text-embedding-ada-002\u0026#34; client = OpenAI() 所有下载的论文都被存储在本地**./data/papers目录中，并且每篇文章的详细信息（包括其嵌入向量）都记录在arxiv_library.csv**文件中。\ndirectory = \u0026#39;./data/papers\u0026#39; # Check if the directory already exists if not os.path.exists(directory): # If the directory doesn\u0026#39;t exist, create it and any necessary intermediate directories os.makedirs(directory) print(f\u0026#34;Directory \u0026#39;{directory}\u0026#39; created successfully.\u0026#34;) else: # If the directory already exists, print a message indicating it print(f\u0026#34;Directory \u0026#39;{directory}\u0026#39; already exists.\u0026#34;) # Set a directory to store downloaded papers data_dir = os.path.join(os.curdir, \u0026#34;data\u0026#34;, \u0026#34;papers\u0026#34;) paper_dir_filepath = \u0026#34;./data/arxiv_library.csv\u0026#34; # Generate a blank dataframe where we can store downloaded files df = pd.DataFrame(list()) df.to_csv(paper_dir_filepath) 我们将定义一些utils function用于：\n文章获取与存储：通过**get_articles**函数查询主题相关的文章，系统自动下载文章并记录重要信息及embedding向量。\n文章选择与内容提取：根据用户的查询，系统通过计算embedding向量的相似度来选择最相关的文章，并提取出文章的文本内容。\n内容分块与总结：长文本被分割成多个较小的块，每个块被独立总结。\n汇总总结：所有独立块的总结被汇总成一篇全面的总结，更好地回应用户的查询。\n@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3)) def embedding_request(text): response = client.embeddings.create(input=text, model=EMBEDDING_MODEL) return response @retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3)) def get_articles(query, library=paper_dir_filepath, top_k=5): \u0026#34;\u0026#34;\u0026#34;This function gets the top_k articles based on a user\u0026#39;s query, sorted by relevance. It also downloads the files and stores them in arxiv_library.csv to be retrieved by the read_article_and_summarize. \u0026#34;\u0026#34;\u0026#34; client = arxiv.Client() search = arxiv.Search( query = query, max_results = top_k, sort_by = arxiv.SortCriterion.SubmittedDate ) result_list = [] for result in client.results(search): result_dict = {} result_dict.update({\u0026#34;title\u0026#34;: result.title}) result_dict.update({\u0026#34;summary\u0026#34;: result.summary}) # Taking the first url provided result_dict.update({\u0026#34;article_url\u0026#34;: [x.href for x in result.links][0]}) result_dict.update({\u0026#34;pdf_url\u0026#34;: [x.href for x in result.links][1]}) result_list.append(result_dict) # Store references in library file response = embedding_request(text=result.title) file_reference = [ result.title, result.download_pdf(data_dir), response.data[0].embedding, ] # Write to file with open(library, \u0026#34;a\u0026#34;) as f_object: writer_object = writer(f_object) writer_object.writerow(file_reference) f_object.close() return result_list def strings_ranked_by_relatedness( query: str, df: pd.DataFrame, relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y), top_n: int = 100, ) -\u0026gt; list[str]: \u0026#34;\u0026#34;\u0026#34;Returns a list of strings and relatednesses, sorted from most related to least.\u0026#34;\u0026#34;\u0026#34; query_embedding_response = embedding_request(query) query_embedding = query_embedding_response.data[0].embedding strings_and_relatednesses = [ (row[\u0026#34;filepath\u0026#34;], relatedness_fn(query_embedding, row[\u0026#34;embedding\u0026#34;])) for i, row in df.iterrows() ] strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True) strings, relatednesses = zip(*strings_and_relatednesses) return strings[:top_n] def read_pdf(filepath): \u0026#34;\u0026#34;\u0026#34;Takes a filepath to a PDF and returns a string of the PDF\u0026#39;s contents\u0026#34;\u0026#34;\u0026#34; # creating a pdf reader object reader = PdfReader(filepath) pdf_text = \u0026#34;\u0026#34; page_number = 0 for page in reader.pages: page_number += 1 pdf_text += page.extract_text() + f\u0026#34;\\nPage Number: {page_number}\u0026#34; return pdf_text # Split a text into smaller chunks of size n, preferably ending at the end of a sentence def create_chunks(text, n, tokenizer): \u0026#34;\u0026#34;\u0026#34;Returns successive n-sized chunks from provided text.\u0026#34;\u0026#34;\u0026#34; tokens = tokenizer.encode(text) i = 0 while i \u0026lt; len(tokens): # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens j = min(i + int(1.5 * n), len(tokens)) while j \u0026gt; i + int(0.5 * n): # Decode the tokens and check for full stop or newline chunk = tokenizer.decode(tokens[i:j]) if chunk.endswith(\u0026#34;.\u0026#34;) or chunk.endswith(\u0026#34;\\n\u0026#34;): break j -= 1 # If no end of sentence found, use n tokens as the chunk size if j == i + int(0.5 * n): j = min(i + n, len(tokens)) yield tokens[i:j] i = j def extract_chunk(content, template_prompt): \u0026#34;\u0026#34;\u0026#34;This function applies a prompt to some input content. In this case it returns a summarized chunk of text\u0026#34;\u0026#34;\u0026#34; prompt = template_prompt + content response = client.chat.completions.create( model=GPT_MODEL, messages=[{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: prompt}], temperature=0 ) return response.choices[0].message.content def summarize_text(query): \u0026#34;\u0026#34;\u0026#34;This function does the following: - Reads in the arxiv_library.csv file in including the embeddings - Finds the closest file to the user\u0026#39;s query - Scrapes the text out of the file and chunks it - Summarizes each chunk in parallel - Does one final summary and returns this to the user\u0026#34;\u0026#34;\u0026#34; # A prompt to dictate how the recursive summarizations should approach the input paper summary_prompt = \u0026#34;\u0026#34;\u0026#34;Summarize this text from an academic paper. Extract any key points with reasoning.\\n\\nContent:\u0026#34;\u0026#34;\u0026#34; # If the library is empty (no searches have been performed yet), we perform one and download the results library_df = pd.read_csv(paper_dir_filepath).reset_index() if len(library_df) == 0: print(\u0026#34;No papers searched yet, downloading first.\u0026#34;) get_articles(query) print(\u0026#34;Papers downloaded, continuing\u0026#34;) library_df = pd.read_csv(paper_dir_filepath).reset_index() library_df.columns = [\u0026#34;title\u0026#34;, \u0026#34;filepath\u0026#34;, \u0026#34;embedding\u0026#34;] library_df[\u0026#34;embedding\u0026#34;] = library_df[\u0026#34;embedding\u0026#34;].apply(ast.literal_eval) strings = strings_ranked_by_relatedness(query, library_df, top_n=1) print(\u0026#34;Chunking text from paper\u0026#34;) pdf_text = read_pdf(strings[0]) # Initialise tokenizer tokenizer = tiktoken.get_encoding(\u0026#34;cl100k_base\u0026#34;) results = \u0026#34;\u0026#34; # Chunk up the document into 1500 token chunks chunks = create_chunks(pdf_text, 1500, tokenizer) text_chunks = [tokenizer.decode(chunk) for chunk in chunks] print(\u0026#34;Summarizing each chunk of text\u0026#34;) # Parallel process the summaries with concurrent.futures.ThreadPoolExecutor( max_workers=len(text_chunks) ) as executor: futures = [ executor.submit(extract_chunk, chunk, summary_prompt) for chunk in text_chunks ] with tqdm(total=len(text_chunks)) as pbar: for _ in concurrent.futures.as_completed(futures): pbar.update(1) for future in futures: data = future.result() results += data # Final summary print(\u0026#34;Summarizing into overall summary\u0026#34;) response = client.chat.completions.create( model=GPT_MODEL, messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;\u0026#34;\u0026#34;Write a summary collated from this collection of key points extracted from an academic paper. The summary should highlight the core argument, conclusions and evidence, and answer the user\u0026#39;s query. User query: {query} The summary should be structured in bulleted lists following the headings Core Argument, Evidence, and Conclusions. Key points:\\n{results}\\nSummary:\\n\u0026#34;\u0026#34;\u0026#34;, } ], temperature=0, ) return response 实现一个**Conversation**类，用于支持与API进行多轮对话\n@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3)) def chat_completion_request(messages, functions=None, model=GPT_MODEL): try: response = client.chat.completions.create( model=model, messages=messages, functions=functions, ) return response except Exception as e: print(\u0026#34;Unable to generate ChatCompletion response\u0026#34;) print(f\u0026#34;Exception: {e}\u0026#34;) return e class Conversation: def __init__(self): self.conversation_history = [] def add_message(self, role, content): message = {\u0026#34;role\u0026#34;: role, \u0026#34;content\u0026#34;: content} self.conversation_history.append(message) def display_conversation(self, detailed=False): role_to_color = { \u0026#34;system\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;user\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;assistant\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;function\u0026#34;: \u0026#34;magenta\u0026#34;, } for message in self.conversation_history: print( colored( f\u0026#34;{message[\u0026#39;role\u0026#39;]}: {message[\u0026#39;content\u0026#39;]}\\n\\n\u0026#34;, role_to_color[message[\u0026#34;role\u0026#34;]], ) ) 完成以上基本工作， 接下来是agent的核心内容\n定义工具列表 tools\narxiv_functions = [ { \u0026#34;name\u0026#34;: \u0026#34;get_articles\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;\u0026#34;Use this function to get academic papers from arXiv to answer user questions.\u0026#34;\u0026#34;\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;\u0026#34;\u0026#34; User query in JSON. Responses should be summarized and should include the article URL reference \u0026#34;\u0026#34;\u0026#34;, } }, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;], }, }, { \u0026#34;name\u0026#34;: \u0026#34;read_article_and_summarize\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;\u0026#34;Use this function to read whole papers and provide a summary for users. You should NEVER call this function before get_articles has been called in the conversation.\u0026#34;\u0026#34;\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;\u0026#34;\u0026#34; Description of the article in plain text based on the user\u0026#39;s query \u0026#34;\u0026#34;\u0026#34;, } }, \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;], }, } ] 定义function用于工具调用\ndef chat_completion_with_function_execution(messages, functions=[None]): \u0026#34;\u0026#34;\u0026#34;This function makes a ChatCompletion API call with the option of adding functions\u0026#34;\u0026#34;\u0026#34; response = chat_completion_request(messages, functions) full_message = response.choices[0] if full_message.finish_reason == \u0026#34;function_call\u0026#34;: print(f\u0026#34;Function generation requested, calling function\u0026#34;) return call_arxiv_function(messages, full_message) else: print(f\u0026#34;Function not required, responding to user\u0026#34;) return response def call_arxiv_function(messages, full_message): \u0026#34;\u0026#34;\u0026#34;Function calling function which executes function calls when the model believes it is necessary. Currently extended by adding clauses to this if statement.\u0026#34;\u0026#34;\u0026#34; if full_message.message.function_call.name == \u0026#34;get_articles\u0026#34;: try: parsed_output = json.loads( full_message.message.function_call.arguments ) print(\u0026#34;Getting search results\u0026#34;) results = get_articles(parsed_output[\u0026#34;query\u0026#34;]) except Exception as e: print(parsed_output) print(f\u0026#34;Function execution failed\u0026#34;) print(f\u0026#34;Error message: {e}\u0026#34;) messages.append( { \u0026#34;role\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;name\u0026#34;: full_message.message.function_call.name, \u0026#34;content\u0026#34;: str(results), } ) try: print(\u0026#34;Got search results, summarizing content\u0026#34;) response = chat_completion_request(messages) return response except Exception as e: print(type(e)) raise Exception(\u0026#34;Function chat request failed\u0026#34;) elif ( full_message.message.function_call.name == \u0026#34;read_article_and_summarize\u0026#34; ): parsed_output = json.loads( full_message.message.function_call.arguments ) print(\u0026#34;Finding and reading paper\u0026#34;) summary = summarize_text(parsed_output[\u0026#34;query\u0026#34;]) return summary else: raise Exception(\u0026#34;Function does not exist and cannot be called\u0026#34;) arXiv conversation, Start with a system message\npaper_system_message = \u0026#34;\u0026#34;\u0026#34;You are arXivGPT, a helpful assistant pulls academic papers to answer user questions. You summarize the papers clearly so the customer can decide which to read to answer their question. You always provide the article_url and title so the user can understand the name of the paper and click through to access it. Begin!\u0026#34;\u0026#34;\u0026#34; paper_conversation = Conversation() paper_conversation.add_message(\u0026#34;system\u0026#34;, paper_system_message) # Add a user message paper_conversation.add_message(\u0026#34;user\u0026#34;, \u0026#34;Hi, how does PPO reinforcement learning work?\u0026#34;) chat_response = chat_completion_with_function_execution( paper_conversation.conversation_history, functions=arxiv_functions ) assistant_message = chat_response.choices[0].message.content paper_conversation.add_message(\u0026#34;assistant\u0026#34;, assistant_message) display(Markdown(assistant_message)) output:\nFunction generation requested, calling function Getting search results Got search results, summarizing content I found several papers related to PPO reinforcement learning. Here are a few summaries: Title: \u0026#34;Bandit Profit-maximization for Targeted Marketing\u0026#34; Summary: This paper presents near-optimal algorithms for optimizing profit over multiple demand curves, which are dependent on different ancillary variables while maintaining the same price. It is relevant to PPO reinforcement learning as it tackles a sequential profit-maximization problem. Article URL: Link Title: \u0026#34;Inferring potential landscapes: A Schrödinger bridge approach to Maximum Caliber\u0026#34; Summary: This work extends Schrödinger bridges to account for integral constraints along paths, specifically in the context of Maximum Caliber, a Maximum Entropy principle applied in a dynamic context. While not directly related to PPO reinforcement learning, it can provide insights into stochastic dynamics and inference of time-varying potential landscapes. Article URL: Link Title: \u0026#34;a-DCF: an architecture agnostic metric with application to spoofing-robust speaker verification\u0026#34; Summary: This paper proposes an architecture-agnostic detection cost function (a-DCF) for evaluating spoofing-robust automatic speaker verification (ASV) systems. Although it does not focus on PPO reinforcement learning, it provides a metric for evaluating ASV systems in the presence of spoofing attacks. Article URL: Link These papers should provide insights into different aspects of reinforcement learning and related topics. Add another user message to induce our system to use the second tool\npaper_conversation.add_message( \u0026#34;user\u0026#34;, \u0026#34;Can you read the PPO sequence generation paper for me and give me a summary\u0026#34;, ) updated_response = chat_completion_with_function_execution( paper_conversation.conversation_history, functions=arxiv_functions ) display(Markdown(updated_response.choices[0].message.content)) output:\nFunction generation requested, calling function Finding and reading paper Chunking text from paper Summarizing each chunk of text 100%|██████████| 4/4 [00:04\u0026lt;00:00, 1.11s/it] Summarizing into overall summary Core Argument: The paper discusses the potential of using a general-purpose large language model (LLM) to learn the structural biophysics of DNA. The authors show that fine-tuning a LLM, specifically chatGPT 3.5-turbo, can enhance its ability to analyze and design DNA sequences and their structures. The study focuses on the formation of secondary structures in DNA, which are governed by base pairing and stacking bonds. The authors propose a method that involves chaining together models fine-tuned for subtasks and using a chain-of-thought approach to improve the model\u0026#39;s performance. Evidence: The authors use the NUPACK software suite to provide data for training and validation. The expert pipeline approach involves using models that have been fine-tuned for subtasks and feeding their outputs into each other. The models perform better when they explicitly consider the nearest neighbor window and the reverse complement of the sequences. The pipeline approach, where a separate model determines the reverse complement and feeds it to another model for secondary structure prediction, enhances the accuracy of the predictions. The performance of the models improves with larger training sets. Conclusions: The study demonstrates the potential of using LLMs to learn DNA structural biophysics. Integrating experimental data and machine learning is important in scientific research. The expert pipeline approach and breaking down the problem into smaller subtasks improve the performance of the models in DNA sequence analysis. The combination of chain-of-thought and model pipeline provides the best results in analysis tasks. The CoT approach, combined with the reverse complement transformation, yields the highest accuracy in design tasks. The addition of an error checking layer further improves accuracy in design tasks. Sequence design is more challenging than analysis, but error correction can compensate for the increased difficulty. Larger training sets benefit design tasks more. Future research directions include exploring chaining smaller models for performance improvement and using an LLM architecture involving both an encoder and decoder for direct sequence comparison. Function calling via open source LLMs 在考虑成本和隐私性的背景下，我们可能会倾向于在开源的大型语言模型（LLM）上实现函数调用功能。目前，有几个框架支持以类似OpenAI API的形式调用工具（tools call）：\nXinference\nText Generation Inference (TGI)\n而在开源大型语言模型（LLM）方面，支持工具调用的主要有：\nLlama-3\nMixtral-8x7B-Instruct-v0.1\nqwent\nchatGLM-6B\nNexusRaven-13B\ngorilla-openfunctions-v1\n等等\n以下以Xinference和chatGLM-6B为例，探索如何通过OpenAI API的形式调用开源模型的函数调用功能。\n环境\n%pip install -U -q xinference[transformers] openai langchain !pip install typing-extensions --upgrade ## Start Local Server !nohup xinference-local \u0026gt; xinference.log 2\u0026gt;\u0026amp;1 \u0026amp; 模型加载\n!xinference launch -u my-llm --model-name chatglm3 --size-in-billions 6 --model-format pytorch ## Interact with the running model import openai messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Who are you?\u0026#34; } ] client = openai.Client(api_key=\u0026#34;empty\u0026#34;, base_url=f\u0026#34;http://0.0.0.0:9997/v1\u0026#34;) client.chat.completions.create( model=\u0026#34;my-llm\u0026#34;, messages=messages, ) # ChatCompletion(id=\u0026#39;chatda6056ac-da01-11ee-b92e-0242ac1c000c\u0026#39;, choices=[Choice(finish_reason=\u0026#39;stop\u0026#39;, index=0, logprobs=None, message=ChatCompletionMessage(content=\u0026#34;I am an AI assistant named ChatGLM3-6B, which is developed based on the language model jointly trained by Tsinghua University KEG Lab and Zhipu AI Company in 2023. My job is to provide appropriate answers and support to users\u0026#39; questions and requests.\u0026#34;, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=None))], created=1709541198, model=\u0026#39;my-llm\u0026#39;, object=\u0026#39;chat.completion\u0026#39;, system_fingerprint=None, usage=CompletionUsage(completion_tokens=-1, prompt_tokens=-1, total_tokens=-1)) without tool using\ncompletion = client.chat.completions.create( model=\u0026#34;my-llm\u0026#34;, messages=[{\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What is the weather like in London?\u0026#34;}] ) # print(handle_response(completion)) print(completion.choices[0].message.content) \u0026#34;\u0026#34;\u0026#34; London has a temperate climate with warm summers and cool winters. The average temperature during the summer months (June to August) is around 18°C, while the winter months (December to February) are around 6°C. The city experiences heavy rainfall throughout the year, with an annual precipitation of around 350 mm. The average precipitation on the weekends is around 40 mm. London\u0026#39;s cloudy skies are common throughout the year, but they are especially prevalent in December and January. \u0026#34;\u0026#34;\u0026#34; tool using\ntools = [ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the current weather in a given location\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;unit\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;celsius\u0026#34;, \u0026#34;fahrenheit\u0026#34;]}, }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;], }, }, } ] def get_completion(messages, model=\u0026#34;my-llm\u0026#34;, temperature=0, max_tokens=500, tools=None, tool_choice=None): response = client.chat.completions.create( model=model, messages=messages, temperature=temperature, max_tokens=max_tokens, tools=tools, tool_choice=tool_choice ) return response.choices[0].message # Defines a dummy function to get the current weather def get_current_weather(location, unit=\u0026#34;fahrenheit\u0026#34;): \u0026#34;\u0026#34;\u0026#34;Get the current weather in a given location\u0026#34;\u0026#34;\u0026#34; weather = { \u0026#34;location\u0026#34;: location, \u0026#34;temperature\u0026#34;: \u0026#34;50\u0026#34;, \u0026#34;unit\u0026#34;: unit, } return json.dumps(weather) messages = [] messages.append({\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What\u0026#39;s the weather like in Boston!\u0026#34;}) assistant_message = get_completion(messages, tools=tools, tool_choice=\u0026#34;auto\u0026#34;) assistant_message = json.loads(assistant_message.model_dump_json()) assistant_message[\u0026#34;content\u0026#34;] = str(assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;function\u0026#34;]) #a temporary patch but this should be handled differently # remove \u0026#34;function_call\u0026#34; from assistant message del assistant_message[\u0026#34;function_call\u0026#34;] messages.append(assistant_message) # get the weather information to pass back to the model weather = get_current_weather(messages[1][\u0026#34;tool_calls\u0026#34;][0][\u0026#34;function\u0026#34;][\u0026#34;arguments\u0026#34;]) messages.append({\u0026#34;role\u0026#34;: \u0026#34;tool\u0026#34;, \u0026#34;tool_call_id\u0026#34;: assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;id\u0026#34;], \u0026#34;name\u0026#34;: assistant_message[\u0026#34;tool_calls\u0026#34;][0][\u0026#34;function\u0026#34;][\u0026#34;name\u0026#34;], \u0026#34;content\u0026#34;: weather}) final_response = get_completion(messages, tools=tools) final_response \u0026#34;\u0026#34;\u0026#34; ChatCompletionMessage(content=\u0026#39;The current weather in Boston is 50 degrees Fahrenheit.\u0026#39;, role=\u0026#39;assistant\u0026#39;, function_call=None, tool_calls=[]) \u0026#34;\u0026#34;\u0026#34; LLM 在执行function calling时经历了什么 可惜我们并不能看到openAI的模型在服务器端发生了什么，但是根据开源的模型和推理框架，我们某种程度上，也能对LLM在执行function calling的背后逻辑一探究竟。\n这部分内容可以从推理框架和开源模型的源码中找到答案。\n根据xinference 的源码：https://github.com/xorbitsai/inference/blob/main/xinference/model/llm/utils.py#L42\n我们主要关注ChatGLM3 和Qwen\n当我们使用以下假设对话时：\nmessages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;今天北京的天气怎么样？\u0026#34; } ] tools = [ { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the current weather in a given location\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;unit\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;], }, } ] 根据GLM的官方文档，则最终给到ChatGLM3模型的prompt应该长这样：\n\u0026lt;|system|\u0026gt; Answer the following questions as best as you can. You have access to the following tools: [ { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the current weather in a given location\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The city and state, e.g. San Francisco, CA\u0026#34;, }, \u0026#34;unit\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, }, \u0026#34;required\u0026#34;: [\u0026#34;location\u0026#34;], }, } ] \u0026lt;|user|\u0026gt; 今天北京的天气怎么样？ \u0026lt;|assistant|\u0026gt; 好的，让我们来查看今天的天气 \u0026lt;|assistant|\u0026gt;get_current_weather ```python tool_call(location=\u0026#34;beijing\u0026#34;, unit=\u0026#34;celsius\u0026#34;) ``` \u0026lt;|observation|\u0026gt; {\u0026#34;temperature\u0026#34;: 22} \u0026lt;|assistant|\u0026gt; 根据查询结果，今天北京的气温为 22 摄氏度。 根据xinference 中有关qwen的代码\nelif prompt_style.style_name == \u0026#34;QWEN\u0026#34;: if tools: tool_desc = \u0026#34;\u0026#34;\u0026#34;{name_for_model}: Call this tool to interact with the {name_for_human} API. What is the {name_for_human} API useful for? {description_for_model} Parameters: {parameters} Format the arguments as a JSON object.\u0026#34;\u0026#34;\u0026#34; react_instruction = \u0026#34;\u0026#34;\u0026#34;Answer the following questions as best you can. You have access to the following APIs: {tools_text} Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [{tools_name_text}] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can be repeated zero or more times) Thought: I now know the final answer Final Answer: the final answer to the original input question Begin!\u0026#34;\u0026#34;\u0026#34; tools_text = [] tools_name_text = [] for func_info in tools: parameters = [] required_parameters = func_info[\u0026#34;function\u0026#34;][\u0026#34;parameters\u0026#34;].get( \u0026#34;required\u0026#34;, [] ) for name, p in func_info[\u0026#34;function\u0026#34;][\u0026#34;parameters\u0026#34;][ \u0026#34;properties\u0026#34; ].items(): param = dict({\u0026#34;name\u0026#34;: name}, **p) if name in required_parameters: param[\u0026#34;required\u0026#34;] = True parameters.append(param) name = func_info[\u0026#34;function\u0026#34;][\u0026#34;name\u0026#34;] desc = func_info[\u0026#34;function\u0026#34;][\u0026#34;description\u0026#34;] tool_string = tool_desc.format( name_for_model=name, name_for_human=name, # Hint: You can add the following format requirements in description: # \u0026#34;Format the arguments as a JSON object.\u0026#34; # \u0026#34;Enclose the code within triple backticks (`) at the beginning and end of the code.\u0026#34; description_for_model=desc, parameters=json.dumps(parameters, ensure_ascii=False), ) tools_text.append(tool_string) tools_name_text.append(name) tools_text_string = \u0026#34;\\n\\n\u0026#34;.join(tools_text) tools_name_text_string = \u0026#34;, \u0026#34;.join(tools_name_text) tool_system = react_instruction.format( tools_text=tools_text_string, tools_name_text=tools_name_text_string, ) else: tool_system = \u0026#34;\u0026#34; ret = f\u0026#34;\u0026lt;|im_start|\u0026gt;system\\n{prompt_style.system_prompt}\u0026lt;|im_end|\u0026gt;\u0026#34; for message in chat_history: role = get_role(message[\u0026#34;role\u0026#34;]) content = message[\u0026#34;content\u0026#34;] ret += prompt_style.intra_message_sep if tools: if role == \u0026#34;user\u0026#34;: if tool_system: content = tool_system + f\u0026#34;\\n\\nQuestion: {content}\u0026#34; tool_system = \u0026#34;\u0026#34; else: content = f\u0026#34;Question: {content}\u0026#34; elif role == \u0026#34;assistant\u0026#34;: tool_calls = message.get(\u0026#34;tool_calls\u0026#34;) if tool_calls: func_call = tool_calls[0][\u0026#34;function\u0026#34;] f_name, f_args = ( func_call[\u0026#34;name\u0026#34;], func_call[\u0026#34;arguments\u0026#34;], ) content = f\u0026#34;Thought: I can use {f_name}.\\nAction: {f_name}\\nAction Input: {f_args}\u0026#34; elif content: content = f\u0026#34;Thought: I now know the final answer.\\nFinal answer: {content}\u0026#34; elif role == \u0026#34;tool\u0026#34;: role = \u0026#34;function\u0026#34; content = f\u0026#34;Observation: {content}\u0026#34; else: raise Exception(f\u0026#34;Unsupported message role: {role}\u0026#34;) if content: content = content.lstrip(\u0026#34;\\n\u0026#34;).rstrip() ret += f\u0026#34;\u0026lt;|im_start|\u0026gt;{role}\\n{content}\u0026lt;|im_end|\u0026gt;\u0026#34; else: ret += f\u0026#34;\u0026lt;|im_start|\u0026gt;{role}\\n\u0026#34; return ret 会稍微复杂一些， 利用了react的COT方式（代码中的react_instruction），要求模型以一系列的**Thought（思考）、Action（行动）、Action Input（行动输入）和Observation**（观察结果）步骤，最终给出问题的答案，以增加正确性。\n假设使用以下工具列表和对话历史：\n# 工具列表 tools = [ { \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;geo_lookup\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Retrieves geographical information.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;required\u0026#34;: [\u0026#34;query\u0026#34;], \u0026#34;properties\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The query to lookup.\u0026#34; } } } } } ] chat_history = [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;What is the population of Tokyo?\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;tool_calls\u0026#34;: [ { \u0026#34;function\u0026#34;: \u0026#34;geo_lookup\u0026#34;, \u0026#34;arguments\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;Tokyo\u0026#34; } } ], \u0026#34;content\u0026#34;: \u0026#34;The population of Tokyo is about 14 million.\u0026#34; } ] 可以推断出，最终输入Qwen的prompt应该长这样：\nsystem Answer the following questions as best you can. You have access to the following APIs: geo_lookup: Call this tool to interact with the geo_lookup API. What is the geo_lookup API useful for? Retrieves geographical information. Parameters: [{\u0026#34;name\u0026#34;: \u0026#34;query\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The query to lookup.\u0026#34;, \u0026#34;required\u0026#34;: true}] Format the arguments as a JSON object. Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [geo_lookup] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can be repeated zero or more times) Thought: I now know the final answer Final Answer: the final answer to the original input question Begin! user Question: What is the population of Tokyo? assistant Thought: I can use geo_lookup to find the information. Action: geo_lookup Action Input: {\u0026#34;query\u0026#34;: \u0026#34;Tokyo\u0026#34;} Observation: The population of Tokyo is about 14 million. Thought: I now know the final answer. Final answer: The population of Tokyo is about 14 million. 在这个例子中，用户询问东京的人口数量。助手利用**geo_lookup**工具进行查询，具体的行动步骤包括：\n思考：助手决定可以使用**geo_lookup**工具来查找信息。\n行动：实际调用**geo_lookup**工具。\n行动输入：向工具传递的参数，即查询**\u0026quot;Tokyo\u0026quot;**。\n观察：观察到的结果，这里是东京的人口大约为1400万。\n最终思考：基于观察结果，助手得出了最终答案。\n最终答案：向用户提供的答案，即东京的人口数量。\n更详细的内容，建议看这篇知乎文章：Qwen Function Calling 的对话模板及训练方法总结; 以及qwen的官方文档：ReAct Prompting 示例\n参考 openAI function calling\nHow to call functions with chat models\nHow_to_call_functions_for_knowledge_retrieval\nQwen Function Calling 的对话模板及训练方法总结\nqwen的官方文档\nGLM的官方文档\ntool-using via Groq API\nJson mode in Groq\nOpenAI JSON Mode \u0026amp; Seeding\nOpenAI API Guide: Using JSON Mode\n","permalink":"https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0openai-function-calling%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/","summary":"\u003ch2 id=\"写在最开始\"\u003e写在最开始\u003c/h2\u003e\n\u003cp\u003e当我们在讨论基于大型语言模型（LLM-based）的智能代理（agent）时，我们究竟在谈论什么？根据Lilian W在其文章《LLM Powered Autonomous Agents》中的讨论，一个智能代理需要具备几个核心能力：规划（Planning）、记忆（Memory）、以及工具使用（Tool use）。特别地，工具使用方面的进展，得益于OpenAI在API中提供的function calling功能，为我们开启了新的可能性。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://lilianweng.github.io/posts/2023-06-23-agent/agent-overview.png\" alt=\"AGI\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eOpenAI function calling，作为智能代理与外部工具交互的基本方式，对于每位从业者来说都是必备技能。随着技术的发展，我们期望的不只是能与我们对话的LLM，而是能够辅助我们使用各种工具、做出决策的智能伙伴。\u003c/p\u003e\n\u003cp\u003e不过需要特别指出的是，最近OpenAI在Chat Completions API中已经废弃了“函数（function）”的使用，转而采用“工具（tool）”。这一变更旨在拓宽LLM集成的功能范围，为更复杂的交互模式铺平道路，如构建能够相互作用的多代理系统。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.16.54.png\" alt=\"截屏2024-03-28 15.16.54.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.17.38.png\" alt=\"截屏2024-03-28 15.17.38.png\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e尽管如此，由于语言习惯的原因，本文中仍然会使用function calling的术语来描述OpenAI的tool using功能，因为“function calling”的说法已经深入人心了。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e核心内容概览\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eFunction Calling的定义\u003c/strong\u003e：解释什么是function calling，以及它在智能代理工作中的作用。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eOpenAI Cookbook示例\u003c/strong\u003e：提供实际的function calling示例，帮助读者理解其在实际应用中的用途。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e开源LLM的Tool Using\u003c/strong\u003e：探索如何在开源大型语言模型中实现工具使用，以及LLM在tool using的时候经历了什么。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cdel\u003e评价与训练\u003c/del\u003e\u003c/strong\u003e\u003cdel\u003e：讨论如何评价开源模型的工具使用能力，以及如何训练LLM进行有效的工具使用。\u003c/del\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e鉴于整理笔记的速度远赶不上更新的速度， 会将第四部份作为单独的部分整理。\u003c/p\u003e\n\u003ch2 id=\"何为function-calling\"\u003e何为function calling\u003c/h2\u003e\n\u003cp\u003e一句话解释：\u003cstrong\u003efunction calling从本质上并不是严格的工具调用， 而是作为工具调用的前奏，它通过更加结构化的方式指导LLM输出，为在本地执行具体函数提供了参数，铺平了道路。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e具体来说，function calling允许LLM在执行过程中通过指定的参数来调用并执行一个特定的函数。这种方式不仅实现了代码的重用和模块化处理，而且能够从模型中获取更可靠的结构化数据回应。在API调用过程中，开发者可以描述想要执行的功能，并让模型智能地选择输出包含所需参数的JSON对象。\u003cstrong\u003e这个过程中，Chat Completions API本身不直接执行任何函数调用，而是生成了可以在开发者代码中实现函数调用的JSON。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003efunction calling的应用范围广泛，如\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e创建智能助手：通过调用外部API回答问题。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e转换指令：将自然语言指令转换成API调用指令。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e数据提取：从文本中提取结构化数据。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003efunction calling的过程涵盖了从定义函数集、通过模型生成遵循自定义模式的JSON对象字符串，到在代码中解析这个字符串并调用相应函数的全过程。这一连串操作不仅自动化了交互过程，还确保了执行操作的安全性和准确性。\u003c/p\u003e\n\u003ch2 id=\"一些常见的问题\"\u003e一些常见的问题\u003c/h2\u003e\n\u003ch3 id=\"json-mode\"\u003eJSON mode\u003c/h3\u003e\n\u003cp\u003ejson mode 和tool-using 有什么关系？有了json mode 还需要用到tool-using吗？\u003c/p\u003e\n\u003cp\u003e从json mode 的本质， 更多的是在system prompt 增加一句类似“请以json格式输出”之类的话，然后在LLM输出时增加json结果检查和格式转换。在使用时只需要在\u003ccode\u003eclient.chat.completions.create \u003c/code\u003e中 增加\u003ccode\u003eresponse_format={ \u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot; }\u003c/code\u003e 即可。\u003c/p\u003e","title":"Agent学习笔记：OpenAI Function Calling完全指南"},{"content":"个人介绍 后现代人类 AI从业者与终身学习者 工作狂 世界探索者 INFJ 阅读 听歌 创作 欢迎来到我的个人博客！\n","permalink":"https://niraya666.github.io/about/","summary":"\u003ch3 id=\"个人介绍\"\u003e个人介绍\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e后现代人类\u003c/li\u003e\n\u003cli\u003eAI从业者与终身学习者\u003c/li\u003e\n\u003cli\u003e工作狂\u003c/li\u003e\n\u003cli\u003e世界探索者\u003c/li\u003e\n\u003cli\u003eINFJ\u003c/li\u003e\n\u003cli\u003e阅读 听歌 创作\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e欢迎来到我的个人博客！\u003c/p\u003e","title":"About"},{"content":" 引言 在信息化时代，数据和知识的快速提取变得尤为重要。特别是对于学术和技术文档，如何从格式丰富且结构复杂的PDF文件中准确地提取信息，是提高研究效率的关键。本文将探讨几种先进的技术方法，用于优化学术论文的PDF解析及其表格内容的处理。\n对于文档解析，langchain 和 llama_index 提供的 document loader 能够支持多种文件类型，覆盖绝大多数文档格式的需求。但对于pdf解析而言还存在着一些挑战。\n人类与机器的阅读差异 尽管PDF格式适合人类阅读，提供了优秀的视觉体验和格式保真，但它并不适合机器阅读。PDF文件通常包含复杂的布局和多样的内容元素，如多列布局、公式和表格，这些都给自动解析带来了挑战。\n常见的PDF解析问题 使用传统的PDF解析库可能遇到多种问题：\n多列布局导致的文本流读取错误。\n公式和表格的解析效果差，难以正确提取信息。\n解析过程中结构化信息（如标题和列表）的丢失。\n影印版PDF的文本无法被标准OCR工具识别。\n高级解析技术 根据unstractued提供的方案，文档解析可以大致分为两种方法：结构化解析和基于图像的解析。结构化解析侧重于从文档中提取文字和其它字符数据。而图像基解析则包括以下两种技术：\nOCR技术：首先使用目标检测模型对文档布局进行分析，识别出标题、表格等关键元素的位置，然后在这些位置上使用OCR技术提取文字。\n基于Transformer的端到端解析：使用深度学习模型直接将图像转换为相应的文字内容。在这方面，Dount 和 Nougat 模型表现出色，尤其是 Nougat 能够将图像中的文章整理成Markdown或Latex格式，非常适合需要保留结构信息（如标题层级、公式和表格）的场景。\n只可惜Nougat只针对英文的学术论文做了训练，但遇到其他语言如中文论文的效果就不是那么的好了。\n必须强调一点的是，Markdown格式因其简洁性和易于解析的特点，被广泛认为是LLM（大型语言模型）友好的文档格式。Markdown通过明确的标记语法，帮助模型更好地理解文档结构和内容，从而提高信息提取的准确性和效率。特别在存在大量公式，表格的学术论文场景下，Markdown可能是更合适的格式选择。\n快速上手：使用Nougat将pdf解析成适合LLM读取的markdown 依赖按照\n!pip install -q pymupdf python-Levenshtein nltk !pip install -q git+https://github.com/huggingface/transformers.git Load model and processor\nfrom transformers import AutoProcessor, VisionEncoderDecoderModel import torch processor = AutoProcessor.from_pretrained(\u0026#34;facebook/nougat-base\u0026#34;) model = VisionEncoderDecoderModel.from_pretrained(\u0026#34;facebook/nougat-base\u0026#34;) device = \u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34; model.to(device) 将pdf转成图像\nfrom typing import Optional, List import io import fitz from pathlib import Path def rasterize_paper( pdf: Path, outpath: Optional[Path] = None, dpi: int = 96, return_pil=False, pages=None, ) -\u0026gt; Optional[List[io.BytesIO]]: \u0026#34;\u0026#34;\u0026#34; Rasterize a PDF file to PNG images. Args: pdf (Path): The path to the PDF file. outpath (Optional[Path], optional): The output directory. If None, the PIL images will be returned instead. Defaults to None. dpi (int, optional): The output DPI. Defaults to 96. return_pil (bool, optional): Whether to return the PIL images instead of writing them to disk. Defaults to False. pages (Optional[List[int]], optional): The pages to rasterize. If None, all pages will be rasterized. Defaults to None. Returns: Optional[List[io.BytesIO]]: The PIL images if `return_pil` is True, otherwise None. \u0026#34;\u0026#34;\u0026#34; pillow_images = [] if outpath is None: return_pil = True try: if isinstance(pdf, (str, Path)): pdf = fitz.open(pdf) if pages is None: pages = range(len(pdf)) for i in pages: page_bytes: bytes = pdf[i].get_pixmap(dpi=dpi).pil_tobytes(format=\u0026#34;PNG\u0026#34;) if return_pil: pillow_images.append(io.BytesIO(page_bytes)) else: with (outpath / (\u0026#34;%02d.png\u0026#34; % (i + 1))).open(\u0026#34;wb\u0026#34;) as f: f.write(page_bytes) except Exception: pass if return_pil: return pillow_images from transformers import StoppingCriteria, StoppingCriteriaList from collections import defaultdict class RunningVarTorch: def __init__(self, L=15, norm=False): self.values = None self.L = L self.norm = norm def push(self, x: torch.Tensor): assert x.dim() == 1 if self.values is None: self.values = x[:, None] elif self.values.shape[1] \u0026lt; self.L: self.values = torch.cat((self.values, x[:, None]), 1) else: self.values = torch.cat((self.values[:, 1:], x[:, None]), 1) def variance(self): if self.values is None: return if self.norm: return torch.var(self.values, 1) / self.values.shape[1] else: return torch.var(self.values, 1) class StoppingCriteriaScores(StoppingCriteria): def __init__(self, threshold: float = 0.015, window_size: int = 200): super().__init__() self.threshold = threshold self.vars = RunningVarTorch(norm=True) self.varvars = RunningVarTorch(L=window_size) self.stop_inds = defaultdict(int) self.stopped = defaultdict(bool) self.size = 0 self.window_size = window_size @torch.no_grad() def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor): last_scores = scores[-1] self.vars.push(last_scores.max(1)[0].float().cpu()) self.varvars.push(self.vars.variance()) self.size += 1 if self.size \u0026lt; self.window_size: return False varvar = self.varvars.variance() for b in range(len(last_scores)): if varvar[b] \u0026lt; self.threshold: if self.stop_inds[b] \u0026gt; 0 and not self.stopped[b]: self.stopped[b] = self.stop_inds[b] \u0026gt;= self.size else: self.stop_inds[b] = int( min(max(self.size, 1) * 1.15 + 150 + self.window_size, 4095) ) else: self.stop_inds[b] = 0 self.stopped[b] = False return all(self.stopped.values()) and len(self.stopped) \u0026gt; 0 将pdf转成markdown\nfrom tqdm import tqdm def trans_pdf_to_markdown(filepath): output = \u0026#34;\u0026#34; images = rasterize_paper(pdf=filepath, return_pil=True) for i in tqdm(range(len(images))): image = Image.open(images[i]) pixel_values = processor(images=image, return_tensors=\u0026#34;pt\u0026#34;).pixel_values # autoregressively generate tokens, with custom stopping criteria (as defined by the Nougat authors) outputs = model.generate(pixel_values.to(device), min_length=1, max_length=3584, bad_words_ids=[[processor.tokenizer.unk_token_id]], return_dict_in_generate=True, output_scores=True, stopping_criteria=StoppingCriteriaList([StoppingCriteriaScores()]), ) generated = processor.batch_decode(outputs[0], skip_special_tokens=True)[0] generated = processor.post_process_generation(generated, fix_markdown=True) output+=generated output+=\u0026#34;\\n\\n\u0026#34; return output filepath = \u0026#39;xxx.pdf\u0026#39; makrdown_ = trans_pdf_to_markdown(filepath) 具体参考Nougat的官方示例。\n表格类数据的RAG问题 表格类目前的解决方案主要有两种：\n对于内容较小的表格，一般采用LLM对表格进行summary， 以table summary构建查询的index，在召回后， 进行表格内容的复原或者根据问题后处理提供至LLM进行生成。\n对于内容较多的表格， 一般采取结构化处理， 也就是存储至数据库， 在查询阶段根据问题匹配对应的表schema， 有模型执行text-to-sql任务，生成sql并执行获得结果，最终根据结果回答内容。\n对于第一种方案，在Langchain 的cookbook中提到了Semi-structured RAG的方法值得借鉴；\n此外在HRoT这篇工作中， 也提到了类似的方法；\n在HRoT这篇工作中， 增加了将table基于问题进行重构的算法，\nType-Aware Table Reconstruction algorithm\n该算法的实现步骤如下：\n问题分类：首先，算法对问题进行分类，判断问题是算术问题还是跨列选择问题。这有助于确定需要从表格中检索的信息类型。\n获取表格和证据：对于算术问题，算法获取与问题相关的表格集合。然后，从这些表格中提取出作为证据的文本和表格片段。\n表格分区：对于每个表格，算法将其分区为多个子表格。这是通过获取表格的跨度列表（Lt）来完成的，该列表包含了表格中每个头部（行和列）的起始和结束位置。\n确定保留的行和列：算法根据问题类型和证据来确定哪些行和列是回答问题所必需的。这是通过分析每个证据的子标题（即表格中的行和列标题）来实现的。\n重建表格：在确定了需要保留的行和列之后，算法根据这些信息重建表格。重建的表格只包含对问题回答有帮助的信息，从而减少了无关信息的干扰。\n在TableQuery 这篇工作中， 利用一系列模块组件，实现了基于LLM对数据库的高效查询。\nTableQuery的架构设计包括以下几个主要模块：\nDatastore：Datastore是一个表格集合，可以通过自然语言查询。这些表格可以是数据库或电子表格目录。除了表格数据，Datastore还包含模式文件，这些文件包含每个表的元数据，如表关键词、列名、列类型、列关键词（用户为列名提供的关键词）等。模式文件可以手动为这些表创建，也可以通过应用各种启发式方法自动生成。\nTable Selector：表选择器根据输入查询从Datastore中选择合适的表。这是通过从输入查询中提取关键词，并找到与问题关键词（以及模式中的表关键词、列名、列关键词等）重叠系数最大的表来完成的。\nKnown Fields Extractor：已知字段提取器提取查询中已经给出值的列。对于这些列中的每一个，也提取了相应的值。这是通过一个预训练的深度学习模型来完成的，该模型用于在自由文本上执行问答。\nUnknown Fields Extractor：未知字段提取器提取需要从选定表中检索值的列。这是通过排除已知字段提取器已经从查询中提取的列，并找到其列关键词与问题关键词重叠系数最大的列来完成的。\nAggregate Function Classifier：一些查询可能需要对选定表中的未知字段的值执行进一步操作。这是通过在生成的SQL查询中包含SQL聚合函数（如COUNT、SUM、MIN、MAX、AVG等）来实现的。聚合函数分类器决定给定输入查询要使用的聚合函数。为了执行这项任务，作者训练了一个两层的神经网络，该网络以使用通用句子编码器编码的查询作为输入，并输出要使用的适当聚合函数（如果有的话）。\nSQL Generator：结合已知字段和值、未知字段和聚合函数来构建SQL查询，当该查询在选定的表上运行时，返回所需的结果。\n关于text-to-sql的更详尽内容， 可以参考这篇综述文章：Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey。 限于篇幅就不展开了。\n参考文献 langchain: Document loaders\nNougat: Neural Optical Understanding for Academic Documents\nlangchain: Semi-structured RAG\nHRoT: Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering\nTableQuery： Querying tabular data with natural language\nNatural Language Interfaces for Tabular Data Querying and Visualization: A Survey\n","permalink":"https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E4%B8%8E%E8%A1%A8%E6%A0%BC%E5%A4%84%E7%90%86/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/post-cover/rag_toolkits_2.JPG\" alt=\"image\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"引言\"\u003e\u003cstrong\u003e引言\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003e在信息化时代，数据和知识的快速提取变得尤为重要。特别是对于学术和技术文档，如何从格式丰富且结构复杂的PDF文件中准确地提取信息，是提高研究效率的关键。本文将探讨几种先进的技术方法，用于优化学术论文的PDF解析及其表格内容的处理。\u003c/p\u003e\n\u003cp\u003e对于文档解析，\u003cstrong\u003e\u003ccode\u003elangchain\u003c/code\u003e\u003c/strong\u003e 和 \u003cstrong\u003e\u003ccode\u003ellama_index\u003c/code\u003e\u003c/strong\u003e 提供的 \u003cstrong\u003e\u003ccode\u003edocument loader\u003c/code\u003e\u003c/strong\u003e 能够支持多种文件类型，覆盖绝大多数文档格式的需求。但对于pdf解析而言还存在着一些挑战。\u003c/p\u003e\n\u003ch3 id=\"人类与机器的阅读差异\"\u003e\u003cstrong\u003e人类与机器的阅读差异\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e尽管PDF格式适合人类阅读，提供了优秀的视觉体验和格式保真，但它并不适合机器阅读。PDF文件通常包含复杂的布局和多样的内容元素，如多列布局、公式和表格，这些都给自动解析带来了挑战。\u003c/p\u003e\n\u003ch3 id=\"常见的pdf解析问题\"\u003e\u003cstrong\u003e常见的PDF解析问题\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e使用传统的PDF解析库可能遇到多种问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e多列布局导致的文本流读取错误。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e公式和表格的解析效果差，难以正确提取信息。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e解析过程中结构化信息（如标题和列表）的丢失。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e影印版PDF的文本无法被标准OCR工具识别。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"高级解析技术\"\u003e\u003cstrong\u003e高级解析技术\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e根据\u003ca href=\"https://unstructured.io/\"\u003eunstractued\u003c/a\u003e提供的方案，文档解析可以大致分为两种方法：结构化解析和基于图像的解析。结构化解析侧重于从文档中提取文字和其它字符数据。而图像基解析则包括以下两种技术：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eOCR技术\u003c/strong\u003e：首先使用目标检测模型对文档布局进行分析，识别出标题、表格等关键元素的位置，然后在这些位置上使用OCR技术提取文字。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e基于Transformer的端到端解析\u003c/strong\u003e：使用深度学习模型直接将图像转换为相应的文字内容。在这方面，\u003cstrong\u003e\u003ccode\u003eDount\u003c/code\u003e\u003c/strong\u003e 和 \u003cstrong\u003e\u003ccode\u003eNougat\u003c/code\u003e\u003c/strong\u003e 模型表现出色，尤其是 \u003cstrong\u003e\u003ccode\u003eNougat\u003c/code\u003e\u003c/strong\u003e 能够将图像中的文章整理成Markdown或Latex格式，非常适合需要保留结构信息（如标题层级、公式和表格）的场景。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e只可惜Nougat只针对英文的学术论文做了训练，但遇到其他语言如中文论文的效果就不是那么的好了。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://unstructured-io.github.io/unstructured/_images/strategy.png\" alt=\"\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e必须强调一点的是，Markdown格式因其简洁性和易于解析的特点，被广泛认为是LLM（大型语言模型）友好的文档格式。Markdown通过明确的标记语法，帮助模型更好地理解文档结构和内容，从而提高信息提取的准确性和效率。特别在存在大量公式，表格的学术论文场景下，Markdown可能是更合适的格式选择。\u003c/p\u003e\n\u003ch2 id=\"快速上手使用nougat将pdf解析成适合llm读取的markdown\"\u003e快速上手：使用Nougat将pdf解析成适合LLM读取的markdown\u003c/h2\u003e\n\u003cp\u003e依赖按照\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e!\u003c/span\u003e\u003cspan class=\"n\"\u003epip\u003c/span\u003e \u003cspan class=\"n\"\u003einstall\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003eq\u003c/span\u003e \u003cspan class=\"n\"\u003epymupdf\u003c/span\u003e \u003cspan class=\"n\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003eLevenshtein\u003c/span\u003e \u003cspan class=\"n\"\u003enltk\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"err\"\u003e!\u003c/span\u003e\u003cspan class=\"n\"\u003epip\u003c/span\u003e \u003cspan class=\"n\"\u003einstall\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"n\"\u003eq\u003c/span\u003e \u003cspan class=\"n\"\u003egit\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"n\"\u003ehttps\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"o\"\u003e//\u003c/span\u003e\u003cspan class=\"n\"\u003egithub\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecom\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003ehuggingface\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"n\"\u003etransformers\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egit\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eLoad model and processor\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etransformers\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eAutoProcessor\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eVisionEncoderDecoderModel\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003etorch\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eprocessor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eAutoProcessor\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efrom_pretrained\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;facebook/nougat-base\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eVisionEncoderDecoderModel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efrom_pretrained\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;facebook/nougat-base\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;cuda\u0026#34;\u003c/span\u003e \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecuda\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eis_available\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"k\"\u003eelse\u003c/span\u003e \u003cspan class=\"s2\"\u003e\u0026#34;cpu\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003emodel\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eto\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edevice\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e将pdf转成图像\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etyping\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eOptional\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eList\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003eio\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"nn\"\u003efitz\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003epathlib\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003ePath\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erasterize_paper\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003ePath\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eoutpath\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003eOptional\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ePath\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003edpi\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e96\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003ereturn_pil\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epages\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eOptional\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eList\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eio\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\u003cspan class=\"p\"\u003e]]:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"s2\"\u003e\u0026#34;\u0026#34;\u0026#34;\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    Rasterize a PDF file to PNG images.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    Args:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        pdf (Path): The path to the PDF file.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        outpath (Optional[Path], optional): The output directory. If None, the PIL images will be returned instead. Defaults to None.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        dpi (int, optional): The output DPI. Defaults to 96.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        return_pil (bool, optional): Whether to return the PIL images instead of writing them to disk. Defaults to False.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        pages (Optional[List[int]], optional): The pages to rasterize. If None, all pages will be rasterized. Defaults to None.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    Returns:\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e        Optional[List[io.BytesIO]]: The PIL images if `return_pil` is True, otherwise None.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"s2\"\u003e    \u0026#34;\u0026#34;\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003epillow_images\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003eoutpath\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003ereturn_pil\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eTrue\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003etry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"nb\"\u003eisinstance\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003estr\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ePath\u003c/span\u003e\u003cspan class=\"p\"\u003e)):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003epdf\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003efitz\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003epages\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003epages\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003elen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"n\"\u003epages\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"n\"\u003epage_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003ebytes\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003epdf\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget_pixmap\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edpi\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003edpi\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epil_tobytes\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eformat\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;PNG\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ereturn_pil\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"n\"\u003epillow_images\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eio\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eBytesIO\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epage_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"k\"\u003ewith\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eoutpath\u003c/span\u003e \u003cspan class=\"o\"\u003e/\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"si\"\u003e%02d\u003c/span\u003e\u003cspan class=\"s2\"\u003e.png\u0026#34;\u003c/span\u003e \u003cspan class=\"o\"\u003e%\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)))\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eopen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s2\"\u003e\u0026#34;wb\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"k\"\u003eas\u003c/span\u003e \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                    \u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewrite\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003epage_bytes\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eexcept\u003c/span\u003e \u003cspan class=\"ne\"\u003eException\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003epass\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003ereturn_pil\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003epillow_images\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003etransformers\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003eStoppingCriteria\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eStoppingCriteriaList\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kn\"\u003efrom\u003c/span\u003e \u003cspan class=\"nn\"\u003ecollections\u003c/span\u003e \u003cspan class=\"kn\"\u003eimport\u003c/span\u003e \u003cspan class=\"n\"\u003edefaultdict\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eRunningVarTorch\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eL\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e15\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enorm\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003eFalse\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eL\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eL\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enorm\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003enorm\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003epush\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eTensor\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eassert\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003edim\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"o\"\u003e==\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e[:,\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eelif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshape\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eL\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecat\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e[:,\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e]),\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecat\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"p\"\u003e[:,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:],\u003c/span\u003e \u003cspan class=\"n\"\u003ex\u003c/span\u003e\u003cspan class=\"p\"\u003e[:,\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e]),\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003evariance\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e \u003cspan class=\"ow\"\u003eis\u003c/span\u003e \u003cspan class=\"kc\"\u003eNone\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enorm\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e/\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshape\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eStoppingCriteriaScores\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eStoppingCriteria\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ethreshold\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003efloat\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mf\"\u003e0.015\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e200\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"nb\"\u003esuper\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"fm\"\u003e__init__\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethreshold\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ethreshold\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evars\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eRunningVarTorch\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enorm\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"kc\"\u003eTrue\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evarvars\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eRunningVarTorch\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eL\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estop_inds\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edefaultdict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edefaultdict\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003ebool\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"nd\"\u003e@torch.no_grad\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"fm\"\u003e__call__\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003einput_ids\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eLongTensor\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003escores\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003etorch\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eFloatTensor\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003elast_scores\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003escores\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evars\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epush\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elast_scores\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emax\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)[\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003efloat\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecpu\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evarvars\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003epush\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evars\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evariance\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e \u003cspan class=\"o\"\u003e+=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"kc\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"n\"\u003evarvar\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evarvars\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evariance\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eb\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003elen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elast_scores\u003c/span\u003e\u003cspan class=\"p\"\u003e)):\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"n\"\u003evarvar\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ethreshold\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estop_inds\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e \u003cspan class=\"ow\"\u003eand\u003c/span\u003e \u003cspan class=\"ow\"\u003enot\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                    \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estop_inds\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026gt;=\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                    \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estop_inds\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nb\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                        \u003cspan class=\"nb\"\u003emin\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nb\"\u003emax\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e \u003cspan class=\"mf\"\u003e1.15\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"mi\"\u003e150\u003c/span\u003e \u003cspan class=\"o\"\u003e+\u003c/span\u003e \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ewindow_size\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e4095\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                    \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e            \u003cspan class=\"k\"\u003eelse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estop_inds\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e                \u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eb\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003eFalse\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"nb\"\u003eall\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evalues\u003c/span\u003e\u003cspan class=\"p\"\u003e())\u003c/span\u003e \u003cspan class=\"ow\"\u003eand\u003c/span\u003e \u003cspan class=\"nb\"\u003elen\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"bp\"\u003eself\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estopped\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e将pdf转成markdown\u003c/p\u003e","title":"RAG工具箱：文档解析与表格处理"},{"content":"游记：2024-春 昆明大理 昆明 时间似乎停止了 不知为何在昆明有一种回到兰州的感觉，一样的三线省会，似曾相识的破败老城区街道，赫鲁晓夫楼，砖瓦房，和五六十年代的家属大院，似乎时间就停止流动了。我不认为这是种贬义的表达，至少清晨行走在老街区，唤起了我上学时，清晨走出校园到火车站赶火车的尘封记忆。 不过需要提一嘴的是，似乎当前的实体经济，特别是在老城区，不论是这次旅行所看到的，还是之前在故乡和别的城市所看到的，可以说是很糟糕了。目光所及有一半的店面处于关门转让的状态，而开着的那一半，又有近乎三成处于清仓甩卖中。\n古镇PTSD 在全国绝大多数古镇逐渐趋同演化的当下，不知这是否是件悲哀的事。因为去云南省博物馆的途中会路过官渡古镇，遂决定顺便去看看。从古镇的东北边进入至正门而出，这次访问让我有幸同时见证了从破败而真实的古镇到商业化过度开发的古镇的转变。\n在历史长河中被剥夺了名字的人 在昆明这个城市名字的由来中，有一段被历史辗转淡忘的故事。昆明这一名称起源于昆明夷——西汉时期活跃在洱海周边的一个游牧民族。而在这片土地上生活的滇人，一个拥有先进青铜技术的农耕文明，不断地抵抗游牧民族的侵扰。尽管如此，在历史的长河中，正是这些滇人创造了辉煌的文明，却在历史的演进中失去了自己的名字。这不禁让人感受到一种悲剧的讽刺——在自己孕育辉煌的土地上，却被剥夺了命名的权力。这反映出历史的无情，以及文化与权力之间复杂的交织。\n故乡与迁徙 在省博的临时展区，有幸看到了一个关于迁徙和故乡的特别展。 正巧这次来云南的最初目的也是为了探寻人生的下一个迁徙地。\n今天，流动成为常态。我们祖辈所拥有的那种一生居于一地的安稳逐渐被打破。很多人离开熟悉的地方，到另一处，与来自天南地北的人一起，不知不觉将异乡生活成故乡。\n而提到故乡，你会想到什么？是那方伴你长大的土地，是老屋里围炉团聚的家人，是家乡菜的味道和浓浓的乡音，是家门口熟悉的街道、树林和田地，是小时候玩耍的院子，和那群如今已各奔东西的伙伴。无论走多远，想到那一草一木，一人一景，就安宁。\n这也许就是人们一直以来追寻的栖息地。在远方，在心里，它叫“香格里拉”。\n现代的我们因为各种原因，在故乡与异乡之间辗转，继续着“迁徙与流动”。展览策划过程中，我们以“故乡”“现居地”“理想地”为题，以“故事+展品”的方式开启活动征集，鼓励不同身份的人群通过不同角度的讲述，分享他们的感受与思考。在近一个月的时间里，我们得到了大家的积极回响。在大家的分享中，我们与不同的故事和记忆相连，也看到因为不同而更加多元、广阔的世界。\n这里展示的文字和物品，是记忆的承载，也是对“故的未来。\n乡”的“好久不见”，它记录着我们的成长，也指引着我们\n大理 这次来大理的初始动机是实地考察和调研“数字游民”这个群体，他们是否真正像想象中的自由，他们是如何工作和生活的， 他们背后的故事又是什么？ 以及他们为什么选择大理？\n感谢Dalihub， 让我有幸认识一群有趣的人。\n来自海边房子\nDalihub的秘密空间\n救火途中的直升机\n自由飞翔\n猜你喜欢是“坏”的吗 在大理的第二天，我便幸运地参与了一场与我的工作密切相关的线下沙龙活动，主题涉及推荐系统。我的工作列表中正好有一项是关于如何防止大型科技公司通过推荐系统作恶的问题。 活动中，主讲人“西雅图大黄蜂”提出了一个观点：所有的算法和技术本质上都是中性的，真正的“恶”是由使用它们的人带来的。作为技术从业者，我们当然不希望看到自己的发明像原子弹一样被用于恶劣的目的。但现实往往很残酷，技术的接受与否很大程度上是由资本决定的，而非我们。\n之前我考虑过一个想法：将推荐系统的召回和排序分开，召回过程保留在服务器端，而排序则转移到用户端，这样一来可以提高用户的隐私保护。技术上并不复杂，真正的挑战来自于资本或大公司缺乏推行此类改变的动力。除非有一天，大多数用户愿意为保护隐私牺牲一定的便利性，否则这种改变还遥遥无期，至少在当前的中国是这样的。\n再次感谢主理人Nian和主讲人魏峰，一次难忘的体验。\n真的躺平吗？不，只是喘口气 选择大理的理由： 成本，气候， 和有趣的人们\n在大理，你可以遇到形形色色的人物：那些选择在此旅居的设计师，决定在退休后移居大理的上海夫妇，因成本考虑而搬来的独立开发者，还有视大理为家的咨询师小姐姐。这些都是构成大理独特社群氛围的不同面貌。\n当你不确定下一步该做什么时，不妨去洱海边走走，那里的美景足以让你放慢脚步，深呼吸，重新找回自己的节奏。在大理，即便是“躺平”，也是一种享受生活、与自然和谐共处的态度。\n洱海边落日\n取舍，及时调整自己的欲望 在网上能看到很多对于大理的劝退文， 无外乎就是过度商业化网红化， 城市规划稀烂，交通不方便，宰客现象严重等等。 以上我都认同， 对于一个习惯了大城市便利的人而言， 初到大理的感受的确是如此。 和在地的小伙伴聊下来，发现及时调整自己的欲望还是挺重要的。\n但是，在早晨拉开窗帘看到洱海的一瞬间， 似乎这一切都是值得的。\n随处可见的丁达尔效应\n去跳海，去发疯！\n西南旅游小Tips 注意防晒， 保湿，加湿器和润唇膏很重要。 尽量避开春季，因为春季是风季，很有可能因为大风而错过苍山的缆车。 大理古城的主干道不值得驻足，真正有趣的东西隐藏在巷子里\n这一切就像是一场梦\n感谢在大理遇到的所有人事物\n下一次再见\n","permalink":"https://niraya666.github.io/travel/%E6%B8%B8%E8%AE%B02024-%E6%98%A5-%E6%98%86%E6%98%8E%E5%A4%A7%E7%90%86/","summary":"\u003ch1 id=\"游记2024-春-昆明大理\"\u003e游记：2024-春 昆明大理\u003c/h1\u003e\n\u003ch2 id=\"昆明\"\u003e昆明\u003c/h2\u003e\n\u003ch3 id=\"时间似乎停止了\"\u003e时间似乎停止了\u003c/h3\u003e\n\u003cp\u003e不知为何在昆明有一种回到兰州的感觉，一样的三线省会，似曾相识的破败老城区街道，赫鲁晓夫楼，砖瓦房，和五六十年代的家属大院，似乎时间就停止流动了。我不认为这是种贬义的表达，至少清晨行走在老街区，唤起了我上学时，清晨走出校园到火车站赶火车的尘封记忆。\n不过需要提一嘴的是，似乎当前的实体经济，特别是在老城区，不论是这次旅行所看到的，还是之前在故乡和别的城市所看到的，可以说是很糟糕了。目光所及有一半的店面处于关门转让的状态，而开着的那一半，又有近乎三成处于清仓甩卖中。\u003c/p\u003e\n\u003ch3 id=\"古镇ptsd\"\u003e古镇PTSD\u003c/h3\u003e\n\u003cp\u003e在全国绝大多数古镇逐渐趋同演化的当下，不知这是否是件悲哀的事。因为去云南省博物馆的途中会路过官渡古镇，遂决定顺便去看看。从古镇的东北边进入至正门而出，这次访问让我有幸同时见证了从破败而真实的古镇到商业化过度开发的古镇的转变。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53659997366_7bdf10738b_w.jpg\" alt=\"官渡古镇\"  /\u003e\n\u003c/p\u003e\n\u003ch3 id=\"在历史长河中被剥夺了名字的人\"\u003e在历史长河中被剥夺了名字的人\u003c/h3\u003e\n\u003cp\u003e在昆明这个城市名字的由来中，有一段被历史辗转淡忘的故事。昆明这一名称起源于昆明夷——西汉时期活跃在洱海周边的一个游牧民族。而在这片土地上生活的滇人，一个拥有先进青铜技术的农耕文明，不断地抵抗游牧民族的侵扰。尽管如此，在历史的长河中，正是这些滇人创造了辉煌的文明，却在历史的演进中失去了自己的名字。这不禁让人感受到一种悲剧的讽刺——在自己孕育辉煌的土地上，却被剥夺了命名的权力。这反映出历史的无情，以及文化与权力之间复杂的交织。\u003c/p\u003e\n\u003ch3 id=\"故乡与迁徙\"\u003e故乡与迁徙\u003c/h3\u003e\n\u003cp\u003e在省博的临时展区，有幸看到了一个关于迁徙和故乡的特别展。 正巧这次来云南的最初目的也是为了探寻人生的下一个迁徙地。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e今天，流动成为常态。我们祖辈所拥有的那种一生居于一地的安稳逐渐被打破。很多人离开熟悉的地方，到另一处，与来自天南地北的人一起，不知不觉将异乡生活成故乡。\u003c/p\u003e\n\u003cp\u003e而提到故乡，你会想到什么？是那方伴你长大的土地，是老屋里围炉团聚的家人，是家乡菜的味道和浓浓的乡音，是家门口熟悉的街道、树林和田地，是小时候玩耍的院子，和那群如今已各奔东西的伙伴。无论走多远，想到那一草一木，一人一景，就安宁。\u003c/p\u003e\n\u003cp\u003e这也许就是人们一直以来追寻的栖息地。在远方，在心里，它叫“香格里拉”。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e现代的我们因为各种原因，在故乡与异乡之间辗转，继续着“迁徙与流动”。展览策划过程中，我们以“故乡”“现居地”“理想地”为题，以“故事+展品”的方式开启活动征集，鼓励不同身份的人群通过不同角度的讲述，分享他们的感受与思考。在近一个月的时间里，我们得到了大家的积极回响。在大家的分享中，我们与不同的故事和记忆相连，也看到因为不同而更加多元、广阔的世界。\u003c/p\u003e\n\u003cp\u003e这里展示的文字和物品，是记忆的承载，也是对“故的未来。\u003c/p\u003e\n\u003cp\u003e乡”的“好久不见”，它记录着我们的成长，也指引着我们\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"大理\"\u003e大理\u003c/h2\u003e\n\u003cp\u003e这次来大理的初始动机是实地考察和调研“数字游民”这个群体，他们是否真正像想象中的自由，他们是如何工作和生活的， 他们背后的故事又是什么？ 以及他们为什么选择大理？\u003c/p\u003e\n\u003cp\u003e感谢Dalihub， 让我有幸认识一群有趣的人。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53660356884_1676ae103e_z.jpg\" alt=\"E0322096-D284-4044-BFAD-C6655AA9EAB9_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e来自海边房子\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53660223478_846693b3a1_w.jpg\" alt=\"259DFD62-6C94-4135-9D79-CD1A775DCFF1_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eDalihub的秘密空间\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53660223473_2d7c23b817_w.jpg\" alt=\"5E8B65D3-9970-41AB-9E2A-133E8CB0952C_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e救火途中的直升机\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53660223468_35ffcb583c_w.jpg\" alt=\"7F7303CF-6B12-4417-B71A-B0826682E0F2_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e自由飞翔\u003c/p\u003e\n\u003ch3 id=\"猜你喜欢是坏的吗\"\u003e猜你喜欢是“坏”的吗\u003c/h3\u003e\n\u003cp\u003e在大理的第二天，我便幸运地参与了一场与我的工作密切相关的线下沙龙活动，主题涉及推荐系统。我的工作列表中正好有一项是关于如何防止大型科技公司通过推荐系统作恶的问题。\n活动中，主讲人“西雅图大黄蜂”提出了一个观点：所有的算法和技术本质上都是中性的，真正的“恶”是由使用它们的人带来的。作为技术从业者，我们当然不希望看到自己的发明像原子弹一样被用于恶劣的目的。但现实往往很残酷，技术的接受与否很大程度上是由资本决定的，而非我们。\u003c/p\u003e\n\u003cp\u003e之前我考虑过一个想法：将推荐系统的召回和排序分开，召回过程保留在服务器端，而排序则转移到用户端，这样一来可以提高用户的隐私保护。技术上并不复杂，真正的挑战来自于资本或大公司缺乏推行此类改变的动力。除非有一天，大多数用户愿意为保护隐私牺牲一定的便利性，否则这种改变还遥遥无期，至少在当前的中国是这样的。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://mmbiz.qpic.cn/mmbiz_png/XVQWiaVrXNFVWAFWZMMYiczNYLvg9dPX3JKlYNQexPiceosvQXz4CHIic0ZN0Naw6BHDxQj7Rd1kZvFoBV9HBxKZ4A/640?wx_fmt=png\u0026amp;from=appmsg\u0026amp;tp=webp\u0026amp;wxfrom=5\u0026amp;wx_lazy=1\u0026amp;wx_co=1\" alt=\"的多面人生.JPG\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e再次感谢主理人Nian和主讲人魏峰，一次难忘的体验。\u003c/p\u003e\n\u003ch3 id=\"真的躺平吗不只是喘口气\"\u003e真的躺平吗？不，只是喘口气\u003c/h3\u003e\n\u003cp\u003e选择大理的理由： 成本，气候， 和有趣的人们\u003c/p\u003e\n\u003cp\u003e在大理，你可以遇到形形色色的人物：那些选择在此旅居的设计师，决定在退休后移居大理的上海夫妇，因成本考虑而搬来的独立开发者，还有视大理为家的咨询师小姐姐。这些都是构成大理独特社群氛围的不同面貌。\u003c/p\u003e\n\u003cp\u003e当你不确定下一步该做什么时，不妨去洱海边走走，那里的美景足以让你放慢脚步，深呼吸，重新找回自己的节奏。在大理，即便是“躺平”，也是一种享受生活、与自然和谐共处的态度。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53659998511_c358f49f0b_c.jpg\" alt=\"458FFF9D-2F2B-44BA-97C6-61BCE1D4637D_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e洱海边落日\u003c/p\u003e\n\u003ch3 id=\"取舍及时调整自己的欲望\"\u003e取舍，及时调整自己的欲望\u003c/h3\u003e\n\u003cp\u003e在网上能看到很多对于大理的劝退文， 无外乎就是过度商业化网红化， 城市规划稀烂，交通不方便，宰客现象严重等等。 以上我都认同， 对于一个习惯了大城市便利的人而言， 初到大理的感受的确是如此。 和在地的小伙伴聊下来，发现及时调整自己的欲望还是挺重要的。\u003c/p\u003e\n\u003cp\u003e但是，在早晨拉开窗帘看到洱海的一瞬间， 似乎这一切都是值得的。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53659999386_a95d8713d9_w.jpg\" alt=\"732C07E9-39CD-430A-87F5-2C0D20084DF2_1_105_c.jpeg\"  /\u003e\n\n随处可见的丁达尔效应\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e去跳海，去发疯！\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://live.staticflickr.com/65535/53660223128_1d2709b4df_w.jpg\" alt=\"63447450-9DD1-4BE2-8450-25E4E5F54DBA_1_105_c.jpeg\"  /\u003e\n\u003c/p\u003e","title":"游记：2024-春 昆明大理"},{"content":"写在最前面 在过去的几个月中，我主要致力于与RAG（检索增强生成模型）相关的研究和实验工作。通过深入地分析众多论文和项目代码，我发现虽然在RAG领域取得基本成就相对容易，但要实现出色的成果却异常困难。\n此系列文章旨在分享我在RAG研究中的心得和挑战。正如我们从OpenAI的开发者日活动中看到的，即使是在这个领域的领头羊也在不断试验和努力以寻求突破。\n在我们深入探索RAG系统提升的各种方法之前，有一个基本问题需要解决：我们如何准确地评估一个RAG系统的性能？这就像是在机器学习或深度学习任务中没有给定的测试集和评价标准，我们难以判断实验的成功与否。\n因此，本系列的第一篇文章将聚焦于介绍RAG系统的评价方法、相关指标以及测试框架，为我们接下来的探索设定明确的标准和目标。\n测试框架 以下是一些测试框架，为RAG系统评估提供了强大的支持。\nTruLens TruLens提供了一个独特的视角来评估和跟踪大型语言模型（LLM）实验，通过一系列创新的功能和方法，帮助开发者和研究人员更深入地了解模型性能和行为。\nTruLens的反馈功能（Feedback Functions）是其核心概念之一，提供了一种程序化的方法来评估应用的运行表现。这些函数从“可扩展性”和“有意义性”两个维度出发，考虑评估的范围，旨在为用户提供有价值的反馈，帮助他们理解和改进他们的LLM应用。\n在RAG应用中，提供准确的上下文信息至关重要，以避免生成不真实的“幻觉”答案。TruLens采用了创新性的RAG三元组评估方法，专门针对RAG架构的每个环节进行幻觉风险评估，确保模型的每个部分都能有效地工作，从而减少误导信息的产生。\n上下文相关性（Context Relevance） 上下文相关性是评估RAG应用的第一步，确保每一段检索到的上下文都与提出的查询紧密相关。TruLens利用序列化记录的结构来评估上下文的相关性，这是一个关键的步骤，确保模型在正确的信息上生成回答。\n真实性（Groundedness） 在检索到的上下文信息的基础上，大型语言模型将生成答案。TruLens强调了独立验证每个回答的重要性，以确保它们基于可靠信息，并且能够在检索到的上下文中找到支持的证据。这一步骤是确保模型回答的真实性和可靠性的关键。\n答案相关性（Answer Relevance） 最后，评估需要确保最终回答有效地解答了原始问题，这通过评估应用的最终回答与用户输入的相关性来实现。这一过程确保了模型的输出不仅是真实的，而且是对用户查询有用的。\nTruLens还提出了“诚实、无害和有帮助”的评估原则（Honest, Harmless, and Helpful Evaluations），这些原则旨在确保LLM应用在提供帮助的同时，也是安全和可信的。\nRagas Ragas框架专为评估检索增强生成（RAG）系统而设计，定义了四个核心评估指标：上下文相关性（context_relevancy）、上下文回溯（context_recall）、忠实度（faithfulness）和答案相关性（answer_relevancy）。这些指标共同构成了Ragas的评分体系，提供了一个全面的方法来评价RAG系统的性能。\n此外，Ragas巧妙地利用大语言模型（LLM）进行无参考评估，有效降低了评估成本。通过这种方法，Ragas能够提供一种既经济又有效的方式来评估RAG系统，尤其是在处理大量数据和复杂查询时。\n其他测试框架\nDeepEval\nDeepEval How to Evaluate RAG Applications in CI/CD Pipelines with DeepEval\nARES\ngithub: https://github.com/stanford-futuredata/ARES\nPaper: ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems\nLangChain Evals\nLlama Index Evals\nUpTrain\n数据 在评估数据集时，不必依赖人工标注的标准答案，而是通过底层的大语言模型 (LLM) 来进行评估。\n为了对 RAG 流程进行评估，需要以下几种信息：\nquestion：这是RAG流程的输入，即用户的查询问题。\nanswer：这是由RAG流程生成的答案，也就是输出结果。\ncontexts：这是为了解答question而从外部知识源检索到的相关上下文信息。\n指标 在深入研究检索增强生成（RAG）系统和其他相关技术时，了解和使用正确的评估指标至关重要。以下是几个关键指标，它们帮助我们量化和评估检索系统的效能：\n检索指标 MRR（平均倒数排名） MRR是衡量检索系统性能的一种方法，特别关注于检索结果中的首次正确命中的排名。MRR的高值表示系统能够更频繁地将相关结果排在前列。\n$$ MRR = \\frac{1}{查询数量}\\sum_{i=1}^{查询数量} \\frac{1}{首次正确命中的排名} $$\n这个指标特别有用，因为它直接关注于用户最有可能查看的第一个搜索结果的质量。\n召回率（Recall） 召回率是另一个重要指标，它衡量了系统检索到的相关文档数量与总的相关文档数量之间的比例。高召回率意味着系统能够检索到更多的相关文档。\n$$ Recall = \\frac{检索到的相关文档数量}{总的相关文档数量} $$\nNDCG（标准化折扣累积增益） NDCG（Normalized Discounted Cumulative Gain）是一个在信息检索、推荐系统和机器学习领域常用的评估指标，用于衡量一个系统或模型返回的结果列表的质量。NDCG特别关注于结果的排序质量，即最相关或最有价值的结果是否排在了列表的前面。与其他评估指标相比，NDCG的独特之处在于它考虑了结果的相关性（relevance）不仅是二元的（相关或不相关），而且可以是多级的（例如，从不相关到非常相关的多个级别）。\nEM（精确匹配） EM度量了系统输出的答案与标准答案完全一致的比例，是评估系统准确度的直接方式。在某些场景下，即使是非常小的差异也可能导致答案被视为不正确，这使得EM成为一个严格的评估标准。\n基于大语言模型评估的LLM生成指标 在RAG任务中，对LLM回答的问题主要关注了回答的可验证性（verifiability），即是否严格遵循检索到的上下文如实回答。可验证性由两部分组成：\n高引用召回率（high citation recall）：即所有生成的内容都有充分的引用（外部知识）支持。\n高引用精度（high citation precision）：每个引用是否真的支持生成的内容。\n回答相关性（Answer Relevance） 回答相关性关注的是系统生成的回答与用户提出的问题之间的相关性。理想情况下，回答应该直接且准确地对应于问题，没有偏离主题或提供不相关的信息。\nTruLens中回答相关性的计算方式： TruLens通过提供一种基于LLM的评估方法，允许开发者和研究人员通过编程方式获取对系统生成回答的相关性评估。这种方法利用链式推理（Chain of Thought, CoT）增强理解和推理过程，为评估提供透明度和可解释性。\nfrom trulens_eval.feedback.provider.openai import OpenAI openai_provider = OpenAI() qa_relevance = ( Feedback(openai_provider.relevance_with_cot_reasons, name=\u0026#34;Answer Relevance\u0026#34;) .on_input_output() ) 在relevance_with_cot_reasons方法中，使用聊天完成模型来评估回答对于提示的相关性，并揭示评分背后的推理过程。这种方法不仅考虑回答的内容和长度，而且还评估其是否全面回答了问题，并提供了与问题所有部分相关的上下文信息。\nRAGAS中回答相关性的计算逻辑： RAGAS通过利用LLM重新生成问题（QUESTION_GEN），然后计算这个重新生成的问题与原始问题之间的相似度来评估回答的相关性。这种方法特别关注于系统生成回答的准确性和与原始问题的对应关系。\n# https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/_answer_relevance.py QUESTION_GEN = HumanMessagePromptTemplate.from_template( \u0026#34;\u0026#34;\u0026#34; Generate question for the given answer. Answer:\\nThe PSLV-C56 mission is scheduled to be launched on Sunday, 30 July 2023 at 06:30 IST / 01:00 UTC. It will be launched from the Satish Dhawan Space Centre, Sriharikota, Andhra Pradesh, India Question: When is the scheduled launch date and time for the PSLV-C56 mission, and where will it be launched from? Answer:{answer} Question: \u0026#34;\u0026#34;\u0026#34; ) 不过，由于用户提出的问题通常比较简略，使用RAGAS计算出的回答相关性通常较低。\n上下文相关性（Context Relevance） 上下文相关性专注于评估给定上下文（例如从数据库或文档中检索到的信息片段）与用户查询之间的相关性。高相关性的上下文信息为大型语言模型（LLM）提供了生成准确回答的基础。\n在TruLens中上下文相关性的计算方式： 在TruLens，上下文相关性的评估使用了与回答相关性相同的反馈函数，但是采用了不同的选择器来专注于输入（用户问题）和检索到的上下文信息之间的相关性。这通过对输入问题和来源节点中的文本应用.on_input().on(TruLlama.select_source_nodes().node.text)选择器并计算它们的平均相关性得分来实现。\nqs_relevance = ( Feedback(openai_provider.relevance_with_cot_reasons, name=\u0026#34;Context Relevance\u0026#34;) .on_input() .on(TruLlama.select_source_nodes().node.text) .aggregate(np.mean) ) 底层计算逻辑：此过程首先识别出与用户问题直接相关的上下文信息，评估这些信息的相关性，可能会应用链式推理（CoT）方法来提高评分的准确性和深度。最终生成的平均分表示了上下文信息的整体相关性，分值范围从0到1。\n在RAGAS中上下文相关性的计算逻辑： RAGAS采用了一种略有不同的方法来计算上下文相关性。它通过提取与问题相关的上下文句子（candidate sentences），并对这些句子进行自洽性检查。然后，使用提取的句子数量与检索到的上下文中的总句子数量的比率作为评分标准。\n$$ \\text{context relevancy} = \\frac{|S|}{|\\text{Total number of sentences in retrieved context}|} $$\n这个方法通过使用LLM根据问题和上下文，从上下文中提取出能够支持回答的句子，进而计算这些候选句子和上下文的长度占比（这里使用的是词元数量的比值）。\n# https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/_context_relevancy.py CONTEXT_RELEVANCE = HumanMessagePromptTemplate.from_template( \u0026#34;\u0026#34;\u0026#34;\\ Please extract relevant sentences from the provided context that is absolutely required answer the following question. If no relevant sentences are found, or if you believe the question cannot be answered from the given context, return the phrase \u0026#34;Insufficient Information\u0026#34;. While extracting candidate sentences you\u0026#39;re not allowed to make any changes to sentences from given context. question:{question} context:\\n{context} candidate sentences:\\n\u0026#34;\u0026#34;\u0026#34; ) 真实性或忠实度（Groundedness or Faithfulness） 在TruLens和RAGAS中，真实性或忠实度的评估旨在衡量生成的声明或回答在事实上的准确性及其对源材料的依赖程度。这一评估标准对于确保生成内容的质量和可信度至关重要。\nTruLens中的Groundedness 在TruLens框架中，groundedness的评估通过检查声明中的每个句子是否在源材料中有支持来进行。这个过程利用大型语言模型（LLM）和链式推理（Chain of Thought, CoT）方法来增强评估的准确性和深度。具体来说，评估方法会将整个声明作为一个整体进行处理，并对声明中的每个句子赋予一个从0到10的评分，0代表没有任何信息重叠，而10代表信息完全重叠。\ngrounded = Groundedness(groundedness_provider=openai_provider) groundedness = ( Feedback(grounded.groundedness_measure_with_cot_reasons, name=\u0026#34;Groundedness\u0026#34;) .on(TruLlama.select_source_nodes().node.text) .on_output() .aggregate(grounded.grounded_statements_aggregator) ) RAGAS中的Faithfulness 而在RAGAS框架中，Faithfulness（忠实度）的概念与TruLens中的Groundedness（真实性）相似，旨在评估生成回答的事实一致性。忠实度得分通过比较生成回答中的声明与给定上下文的一致性来计算，特别是检查回答中的声明是否可以从给定的上下文中推断出来。\n$$ \\text{Faithfulness score} = \\frac{|\\text{Number of claims that can be inferred from given context}|}{|\\text{Total number of claims in the generated answer}|} $$\n# https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/_faithfulness.py LONG_FORM_ANSWER_PROMPT = HumanMessagePromptTemplate.from_template( \u0026#34;\u0026#34;\u0026#34;\\ Given a question and answer, create one or more statements from each sentence in the given answer. question: Who was Albert Einstein and what is he best known for? answer: He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics. statements:\\nAlbert Einstein was born in Germany.\\nAlbert Einstein was best known for his theory of relativity. question: Cadmium Chloride is slightly soluble in this chemical, it is also called what? answer: alcohol statements:\\nCadmium Chloride is slightly soluble in alcohol. question: Were Shahul and Jithin of the same nationality? answer: They were from different countries. statements:\\nShahul and Jithin were from different countries. question:{question} answer: {answer} statements:\\n\u0026#34;\u0026#34;\u0026#34; # noqa: E501 ) NLI_STATEMENTS_MESSAGE = HumanMessagePromptTemplate.from_template( \u0026#34;\u0026#34;\u0026#34; Prompt: Natural language inference Consider the given context and following statements, then determine whether they are supported by the information present in the context.Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format. Context:\\nJohn is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects. statements:\\n1. John is majoring in Biology.\\n2. John is taking a course on Artificial Intelligence.\\n3. John is a dedicated student.\\n4. John has a part-time job.\\n5. John is interested in computer programming.\\n Answer: 1. John is majoring in Biology. Explanation: John\u0026#39;s major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology. Verdict: No. 2. John is taking a course on Artificial Intelligence. Explanation: The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI. Verdict: No. 3. John is a dedicated student. Explanation: The prompt states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication. Verdict: Yes. 4. John has a part-time job. Explanation: There is no information given in the context about John having a part-time job. Therefore, it cannot be deduced that John has a part-time job. Verdict: No. 5. John is interested in computer programming. Explanation: The context states that John is pursuing a degree in Computer Science, which implies an interest in computer programming. Verdict: Yes. Final verdict for each statement in order: No. No. Yes. No. Yes. context:\\n{context} statements:\\n{statements} Answer: 微调模型评估 在评估RAG系统时，虽然GPT-4等大型语言模型（LLM）因其高性能而被广泛使用，但由于成本和本地部署的需要，选择一个有效的本地部署开源模型也成为了许多研究和应用场景的必需。然而，与GPT-4等高级模型相比，这些本地开源模型的能力通常存在差距，特别是在特定领域内的应用效果上。因此，针对特定领域微调一个LLM用于评估变得尤为重要。\n以下是使用Trulens测试框架，基于笔者所在领域的语料库，对同一个RAG系统使用不同的开源LLM进行评价的结果展示。特别关注的是不同验证模型的失败评分率，这里的失败评分率指的是模型无法按照提示给出有效评分的情况（例如，要求在0～1范围内打分，但模型未给出评分或评分超出范围）。\n失败评分率对比\neval model Groundedness-FailRatio Context-Relevance-FailRatio Answer-Relevance-FailRatio Records gpt-3.5-turbo 0.00 0.00 0.00 41 gpt-4-turbo 0.00 0.00 0.00 41 Qwen1.5-14B-chat 0.07 0.05 0.02 41 Qwen1.5-7B-chat 0.10 0.10 0.07 41 zephyr-7b-beta 0.27 0.22 0.22 41 Qwen1.5-4B-chat 0.32 0.15 0.17 41 chatGLM3-6b-32K 0.36 0.71 0.54 41 微调策略和建议 为了确保评价结果的稳定性和准确性，微调模型时使用的数据集应特别关注于测试框架中使用的提示格式。这样做旨在提高模型对特定提示格式的响应能力，从而提高评价的准确度和一致性。\n此外，从测试结果来看，建议至少使用13B以上的模型进行评价。较小的模型可能在遵循指令和评分准确性方面存在挑战，从而影响评价结果的可靠性。\n对于这个场景的微调，一般采用LoRA微调方法即可满足需求。LoRA（Low-Rank Adaptation）是一种有效的微调技术，可以在不大幅增加模型参数的前提下，通过更新模型的少数关键参数来实现性能的提升。这种方法特别适用于需要特定领域知识增强的场景。\n如果能够收集到足够多的人类反馈结果，采用RLHF（Reinforcement Learning from Human Feedback）专门训练一个评价模型也是一个可行的选择。RLHF通过从人类反馈中学习来优化模型的性能，这可以在成本可控的范围内提供更精确的评价结果。\n传统NLP评估 BLEU BLEU（Bilingual Evaluation Understudy）通过计算机器翻译输出与一个或多个人工翻译的参考译文之间的词汇精确度来评价翻译的质量。BLEU的主要目的是自动地评估文本翻译的好坏，尽量接近人类翻译质量评估的结果。\nROUGE ROUGE（Recall-Oriented Understudy for Gisting Evaluation）是自然语言处理（NLP）任务中常用的一种评估指标，尤其在自动文摘（自动摘要）和机器翻译等领域中非常流行。它主要用于评估自动生成的文本与人工编写的参考文本之间的相似度。ROUGE指标通过计算生成文本与参考文本之间的重叠来量度生成文本的质量。\n常见的ROUGE度量方式有：基于n-gram的重叠度量方法(如ROUGE-1, ROUGE-2)。它计算生成文本与参考文本之间共有的n-grams的数量，并以此评估生成文本的质量。以及基于最长公共子序列（LCS） 的 ROUGE-L，它考虑了句子级别的结构相似性，不仅仅是简单的词汇重叠。通过计算最长公共子序列的长度，ROUGE-L能够捕捉到生成文本和参考文本之间的顺序依赖性，从而提供更全面的相似度评估。\n对于n-gram ROUGE有两个变体： 召回率（Recall）：参考文本中与生成文本共有的n-grams数量除以参考文本中的n-grams总数。精确率（Precision）：参考文本中与生成文本共有的n-grams数量除以生成文本中的n-grams总数。以及二者的调和平均 F1-score。\nMore Details：\npaper: ROUGE: A Package for Automatic Evaluation of Summaries\nblog: GenAI model evaluation metric — ROUGE\n例子：\n# !pip install rouge from rouge import Rouge rouge = Rouge() long = \u0026#39;It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us.\u0026#39; short = \u0026#39;It was an age of wisdom, foolishness, belief, Light, Darkness, hope, and despair, with both light and darkness.\u0026#39; scores = rouge.get_scores(short, long) print(scores) # output: \u0026#39;\u0026#39;\u0026#39; [{\u0026#39;rouge-1\u0026#39;: {\u0026#39;r\u0026#39;: 0.39285714285714285, \u0026#39;p\u0026#39;: 0.6470588235294118, \u0026#39;f\u0026#39;: 0.4888888841876543}, \u0026#39;rouge-2\u0026#39;: {\u0026#39;r\u0026#39;: 0.06976744186046512, \u0026#39;p\u0026#39;: 0.17647058823529413, \u0026#39;f\u0026#39;: 0.09999999593888906}, \u0026#39;rouge-l\u0026#39;: {\u0026#39;r\u0026#39;: 0.39285714285714285, \u0026#39;p\u0026#39;: 0.6470588235294118, \u0026#39;f\u0026#39;: 0.4888888841876543}}] \u0026#39;\u0026#39;\u0026#39; where r, p, and f representing for recall, precision, and f_score.\nROUGE指标的缺点：\n依赖于参考文本： 如果参考文本的质量不高或者数量不足，可能会导致评分不准确\n忽略语义信息： 即使两段文本表达相同的意思，但使用了不同的词汇或表达方式，ROUGE评分也可能较低\n无法评价文本的流畅性和一致性\n对长文本的评价能力有限\n无法全面评估信息的新颖性和重要性\n数据集 一些公开的RAG数据集\nHotpotQA (HQA) 数据集链接：HotpotQA at Hugging Face\n特点：基于维基百科的问答数据集，需要阅读多个支持文档来回答和推理问题。问题多样，不局限于任何预先存在的知识库。提供了句子级别的支持以强化LLM的推理需求。最后，提供了新类型的事实对比问题，测试LLMs提取和比较文本中各种实体属性的能力。\nQasper (QASP) 数据集链接：Qasper at Hugging Face\n特点：基于NLP论文的问答数据集，筛选自Semantic Scholar Open Research Corpus (S2ORC)。\nNarrativeQA (NQA) 数据集链接：NarrativeQA at Hugging Face\n特点：NarrativeQA是一个英语语言的故事和相应问题的数据集，旨在测试阅读理解能力，特别是对长文档的理解。\nQuALITY (QLTY) 数据集链接：QuALITY at Hugging Face\n特点：一个基于故事和文章的多项选择问答数据集，来源包括Project Gutenberg和Open American National Corpus等资源。\nPopQA 论文链接：PopQA Paper\n数据集链接：PopQA at Hugging Face\n特点：PopQA是一个大规模的开放领域问答（QA）数据集，包含14k个以实体为中心的QA对。每个问题都是通过使用模板将从Wikidata检索到的知识元组转换而来的。\nTriviaQA 数据集链接：TriviaQA at Hugging Face\n特点：TriviaqQA是一个阅读理解数据集，包含超过650K的问题-答案-证据三元组。TriviaqQA包括由琐事爱好者编写的95K个问题-答案对。\nASQA 数据集链接：ASQA at Hugging Face\n特点：ASQA是第一个专注于含糊事实问题的长形式问答数据集。与以往的长形式答案数据集不同，每个问题都标注了长形式答案和可由生成段落回答的提取式问答对。\nPUBHEALTH 数据集链接：PUBHEALTH at Hugging Face\n特点：一个包含11,832个用于事实检查的声明的数据集，这些声明涉及一系列健康话题，包括生物医学主题（如传染病、干细胞研究）、政府医疗政策（如堕胎、心理健康、妇女健康）以及其他与公共健康相关的故事。\n推荐阅读 RAGAS Paper\n用 RAGAs（检索增强生成评估）评估 RAG（检索增强型生成）应用 [译]\n如何构建高效的 RAG 系统\nEvaluating Verifiability in Generative Search Engines\nBuilding and Evaluating Advanced RAG\nSteps In Evaluating Retrieval Augmented Generation (RAG) Pipelines\nGenAI model evaluation metric — ROUGE\nRetrieval Augmented Generation (RAG) for LLMs\nRAG Evaluation\n","permalink":"https://niraya666.github.io/posts/rag_toolkit_eval/","summary":"\u003ch2 id=\"写在最前面\"\u003e写在最前面\u003c/h2\u003e\n\u003cp\u003e在过去的几个月中，我主要致力于与RAG（检索增强生成模型）相关的研究和实验工作。通过深入地分析众多论文和项目代码，我发现虽然在RAG领域取得基本成就相对容易，但要实现出色的成果却异常困难。\u003c/p\u003e\n\u003cp\u003e此系列文章旨在分享我在RAG研究中的心得和挑战。正如我们从OpenAI的开发者日活动中看到的，即使是在这个领域的领头羊也在不断试验和努力以寻求突破。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/img/rag_toolkits/1_1.png\" alt=\"from openAI devday\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003e在我们深入探索RAG系统提升的各种方法之前，有一个基本问题需要解决：我们如何准确地评估一个RAG系统的性能？这就像是在机器学习或深度学习任务中没有给定的测试集和评价标准，我们难以判断实验的成功与否。\u003c/p\u003e\n\u003cp\u003e因此，本系列的第一篇文章将聚焦于介绍RAG系统的评价方法、相关指标以及测试框架，为我们接下来的探索设定明确的标准和目标。\u003c/p\u003e\n\u003ch2 id=\"测试框架\"\u003e测试框架\u003c/h2\u003e\n\u003cp\u003e以下是一些测试框架，为RAG系统评估提供了强大的支持。\u003c/p\u003e\n\u003ch3 id=\"trulens\"\u003e\u003cstrong\u003eTruLens\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eTruLens提供了一个独特的视角来评估和跟踪大型语言模型（LLM）实验，通过一系列创新的功能和方法，帮助开发者和研究人员更深入地了解模型性能和行为。\u003c/p\u003e\n\u003cp\u003eTruLens的反馈功能（Feedback Functions）是其核心概念之一，提供了一种程序化的方法来评估应用的运行表现。这些函数从“可扩展性”和“有意义性”两个维度出发，考虑评估的范围，旨在为用户提供有价值的反馈，帮助他们理解和改进他们的LLM应用。\u003c/p\u003e\n\u003cp\u003e在RAG应用中，提供准确的上下文信息至关重要，以避免生成不真实的“幻觉”答案。TruLens采用了创新性的RAG三元组评估方法，专门针对RAG架构的每个环节进行幻觉风险评估，确保模型的每个部分都能有效地工作，从而减少误导信息的产生。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://www.trulens.org/assets/images/RAG_Triad.jpg\" alt=\"TruLens RAG_Triad\"  /\u003e\n\u003c/p\u003e\n\u003ch4 id=\"上下文相关性context-relevance\"\u003e上下文相关性（Context Relevance）\u003c/h4\u003e\n\u003cp\u003e上下文相关性是评估RAG应用的第一步，确保每一段检索到的上下文都与提出的查询紧密相关。TruLens利用序列化记录的结构来评估上下文的相关性，这是一个关键的步骤，确保模型在正确的信息上生成回答。\u003c/p\u003e\n\u003ch4 id=\"真实性groundedness\"\u003e真实性（Groundedness）\u003c/h4\u003e\n\u003cp\u003e在检索到的上下文信息的基础上，大型语言模型将生成答案。TruLens强调了独立验证每个回答的重要性，以确保它们基于可靠信息，并且能够在检索到的上下文中找到支持的证据。这一步骤是确保模型回答的真实性和可靠性的关键。\u003c/p\u003e\n\u003ch4 id=\"答案相关性answer-relevance\"\u003e答案相关性（Answer Relevance）\u003c/h4\u003e\n\u003cp\u003e最后，评估需要确保最终回答有效地解答了原始问题，这通过评估应用的最终回答与用户输入的相关性来实现。这一过程确保了模型的输出不仅是真实的，而且是对用户查询有用的。\u003c/p\u003e\n\u003cp\u003eTruLens还提出了“诚实、无害和有帮助”的评估原则（Honest, Harmless, and Helpful Evaluations），这些原则旨在确保LLM应用在提供帮助的同时，也是安全和可信的。\u003c/p\u003e\n\u003ch3 id=\"ragas\"\u003eRagas\u003c/h3\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://docs.ragas.io/en/stable/_static/imgs/component-wise-metrics.png\" alt=\"Ragas\"  /\u003e\n\u003c/p\u003e\n\u003cp\u003eRagas框架专为评估检索增强生成（RAG）系统而设计，定义了四个核心评估指标：上下文相关性（context_relevancy）、上下文回溯（context_recall）、忠实度（faithfulness）和答案相关性（answer_relevancy）。这些指标共同构成了Ragas的评分体系，提供了一个全面的方法来评价RAG系统的性能。\u003c/p\u003e\n\u003cp\u003e此外，Ragas巧妙地利用大语言模型（LLM）进行无参考评估，有效降低了评估成本。通过这种方法，Ragas能够提供一种既经济又有效的方式来评估RAG系统，尤其是在处理大量数据和复杂查询时。\u003c/p\u003e\n\u003cp\u003e其他测试框架\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDeepEval\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/confident-ai/deepeval\"\u003eDeepEval\u003c/a\u003e \u003ca href=\"https://www.confident-ai.com/blog/how-to-evaluate-rag-applications-in-ci-cd-pipelines-with-deepeval\"\u003eHow to Evaluate RAG Applications in CI/CD Pipelines with DeepEval\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eARES\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003egithub: \u003ca href=\"https://github.com/stanford-futuredata/ARES\"\u003ehttps://github.com/stanford-futuredata/ARES\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePaper: ARES: \u003ca href=\"https://arxiv.org/abs/2311.09476\"\u003eAn Automated Evaluation Framework for Retrieval-Augmented Generation Systems\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"https://python.langchain.com/docs/guides/evaluation/\"\u003eLangChain Evals\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://docs.llamaindex.ai/en/stable/module_guides/evaluating/root.html\"\u003eLlama Index Evals\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/uptrain-ai/uptrain\"\u003eUpTrain\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"数据\"\u003e数据\u003c/h2\u003e\n\u003cp\u003e在评估数据集时，不必依赖人工标注的标准答案，而是通过底层的大语言模型 (LLM) 来进行评估。\u003c/p\u003e","title":"RAG工具箱：评估RAG系统的方法论"},{"content":"Hello-World! 欢迎来到我的博客\n在这里，我将深入探索生成式人工智能的奥秘，同时也会涉猎音乐、电影等领域，分享一些个人的思考和感悟。\n为什么我决定写博客 在生活的纷扰和无尽的日常中，我发现自己一直在与拖延症作斗争。直到今天，我终于下定决心，决定将心中的思绪和感悟记录下来，开启我的博客之旅。\n有几个原因驱使我做出了这个决定。\n首先，岁月不饶人，尤其是经历了新冠疫情之后，我明显感觉到我的记忆力不如以往。过去能够轻松驾驭多重任务的我，如今却常在走入客厅的半路上忘记初衷，或是在浏览器的搜索框前失去了寻找的目的。这种突如其来的迷茫，让我开始思索，我的思绪是否正如秋日里的落叶，悄然飘落。\n其次，在深夜的静思中，我时常回想起坂本龙一那句引人深思的话：“我还能看到几次满月？”这不仅是对时间流逝的感慨，更是一种对生命有限性的深刻体悟。在这有限的时光里，我究竟能留下什么？假如我的时间之沙仅剩下几颗，我的存在又有何意义？我不求答案，但愿通过这些文字，如同在时间的长河中种下一棵树，哪怕是最微小的存在，也能留下自己生命的痕迹。\n最后，我被“数据主义”（Dataism）这一概念深深吸引，它如同一面镜子，映照出在数字时代，我们的数据、思考和情感不仅仅是信息的载体，更是构成我们数字化身份的基石。随着AI的羽翼日渐丰满，我开始憧憬一个可能的未来，其中一个由我的数据、思想和经历塑造出的“我”，在某个未知的时间点复苏。这种思考，如同在深海中发现了一座灯塔，为我的存在指明了一条全新的路径。在这个时代，我选择不再是沉默的旁观者，而是通过我的文字，积极参与到这场未知的探索中。\n因此，这篇博客标志着我的新开始。虽然不确定未来的路会怎样，但至少，在这个过程中，我会找到自己的声音，并希望能够与你共鸣。\n","permalink":"https://niraya666.github.io/posts/helloworld/","summary":"\u003ch1 id=\"hello-world\"\u003eHello-World!\u003c/h1\u003e\n\u003cp\u003e欢迎来到我的博客\u003c/p\u003e\n\u003cp\u003e在这里，我将深入探索生成式人工智能的奥秘，同时也会涉猎音乐、电影等领域，分享一些个人的思考和感悟。\u003c/p\u003e\n\u003ch2 id=\"为什么我决定写博客\"\u003e为什么我决定写博客\u003c/h2\u003e\n\u003cp\u003e在生活的纷扰和无尽的日常中，我发现自己一直在与拖延症作斗争。直到今天，我终于下定决心，决定将心中的思绪和感悟记录下来，开启我的博客之旅。\u003c/p\u003e\n\u003cp\u003e有几个原因驱使我做出了这个决定。\u003c/p\u003e\n\u003cp\u003e首先，岁月不饶人，尤其是经历了新冠疫情之后，我明显感觉到我的记忆力不如以往。过去能够轻松驾驭多重任务的我，如今却常在走入客厅的半路上忘记初衷，或是在浏览器的搜索框前失去了寻找的目的。这种突如其来的迷茫，让我开始思索，我的思绪是否正如秋日里的落叶，悄然飘落。\u003c/p\u003e\n\u003cp\u003e其次，在深夜的静思中，我时常回想起坂本龙一那句引人深思的话：“我还能看到几次满月？”这不仅是对时间流逝的感慨，更是一种对生命有限性的深刻体悟。在这有限的时光里，我究竟能留下什么？假如我的时间之沙仅剩下几颗，我的存在又有何意义？我不求答案，但愿通过这些文字，如同在时间的长河中种下一棵树，哪怕是最微小的存在，也能留下自己生命的痕迹。\u003c/p\u003e\n\u003cp\u003e最后，我被“数据主义”（Dataism）这一概念深深吸引，它如同一面镜子，映照出在数字时代，我们的数据、思考和情感不仅仅是信息的载体，更是构成我们数字化身份的基石。随着AI的羽翼日渐丰满，我开始憧憬一个可能的未来，其中一个由我的数据、思想和经历塑造出的“我”，在某个未知的时间点复苏。这种思考，如同在深海中发现了一座灯塔，为我的存在指明了一条全新的路径。在这个时代，我选择不再是沉默的旁观者，而是通过我的文字，积极参与到这场未知的探索中。\u003c/p\u003e\n\u003cp\u003e因此，这篇博客标志着我的新开始。虽然不确定未来的路会怎样，但至少，在这个过程中，我会找到自己的声音，并希望能够与你共鸣。\u003c/p\u003e\n\u003cscript src=\"https://utteranc.es/client.js\"\n        repo=\"https://github.com/Niraya666/niraya666.github.io\"\n        issue-term=\"pathname\"\n        theme=\"github-dark\"\n        crossorigin=\"anonymous\"\n        async\u003e\n\u003c/script\u003e","title":"My First Post: Hello-World!"},{"content":"","permalink":"https://niraya666.github.io/travel-map/","summary":"","title":"Travel Map"}]