<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Tool-Using on LZY Blog</title>
    <link>https://niraya666.github.io/tags/tool-using/</link>
    <description>Recent content in Tool-Using on LZY Blog</description>
    <image>
      <title>LZY Blog</title>
      <url>https://niraya666.github.io/images/papermod-cover.png</url>
      <link>https://niraya666.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 25 Jun 2024 17:00:00 +0800</lastBuildDate>
    <atom:link href="https://niraya666.github.io/tags/tool-using/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Agent学习笔记： 如何验证模型的tool-using能力</title>
      <link>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/</link>
      <pubDate>Tue, 25 Jun 2024 17:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/</guid>
      <description>&lt;p&gt;本文将简单介绍如何评价LLM的tool-using 能力。&lt;/p&gt;
&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;p&gt;在工具使用评估方面，过去的研究主要有以下几种思路：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对比工具使用和纯LLM在基准测试上的分数&lt;/strong&gt;：例如&lt;a href=&#34;https://arxiv.org/abs/2302.04761&#34;&gt;Toolformer&lt;/a&gt;和&lt;a href=&#34;https://arxiv.org/abs/2305.17126&#34;&gt;LATM&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在Toolformer研究中，通过下游任务如语言模型评估基准测试、数学推理任务和问答任务来验证工具使用的有效性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LATM则采用了来自BigBench的六个数据集进行评估。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;测试工具使用的准确率和响应质量&lt;/strong&gt;：例如&lt;a href=&#34;https://arxiv.org/abs/2304.08244&#34;&gt;API-Bank&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在评估过程中，首先初始化评估系统，确保每个API的数据库包含默认值。然后，将预测的API调用与手动标注的API调用进行比较，以确定它们的一致性。响应评估则使用ROUGE-L指标。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;利用LLM对工具使用的效果进行评价&lt;/strong&gt;：例如Tool-bench。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;two evaluation metrics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pass Rate&lt;/strong&gt;: Calculates the proportion of successfully completing an instruction within limited OpenAI API calls.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Preference&lt;/strong&gt;: Measured by comparing two answers (action sequences) for a given instruction.We pre-define a set of criteria for a better answer, which are organized as prompts for ChatGPT.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;构造虚拟运行环境，测试代理与环境的交互结果&lt;/strong&gt;：例如ToolAlpaca。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用LLM模拟环境（用户代理和助手代理），并使用GPT-4对ToolAlpaca模型进行机器评估，评估其使用各种未见工具的能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于绝大多数企业和垂直场景下， 其中思路1需要构建额外的测试集成本比较高（但还是有必要的）， 而思路4构造虚拟运行环境实际上并不现实； 所以还是选择思路2，外加通过思路3辅助判断；换句话说， 根据场景，构造工具列表和工具调用的ground-truth（包括函数名， 和传入参数）  ，在存在歧义时，采用ROUGE评价响应质量， 或者使用LLM判断响应结果并评价。&lt;/p&gt;
&lt;p&gt;顺带提一下Langchain 项目中有关Agent的tool-using能力测试的内容， 不过由于Langchain项目又臭又长，且有很大的局限性， 这里只讨论其思路。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Agent学习笔记：OpenAI Function Calling完全指南</title>
      <link>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0openai-function-calling%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sun, 28 Apr 2024 15:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0openai-function-calling%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/</guid>
      <description>&lt;h2 id=&#34;写在最开始&#34;&gt;写在最开始&lt;/h2&gt;
&lt;p&gt;当我们在讨论基于大型语言模型（LLM-based）的智能代理（agent）时，我们究竟在谈论什么？根据Lilian W在其文章《LLM Powered Autonomous Agents》中的讨论，一个智能代理需要具备几个核心能力：规划（Planning）、记忆（Memory）、以及工具使用（Tool use）。特别地，工具使用方面的进展，得益于OpenAI在API中提供的function calling功能，为我们开启了新的可能性。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/agent-overview.png&#34; alt=&#34;AGI&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;OpenAI function calling，作为智能代理与外部工具交互的基本方式，对于每位从业者来说都是必备技能。随着技术的发展，我们期望的不只是能与我们对话的LLM，而是能够辅助我们使用各种工具、做出决策的智能伙伴。&lt;/p&gt;
&lt;p&gt;不过需要特别指出的是，最近OpenAI在Chat Completions API中已经废弃了“函数（function）”的使用，转而采用“工具（tool）”。这一变更旨在拓宽LLM集成的功能范围，为更复杂的交互模式铺平道路，如构建能够相互作用的多代理系统。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.16.54.png&#34; alt=&#34;截屏2024-03-28 15.16.54.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.17.38.png&#34; alt=&#34;截屏2024-03-28 15.17.38.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;尽管如此，由于语言习惯的原因，本文中仍然会使用function calling的术语来描述OpenAI的tool using功能，因为“function calling”的说法已经深入人心了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核心内容概览&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Function Calling的定义&lt;/strong&gt;：解释什么是function calling，以及它在智能代理工作中的作用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OpenAI Cookbook示例&lt;/strong&gt;：提供实际的function calling示例，帮助读者理解其在实际应用中的用途。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;开源LLM的Tool Using&lt;/strong&gt;：探索如何在开源大型语言模型中实现工具使用，以及LLM在tool using的时候经历了什么。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;del&gt;评价与训练&lt;/del&gt;&lt;/strong&gt;&lt;del&gt;：讨论如何评价开源模型的工具使用能力，以及如何训练LLM进行有效的工具使用。&lt;/del&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;鉴于整理笔记的速度远赶不上更新的速度， 会将第四部份作为单独的部分整理。&lt;/p&gt;
&lt;h2 id=&#34;何为function-calling&#34;&gt;何为function calling&lt;/h2&gt;
&lt;p&gt;一句话解释：&lt;strong&gt;function calling从本质上并不是严格的工具调用， 而是作为工具调用的前奏，它通过更加结构化的方式指导LLM输出，为在本地执行具体函数提供了参数，铺平了道路。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;具体来说，function calling允许LLM在执行过程中通过指定的参数来调用并执行一个特定的函数。这种方式不仅实现了代码的重用和模块化处理，而且能够从模型中获取更可靠的结构化数据回应。在API调用过程中，开发者可以描述想要执行的功能，并让模型智能地选择输出包含所需参数的JSON对象。&lt;strong&gt;这个过程中，Chat Completions API本身不直接执行任何函数调用，而是生成了可以在开发者代码中实现函数调用的JSON。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;function calling的应用范围广泛，如&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;创建智能助手：通过调用外部API回答问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;转换指令：将自然语言指令转换成API调用指令。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据提取：从文本中提取结构化数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;function calling的过程涵盖了从定义函数集、通过模型生成遵循自定义模式的JSON对象字符串，到在代码中解析这个字符串并调用相应函数的全过程。这一连串操作不仅自动化了交互过程，还确保了执行操作的安全性和准确性。&lt;/p&gt;
&lt;h2 id=&#34;一些常见的问题&#34;&gt;一些常见的问题&lt;/h2&gt;
&lt;h3 id=&#34;json-mode&#34;&gt;JSON mode&lt;/h3&gt;
&lt;p&gt;json mode 和tool-using 有什么关系？有了json mode 还需要用到tool-using吗？&lt;/p&gt;
&lt;p&gt;从json mode 的本质， 更多的是在system prompt 增加一句类似“请以json格式输出”之类的话，然后在LLM输出时增加json结果检查和格式转换。在使用时只需要在&lt;code&gt;client.chat.completions.create &lt;/code&gt;中 增加&lt;code&gt;response_format={ &amp;quot;type&amp;quot;: &amp;quot;json_object&amp;quot; }&lt;/code&gt; 即可。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
