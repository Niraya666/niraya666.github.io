<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Agent on LZY Blog</title>
    <link>http://localhost:1313/tags/agent/</link>
    <description>Recent content in Agent on LZY Blog</description>
    <image>
      <title>LZY Blog</title>
      <url>http://localhost:1313/images/papermod-cover.png</url>
      <link>http://localhost:1313/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 21 Aug 2024 14:49:00 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/agent/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM 输出限制：Structured Outputs、受限编码和提示词工程</title>
      <link>http://localhost:1313/posts/llm-%E8%BE%93%E5%87%BA%E9%99%90%E5%88%B6structured-outputs%E5%8F%97%E9%99%90%E7%BC%96%E7%A0%81%E5%92%8C%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/</link>
      <pubDate>Wed, 21 Aug 2024 14:49:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/llm-%E8%BE%93%E5%87%BA%E9%99%90%E5%88%B6structured-outputs%E5%8F%97%E9%99%90%E7%BC%96%E7%A0%81%E5%92%8C%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/</guid>
      <description>&lt;p&gt;在使用大型语言模型（LLM）时，我们常常面临一个挑战：如何从模型输出中准确提取自己所需的信息。例如，当我们希望模型输出 JSON 格式的数据时，由于模型生成的内容并不总是稳定，可能需要额外编写大量的正则表达式来匹配并提取其中的有效信息。然而，由于 LLM 的能力，导致其输出结构并不永远可靠。&lt;/p&gt;
&lt;p&gt;现阶段， 让LLM按要求生成特定格式文本的主要方法有几种种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;微调：使模型的输出遵循特定格式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OpenAI Json-mode/Structured Outputs/function-calling:&lt;/strong&gt; 这些功能允许模型生成更严格、结构化的输出，但受限于openAI平台。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;格式约束&lt;/strong&gt;：在decoding阶段进行约束，限制模型的输出，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Engineering&lt;/strong&gt;： 最简单的办法，但不稳定。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多阶段prompting： 通过多个步骤的提示逐步引导模型生成所需的格式。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文将聚焦在Structured Outputs， 受限编码， 和prompt-engineering的角度，探讨它们在生成特定格式文本中的应用和效果。&lt;/p&gt;
&lt;h2 id=&#34;json-mode&#34;&gt;Json Mode&lt;/h2&gt;
&lt;p&gt;仅特定模型和平台支持&lt;/p&gt;
&lt;p&gt;以openAI 为例， 在&lt;code&gt;openai.chat.completions.create&lt;/code&gt; 参数中增加&lt;code&gt;response_format={&amp;quot;type&amp;quot;:&amp;quot;json_object&amp;quot;}&lt;/code&gt; 即可（具体参见：&lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat/create#chat-create-response_format&#34;&gt;response_format&lt;/a&gt; ）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;需要在prompt中要求输出json格式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不能保证完全按要求的格式结构输出&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但非100%成功率，存在一些需要额外检测和适当处理的edge case。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
  &lt;summary&gt;Handling edge cases&lt;/summary&gt;
  &lt;details&gt;
    &lt;summary&gt;根据OpenAI官方文档提供的处理方案&lt;/summary&gt;
    https://platform.openai.com/docs/guides/structured-outputs/json-mode
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;we_did_not_specify_stop_tokens&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;completions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;gpt-3.5-turbo-0125&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;You are a helpful assistant designed to output JSON.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Who won the world series in 2020? Please respond in the format {winner: ...}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;response_format&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;json_object&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Check if the conversation was too long for the context window, resulting in incomplete JSON &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finish_reason&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;length&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# your code should handle this error case&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Check if the OpenAI safety system refused the request and generated a refusal instead&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;refusal&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# your code should handle this error case&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# In this case, the .content field will contain the explanation (if any) that the model generated for why it is refusing&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;refusal&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Check if the model&amp;#39;s output included restricted content, so the generation of JSON was halted and may be partial&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finish_reason&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content_filter&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# your code should handle this error case&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finish_reason&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;stop&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# In this case the model has either successfully finished generating the JSON object according to your schema, or the model generated one of the tokens you provided as a &amp;#34;stop token&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;we_did_not_specify_stop_tokens&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;c1&#34;&gt;# If you didn&amp;#39;t specify any stop tokens, then the generation is complete and the content key will contain the serialized JSON object&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;c1&#34;&gt;# This is guaranteed to parse successfully and should now contain  &amp;#34;{&amp;#34;winner&amp;#34;: &amp;#34;Los Angeles Dodgers&amp;#34;}&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;c1&#34;&gt;# Check if the response.choices[0].message.content ends with one of your stop tokens and handle appropriately&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Your code should handle errors here, for example a network error calling the API&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;使用pydantic的方案&lt;/summary&gt;
    使用pydantic的方案
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pydantic&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;BaseModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;EmailStr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ValidationError&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# 定义你期望的 JSON 数据模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;UserModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BaseModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;email&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;EmailStr&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# 检查 JSON 是否符合模型的函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;validate_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# 将输入的 JSON 字符串转换为 UserModel 实例&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;UserModel&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parse_raw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# 如果验证通过，返回字典&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ValidationError&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;JSON validation error: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ve&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# 示例用法&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;{&amp;#34;name&amp;#34;: &amp;#34;John Doe&amp;#34;, &amp;#34;email&amp;#34;: &amp;#34;john.doe@example.com&amp;#34;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;validated_json&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;validate_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;validated_json&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;JSON is valid and conforms to the schema:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;validated_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;JSON is invalid.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/details&gt;
&lt;/details&gt;
&lt;p&gt;Json-Mode 更多是对于输出json的格式进行检查(即Json格式的有效性)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Agent学习笔记： 如何验证模型的tool-using能力</title>
      <link>http://localhost:1313/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/</link>
      <pubDate>Tue, 25 Jun 2024 17:00:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/</guid>
      <description>&lt;p&gt;本文将简单介绍如何评价LLM的tool-using 能力。&lt;/p&gt;
&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;p&gt;在工具使用评估方面，过去的研究主要有以下几种思路：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对比工具使用和纯LLM在基准测试上的分数&lt;/strong&gt;：例如&lt;a href=&#34;https://arxiv.org/abs/2302.04761&#34;&gt;Toolformer&lt;/a&gt;和&lt;a href=&#34;https://arxiv.org/abs/2305.17126&#34;&gt;LATM&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在Toolformer研究中，通过下游任务如语言模型评估基准测试、数学推理任务和问答任务来验证工具使用的有效性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LATM则采用了来自BigBench的六个数据集进行评估。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;测试工具使用的准确率和响应质量&lt;/strong&gt;：例如&lt;a href=&#34;https://arxiv.org/abs/2304.08244&#34;&gt;API-Bank&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在评估过程中，首先初始化评估系统，确保每个API的数据库包含默认值。然后，将预测的API调用与手动标注的API调用进行比较，以确定它们的一致性。响应评估则使用ROUGE-L指标。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;利用LLM对工具使用的效果进行评价&lt;/strong&gt;：例如Tool-bench。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;two evaluation metrics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pass Rate&lt;/strong&gt;: Calculates the proportion of successfully completing an instruction within limited OpenAI API calls.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Preference&lt;/strong&gt;: Measured by comparing two answers (action sequences) for a given instruction.We pre-define a set of criteria for a better answer, which are organized as prompts for ChatGPT.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;构造虚拟运行环境，测试代理与环境的交互结果&lt;/strong&gt;：例如ToolAlpaca。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用LLM模拟环境（用户代理和助手代理），并使用GPT-4对ToolAlpaca模型进行机器评估，评估其使用各种未见工具的能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于绝大多数企业和垂直场景下， 其中思路1需要构建额外的测试集成本比较高（但还是有必要的）， 而思路4构造虚拟运行环境实际上并不现实； 所以还是选择思路2，外加通过思路3辅助判断；换句话说， 根据场景，构造工具列表和工具调用的ground-truth（包括函数名， 和传入参数）  ，在存在歧义时，采用ROUGE评价响应质量， 或者使用LLM判断响应结果并评价。&lt;/p&gt;
&lt;p&gt;顺带提一下Langchain 项目中有关Agent的tool-using能力测试的内容， 不过由于Langchain项目又臭又长，且有很大的局限性， 这里只讨论其思路。&lt;/p&gt;</description>
    </item>
    <item>
      <title>基于大语言模型的 Agent：科普向</title>
      <link>http://localhost:1313/posts/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84-agent%E7%A7%91%E6%99%AE%E5%90%91/</link>
      <pubDate>Mon, 13 May 2024 16:00:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84-agent%E7%A7%91%E6%99%AE%E5%90%91/</guid>
      <description>&lt;h2 id=&#34;写在开头&#34;&gt;写在开头&lt;/h2&gt;
&lt;p&gt;本文是基于最近组内技术交流的文字稿整理。&lt;/p&gt;
&lt;h2 id=&#34;what-is-agent&#34;&gt;What is Agent？&lt;/h2&gt;
&lt;p&gt;在探讨复杂的人工智能技术之前，让我们先回顾一下生活中的一个简单例子：扫地机器人。这种智能设备在房间中自主导航，避开障碍物，寻找最有效的清洁路径。它就是一个现实生活中的Agent——一个可以自主决策和行动的实体。&lt;/p&gt;
&lt;p&gt;在人工智能领域，Agent指的是任何可以感知其环境并根据感知结果做出决策的实体。这些决策旨在完成某些任务或达成特定的目标。Agent的行为可以简单如游戏里的机器人，也可以复杂如自动驾驶汽车。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/Pasted%202024-05-10-14-58-28.webp&#34; alt=&#34;Pasted 2024-05-10-14-58-28.webp&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;开始于强化学习&#34;&gt;开始于强化学习&lt;/h3&gt;
&lt;p&gt;在强化学习中， 我们往往能见到agent的概念。强化学习是一种机器学习方法，它教导Agent通过试错法找到最佳行动路径。就像训练小狗一样，我们通过奖励来引导Agent做出正确的决策。Agent的目标是在与环境的交互中寻找最优策略。理想情况下，如果Agent能够获取足够多的真实环境数据，它就能找到最佳解决方案。然而，由于真实环境的复杂性，完全模拟真实世界是不现实的。&lt;/p&gt;
&lt;p&gt;目前，强化学习主要适用于环境简单、问题定义明确的场景，如围棋或视频游戏。这种方法在虚拟环境中通过大量试错来探索解决方案，这种方法虽然有效，但缺乏灵活性和高效性。与人类学习新技能的方式相比，强化学习的效率远低。人们通常通过少量的尝试就能迅速掌握新技能，而强化学习可能需要成千上万次的试错。&lt;/p&gt;
&lt;p&gt;这时候，如果agent具有大脑就好了。&lt;/p&gt;
&lt;h3 id=&#34;将llms作为大脑-赋能智能agent的关键技术&#34;&gt;将LLMs作为大脑: &lt;strong&gt;赋能智能Agent的关键技术&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;相较于基于强化学习的Agent，人类的优势在于我们天生具备的记忆能力和逻辑判断能力，甚至包括反思和从经验中学习的能力。这些能力使得我们能够通过极少的试错迅速适应和掌握新技能。&lt;/p&gt;
&lt;p&gt;语言模型（LLMs）为AI领域带来了革命性的变化。LLMs通过其深度学习的新范式，以及在思维链和自然语言理解方面的强大能力，预示着Agent将拥有更强大的学习和迁移能力。这种能力的提升将使得创建广泛应用且实用的Agent成为可能。&lt;/p&gt;
&lt;p&gt;虽然LLM是否真正具备了推理能力仍然存疑，但LLM的出现无疑改变了很多。以COT（Chain of Thought）为例，这种模型通过打印解题的中间步骤，加强了在数学和逻辑推理方面的能力，减少了幻觉的出现。这一突破性的工作揭示了LLM在不同场景下的强大&amp;quot;in-context learning&amp;quot;能力，以及其在未经微调的情况下的泛化能力。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png&#34; alt=&#34;截屏2024-05-08 15.37.21.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;将LLM视为AI Agent的大脑，为自动化系统提供了一种全新的构思方式。这种基于LLM的agent系统综合了规划、记忆、工具使用和行动的能力，通过API调用与外部世界互动，显示出了前所未有的灵活性和效率。&lt;/p&gt;
&lt;p&gt;根据&lt;a href=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/&#34;&gt;LLM Powered Autonomous Agents&lt;/a&gt;一文对LLM-based agent系统的定义， agent需要具备的基本能力：规划+记忆+工具+行动。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规划能力&lt;/strong&gt;：将复杂的任务分解成小任务， 并管理每一个子任务的目标， 并从过去的失败中反思，以吸取经验。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;记忆&lt;/strong&gt;：LLM的上下文长度有限， 通过额外的记忆系统以提升LLM作为大脑的能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;工具调用&amp;amp;行动&lt;/strong&gt;：LLM通过API调用的方式，执行任务， 与外界交互，而不是只是输出文字。&lt;/p&gt;
&lt;h3 id=&#34;探索ai代理的独特能力人类与单一llm无法比拟&#34;&gt;&lt;strong&gt;探索AI代理的独特能力：人类与单一LLM无法比拟&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;AI系统的主要优势在于它们的规模和效率。这些系统能够执行以下任务，超越人类能力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;大规模数据处理&lt;/strong&gt;：AI能够高效地分析和处理超出人类理解范围的数据量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;无需休息的持续操作&lt;/strong&gt;：AI系统可以不间断地运行，而无需像人类那样休息和恢复。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;超快速计算&lt;/strong&gt;：AI可以迅速执行复杂的计算，处理速度和效率远超人类。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;AI代理与单一LLM的不同:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;根据Andrew Ng在讲座中分享的内容，使用相对“简单”模型的代理工作流程（例如GPT-3.5）在实际应用中往往能够超越使用“智能”模型（如GPT-4）的零次提示。这说明在特定场景下，选择适当的AI模型和策略可能比单一的高级模型更有效。&lt;/p&gt;
&lt;p&gt;AI代理在决策制定中的应用也显示出其独特的优势。它们可以在没有情感偏见的情况下，基于大量数据做出快速且精确的决策。这种能力在需要快速响应和高精确度的领域尤为重要，如金融交易和紧急响应系统。&lt;/p&gt;
&lt;h2 id=&#34;agent的规划和思维过程&#34;&gt;&lt;strong&gt;Agent的规划和思维过程&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI Agent在处理复杂任务时，通过将大任务分解成小任务来提高效率。此外，自我反思能力允许Agent从过去的行动中学习，通过评估过去的决策来改善未来的表现。&lt;/p&gt;
&lt;p&gt;CoT，Chain of Thought， &lt;a href=&#34;https://arxiv.org/abs/2201.11903&#34;&gt;Wei et al. 2022&lt;/a&gt;。 即“思维链”，是一种使Agent逐步思考的方法。它通过要求模型展示解决问题的中间步骤来加强其逻辑推理能力，从而提高决策的质量和准确性。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png&#34; alt=&#34;截屏2024-05-08 15.37.21.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tree of Thoughts， ToT&lt;/strong&gt;  (&lt;a href=&#34;https://arxiv.org/abs/2305.10601&#34;&gt;Yao et al. 2023&lt;/a&gt;)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Agent学习笔记：OpenAI Function Calling完全指南</title>
      <link>http://localhost:1313/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0openai-function-calling%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sun, 28 Apr 2024 15:00:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0openai-function-calling%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/</guid>
      <description>&lt;h2 id=&#34;写在最开始&#34;&gt;写在最开始&lt;/h2&gt;
&lt;p&gt;当我们在讨论基于大型语言模型（LLM-based）的智能代理（agent）时，我们究竟在谈论什么？根据Lilian W在其文章《LLM Powered Autonomous Agents》中的讨论，一个智能代理需要具备几个核心能力：规划（Planning）、记忆（Memory）、以及工具使用（Tool use）。特别地，工具使用方面的进展，得益于OpenAI在API中提供的function calling功能，为我们开启了新的可能性。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/agent-overview.png&#34; alt=&#34;AGI&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;OpenAI function calling，作为智能代理与外部工具交互的基本方式，对于每位从业者来说都是必备技能。随着技术的发展，我们期望的不只是能与我们对话的LLM，而是能够辅助我们使用各种工具、做出决策的智能伙伴。&lt;/p&gt;
&lt;p&gt;不过需要特别指出的是，最近OpenAI在Chat Completions API中已经废弃了“函数（function）”的使用，转而采用“工具（tool）”。这一变更旨在拓宽LLM集成的功能范围，为更复杂的交互模式铺平道路，如构建能够相互作用的多代理系统。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.16.54.png&#34; alt=&#34;截屏2024-03-28 15.16.54.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://localhost:1313/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.17.38.png&#34; alt=&#34;截屏2024-03-28 15.17.38.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;尽管如此，由于语言习惯的原因，本文中仍然会使用function calling的术语来描述OpenAI的tool using功能，因为“function calling”的说法已经深入人心了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核心内容概览&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Function Calling的定义&lt;/strong&gt;：解释什么是function calling，以及它在智能代理工作中的作用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OpenAI Cookbook示例&lt;/strong&gt;：提供实际的function calling示例，帮助读者理解其在实际应用中的用途。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;开源LLM的Tool Using&lt;/strong&gt;：探索如何在开源大型语言模型中实现工具使用，以及LLM在tool using的时候经历了什么。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;del&gt;评价与训练&lt;/del&gt;&lt;/strong&gt;&lt;del&gt;：讨论如何评价开源模型的工具使用能力，以及如何训练LLM进行有效的工具使用。&lt;/del&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;鉴于整理笔记的速度远赶不上更新的速度， 会将第四部份作为单独的部分整理。&lt;/p&gt;
&lt;h2 id=&#34;何为function-calling&#34;&gt;何为function calling&lt;/h2&gt;
&lt;p&gt;一句话解释：&lt;strong&gt;function calling从本质上并不是严格的工具调用， 而是作为工具调用的前奏，它通过更加结构化的方式指导LLM输出，为在本地执行具体函数提供了参数，铺平了道路。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;具体来说，function calling允许LLM在执行过程中通过指定的参数来调用并执行一个特定的函数。这种方式不仅实现了代码的重用和模块化处理，而且能够从模型中获取更可靠的结构化数据回应。在API调用过程中，开发者可以描述想要执行的功能，并让模型智能地选择输出包含所需参数的JSON对象。&lt;strong&gt;这个过程中，Chat Completions API本身不直接执行任何函数调用，而是生成了可以在开发者代码中实现函数调用的JSON。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;function calling的应用范围广泛，如&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;创建智能助手：通过调用外部API回答问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;转换指令：将自然语言指令转换成API调用指令。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据提取：从文本中提取结构化数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;function calling的过程涵盖了从定义函数集、通过模型生成遵循自定义模式的JSON对象字符串，到在代码中解析这个字符串并调用相应函数的全过程。这一连串操作不仅自动化了交互过程，还确保了执行操作的安全性和准确性。&lt;/p&gt;
&lt;h2 id=&#34;一些常见的问题&#34;&gt;一些常见的问题&lt;/h2&gt;
&lt;h3 id=&#34;json-mode&#34;&gt;JSON mode&lt;/h3&gt;
&lt;p&gt;json mode 和tool-using 有什么关系？有了json mode 还需要用到tool-using吗？&lt;/p&gt;
&lt;p&gt;从json mode 的本质， 更多的是在system prompt 增加一句类似“请以json格式输出”之类的话，然后在LLM输出时增加json结果检查和格式转换。在使用时只需要在&lt;code&gt;client.chat.completions.create &lt;/code&gt;中 增加&lt;code&gt;response_format={ &amp;quot;type&amp;quot;: &amp;quot;json_object&amp;quot; }&lt;/code&gt; 即可。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
