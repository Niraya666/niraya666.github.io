<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Agent on LZY Blog</title>
    <link>https://niraya666.github.io/tags/agent/</link>
    <description>Recent content in Agent on LZY Blog</description>
    <image>
      <title>LZY Blog</title>
      <url>https://niraya666.github.io/images/papermod-cover.png</url>
      <link>https://niraya666.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 26 Jan 2026 21:55:00 +0800</lastBuildDate>
    <atom:link href="https://niraya666.github.io/tags/agent/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Agent Infra: sandbox技术和选型</title>
      <link>https://niraya666.github.io/posts/agent-infra-sandbox%E6%8A%80%E6%9C%AF%E5%92%8C%E9%80%89%E5%9E%8B/</link>
      <pubDate>Mon, 26 Jan 2026 21:55:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/agent-infra-sandbox%E6%8A%80%E6%9C%AF%E5%92%8C%E9%80%89%E5%9E%8B/</guid>
      <description>&lt;h2 id=&#34;背景-从context-engineering-角度出发&#34;&gt;背景: 从Context Engineering 角度出发&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;在量子力学中，希尔伯特空间内的任何复杂&lt;strong&gt;量子态&lt;/strong&gt;，本质上都是一组&lt;strong&gt;正交完备基矢&lt;/strong&gt;的线性叠加&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在过去我们总是以为，只要给LLM足够多的tools，则agent就更强大，但事实总是事与愿违，工具并非越多越好，过多的工具，会降低使用准确率和浪费宝贵的上下文，也就是 &lt;strong&gt;Context Rot；&lt;/strong&gt; 于是乎，有了一个新的领域：&lt;strong&gt;Context Engineering。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;根据业界领先的context Engineering的经验：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cursor 的 &amp;ldquo;File-based Tools&amp;rdquo;&lt;/strong&gt;： Cursor 采取了一种文档化方案，将工具的“说明书”全部文件化。当 Agent 需要使用某个能力时，它会先通过Retrieval找到对应的文档，阅读后生成代码&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Manus 的 &amp;ldquo;Context Offloading&amp;rdquo;&lt;/strong&gt;： 在 Manus 的设计中，采用了层级化的工具架构。为了应对复杂的长流程任务，Agent 不再试图把所有中间状态都记在 Context Window 里，而是利用&lt;strong&gt;文件系统&lt;/strong&gt;进行 Context Offloading（上下文卸载）。文件系统成为了 Agent 的外挂memory（不同于compact的有损压缩，Offloading是无损的）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Anthropic 的 &amp;ldquo;Programming tool-using&amp;rdquo; 和skills&lt;/strong&gt;：由agent自身编写代码实现tool-call相比于直接的tool-call能够节约大量context；同时agent skills本质上也是利用了file-system，对宝贵的context 进行节约的设计&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;显而易见，&lt;strong&gt;代码执行环境 (Code Execution)&lt;/strong&gt; 和 &lt;strong&gt;可读写的文件系统 (File System)&lt;/strong&gt; 已经超越了辅助工具的范畴，成为 Agent 组件中必要且不可或缺的部分。&lt;/p&gt;
&lt;p&gt;しかし赋予 Agent “写代码”和“改文件”的能力，等同于赋予了它巨大的破坏力。&lt;/p&gt;
&lt;p&gt;与传统软件确定的执行路径不同，Agent 的行为是基于概率和上下文动态生成的&lt;/p&gt;
&lt;p&gt;意味着：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Injection&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Agent 的幻觉导致死循环或资源耗尽&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，通过为 Agent 划定严格的 &lt;strong&gt;安全边界（Sandbox）&lt;/strong&gt;——如网络隔离、文件系统隔离、进程隔离，便显得尤为重要。&lt;/p&gt;
&lt;p&gt;此外与 Claude Code 这样跑在开发者本地电脑上的 Coding Agent 不同，开发者通常拥有把控风险的能力（虽然在 &amp;ldquo;YOLO 模式&amp;rdquo; 下误删文件的事故屡见不鲜）；对于部署在云端的 Agent 服务，这两者存在着信任边界的差异，用户不希望为 Agent 的每一次执行 点击“批准”，&lt;strong&gt;只要 Agent 在sandbox内折腾，它就是安全的&lt;/strong&gt;；&lt;/p&gt;</description>
    </item>
    <item>
      <title>如何构建可靠的 Agent 评估体系：读 Anthropic 技术博客有感</title>
      <link>https://niraya666.github.io/posts/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E5%8F%AF%E9%9D%A0%E7%9A%84-ai-agent-%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB-%E8%AF%BB-anthropic-%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E6%9C%89%E6%84%9F/</link>
      <pubDate>Mon, 19 Jan 2026 21:08:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E5%8F%AF%E9%9D%A0%E7%9A%84-ai-agent-%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB-%E8%AF%BB-anthropic-%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2%E6%9C%89%E6%84%9F/</guid>
      <description>&lt;p&gt;读完 Anthropic 的一篇博客&lt;a href=&#34;https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents&#34;&gt; &lt;em&gt;Demystifying evals for AI agents&lt;/em&gt;&lt;/a&gt;，深有感触。&lt;/p&gt;
&lt;p&gt;结合文章内容和最近的工程实践，整理了一些关于构建 Agent 评估体系的笔记，和一些思考。&lt;/p&gt;
&lt;h2 id=&#34;为什么需要-evals&#34;&gt;为什么需要 Evals？&lt;/h2&gt;
&lt;p&gt;Evals 的本质不是为了打分，而是为了让开发可量化。&lt;/p&gt;
&lt;p&gt;在缺乏评估体系时，开发团队往往面临着极大的不确定性：无论是优化 Prompt 还是更换基座模型，都难以判断这些变更是真正解决了问题，还是在引入新问题的同时破坏了原有的能力。&lt;/p&gt;
&lt;p&gt;在早期的 Demo 阶段，依赖人工测试或许能快速验证想法。然而，Agent 系统不同于单次交互的对话模型，它包含多步骤推理和动态工具调用。随着系统复杂度的增加，手动测试的覆盖率和回归效率将难以为继，团队很容易陷入“由于缺乏前置检测，只能依赖线上反馈被动修复 Bug”的恶性循环。&lt;/p&gt;
&lt;p&gt;此外，Evals 也是产品与研发之间的通用语言。将模糊的主观感受，转化为准确率、响应延迟和 Token 成本等可度量的工程指标。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fbd42e7b2f3e9bb5218142796d3ede4816588dec0-4584x2834.png&amp;amp;w=3840&amp;amp;q=75&#34; alt=&#34;&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;目前的评估方式，依旧还是三大件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;人工评估&lt;/strong&gt;：最准确但最贵。通常用来作为Golden，用于校准自动评估的准确性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;代码基准 (Code-based)&lt;/strong&gt;：适用于有明确唯一答案的场景（如数学计算、代码运行）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LLM-as-a-judge&lt;/strong&gt;：目前的主流。用更强的模型去评估其他模型的输出。&lt;strong&gt;关键点&lt;/strong&gt;：需要经过人类专家的校准。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;（注：关于评估的具体细节与最佳实践，推荐参考 Hugging Face  的 &lt;strong&gt;&lt;a href=&#34;https://huggingface.co/spaces/OpenEvals/evaluation-guidebook#the-model-builder-perspective-am-i-building-a-strong-model&#34;&gt;The LLM Evaluation Guidebook&lt;/a&gt;&lt;/strong&gt; ）&lt;/p&gt;
&lt;h2 id=&#34;agent-eval-和llm-eval-的不同&#34;&gt;Agent Eval 和LLM Eval 的不同&lt;/h2&gt;
&lt;p&gt;相比于单纯的 RAG 或 LLM 评估，Agent 的评估复杂度要高得多。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从“测模型”到“测系统”&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;正如&lt;a href=&#34;https://epoch.ai/gradient-updates/why-benchmarking-is-hard&#34;&gt;Why benchmarking is hard&lt;/a&gt;，中提到的“许多变动的部件和自由度都会影响最终结果”。在 Agent 开发中，&lt;/p&gt;
&lt;p&gt;我们测试的永远不是“裸模型”，而是 &lt;strong&gt;“模型 + Harness”&lt;/strong&gt; 这个整体。&lt;/p&gt;
&lt;p&gt;这里的Harness 分成两大部分：Eval Harness（我们的评估系统本身）+ Agent Harness (Scaffold)。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tongyi Deep Research 论文笔记</title>
      <link>https://niraya666.github.io/posts/tongyi-deep-research-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Mon, 24 Nov 2025 20:08:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/tongyi-deep-research-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;p&gt;看着&lt;a href=&#34;https://www.modelscope.cn/studios/jialongwu/Tongyi-DeepResearch&#34;&gt;Tongyi Deep Research&lt;/a&gt; （TDR）用着30B的参数量能够跑出媲美闭源模型的效果，总是好奇究竟怎么做到的?&lt;/p&gt;
&lt;p&gt;最近一个多月断断续续，总算读完了了Tongyi Deep Research 的一系列论文，虽说越往后，官方透露的技术细节越少，但细读下来，依然能一窥其背后的“门道”。&lt;/p&gt;
&lt;p&gt;最大的感受是，TDR在训练算法上并没有太多黑科技，反倒是&lt;strong&gt;数据的合成、训练环境的设计和大量的工程化设计&lt;/strong&gt;，或许才是其成功的关键，以及重点。&lt;/p&gt;
&lt;p&gt;大概从以下3个角度出发，整理了下TDR系列论文中的最佳实践和创新点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Agent的训练方式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;训练所使用的数据合成管道和方法论&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;工程化优化和设计&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;训练方式&#34;&gt;训练方式&lt;/h2&gt;
&lt;p&gt;通过LLM+工程化实现agent，还是直接将agent能力内化至LLM中？TDL选择了后者，并提供了更完整的训练链路：Agentic Mid-training + Agentic post-training。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Agentic Mid-training&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这一概念主要源于&lt;a href=&#34;https://arxiv.org/abs/2509.13310&#34;&gt;AgentFounder&lt;/a&gt;论文，其核心思想是在传统的后训练（Post-training）之前，增加一个&lt;strong&gt;Agentic Continual Pre-training (CPT)&lt;/strong&gt; 阶段。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/Tongyi%20Deep%20Research%20%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0-assets/%e6%88%aa%e5%b1%8f2025-10-24%20%e4%b8%8b%e5%8d%881.32.19.png&#34; alt=&#34;截屏2025-10-24 下午1.32.19.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为什么需要CPT？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;后训练流程面临一个核心困境：要求一个用来预测下一个token的LLM，在后训练阶段同时学习两件截然不同的事：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如何理解和调用工具、如何进行多步规划 （基础的agent能力）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何在特定复杂任务上做出最优决策 （专家能力）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Agentic CPT的目标就是解决这一矛盾，先将一个通用的LLM转变为Agentic Foundation Model，将更强的工具调用和推理能力内化其中。&lt;/p&gt;
&lt;p&gt;相比之下，后一个阶段（agentic post-training）方法基本上成为共识： SFT+RL，并没有太多新的东西。&lt;/p&gt;
&lt;p&gt;在RL的环境构建，采用了双环境的设计， 针对web-agent场景， 一个虚拟环境确实可以节约大量的时间和成本：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;模拟环境：&lt;/strong&gt; 构建一个离线的搜索和查询环境，用于快速验证算法和策略&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;真实世界环境：&lt;/strong&gt; 真实的外部API，用于训练和评估；采用5种工具（Search, Visit, Python Interpreter, Google Scholar, and File Parser）；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;数据合成&#34;&gt;数据合成&lt;/h2&gt;
&lt;p&gt;如何获得&lt;strong&gt;大量高质量的合成数据&lt;/strong&gt;来支撑CPT、SFT和RL？&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/Tongyi%20Deep%20Research%20%e8%ae%ba%e6%96%87%e7%ac%94%e8%ae%b0-assets/image.png&#34; alt=&#34;image.png&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;webwalker--webdancer&#34;&gt;WebWalker &amp;amp; WebDancer&lt;/h3&gt;
&lt;p&gt;这两个工作中对应着几个benchmark和数据集的构建：&lt;strong&gt;WebWalkerQA 和 CRAWL QA&lt;/strong&gt; (模拟浏览) &amp;amp; &lt;strong&gt;E2HQA&lt;/strong&gt;(由易到难)&lt;/p&gt;</description>
    </item>
    <item>
      <title>初探 Mem0</title>
      <link>https://niraya666.github.io/posts/%E5%88%9D%E6%8E%A2mem0/</link>
      <pubDate>Tue, 20 May 2025 18:44:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/%E5%88%9D%E6%8E%A2mem0/</guid>
      <description>&lt;h2 id=&#34;写在开头&#34;&gt;写在开头&lt;/h2&gt;
&lt;p&gt;本文是对于&lt;a href=&#34;https://github.com/mem0ai/mem0&#34;&gt;Mem0&lt;/a&gt;的论文解读和使用记录；&lt;/p&gt;
&lt;p&gt;Mem0 是一款面向LLM应用的memory layer框架，同时是开源的。虽然它最早在 2024 年中旬亮相，起初的框架设计并没有太多亮眼之处，不过在最近，发布了一次比较重大的更新（基本上是重构了）采用了基于 AI-agent 的对话记忆提取、更新和查询等机制，实际体验下来，算是目前为止比较好用的了。&lt;/p&gt;
&lt;h2 id=&#34;paper笔记&#34;&gt;Paper笔记&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2504.19413&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;创新点&#34;&gt;&lt;strong&gt;创新点&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Mem0架构&lt;/strong&gt;：提出了一种可扩展的、以记忆为中心的AI代理架构，能够动态地从对话中抽取、整合和检索关键信息，实现长期、跨会话的记忆&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Mem0g（图记忆扩展）&lt;/strong&gt;：在基础架构上进一步引入“图结构记忆”，用有向标注图（节点为实体，边为关系）来捕捉对话中复杂的实体关系和事件顺序，提升多跳推理和时序推理能力&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mem0实现&#34;&gt;&lt;strong&gt;Mem0实现&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%88%9d%e6%8e%a2Mem0-assets/Pasted%202025-05-20-16-29-02.png&#34; alt=&#34;Pasted 2025-05-20-16-29-02.png&#34;  /&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;extraction phase:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每当有一对新的消息$(m_{t},m_{t−1})$进入系统时，系统会启动记忆抽取流程&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;系统会同时参考两类上下文信息: &lt;strong&gt;全局对话摘要（S）和 最近的消息序列&lt;/strong&gt;${m_{t−m}, &amp;hellip;, m_{t−2}}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;组合成一个完整的提示（prompt）&lt;strong&gt;P&lt;/strong&gt;，输入给LLM实现的抽取函数&lt;strong&gt;ϕ&lt;/strong&gt;。LLM会基于这些信息，抽取出本轮对话中值得记忆的关键信息（$Ω = (ω_1,&amp;hellip;,ω_n )$），作为候选事实，准备加入知识库&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为保障S始终是最新的，使用异步摘要生成模块，定期刷新摘要内容&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;update phase：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;核心任务：检查这些新事实和已有记忆之间的关系和证知识库的内容既不重复，也不矛盾，始终保持一致和精简&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对每一个新抽取的事实（$ω_i$），系统会&lt;strong&gt;检索数据库中与之最相似的s条已有记忆&lt;/strong&gt;（用向量嵌入做语义相似度检索）, 将$ω_i$ 和相似记忆一起交给LLM，由LLM从以下4种工具选择并执行（tool-using）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ADD&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DELETE&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NOOP&lt;/strong&gt; （什么也不做）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体算法&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%88%9d%e6%8e%a2Mem0-assets/%e6%88%aa%e5%b1%8f2025-05-10%20%e4%b8%8b%e5%8d%883.13.17.png&#34; alt=&#34;截屏2025-05-10 下午3.13.17.png&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;mem0g实现&#34;&gt;&lt;strong&gt;Mem0g实现&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%88%9d%e6%8e%a2Mem0-assets/Pasted%202025-05-20-16-31-40.png&#34; alt=&#34;Pasted 2025-05-20-16-31-40.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;以图$G = ( V , E , L )$ 建模记忆，(实体、关系、和语义label)&lt;/p&gt;
&lt;p&gt;每个entity（node）包含三部分信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;entity type classification：用于标记这个实体属于哪一类&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;embedding vector：实体语义含义的向量表示，便于后续做语义相似度检索和推理&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;metadata： 主要包括创建时间戳（creation timestamp），用于记录这个实体被加入知识图谱的时间，有助于时序推理&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;relationships 用triplet的表示：&lt;/p&gt;</description>
    </item>
    <item>
      <title>LangMem: 一些学习笔记</title>
      <link>https://niraya666.github.io/posts/langmem-%E4%B8%80%E4%BA%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 10 Apr 2025 10:44:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/langmem-%E4%B8%80%E4%BA%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>&lt;p&gt;本文是我在阅读 LangMem 的源码与相关文档过程中整理的一些学习笔记。&lt;/p&gt;
&lt;p&gt;一直以来，我对智能体（Agent）的记忆机制充满好奇：理想的 memory 应该具备怎样的结构？又该如何设计？目前市面上关于 memory 的实现大多中规中矩，尚未看到令人眼前一亮的方案。为此，我决定多参考一些开源项目，以期获得新的灵感。&lt;/p&gt;
&lt;p&gt;总体来看，LangMem 作为 LangChain 推出的一款 memory 框架，设计上较为常规，虽有部分值得借鉴之处，但亮点不多，不建议投入过多时间深入研究。同时，与 LangChain 的其他项目类似，其代码结构和文档编写较为混乱，阅读体验不佳。&lt;/p&gt;
&lt;h2 id=&#34;core-concepts&#34;&gt;Core-Concepts&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://langchain-ai.github.io/langmem/concepts/conceptual_guide/&#34;&gt;core-concepts &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在LangMem所设计的memory体系中， 定义了几种不同的&lt;strong&gt;Typical Storage Pattern&lt;/strong&gt;：&lt;strong&gt;Collection 、 Profiles和Procedural&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;collection&#34;&gt;Collection&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Collection&lt;/strong&gt; 主要用于存储&lt;strong&gt;不受限制的知识&lt;/strong&gt;，适用于需要长期积累和检索的信息。每条记忆被存储为&lt;strong&gt;独立的文档或记录&lt;/strong&gt;，可以在需要时进行搜索和回忆；&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/LangMem!%20%e4%b8%80%e4%ba%9b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0-assets/Pasted%202025-03-25-14-52-31.png&#34; alt=&#34;Pasted 2025-03-25-14-52-31.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：记录用户的长期知识，例如用户的兴趣、职业背景、技能等&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更新方式&lt;/strong&gt;：需要&lt;strong&gt;合并新信息&lt;/strong&gt;，避免重复或冲突&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;检索方式&lt;/strong&gt;：通过&lt;strong&gt;语义搜索&lt;/strong&gt;或&lt;strong&gt;关键词匹配&lt;/strong&gt;来查找，结合&lt;strong&gt;记忆的重要性&lt;/strong&gt;和&lt;strong&gt;使用频率&lt;/strong&gt;来优化检索结果&lt;/p&gt;
&lt;h3 id=&#34;profiles&#34;&gt;&lt;strong&gt;Profiles&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;存储&lt;strong&gt;结构化的用户信息&lt;/strong&gt;，例如用户的姓名、语言偏好、沟通风格等。与 Collection 不同，Profile 只存储&lt;strong&gt;最新的状态&lt;/strong&gt;，而不是累积所有历史信息。Profile 作为&lt;strong&gt;单一文档&lt;/strong&gt;存储，每次更新时都会&lt;strong&gt;覆盖旧数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/LangMem!%20%e4%b8%80%e4%ba%9b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0-assets/Pasted%202025-03-25-14-52-31%201.png&#34; alt=&#34;Pasted 2025-03-25-14-52-31 1.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：适用于需要&lt;strong&gt;快速访问当前状态&lt;/strong&gt;的应用，例如个性化推荐、用户设置；适用于&lt;strong&gt;需要严格定义数据结构&lt;/strong&gt;的场景，例如用户档案、系统配置；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更新方式：不会创建新记录&lt;/strong&gt;，而是直接&lt;strong&gt;更新现有的 Profile；&lt;strong&gt;适用于&lt;/strong&gt;只关心最新状态&lt;/strong&gt;的应用，而不是历史；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;检索方式&lt;/strong&gt;：直接查找用户的 Profile&lt;/p&gt;
&lt;h3 id=&#34;procedural-memory&#34;&gt;&lt;strong&gt;Procedural Memory&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;类似于人类的工作记忆，用于存储如何执行任务的知识，主要体现在&lt;strong&gt;system prompts 和行为优化&lt;/strong&gt;上&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/LangMem!%20%e4%b8%80%e4%ba%9b%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0-assets/Pasted%202025-03-25-14-52-31%202.png&#34; alt=&#34;Pasted 2025-03-25-14-52-31 2.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：需要长期优化 Agent行为和交互方式，少走弯路&lt;/p&gt;
&lt;p&gt;总结&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;Memory Type&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;用途&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;智能体示例&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;典型存储模式&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Semantic&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Facts &amp;amp; Knowledge&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;User preferences; knowledge triplets&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Profile或Collection&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Episodic&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Past Experiences&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Few-shot examples; 过往对话摘要&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Collection&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Procedural&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;System Behavior&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Core personality and response patterns&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;Prompt rules或Collection&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;writing-memories&#34;&gt;Writing memories&lt;/h2&gt;
&lt;p&gt;提供了两种写入memory的方法：&lt;strong&gt;及时写入&lt;/strong&gt;（适用于要求即时记忆反映的场景）和一段时间后的&lt;strong&gt;异步写入&lt;/strong&gt;（适用于高效处理和存储大量信息的场景）&lt;/p&gt;</description>
    </item>
    <item>
      <title>Agent 学习笔记：框架 ｜ openAI Swarm</title>
      <link>https://niraya666.github.io/posts/agent-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%A1%86%E6%9E%B6--openai-swarm/</link>
      <pubDate>Mon, 11 Nov 2024 11:10:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/agent-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%A1%86%E6%9E%B6--openai-swarm/</guid>
      <description>&lt;h2 id=&#34;开篇&#34;&gt;开篇&lt;/h2&gt;
&lt;p&gt;“CloseAI” 终于又开源了新的项目，可惜OpenAI明确表示，Swarm是一个实验性框架，主要用于教育目的，不适合生产环境，也没有官方支持。不过从这样一个实验性的框架，至少能够了解到OpenAI对于Agent上的一些理解，对于Agent设计上能够有所帮助和借鉴。&lt;/p&gt;
&lt;h2 id=&#34;routines-and-handoffs&#34;&gt;Routines and Handoffs&lt;/h2&gt;
&lt;p&gt;根据&lt;a href=&#34;https://cookbook.openai.com/examples/orchestrating_agents&#34;&gt;openAI cookbook: &lt;strong&gt;Orchestrating Agents: Routines and Handoffs&lt;/strong&gt;&lt;/a&gt;**，**理解这个框架前首先需要理解的两个概念： &lt;strong&gt;Routines&lt;/strong&gt; 和 &lt;strong&gt;Handoffs&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The notion of a &amp;ldquo;routine&amp;rdquo; is not strictly defined, and instead meant to capture the idea of a set of steps. Concretely, let&amp;rsquo;s define a routine to be a list of instructions in natural language (which we&amp;rsquo;ll represent with a system prompt), along with the tools necessary to complete them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Routines（常规）&lt;/strong&gt;：是由一系列步骤构成的流程，可以理解为给定任务的执行步骤，包括对话系统中指令和所需工具的组合。从代码实现上，基本上就是围绕着openAI 的 &lt;code&gt;openai.chat.completions.create&lt;/code&gt;API的一系列内容， 对话、工具调用等。换句话说，routines只是具有对话+工具调用的chatbot，这也是openAI对于Agent的基础抽象。&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM 输出限制：Structured Outputs、受限编码和提示词工程</title>
      <link>https://niraya666.github.io/posts/llm-%E8%BE%93%E5%87%BA%E9%99%90%E5%88%B6structured-outputs%E5%8F%97%E9%99%90%E7%BC%96%E7%A0%81%E5%92%8C%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/</link>
      <pubDate>Wed, 21 Aug 2024 14:49:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/llm-%E8%BE%93%E5%87%BA%E9%99%90%E5%88%B6structured-outputs%E5%8F%97%E9%99%90%E7%BC%96%E7%A0%81%E5%92%8C%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/</guid>
      <description>&lt;p&gt;在使用大型语言模型（LLM）时，我们常常面临一个挑战：如何从模型输出中准确提取自己所需的信息。例如，当我们希望模型输出 JSON 格式的数据时，由于模型生成的内容并不总是稳定，可能需要额外编写大量的正则表达式来匹配并提取其中的有效信息。然而，由于 LLM 的能力，导致其输出结构并不永远可靠。&lt;/p&gt;
&lt;p&gt;现阶段， 让LLM按要求生成特定格式文本的主要方法有几种种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;微调：使模型的输出遵循特定格式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OpenAI Json-mode/Structured Outputs/function-calling:&lt;/strong&gt; 这些功能允许模型生成更严格、结构化的输出，但受限于openAI平台。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;格式约束&lt;/strong&gt;：在decoding阶段进行约束，限制模型的输出，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prompt Engineering&lt;/strong&gt;： 最简单的办法，但不稳定。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多阶段prompting： 通过多个步骤的提示逐步引导模型生成所需的格式。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文将聚焦在Structured Outputs， 受限编码， 和prompt-engineering的角度，探讨它们在生成特定格式文本中的应用和效果。&lt;/p&gt;
&lt;h2 id=&#34;json-mode&#34;&gt;Json Mode&lt;/h2&gt;
&lt;p&gt;仅特定模型和平台支持&lt;/p&gt;
&lt;p&gt;以openAI 为例， 在&lt;code&gt;openai.chat.completions.create&lt;/code&gt; 参数中增加&lt;code&gt;response_format={&amp;quot;type&amp;quot;:&amp;quot;json_object&amp;quot;}&lt;/code&gt; 即可（具体参见：&lt;a href=&#34;https://platform.openai.com/docs/api-reference/chat/create#chat-create-response_format&#34;&gt;response_format&lt;/a&gt; ）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;需要在prompt中要求输出json格式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不能保证完全按要求的格式结构输出&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但非100%成功率，存在一些需要额外检测和适当处理的edge case。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
  &lt;summary&gt;Handling edge cases&lt;/summary&gt;
  &lt;details&gt;
    &lt;summary&gt;根据OpenAI官方文档提供的处理方案&lt;/summary&gt;
    https://platform.openai.com/docs/guides/structured-outputs/json-mode
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;we_did_not_specify_stop_tokens&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;chat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;completions&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;create&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;gpt-3.5-turbo-0125&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;messages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;You are a helpful assistant designed to output JSON.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Who won the world series in 2020? Please respond in the format {winner: ...}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;response_format&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;json_object&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Check if the conversation was too long for the context window, resulting in incomplete JSON &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finish_reason&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;length&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# your code should handle this error case&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Check if the OpenAI safety system refused the request and generated a refusal instead&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;refusal&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# your code should handle this error case&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# In this case, the .content field will contain the explanation (if any) that the model generated for why it is refusing&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;refusal&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Check if the model&amp;#39;s output included restricted content, so the generation of JSON was halted and may be partial&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finish_reason&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;content_filter&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# your code should handle this error case&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finish_reason&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;stop&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# In this case the model has either successfully finished generating the JSON object according to your schema, or the model generated one of the tokens you provided as a &amp;#34;stop token&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;we_did_not_specify_stop_tokens&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;c1&#34;&gt;# If you didn&amp;#39;t specify any stop tokens, then the generation is complete and the content key will contain the serialized JSON object&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;c1&#34;&gt;# This is guaranteed to parse successfully and should now contain  &amp;#34;{&amp;#34;winner&amp;#34;: &amp;#34;Los Angeles Dodgers&amp;#34;}&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;response&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choices&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;message&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;c1&#34;&gt;# Check if the response.choices[0].message.content ends with one of your stop tokens and handle appropriately&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                  &lt;span class=&#34;k&#34;&gt;pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;c1&#34;&gt;# Your code should handle errors here, for example a network error calling the API&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;使用pydantic的方案&lt;/summary&gt;
    使用pydantic的方案
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pydantic&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;BaseModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;EmailStr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ValidationError&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# 定义你期望的 JSON 数据模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;UserModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BaseModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;str&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;age&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;email&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;EmailStr&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# 检查 JSON 是否符合模型的函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;validate_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# 将输入的 JSON 字符串转换为 UserModel 实例&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;UserModel&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;parse_raw&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;c1&#34;&gt;# 如果验证通过，返回字典&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ValidationError&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;JSON validation error: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ve&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;c1&#34;&gt;# 示例用法&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;{&amp;#34;name&amp;#34;: &amp;#34;John Doe&amp;#34;, &amp;#34;email&amp;#34;: &amp;#34;john.doe@example.com&amp;#34;}&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;validated_json&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;validate_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;json_str&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;validated_json&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;JSON is valid and conforms to the schema:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;validated_json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;JSON is invalid.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/details&gt;
&lt;/details&gt;
&lt;p&gt;Json-Mode 更多是对于输出json的格式进行检查(即Json格式的有效性)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Agent学习笔记： 如何验证模型的tool-using能力</title>
      <link>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/</link>
      <pubDate>Tue, 25 Jun 2024 17:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/</guid>
      <description>&lt;p&gt;本文将简单介绍如何评价LLM的tool-using 能力。&lt;/p&gt;
&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;p&gt;在工具使用评估方面，过去的研究主要有以下几种思路：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对比工具使用和纯LLM在基准测试上的分数&lt;/strong&gt;：例如&lt;a href=&#34;https://arxiv.org/abs/2302.04761&#34;&gt;Toolformer&lt;/a&gt;和&lt;a href=&#34;https://arxiv.org/abs/2305.17126&#34;&gt;LATM&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在Toolformer研究中，通过下游任务如语言模型评估基准测试、数学推理任务和问答任务来验证工具使用的有效性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LATM则采用了来自BigBench的六个数据集进行评估。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;测试工具使用的准确率和响应质量&lt;/strong&gt;：例如&lt;a href=&#34;https://arxiv.org/abs/2304.08244&#34;&gt;API-Bank&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在评估过程中，首先初始化评估系统，确保每个API的数据库包含默认值。然后，将预测的API调用与手动标注的API调用进行比较，以确定它们的一致性。响应评估则使用ROUGE-L指标。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;利用LLM对工具使用的效果进行评价&lt;/strong&gt;：例如Tool-bench。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;two evaluation metrics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pass Rate&lt;/strong&gt;: Calculates the proportion of successfully completing an instruction within limited OpenAI API calls.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Preference&lt;/strong&gt;: Measured by comparing two answers (action sequences) for a given instruction.We pre-define a set of criteria for a better answer, which are organized as prompts for ChatGPT.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;构造虚拟运行环境，测试代理与环境的交互结果&lt;/strong&gt;：例如ToolAlpaca。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用LLM模拟环境（用户代理和助手代理），并使用GPT-4对ToolAlpaca模型进行机器评估，评估其使用各种未见工具的能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于绝大多数企业和垂直场景下， 其中思路1需要构建额外的测试集成本比较高（但还是有必要的）， 而思路4构造虚拟运行环境实际上并不现实； 所以还是选择思路2，外加通过思路3辅助判断；换句话说， 根据场景，构造工具列表和工具调用的ground-truth（包括函数名， 和传入参数）  ，在存在歧义时，采用ROUGE评价响应质量， 或者使用LLM判断响应结果并评价。&lt;/p&gt;
&lt;p&gt;顺带提一下Langchain 项目中有关Agent的tool-using能力测试的内容， 不过由于Langchain项目又臭又长，且有很大的局限性， 这里只讨论其思路。&lt;/p&gt;</description>
    </item>
    <item>
      <title>基于大语言模型的 Agent：科普向</title>
      <link>https://niraya666.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84-agent%E7%A7%91%E6%99%AE%E5%90%91/</link>
      <pubDate>Mon, 13 May 2024 16:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84-agent%E7%A7%91%E6%99%AE%E5%90%91/</guid>
      <description>&lt;h2 id=&#34;写在开头&#34;&gt;写在开头&lt;/h2&gt;
&lt;p&gt;本文是基于最近组内技术交流的文字稿整理。&lt;/p&gt;
&lt;h2 id=&#34;what-is-agent&#34;&gt;What is Agent？&lt;/h2&gt;
&lt;p&gt;在探讨复杂的人工智能技术之前，让我们先回顾一下生活中的一个简单例子：扫地机器人。这种智能设备在房间中自主导航，避开障碍物，寻找最有效的清洁路径。它就是一个现实生活中的Agent——一个可以自主决策和行动的实体。&lt;/p&gt;
&lt;p&gt;在人工智能领域，Agent指的是任何可以感知其环境并根据感知结果做出决策的实体。这些决策旨在完成某些任务或达成特定的目标。Agent的行为可以简单如游戏里的机器人，也可以复杂如自动驾驶汽车。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/Pasted%202024-05-10-14-58-28.webp&#34; alt=&#34;Pasted 2024-05-10-14-58-28.webp&#34;  /&gt;
&lt;/p&gt;
&lt;h3 id=&#34;开始于强化学习&#34;&gt;开始于强化学习&lt;/h3&gt;
&lt;p&gt;在强化学习中， 我们往往能见到agent的概念。强化学习是一种机器学习方法，它教导Agent通过试错法找到最佳行动路径。就像训练小狗一样，我们通过奖励来引导Agent做出正确的决策。Agent的目标是在与环境的交互中寻找最优策略。理想情况下，如果Agent能够获取足够多的真实环境数据，它就能找到最佳解决方案。然而，由于真实环境的复杂性，完全模拟真实世界是不现实的。&lt;/p&gt;
&lt;p&gt;目前，强化学习主要适用于环境简单、问题定义明确的场景，如围棋或视频游戏。这种方法在虚拟环境中通过大量试错来探索解决方案，这种方法虽然有效，但缺乏灵活性和高效性。与人类学习新技能的方式相比，强化学习的效率远低。人们通常通过少量的尝试就能迅速掌握新技能，而强化学习可能需要成千上万次的试错。&lt;/p&gt;
&lt;p&gt;这时候，如果agent具有大脑就好了。&lt;/p&gt;
&lt;h3 id=&#34;将llms作为大脑-赋能智能agent的关键技术&#34;&gt;将LLMs作为大脑: &lt;strong&gt;赋能智能Agent的关键技术&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;相较于基于强化学习的Agent，人类的优势在于我们天生具备的记忆能力和逻辑判断能力，甚至包括反思和从经验中学习的能力。这些能力使得我们能够通过极少的试错迅速适应和掌握新技能。&lt;/p&gt;
&lt;p&gt;语言模型（LLMs）为AI领域带来了革命性的变化。LLMs通过其深度学习的新范式，以及在思维链和自然语言理解方面的强大能力，预示着Agent将拥有更强大的学习和迁移能力。这种能力的提升将使得创建广泛应用且实用的Agent成为可能。&lt;/p&gt;
&lt;p&gt;虽然LLM是否真正具备了推理能力仍然存疑，但LLM的出现无疑改变了很多。以COT（Chain of Thought）为例，这种模型通过打印解题的中间步骤，加强了在数学和逻辑推理方面的能力，减少了幻觉的出现。这一突破性的工作揭示了LLM在不同场景下的强大&amp;quot;in-context learning&amp;quot;能力，以及其在未经微调的情况下的泛化能力。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png&#34; alt=&#34;截屏2024-05-08 15.37.21.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;将LLM视为AI Agent的大脑，为自动化系统提供了一种全新的构思方式。这种基于LLM的agent系统综合了规划、记忆、工具使用和行动的能力，通过API调用与外部世界互动，显示出了前所未有的灵活性和效率。&lt;/p&gt;
&lt;p&gt;根据&lt;a href=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/&#34;&gt;LLM Powered Autonomous Agents&lt;/a&gt;一文对LLM-based agent系统的定义， agent需要具备的基本能力：规划+记忆+工具+行动。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规划能力&lt;/strong&gt;：将复杂的任务分解成小任务， 并管理每一个子任务的目标， 并从过去的失败中反思，以吸取经验。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;记忆&lt;/strong&gt;：LLM的上下文长度有限， 通过额外的记忆系统以提升LLM作为大脑的能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;工具调用&amp;amp;行动&lt;/strong&gt;：LLM通过API调用的方式，执行任务， 与外界交互，而不是只是输出文字。&lt;/p&gt;
&lt;h3 id=&#34;探索ai代理的独特能力人类与单一llm无法比拟&#34;&gt;&lt;strong&gt;探索AI代理的独特能力：人类与单一LLM无法比拟&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;AI系统的主要优势在于它们的规模和效率。这些系统能够执行以下任务，超越人类能力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;大规模数据处理&lt;/strong&gt;：AI能够高效地分析和处理超出人类理解范围的数据量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;无需休息的持续操作&lt;/strong&gt;：AI系统可以不间断地运行，而无需像人类那样休息和恢复。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;超快速计算&lt;/strong&gt;：AI可以迅速执行复杂的计算，处理速度和效率远超人类。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;AI代理与单一LLM的不同:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;根据Andrew Ng在讲座中分享的内容，使用相对“简单”模型的代理工作流程（例如GPT-3.5）在实际应用中往往能够超越使用“智能”模型（如GPT-4）的零次提示。这说明在特定场景下，选择适当的AI模型和策略可能比单一的高级模型更有效。&lt;/p&gt;
&lt;p&gt;AI代理在决策制定中的应用也显示出其独特的优势。它们可以在没有情感偏见的情况下，基于大量数据做出快速且精确的决策。这种能力在需要快速响应和高精确度的领域尤为重要，如金融交易和紧急响应系统。&lt;/p&gt;
&lt;h2 id=&#34;agent的规划和思维过程&#34;&gt;&lt;strong&gt;Agent的规划和思维过程&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI Agent在处理复杂任务时，通过将大任务分解成小任务来提高效率。此外，自我反思能力允许Agent从过去的行动中学习，通过评估过去的决策来改善未来的表现。&lt;/p&gt;
&lt;p&gt;CoT，Chain of Thought， &lt;a href=&#34;https://arxiv.org/abs/2201.11903&#34;&gt;Wei et al. 2022&lt;/a&gt;。 即“思维链”，是一种使Agent逐步思考的方法。它通过要求模型展示解决问题的中间步骤来加强其逻辑推理能力，从而提高决策的质量和准确性。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/%e5%9f%ba%e4%ba%8e%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%20Agent%ef%bc%9a%e7%a7%91%e6%99%ae%e5%90%91-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png&#34; alt=&#34;截屏2024-05-08 15.37.21.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tree of Thoughts， ToT&lt;/strong&gt;  (&lt;a href=&#34;https://arxiv.org/abs/2305.10601&#34;&gt;Yao et al. 2023&lt;/a&gt;)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Agent学习笔记：OpenAI Function Calling完全指南</title>
      <link>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0openai-function-calling%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sun, 28 Apr 2024 15:00:00 +0800</pubDate>
      <guid>https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0openai-function-calling%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97/</guid>
      <description>&lt;h2 id=&#34;写在最开始&#34;&gt;写在最开始&lt;/h2&gt;
&lt;p&gt;当我们在讨论基于大型语言模型（LLM-based）的智能代理（agent）时，我们究竟在谈论什么？根据Lilian W在其文章《LLM Powered Autonomous Agents》中的讨论，一个智能代理需要具备几个核心能力：规划（Planning）、记忆（Memory）、以及工具使用（Tool use）。特别地，工具使用方面的进展，得益于OpenAI在API中提供的function calling功能，为我们开启了新的可能性。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/agent-overview.png&#34; alt=&#34;AGI&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;OpenAI function calling，作为智能代理与外部工具交互的基本方式，对于每位从业者来说都是必备技能。随着技术的发展，我们期望的不只是能与我们对话的LLM，而是能够辅助我们使用各种工具、做出决策的智能伙伴。&lt;/p&gt;
&lt;p&gt;不过需要特别指出的是，最近OpenAI在Chat Completions API中已经废弃了“函数（function）”的使用，转而采用“工具（tool）”。这一变更旨在拓宽LLM集成的功能范围，为更复杂的交互模式铺平道路，如构建能够相互作用的多代理系统。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.16.54.png&#34; alt=&#34;截屏2024-03-28 15.16.54.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://niraya666.github.io/img/Agent%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/tool-using/%e6%88%aa%e5%b1%8f2024-03-28%2015.17.38.png&#34; alt=&#34;截屏2024-03-28 15.17.38.png&#34;  /&gt;
&lt;/p&gt;
&lt;p&gt;尽管如此，由于语言习惯的原因，本文中仍然会使用function calling的术语来描述OpenAI的tool using功能，因为“function calling”的说法已经深入人心了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核心内容概览&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Function Calling的定义&lt;/strong&gt;：解释什么是function calling，以及它在智能代理工作中的作用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OpenAI Cookbook示例&lt;/strong&gt;：提供实际的function calling示例，帮助读者理解其在实际应用中的用途。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;开源LLM的Tool Using&lt;/strong&gt;：探索如何在开源大型语言模型中实现工具使用，以及LLM在tool using的时候经历了什么。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;del&gt;评价与训练&lt;/del&gt;&lt;/strong&gt;&lt;del&gt;：讨论如何评价开源模型的工具使用能力，以及如何训练LLM进行有效的工具使用。&lt;/del&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;鉴于整理笔记的速度远赶不上更新的速度， 会将第四部份作为单独的部分整理。&lt;/p&gt;
&lt;h2 id=&#34;何为function-calling&#34;&gt;何为function calling&lt;/h2&gt;
&lt;p&gt;一句话解释：&lt;strong&gt;function calling从本质上并不是严格的工具调用， 而是作为工具调用的前奏，它通过更加结构化的方式指导LLM输出，为在本地执行具体函数提供了参数，铺平了道路。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;具体来说，function calling允许LLM在执行过程中通过指定的参数来调用并执行一个特定的函数。这种方式不仅实现了代码的重用和模块化处理，而且能够从模型中获取更可靠的结构化数据回应。在API调用过程中，开发者可以描述想要执行的功能，并让模型智能地选择输出包含所需参数的JSON对象。&lt;strong&gt;这个过程中，Chat Completions API本身不直接执行任何函数调用，而是生成了可以在开发者代码中实现函数调用的JSON。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;function calling的应用范围广泛，如&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;创建智能助手：通过调用外部API回答问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;转换指令：将自然语言指令转换成API调用指令。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据提取：从文本中提取结构化数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;function calling的过程涵盖了从定义函数集、通过模型生成遵循自定义模式的JSON对象字符串，到在代码中解析这个字符串并调用相应函数的全过程。这一连串操作不仅自动化了交互过程，还确保了执行操作的安全性和准确性。&lt;/p&gt;
&lt;h2 id=&#34;一些常见的问题&#34;&gt;一些常见的问题&lt;/h2&gt;
&lt;h3 id=&#34;json-mode&#34;&gt;JSON mode&lt;/h3&gt;
&lt;p&gt;json mode 和tool-using 有什么关系？有了json mode 还需要用到tool-using吗？&lt;/p&gt;
&lt;p&gt;从json mode 的本质， 更多的是在system prompt 增加一句类似“请以json格式输出”之类的话，然后在LLM输出时增加json结果检查和格式转换。在使用时只需要在&lt;code&gt;client.chat.completions.create &lt;/code&gt;中 增加&lt;code&gt;response_format={ &amp;quot;type&amp;quot;: &amp;quot;json_object&amp;quot; }&lt;/code&gt; 即可。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
