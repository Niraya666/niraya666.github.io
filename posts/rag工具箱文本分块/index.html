<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>RAG工具箱：文本分块 | LZY Blog</title>
<meta name="keywords" content="RAG, RAG-Toolkits">
<meta name="description" content="为什么要进行文本分块？ 大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。
如何进行文本分块 **块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。
文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：
句子分割（Sentence Splitting） 这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。
text = &#34;...&#34; # 你的文本 from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter( separator = &#34;\n\n&#34;, chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 递归字符文本分割（Recursive Character Text Splitting） 这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。
text = &#34;...&#34; # 你的文本 from langchain.text_splitter import RecursiveCharacterTextSplitter text_splitter = RecursiveCharacterTextSplitter( chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 根据langchain 的默认分隔条件 [&quot;\n\n&quot;, &quot;\n&quot;, &quot; &quot;, &quot;&quot;] ,也就是会将text根据该分割条件的顺序（两个换行-&gt;一个换行-&gt;空格）将文本进行递归分割。
针对特定文档的分割方法（Document Specific Splitting） 例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。">
<meta name="author" content="Theme PaperMod">
<link rel="canonical" href="https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://niraya666.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://niraya666.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://niraya666.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://niraya666.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://niraya666.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  

<meta property="og:title" content="RAG工具箱：文本分块" />
<meta property="og:description" content="为什么要进行文本分块？ 大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。
如何进行文本分块 **块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。
文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：
句子分割（Sentence Splitting） 这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。
text = &#34;...&#34; # 你的文本 from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter( separator = &#34;\n\n&#34;, chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 递归字符文本分割（Recursive Character Text Splitting） 这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。
text = &#34;...&#34; # 你的文本 from langchain.text_splitter import RecursiveCharacterTextSplitter text_splitter = RecursiveCharacterTextSplitter( chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 根据langchain 的默认分隔条件 [&quot;\n\n&quot;, &quot;\n&quot;, &quot; &quot;, &quot;&quot;] ,也就是会将text根据该分割条件的顺序（两个换行-&gt;一个换行-&gt;空格）将文本进行递归分割。
针对特定文档的分割方法（Document Specific Splitting） 例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97/" />
<meta property="og:image" content="https://niraya666.github.io/images/papermod-cover.png" />
<meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-05-15T16:11:00+08:00" />
<meta property="article:modified_time" content="2024-05-15T16:11:00+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://niraya666.github.io/images/papermod-cover.png" />
<meta name="twitter:title" content="RAG工具箱：文本分块"/>
<meta name="twitter:description" content="为什么要进行文本分块？ 大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。
如何进行文本分块 **块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。
文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：
句子分割（Sentence Splitting） 这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。
text = &#34;...&#34; # 你的文本 from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter( separator = &#34;\n\n&#34;, chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 递归字符文本分割（Recursive Character Text Splitting） 这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。
text = &#34;...&#34; # 你的文本 from langchain.text_splitter import RecursiveCharacterTextSplitter text_splitter = RecursiveCharacterTextSplitter( chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 根据langchain 的默认分隔条件 [&quot;\n\n&quot;, &quot;\n&quot;, &quot; &quot;, &quot;&quot;] ,也就是会将text根据该分割条件的顺序（两个换行-&gt;一个换行-&gt;空格）将文本进行递归分割。
针对特定文档的分割方法（Document Specific Splitting） 例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://niraya666.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "RAG工具箱：文本分块",
      "item": "https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "RAG工具箱：文本分块",
  "name": "RAG工具箱：文本分块",
  "description": "为什么要进行文本分块？ 大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。\n如何进行文本分块 **块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。\n文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：\n句子分割（Sentence Splitting） 这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。\ntext = \u0026#34;...\u0026#34; # 你的文本 from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter( separator = \u0026#34;\\n\\n\u0026#34;, chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 递归字符文本分割（Recursive Character Text Splitting） 这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。\ntext = \u0026#34;...\u0026#34; # 你的文本 from langchain.text_splitter import RecursiveCharacterTextSplitter text_splitter = RecursiveCharacterTextSplitter( chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 根据langchain 的默认分隔条件 [\u0026quot;\\n\\n\u0026quot;, \u0026quot;\\n\u0026quot;, \u0026quot; \u0026quot;, \u0026quot;\u0026quot;] ,也就是会将text根据该分割条件的顺序（两个换行-\u0026gt;一个换行-\u0026gt;空格）将文本进行递归分割。\n针对特定文档的分割方法（Document Specific Splitting） 例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。",
  "keywords": [
    "RAG", "RAG-Toolkits"
  ],
  "articleBody": "为什么要进行文本分块？ 大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。\n如何进行文本分块 **块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。\n文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：\n句子分割（Sentence Splitting） 这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。\ntext = \"...\" # 你的文本 from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter( separator = \"\\n\\n\", chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 递归字符文本分割（Recursive Character Text Splitting） 这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。\ntext = \"...\" # 你的文本 from langchain.text_splitter import RecursiveCharacterTextSplitter text_splitter = RecursiveCharacterTextSplitter( chunk_size = 256, chunk_overlap = 20 ) docs = text_splitter.create_documents([text]) 根据langchain 的默认分隔条件 [\"\\n\\n\", \"\\n\", \" \", \"\"] ,也就是会将text根据该分割条件的顺序（两个换行-\u003e一个换行-\u003e空格）将文本进行递归分割。\n针对特定文档的分割方法（Document Specific Splitting） 例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。\nlangchain 提供了一些常见文档的分割方法：\nmardown的分割逻辑\n[ # First, try to split along Markdown headings (starting with level 2) \"\\n#{1,6} \", # Note the alternative syntax for headings (below) is not handled here # Heading level 2 # --------------- # End of code block \"```\\n\", # Horizontal lines \"\\n\\\\*\\\\*\\\\*+\\n\", \"\\n---+\\n\", \"\\n___+\\n\", # Note that this splitter doesn't handle horizontal lines defined # by *three or more* of ***, ---, or ___, but this is not handled \"\\n\\n\", \"\\n\", \" \", \"\", ] python的分割逻辑：\n[ # First, try to split along class definitions \"\\nclass \", \"\\ndef \", \"\\n\\tdef \", # Now split by the normal type of lines \"\\n\\n\", \"\\n\", \" \", \"\", ] 表格 重点提示： 后来在我们对数据块进行语义搜索时，直接从表格中匹配嵌入可能会比较困难。开发者常用的做法是，在提取了表格之后，对其进行关键信息提取。然后对这些关键信息的总结进行嵌入。如果这个总结的嵌入与你的搜索目标匹配，那么就可以把原始表格交给你的大语言模型处理。\n语义分块 目前的文本分块方法大多基于结构或字符数量，忽视了文本的实际语义内容。有效的语义分块应当确保内容上相似的数据被归类在一起，这样不仅有助于数据的组织，还能提升后续处理的效率和准确性。\n根据Greg的做法：寻找连续句子间的分割点， 即从第一句话开始，获取其嵌入，然后与第二句进行比较，以此类推。在寻找嵌入距离较大的“分割点”。如果距离超过了一定阈值，就认为这标志着新的语义段落的开始。\n可以通过以下步骤来进行语义分块：\n文档初始处理：首先将你的文档分割成句子，每个句子通常包含关于一个主题的单一观点。\n句子嵌入：利用语言模型获取每个句子的嵌入表示。\n句子比较与分块：从第一句话开始，逐句比较嵌入的相似度。当相邻句子之间的嵌入距离超过预设的阈值时，标记为新的语义段落的开始。\n聚类相似句子：将语义上接近的句子聚集成块，同时保持句子的原始顺序。\n伪代码示例\narticle = \"你的完整文章\" chunks = [article[:1]] # 默认第一部分为一个独立分块 # 文章逐句审查 for sentence in article[1:]: if is_similar(sentence, chunks[-1][-1]): chunks[-1].append(sentence) # 如果新句子与当前块的最后一个句子相似，则加入当前块 else: chunks.append([sentence]) # 如果不相似，则创建新的分块 # 持续这个过程直至文章末尾 # 在这种方法中，is_similar 函数需要定义为比较句子嵌入之间的距离，并判断它们是否足够接近。 特殊分块以及后处理 不见得一定要在召回后，返回原始的chunks。\nSummary(摘要) 处理和存储大量文档的原始数据块往往不是最高效的方法。通过为每个文档创建摘要并进行嵌入，我们不仅可以减少处理的数据量，还能提高检索的速度和准确性。\nhttps://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector#summary\ncreate a summary for each document, embed that along with (or instead of) the document.\nimport uuid from langchain_core.documents import Document from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import ChatPromptTemplate from langchain_openai import ChatOpenAI chain = ( {\"doc\": lambda x: x.page_content} | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\") | ChatOpenAI(max_retries=0) | StrOutputParser() ) summaries = chain.batch(docs, {\"max_concurrency\": 5}) # The vectorstore to use to index the child chunks vectorstore = Chroma(collection_name=\"summaries\", embedding_function=OpenAIEmbeddings()) # The storage layer for the parent documents store = InMemoryByteStore() id_key = \"doc_id\" # The retriever (empty to start) retriever = MultiVectorRetriever( vectorstore=vectorstore, byte_store=store, id_key=id_key, ) doc_ids = [str(uuid.uuid4()) for _ in docs] summary_docs = [ Document(page_content=s, metadata={id_key: doc_ids[i]}) for i, s in enumerate(summaries) ] retriever.vectorstore.add_documents(summary_docs) retriever.docstore.mset(list(zip(doc_ids, docs))) Hypothetical questions HyDE\nhypothetical_document_embeddings\nHyDE (Hypothetical Document Embeddings)\nHyDE（Hypothetical Document Embeddings，假设性文档嵌入），通过生成假设性的答案并对这些生成的文档进行嵌入，而非嵌入原始文本。这种方法特别适用于用户问题简短且与需要查找的原始文本在语义上相似度不高的情况。\n当用户的问题与知识库中的原始文本在语义上相差较大时，传统的文档检索方法可能无法有效地匹配到相关内容。HyDE通过使用大型语言模型（LLMs）根据用户问题生成格式上类似于知识库中文本的假设性答案，从而提升匹配的准确率。\n尽管HyDE可以提升检索的准确性，但这种方法也会一定程度上增加检索的耗时。为了平衡检索准确率和响应速度，可以考虑使用更强大的重排模型（reranking models）。这些模型能够在检索后的阶段进一步优化结果，通过精准地评估和排序生成的假设性答案，以提供最相关的回答。\nParent Document Retriever (PDR) from Advanced RAG Techniques: an Illustrated Overview\nA.K.A Multi-size-chunks(Parent Document Retriever/ parent-child chunks retriever/ Auto Merging Retriever)\n核心思想是，尽管小片段的数据更容易在语义上与短小的用户查询匹配，但这些小片段往往缺乏提供全面回答所需的足够上下文。PDR的解决方案是在检索时优先获取这些小片段，然后识别并返回包含这些小片段的更大父文档，以此为基础进行问题的回答。\n在使用embedding模型召回时，尽可能的将对应文本拆成句子级别，因为往往人的问题都是比较短的句子，这样在语义匹配上能够较好的匹配上；但是在使用LLM做回答时，由需要足够的上下文让模型能够有足够多的背景进行回答；因此在召回的时候倾向于使用small-chunks用于匹配，再通过某些聚合方式合并成一个具备相对完整上下文的较大chunks用作模型回答之背景；\n在Langchain中提供了Parent Document Retriever这一方法。\nDuring retrieval, it first fetches the small chunks but then looks up the parent ids for those chunks and returns those larger documents.\n使用方法：\nfrom langchain.retrievers import ParentDocumentRetriever from langchain.storage import InMemoryStore from langchain.text_splitter import RecursiveCharacterTextSplitter # Retrieving larger chunks # This text splitter is used to create the parent documents parent_splitter = RecursiveCharacterTextSplitter(separators=\"\\n\",chunk_size=2000) # This text splitter is used to create the child documents # It should create documents smaller than the parent child_splitter = RecursiveCharacterTextSplitter(separators=\"\\n\",chunk_size=400) # define your docs = embeddings, and vectorstore # docs = loader.load(...) # emebeddings = OpenAIEmbeddings(...) # vectorstore = Chroma(...) # The storage layer for the parent documents store = InMemoryStore() retriever = ParentDocumentRetriever( vectorstore=vectorstore, docstore=store, child_splitter=child_splitter, parent_splitter=parent_splitter, ) retriever.add_documents(docs) 而在llama_index中也提供了类似的方法。\n# 创建较小的子块 from llama_index.schema import IndexNode sub_chunk_sizes = [256, 512, 864] sub_node_parsers = [ SimpleNodeParser.from_defaults(chunk_size=c) for c in sub_chunk_sizes ] all_nodes = [] for base_node in base_nodes: for n in sub_node_parsers: sub_nodes = n.get_nodes_from_documents([base_node]) sub_inodes = [IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes] all_nodes.extend(sub_inodes) original_node = IndexNode.from_text_node(base_node, base_node.node_id) all_nodes.append(original_node) all_nodes_dict = {n.node_id: n for n in all_nodes} # 创建索引、检索器和查询引擎 vector_index_chunk = VectorStoreIndex( all_nodes, service_context=service_context ) vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2) retriever_chunk = RecursiveRetriever( \"vector\", retriever_dict={\"vector\": vector_retriever_chunk}, node_dict=all_nodes_dict, verbose=True, ) query_engine_chunk = RetrieverQueryEngine.from_args( retriever_chunk, service_context=service_context ) response = query_engine_chunk.query( \"Can you tell me about the key concepts for safety finetuning\" ) print(str(response)) Sentence Window Retrieval 为了更好地分析找到的语境，我们在检索到的最相关单句之前后各扩展 k 个句子，然后把这个扩展后的语境送给 LLM 进行推理\nfrom Advanced RAG Techniques: an Illustrated Overview\n分块可视化小工具 推荐一个可视化chunk-spliting 工具chunkviz\n推荐阅读 Text splitting (chunking) for RAG applications\n5_Levels_Of_Text_Splitting\nlangchain:Semantic Chunking\nChunking Strategies for LLM Applications\nAdvanced RAG Techniques: an Illustrated Overview\nRAG系列05：基于语义的Chunk分割\n",
  "wordCount" : "643",
  "inLanguage": "en",
  "image": "https://niraya666.github.io/images/papermod-cover.png","datePublished": "2024-05-15T16:11:00+08:00",
  "dateModified": "2024-05-15T16:11:00+08:00",
  "author":{
    "@type": "Person",
    "name": "Theme PaperMod"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "LZY Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://niraya666.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://niraya666.github.io/" accesskey="h" title="LZY Blog (Alt + H)">LZY Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://niraya666.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/musik/" title="musik!">
                    <span>musik!</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/monthly/" title="月刊">
                    <span>月刊</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/essay/" title="杂文">
                    <span>杂文</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/travel/" title="游记">
                    <span>游记</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://niraya666.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://niraya666.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      RAG工具箱：文本分块
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2024-05-15 16:11:00 +0800 CST'>May 15, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Theme PaperMod

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e8%bf%9b%e8%a1%8c%e6%96%87%e6%9c%ac%e5%88%86%e5%9d%97" aria-label="为什么要进行文本分块？">为什么要进行文本分块？</a></li>
                <li>
                    <a href="#%e5%a6%82%e4%bd%95%e8%bf%9b%e8%a1%8c%e6%96%87%e6%9c%ac%e5%88%86%e5%9d%97" aria-label="如何进行文本分块">如何进行文本分块</a><ul>
                        
                <li>
                    <a href="#%e5%8f%a5%e5%ad%90%e5%88%86%e5%89%b2sentence-splitting" aria-label="句子分割（Sentence Splitting）">句子分割（Sentence Splitting）</a></li>
                <li>
                    <a href="#%e9%80%92%e5%bd%92%e5%ad%97%e7%ac%a6%e6%96%87%e6%9c%ac%e5%88%86%e5%89%b2recursive-character-text-splitting" aria-label="递归字符文本分割（Recursive Character Text Splitting）">递归字符文本分割（Recursive Character Text Splitting）</a></li>
                <li>
                    <a href="#%e9%92%88%e5%af%b9%e7%89%b9%e5%ae%9a%e6%96%87%e6%a1%a3%e7%9a%84%e5%88%86%e5%89%b2%e6%96%b9%e6%b3%95document-specific-splitting" aria-label="针对特定文档的分割方法（Document Specific Splitting）">针对特定文档的分割方法（Document Specific Splitting）</a></li>
                <li>
                    <a href="#%e8%a1%a8%e6%a0%bc" aria-label="表格">表格</a></li>
                <li>
                    <a href="#%e8%af%ad%e4%b9%89%e5%88%86%e5%9d%97" aria-label="语义分块">语义分块</a></li></ul>
                </li>
                <li>
                    <a href="#%e7%89%b9%e6%ae%8a%e5%88%86%e5%9d%97%e4%bb%a5%e5%8f%8a%e5%90%8e%e5%a4%84%e7%90%86" aria-label="特殊分块以及后处理">特殊分块以及后处理</a><ul>
                        
                <li>
                    <a href="#summary%e6%91%98%e8%a6%81" aria-label="Summary(摘要)">Summary(摘要)</a></li>
                <li>
                    <a href="#hypothetical-questions" aria-label="Hypothetical questions">Hypothetical questions</a></li>
                <li>
                    <a href="#parent-document-retriever-pdr" aria-label="Parent Document Retriever (PDR)">Parent Document Retriever (PDR)</a></li>
                <li>
                    <a href="#sentence-window-retrieval" aria-label="Sentence Window Retrieval">Sentence Window Retrieval</a></li>
                <li>
                    <a href="#%e5%88%86%e5%9d%97%e5%8f%af%e8%a7%86%e5%8c%96%e5%b0%8f%e5%b7%a5%e5%85%b7" aria-label="分块可视化小工具">分块可视化小工具</a></li></ul>
                </li>
                <li>
                    <a href="#%e6%8e%a8%e8%8d%90%e9%98%85%e8%af%bb" aria-label="推荐阅读">推荐阅读</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="为什么要进行文本分块"><strong>为什么要进行文本分块？</strong><a hidden class="anchor" aria-hidden="true" href="#为什么要进行文本分块">#</a></h2>
<p>大型语言模型（LLM）和嵌入式模型都有其处理文本的长度限制。为了有效处理超出这些限制的长文本，我们需要进行文本分块。</p>
<h2 id="如何进行文本分块"><strong>如何进行文本分块</strong><a hidden class="anchor" aria-hidden="true" href="#如何进行文本分块">#</a></h2>
<blockquote>
<p>**块分割戒律：**我们的目标不仅仅是为了划分数据块。更重要的是，我们要以一种便于日后检索和提取价值的格式来整理我们的数据。</p>
</blockquote>
<p>文本分块的根本目的不仅仅是简单地将数据分割成块。更重要的是，我们要以便于检索和提取价值的方式来组织这些数据块。以下是几种常见的分块逻辑：</p>
<h3 id="句子分割sentence-splitting"><strong>句子分割（Sentence Splitting）</strong><a hidden class="anchor" aria-hidden="true" href="#句子分割sentence-splitting">#</a></h3>
<p>这种方法只是简单地将文本切分成N个字符的片段，不考虑内容或形式的连贯性。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">text</span> <span class="o">=</span> <span class="s2">&#34;...&#34;</span> <span class="c1"># 你的文本</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
</span></span><span class="line"><span class="cl"><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">separator</span> <span class="o">=</span> <span class="s2">&#34;</span><span class="se">\n\n</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">chunk_overlap</span>  <span class="o">=</span> <span class="mi">20</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
</span></span></code></pre></div><h3 id="递归字符文本分割recursive-character-text-splitting"><strong>递归字符文本分割（Recursive Character Text Splitting）</strong><a hidden class="anchor" aria-hidden="true" href="#递归字符文本分割recursive-character-text-splitting">#</a></h3>
<p>这种方法首先尝试用一个分隔符将文本切分成小块。如果初始尝试未能达到预期的块大小或结构，就递归地用不同的分隔符重新分割结果块，直到得到满意的结果。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">text</span> <span class="o">=</span> <span class="s2">&#34;...&#34;</span> <span class="c1"># 你的文本</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
</span></span><span class="line"><span class="cl"><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">chunk_overlap</span>  <span class="o">=</span> <span class="mi">20</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
</span></span></code></pre></div><p>根据langchain 的<a href="https://github.com/langchain-ai/langchain/blob/9ef2feb6747f5a69d186bd623b569ad722829a5e/libs/langchain/langchain/text_splitter.py#L842">默认分隔条件</a> <code>[&quot;\n\n&quot;, &quot;\n&quot;, &quot; &quot;, &quot;&quot;]</code> ,也就是会将text根据该分割条件的顺序（两个换行-&gt;一个换行-&gt;空格）将文本进行递归分割。</p>
<h3 id="针对特定文档的分割方法document-specific-splitting"><strong>针对特定文档的分割方法（Document Specific Splitting）</strong><a hidden class="anchor" aria-hidden="true" href="#针对特定文档的分割方法document-specific-splitting">#</a></h3>
<p>例如针对Markdown或Python代码的分割策略，这些策略根据文档的结构来进行分割，如类定义或Markdown标题。</p>
<p>langchain 提供了一些常见文档的分割方法：</p>
<p>mardown的分割逻辑</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="p">[</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># First, try to split along Markdown headings (starting with level 2)</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">#{1,6} &#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Note the alternative syntax for headings (below) is not handled here</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Heading level 2</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># ---------------</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># End of code block</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;```</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Horizontal lines</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n\\</span><span class="s2">*</span><span class="se">\\</span><span class="s2">*</span><span class="se">\\</span><span class="s2">*+</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">---+</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">___+</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Note that this splitter doesn&#39;t handle horizontal lines defined</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># by *three or more* of ***, ---, or ___, but this is not handled</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n\n</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34; &#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">]</span>
</span></span></code></pre></div><p>python的分割逻辑：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="p">[</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># First, try to split along class definitions</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">class &#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">def &#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n\t</span><span class="s2">def &#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Now split by the normal type of lines</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n\n</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34; &#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">]</span>
</span></span></code></pre></div><h3 id="表格">表格<a hidden class="anchor" aria-hidden="true" href="#表格">#</a></h3>
<blockquote>
<p>重点提示： 后来在我们对数据块进行语义搜索时，直接从表格中匹配嵌入可能会比较困难。开发者常用的做法是，在提取了表格之后，对其进行关键信息提取。然后对这些关键信息的总结进行嵌入。如果这个总结的嵌入与你的搜索目标匹配，那么就可以把原始表格交给你的大语言模型处理。</p>
</blockquote>
<h3 id="语义分块">语义分块<a hidden class="anchor" aria-hidden="true" href="#语义分块">#</a></h3>
<p>目前的文本分块方法大多基于结构或字符数量，忽视了文本的实际语义内容。有效的语义分块应当确保内容上相似的数据被归类在一起，这样不仅有助于数据的组织，还能提升后续处理的效率和准确性。</p>
<p>根据Greg的做法：寻找连续句子间的分割点， 即从第一句话开始，获取其嵌入，然后与第二句进行比较，以此类推。在寻找嵌入距离较大的“分割点”。如果距离超过了一定阈值，就认为这标志着新的语义段落的开始。</p>
<p><img loading="lazy" src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5fh1X7aMCmdS_VgAbAmy5g.png" alt=""  />
</p>
<p>可以通过以下步骤来进行语义分块：</p>
<ol>
<li>
<p><strong>文档初始处理</strong>：首先将你的文档分割成句子，每个句子通常包含关于一个主题的单一观点。</p>
</li>
<li>
<p><strong>句子嵌入</strong>：利用语言模型获取每个句子的嵌入表示。</p>
</li>
<li>
<p><strong>句子比较与分块</strong>：从第一句话开始，逐句比较嵌入的相似度。当相邻句子之间的嵌入距离超过预设的阈值时，标记为新的语义段落的开始。</p>
</li>
<li>
<p><strong>聚类相似句子</strong>：将语义上接近的句子聚集成块，同时保持句子的原始顺序。</p>
</li>
</ol>
<p><strong>伪代码示例</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">article</span> <span class="o">=</span> <span class="s2">&#34;你的完整文章&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">chunks</span> <span class="o">=</span> <span class="p">[</span><span class="n">article</span><span class="p">[:</span><span class="mi">1</span><span class="p">]]</span>  <span class="c1"># 默认第一部分为一个独立分块</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 文章逐句审查</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">article</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">is_similar</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">chunks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">        <span class="n">chunks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>  <span class="c1"># 如果新句子与当前块的最后一个句子相似，则加入当前块</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">chunks</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">sentence</span><span class="p">])</span>  <span class="c1"># 如果不相似，则创建新的分块</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 持续这个过程直至文章末尾</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 在这种方法中，is_similar 函数需要定义为比较句子嵌入之间的距离，并判断它们是否足够接近。</span>
</span></span></code></pre></div><h2 id="特殊分块以及后处理">特殊分块以及后处理<a hidden class="anchor" aria-hidden="true" href="#特殊分块以及后处理">#</a></h2>
<p>不见得一定要在召回后，返回原始的chunks。</p>
<h3 id="summary摘要">Summary(摘要)<a hidden class="anchor" aria-hidden="true" href="#summary摘要">#</a></h3>
<p>处理和存储大量文档的原始数据块往往不是最高效的方法。通过为每个文档创建摘要并进行嵌入，我们不仅可以减少处理的数据量，还能提高检索的速度和准确性。</p>
<p><a href="https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector#summary">https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector#summary</a></p>
<blockquote>
<p>create a summary for each document, embed that along with (or instead of) the document.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">uuid</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_core.documents</span> <span class="kn">import</span> <span class="n">Document</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_core.output_parsers</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span><span class="s2">&#34;doc&#34;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">page_content</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="o">|</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s2">&#34;Summarize the following document:</span><span class="se">\n\n</span><span class="si">{doc}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">|</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">max_retries</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">summaries</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="p">{</span><span class="s2">&#34;max_concurrency&#34;</span><span class="p">:</span> <span class="mi">5</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># The vectorstore to use to index the child chunks</span>
</span></span><span class="line"><span class="cl"><span class="n">vectorstore</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">(</span><span class="n">collection_name</span><span class="o">=</span><span class="s2">&#34;summaries&#34;</span><span class="p">,</span> <span class="n">embedding_function</span><span class="o">=</span><span class="n">OpenAIEmbeddings</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="c1"># The storage layer for the parent documents</span>
</span></span><span class="line"><span class="cl"><span class="n">store</span> <span class="o">=</span> <span class="n">InMemoryByteStore</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">id_key</span> <span class="o">=</span> <span class="s2">&#34;doc_id&#34;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># The retriever (empty to start)</span>
</span></span><span class="line"><span class="cl"><span class="n">retriever</span> <span class="o">=</span> <span class="n">MultiVectorRetriever</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">vectorstore</span><span class="o">=</span><span class="n">vectorstore</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">byte_store</span><span class="o">=</span><span class="n">store</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">id_key</span><span class="o">=</span><span class="n">id_key</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">doc_ids</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">summary_docs</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="n">id_key</span><span class="p">:</span> <span class="n">doc_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]})</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">summaries</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">retriever</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">summary_docs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">retriever</span><span class="o">.</span><span class="n">docstore</span><span class="o">.</span><span class="n">mset</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">doc_ids</span><span class="p">,</span> <span class="n">docs</span><span class="p">)))</span>
</span></span></code></pre></div><h3 id="hypothetical-questions">Hypothetical questions<a hidden class="anchor" aria-hidden="true" href="#hypothetical-questions">#</a></h3>
<p><a href="http://boston.lti.cs.cmu.edu/luyug/HyDE/HyDE.pdf">HyDE</a></p>
<p><strong><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb">hypothetical_document_embeddings</a></strong></p>
<p><strong><a href="https://github.com/run-llama/llama_index/blob/main/docs/examples/query_transformations/HyDEQueryTransformDemo.ipynb">HyDE (Hypothetical Document Embeddings)</a></strong></p>
<p>HyDE（Hypothetical Document Embeddings，假设性文档嵌入），通过生成假设性的答案并对这些生成的文档进行嵌入，而非嵌入原始文本。这种方法特别适用于用户问题简短且与需要查找的原始文本在语义上相似度不高的情况。</p>
<p>当用户的问题与知识库中的原始文本在语义上相差较大时，传统的文档检索方法可能无法有效地匹配到相关内容。HyDE通过使用大型语言模型（LLMs）根据用户问题生成格式上类似于知识库中文本的假设性答案，从而提升匹配的准确率。</p>
<p>尽管HyDE可以提升检索的准确性，但这种方法也会一定程度上增加检索的耗时。为了平衡检索准确率和响应速度，可以考虑使用更强大的重排模型（reranking models）。这些模型能够在检索后的阶段进一步优化结果，通过精准地评估和排序生成的假设性答案，以提供最相关的回答。</p>
<h3 id="parent-document-retriever-pdr">Parent Document Retriever (PDR)<a hidden class="anchor" aria-hidden="true" href="#parent-document-retriever-pdr">#</a></h3>
<p><img loading="lazy" src="https://miro.medium.com/v2/resize:fit:2000/format:webp/0*x4rMd50GP99OSDuo.png" alt=""  />
</p>
<p>from <strong><a href="https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6">Advanced RAG Techniques: an Illustrated Overview</a></strong></p>
<p>A.K.A Multi-size-chunks(Parent Document Retriever/ parent-child chunks retriever/ Auto Merging Retriever)</p>
<p>核心思想是，尽管小片段的数据更容易在语义上与短小的用户查询匹配，但这些小片段往往缺乏提供全面回答所需的足够上下文。PDR的解决方案是在检索时优先获取这些小片段，然后识别并返回包含这些小片段的更大父文档，以此为基础进行问题的回答。</p>
<p>在使用embedding模型召回时，尽可能的将对应文本拆成句子级别，因为往往人的问题都是比较短的句子，这样在语义匹配上能够较好的匹配上；但是在使用LLM做回答时，由需要足够的上下文让模型能够有足够多的背景进行回答；因此在召回的时候倾向于使用small-chunks用于匹配，再通过某些聚合方式合并成一个具备相对完整上下文的较大chunks用作模型回答之背景；</p>
<p>在Langchain中提供了<a href="https://python.langchain.com/docs/modules/data_connection/retrievers/parent_document_retriever"><code>Parent Document Retriever</code></a>这一方法。</p>
<blockquote>
<p>During retrieval, it first fetches the small chunks but then looks up the parent ids for those chunks and returns those larger documents.</p>
</blockquote>
<p>使用方法：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.retrievers</span> <span class="kn">import</span> <span class="n">ParentDocumentRetriever</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.storage</span> <span class="kn">import</span> <span class="n">InMemoryStore</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Retrieving larger chunks</span>
</span></span><span class="line"><span class="cl"><span class="c1"># This text splitter is used to create the parent documents</span>
</span></span><span class="line"><span class="cl"><span class="n">parent_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">separators</span><span class="o">=</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># This text splitter is used to create the child documents</span>
</span></span><span class="line"><span class="cl"><span class="c1"># It should create documents smaller than the parent</span>
</span></span><span class="line"><span class="cl"><span class="n">child_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">separators</span><span class="o">=</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">,</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># define your docs = embeddings, and vectorstore</span>
</span></span><span class="line"><span class="cl"><span class="c1"># docs = loader.load(...)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># emebeddings = OpenAIEmbeddings(...)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># vectorstore = Chroma(...)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># The storage layer for the parent documents</span>
</span></span><span class="line"><span class="cl"><span class="n">store</span> <span class="o">=</span> <span class="n">InMemoryStore</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">retriever</span> <span class="o">=</span> <span class="n">ParentDocumentRetriever</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">vectorstore</span><span class="o">=</span><span class="n">vectorstore</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">docstore</span><span class="o">=</span><span class="n">store</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">child_splitter</span><span class="o">=</span><span class="n">child_splitter</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">parent_splitter</span><span class="o">=</span><span class="n">parent_splitter</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">retriever</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</span></span></code></pre></div><p>而在<strong>llama_index中也提供了类似的方法。</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 创建较小的子块</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">llama_index.schema</span> <span class="kn">import</span> <span class="n">IndexNode</span>
</span></span><span class="line"><span class="cl"><span class="n">sub_chunk_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">864</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">sub_node_parsers</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="n">SimpleNodeParser</span><span class="o">.</span><span class="n">from_defaults</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">sub_chunk_sizes</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">all_nodes</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">base_node</span> <span class="ow">in</span> <span class="n">base_nodes</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">sub_node_parsers</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">sub_nodes</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">get_nodes_from_documents</span><span class="p">([</span><span class="n">base_node</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">sub_inodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">IndexNode</span><span class="o">.</span><span class="n">from_text_node</span><span class="p">(</span><span class="n">sn</span><span class="p">,</span> <span class="n">base_node</span><span class="o">.</span><span class="n">node_id</span><span class="p">)</span> <span class="k">for</span> <span class="n">sn</span> <span class="ow">in</span> <span class="n">sub_nodes</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">all_nodes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">sub_inodes</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">original_node</span> <span class="o">=</span> <span class="n">IndexNode</span><span class="o">.</span><span class="n">from_text_node</span><span class="p">(</span><span class="n">base_node</span><span class="p">,</span> <span class="n">base_node</span><span class="o">.</span><span class="n">node_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">all_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">original_node</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">all_nodes_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="o">.</span><span class="n">node_id</span><span class="p">:</span> <span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">all_nodes</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 创建索引、检索器和查询引擎</span>
</span></span><span class="line"><span class="cl"><span class="n">vector_index_chunk</span> <span class="o">=</span> <span class="n">VectorStoreIndex</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">all_nodes</span><span class="p">,</span> <span class="n">service_context</span><span class="o">=</span><span class="n">service_context</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">vector_retriever_chunk</span> <span class="o">=</span> <span class="n">vector_index_chunk</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(</span><span class="n">similarity_top_k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">retriever_chunk</span> <span class="o">=</span> <span class="n">RecursiveRetriever</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;vector&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">retriever_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;vector&#34;</span><span class="p">:</span> <span class="n">vector_retriever_chunk</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="n">node_dict</span><span class="o">=</span><span class="n">all_nodes_dict</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">query_engine_chunk</span> <span class="o">=</span> <span class="n">RetrieverQueryEngine</span><span class="o">.</span><span class="n">from_args</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">retriever_chunk</span><span class="p">,</span> <span class="n">service_context</span><span class="o">=</span><span class="n">service_context</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">response</span> <span class="o">=</span> <span class="n">query_engine_chunk</span><span class="o">.</span><span class="n">query</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;Can you tell me about the key concepts for safety finetuning&#34;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">))</span>
</span></span></code></pre></div><h3 id="sentence-window-retrieval">Sentence Window Retrieval<a hidden class="anchor" aria-hidden="true" href="#sentence-window-retrieval">#</a></h3>
<p>为了更好地分析找到的语境，我们在检索到的最相关单句之前后各扩展 <em>k</em> 个句子，然后把这个扩展后的语境送给 LLM 进行推理</p>
<p><img loading="lazy" src="https://miro.medium.com/v2/resize:fit:2000/format:webp/0*JKZ9m_c6jyIKqCWu.png" alt=""  />
</p>
<p>from <strong><a href="https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6">Advanced RAG Techniques: an Illustrated Overview</a></strong></p>
<h3 id="分块可视化小工具">分块可视化小工具<a hidden class="anchor" aria-hidden="true" href="#分块可视化小工具">#</a></h3>
<p>推荐一个可视化chunk-spliting 工具<a href="https://chunkviz.up.railway.app">chunkviz</a></p>
<h2 id="推荐阅读">推荐阅读<a hidden class="anchor" aria-hidden="true" href="#推荐阅读">#</a></h2>
<p><a href="https://medium.com/@hadiazouni/text-splitting-chunking-for-rag-applications-7ccbb6dcc9f9">Text splitting (chunking) for RAG applications</a></p>
<p><a href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.md">5_Levels_Of_Text_Splitting</a></p>
<p><a href="https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/semantic-chunker/">langchain:Semantic Chunking</a></p>
<p><a href="https://www.pinecone.io/learn/chunking-strategies/">Chunking Strategies for LLM Applications</a></p>
<p><a href="https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6">Advanced RAG Techniques: an Illustrated Overview</a></p>
<p><a href="https://mp.weixin.qq.com/s/ZzXU4VPruRz1jWu4sJy4jQ">RAG系列05：基于语义的Chunk分割</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://niraya666.github.io/tags/rag/">RAG</a></li>
      <li><a href="https://niraya666.github.io/tags/rag-toolkits/">RAG-Toolkits</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://niraya666.github.io/posts/agent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%A6%82%E4%BD%95%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%9A%84tool-using%E8%83%BD%E5%8A%9B/">
    <span class="title">« Prev</span>
    <br>
    <span>Agent学习笔记： 如何验证模型的tool-using能力</span>
  </a>
  <a class="next" href="https://niraya666.github.io/posts/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84-agent%E7%A7%91%E6%99%AE%E5%90%91/">
    <span class="title">Next »</span>
    <br>
    <span>基于大语言模型的 Agent：科普向</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share RAG工具箱：文本分块 on x"
            href="https://x.com/intent/tweet/?text=RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9a%e6%96%87%e6%9c%ac%e5%88%86%e5%9d%97&amp;url=https%3a%2f%2fniraya666.github.io%2fposts%2frag%25E5%25B7%25A5%25E5%2585%25B7%25E7%25AE%25B1%25E6%2596%2587%25E6%259C%25AC%25E5%2588%2586%25E5%259D%2597%2f&amp;hashtags=RAG%2cRAG-Toolkits">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share RAG工具箱：文本分块 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fniraya666.github.io%2fposts%2frag%25E5%25B7%25A5%25E5%2585%25B7%25E7%25AE%25B1%25E6%2596%2587%25E6%259C%25AC%25E5%2588%2586%25E5%259D%2597%2f&amp;title=RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9a%e6%96%87%e6%9c%ac%e5%88%86%e5%9d%97&amp;summary=RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9a%e6%96%87%e6%9c%ac%e5%88%86%e5%9d%97&amp;source=https%3a%2f%2fniraya666.github.io%2fposts%2frag%25E5%25B7%25A5%25E5%2585%25B7%25E7%25AE%25B1%25E6%2596%2587%25E6%259C%25AC%25E5%2588%2586%25E5%259D%2597%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share RAG工具箱：文本分块 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fniraya666.github.io%2fposts%2frag%25E5%25B7%25A5%25E5%2585%25B7%25E7%25AE%25B1%25E6%2596%2587%25E6%259C%25AC%25E5%2588%2586%25E5%259D%2597%2f&title=RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9a%e6%96%87%e6%9c%ac%e5%88%86%e5%9d%97">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share RAG工具箱：文本分块 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fniraya666.github.io%2fposts%2frag%25E5%25B7%25A5%25E5%2585%25B7%25E7%25AE%25B1%25E6%2596%2587%25E6%259C%25AC%25E5%2588%2586%25E5%259D%2597%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share RAG工具箱：文本分块 on whatsapp"
            href="https://api.whatsapp.com/send?text=RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9a%e6%96%87%e6%9c%ac%e5%88%86%e5%9d%97%20-%20https%3a%2f%2fniraya666.github.io%2fposts%2frag%25E5%25B7%25A5%25E5%2585%25B7%25E7%25AE%25B1%25E6%2596%2587%25E6%259C%25AC%25E5%2588%2586%25E5%259D%2597%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share RAG工具箱：文本分块 on telegram"
            href="https://telegram.me/share/url?text=RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9a%e6%96%87%e6%9c%ac%e5%88%86%e5%9d%97&amp;url=https%3a%2f%2fniraya666.github.io%2fposts%2frag%25E5%25B7%25A5%25E5%2585%25B7%25E7%25AE%25B1%25E6%2596%2587%25E6%259C%25AC%25E5%2588%2586%25E5%259D%2597%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share RAG工具箱：文本分块 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=RAG%e5%b7%a5%e5%85%b7%e7%ae%b1%ef%bc%9a%e6%96%87%e6%9c%ac%e5%88%86%e5%9d%97&u=https%3a%2f%2fniraya666.github.io%2fposts%2frag%25E5%25B7%25A5%25E5%2585%25B7%25E7%25AE%25B1%25E6%2596%2587%25E6%259C%25AC%25E5%2588%2586%25E5%259D%2597%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
<div id="utterances">
  <script src="https://utteranc.es/client.js"
        repo="https://github.com/Niraya666/niraya666.github.io.git"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
  </script>
</div>


<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://niraya666.github.io/">LZY Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
