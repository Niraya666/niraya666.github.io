<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>当AI开始展现&#34;顿悟时刻&#34;意味着什么 | LZY Blog</title>
<meta name="keywords" content="杂">
<meta name="description" content="写在前面
本文是前段时间部门内技术分享的文字稿整理；
主要包含2个方面：对于R1模型的简单科普，和开发团队的gen-AI使用指南；
原以为春节假期能稍作休整，未曾料想deepSeek-R1在春节期间引发行业关注。节后复工，各层级领导便密集展开AI技术进展问询。
原计划的&quot;二月摸鱼指南&quot;彻底落空，既要向管理层科普大语言模型技术原理，又要指正领导们被各种营销号洗脑所形成的错误认知；既要推进部门AI应用培训，又要加速系统上线进程；简直了，真是TM的谢谢 DeppSeek了。
About DS R1
什么是Reasoning model

何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。


In Thinking, Fast and Slow, Daniel Kahneman defined System 1 as the automatic, intuitive mode of thinking, and System 2 as the slower, more analytical mode. In the context of autoregressive language models, the usual inference process is akin to System 1 — models generate answers directly. Reasoning is System 2 thinking - models or systems takes time to deliberate to solve more complex problems.">
<meta name="author" content="Theme PaperMod">
<link rel="canonical" href="https://niraya666.github.io/posts/%E5%BD%93ai%E5%BC%80%E5%A7%8B%E5%B1%95%E7%8E%B0%E9%A1%BF%E6%82%9F%E6%97%B6%E5%88%BB%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://niraya666.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://niraya666.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://niraya666.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://niraya666.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://niraya666.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://niraya666.github.io/posts/%E5%BD%93ai%E5%BC%80%E5%A7%8B%E5%B1%95%E7%8E%B0%E9%A1%BF%E6%82%9F%E6%97%B6%E5%88%BB%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="当AI开始展现&#34;顿悟时刻&#34;意味着什么" />
<meta property="og:description" content="写在前面
本文是前段时间部门内技术分享的文字稿整理；
主要包含2个方面：对于R1模型的简单科普，和开发团队的gen-AI使用指南；
原以为春节假期能稍作休整，未曾料想deepSeek-R1在春节期间引发行业关注。节后复工，各层级领导便密集展开AI技术进展问询。
原计划的&quot;二月摸鱼指南&quot;彻底落空，既要向管理层科普大语言模型技术原理，又要指正领导们被各种营销号洗脑所形成的错误认知；既要推进部门AI应用培训，又要加速系统上线进程；简直了，真是TM的谢谢 DeppSeek了。
About DS R1
什么是Reasoning model

何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。


In Thinking, Fast and Slow, Daniel Kahneman defined System 1 as the automatic, intuitive mode of thinking, and System 2 as the slower, more analytical mode. In the context of autoregressive language models, the usual inference process is akin to System 1 — models generate answers directly. Reasoning is System 2 thinking - models or systems takes time to deliberate to solve more complex problems." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://niraya666.github.io/posts/%E5%BD%93ai%E5%BC%80%E5%A7%8B%E5%B1%95%E7%8E%B0%E9%A1%BF%E6%82%9F%E6%97%B6%E5%88%BB%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88/" />
<meta property="og:image" content="https://niraya666.github.io/images/papermod-cover.png" />
<meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-02-23T23:00:00+08:00" />
<meta property="article:modified_time" content="2025-02-23T23:00:00+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://niraya666.github.io/images/papermod-cover.png" />
<meta name="twitter:title" content="当AI开始展现&#34;顿悟时刻&#34;意味着什么"/>
<meta name="twitter:description" content="写在前面
本文是前段时间部门内技术分享的文字稿整理；
主要包含2个方面：对于R1模型的简单科普，和开发团队的gen-AI使用指南；
原以为春节假期能稍作休整，未曾料想deepSeek-R1在春节期间引发行业关注。节后复工，各层级领导便密集展开AI技术进展问询。
原计划的&quot;二月摸鱼指南&quot;彻底落空，既要向管理层科普大语言模型技术原理，又要指正领导们被各种营销号洗脑所形成的错误认知；既要推进部门AI应用培训，又要加速系统上线进程；简直了，真是TM的谢谢 DeppSeek了。
About DS R1
什么是Reasoning model

何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。


In Thinking, Fast and Slow, Daniel Kahneman defined System 1 as the automatic, intuitive mode of thinking, and System 2 as the slower, more analytical mode. In the context of autoregressive language models, the usual inference process is akin to System 1 — models generate answers directly. Reasoning is System 2 thinking - models or systems takes time to deliberate to solve more complex problems."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://niraya666.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "当AI开始展现\"顿悟时刻\"意味着什么",
      "item": "https://niraya666.github.io/posts/%E5%BD%93ai%E5%BC%80%E5%A7%8B%E5%B1%95%E7%8E%B0%E9%A1%BF%E6%82%9F%E6%97%B6%E5%88%BB%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "当AI开始展现\"顿悟时刻\"意味着什么",
  "name": "当AI开始展现\u0022顿悟时刻\u0022意味着什么",
  "description": "写在前面 本文是前段时间部门内技术分享的文字稿整理；\n主要包含2个方面：对于R1模型的简单科普，和开发团队的gen-AI使用指南；\n原以为春节假期能稍作休整，未曾料想deepSeek-R1在春节期间引发行业关注。节后复工，各层级领导便密集展开AI技术进展问询。\n原计划的\u0026quot;二月摸鱼指南\u0026quot;彻底落空，既要向管理层科普大语言模型技术原理，又要指正领导们被各种营销号洗脑所形成的错误认知；既要推进部门AI应用培训，又要加速系统上线进程；简直了，真是TM的谢谢 DeppSeek了。\nAbout DS R1 什么是Reasoning model 何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。\nIn Thinking, Fast and Slow, Daniel Kahneman defined System 1 as the automatic, intuitive mode of thinking, and System 2 as the slower, more analytical mode. In the context of autoregressive language models, the usual inference process is akin to System 1 — models generate answers directly. Reasoning is System 2 thinking - models or systems takes time to deliberate to solve more complex problems.\n",
  "keywords": [
    "杂"
  ],
  "articleBody": "写在前面 本文是前段时间部门内技术分享的文字稿整理；\n主要包含2个方面：对于R1模型的简单科普，和开发团队的gen-AI使用指南；\n原以为春节假期能稍作休整，未曾料想deepSeek-R1在春节期间引发行业关注。节后复工，各层级领导便密集展开AI技术进展问询。\n原计划的\"二月摸鱼指南\"彻底落空，既要向管理层科普大语言模型技术原理，又要指正领导们被各种营销号洗脑所形成的错误认知；既要推进部门AI应用培训，又要加速系统上线进程；简直了，真是TM的谢谢 DeppSeek了。\nAbout DS R1 什么是Reasoning model 何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。\nIn Thinking, Fast and Slow, Daniel Kahneman defined System 1 as the automatic, intuitive mode of thinking, and System 2 as the slower, more analytical mode. In the context of autoregressive language models, the usual inference process is akin to System 1 — models generate answers directly. Reasoning is System 2 thinking - models or systems takes time to deliberate to solve more complex problems.\nLLMs本质上是一个根据上文预测下一个token的自回归模型，那么这样的模型是否具备逻辑推理能力呢？从表现特征来看，LLMs更类似于\"文科生\"的思维模式——在应对需要复杂推理的数学演算、自然科学问题解析及代码编写等场景时，其表现往往力不从心。\n如何让模型的推理能力提升呢？CoT（Chain of Thought， Wei et al. 2022）即“思维链”，是一种使LLM“逐步思考”的方法。它通过要求模型展示解决问题的中间步骤来加强其逻辑推理能力，从而提高决策的质量和准确性。\nCoT更多是从prompting角度， 要求LLM以一定的格式进行回答（“think step by step”），模型对于没有在pre-training中涉及的内容时，效果并不太好，因为过去的LLM训练过程中， 不论是pre-training（预测下一个token）还是SFT（要求模型按照一定的格式输出），都与模型的reasoning 无关，CoT所所展示出的效果，及模型展现出的“推理”，更像是某种程度的“涌现”，而非专门针对性训练，当然也有认为LLMs似乎是在背答案而非真正的推理Can Large Language Models Reason?\n自2024年9月后， OpenAI推出了 o-1 系列模型，也就是世界上第一个推理模型，同时也是第一个专门针对推理任务的模型， 只是“CloseAI” 所提供的信息非常有限， 并没有人知道其如何实现的，大家对其猜测五花八门。\n（from openAI）\n这一切，直到DS R1的出现，才似乎尘埃落定。\nDS R1做了什么 一切，从DS提供的论文出发。\n主要贡献有3点：\n如何通过纯RL训练提升模型的推理能力（DeepSeek-R1-Zero）： 直接在基础模型（DeepSeek-V3-Base）上应用大规模RL，无需SFT作为预热，首次验证纯RL可激励LLM的推理能力,而非采用Reward model 或MCTS。\n如何通过冷启动数据和多阶段训练优化模型的可读性和综合性能（DeepSeek-R1）：引入少量冷启动数据（数千条长CoT示例）进行微调，再通过两阶段RL（推理优化+人类偏好对齐）和SFT提升性能与可读性\n如何将大模型的推理能力高效迁移到小模型： 将大模型（DeepSeek-R1）生成的80万条数据蒸馏到小模型（如Qwen、Llama系列），显著提升小模型推理能力，甚至超越直接对小模型应用RL的效果\n具体而言，对于DeepSeek-R1-Zero，采用了GRPO（Group Relative Policy Optimization，正是DS团队在其另一篇工作DeepSeekMath中所开发的方法），不同于PPO，GRPO无需critic model，降低的显存使用，同时更简化训练过程也让训练过程更高效和稳定。\n此外， 采用FP8（8位浮点数）精度进行训练，也降低了显存占用。\n在奖励机制设计上，采用了rule-based的设计，兼顾Accuracy reward（正确的coding或数学推理结果）与Format rewards（遵循指定输出格式，语言一致性、标记使用等）。\n通过强制模型输出结构化内容（如推理过程和答案）有效引导模型行为；\nDeepSeek-R1-Zero 因采用base-model RL获得，存在Language Mixing ，以及可读性差，对特定任务泛化能力差（因训练目标单一）等问题\nDeepSeek-R1为了解决以上问题：\n→ 引入了语言一致性奖励\n→ 使用从RL阶段生成的checkpoint,通过拒绝采样来筛选出高质量的推理样本\n大致流程：\nSFT(用高质量COT启动RL，以避免早期不稳定性) → 推理强化学习 → SFT(推理+通用领域数据) → 对齐强化学习\n同时， 将DeepSeek-R1生成的80万条数据用于微调小模型，小模型直接继承大模型的推理模式，性能远超直接对小模型应用RL。\n意义和需要澄清的内容 从意义上讲，这是首个在推理能力上与OpenAI o1系列商业模型达到同等水平的开源模型（开源模型权重和公开部分训练细节）；同时，个人认为R1-zero的意义会比R1来的更加重要，因为其完全是基于rule-base RL训练的reasoning 模型， 具备了自我纠错反思的“aha moment“，为开源社区探明了道路，而不是遮遮掩掩的（说的就是你__）；此外， 对于小模型直接用大模型蒸馏从而提升reasoning能力，而不是直接在小模型上RL，为资源受限场景下的模型优化提供了极具参考价值的技术路径。\n一些需要澄清的点：\nNvidia股价大跌，不需要Nvidia了吗：从模型推理的角度，可能有其他的选择，但对于开发运维人员角度，因其生态位和开源社群，Nvidia依旧是首选；训练方面依旧是不可撼动的；\nDS是通过chatGPT蒸馏出来的？：并没有证据能够证明这一点，任何模型对于“自己是谁”的回答都是不具备任何参考价值的，往往都是幻觉。\n赢？不太希望将这件事上升到这样的高度，保持理智，不要捧杀DS，AGI的路还挺长的，任何看完之后心潮澎湃的文章多半都是新闻学的胜利和对于民族主义情绪之利用；但必须承认一点，无论是中美，还是开源闭源的差距都没有想象中的大，似乎差距正在不断缩小。\n**教你本地部署满血版DS-R1？只要99入门到精通？少焦虑，多接触优质信息源，如Twitter(X)上一线研究员的发言讨论和TA们的blog，huggingface上的论文推荐，以及更新：2024年AI领域最值得关注的博主和一手信息源盘点；对于DS- R1所需要的推理硬件参数会在后面专门聊，这里先不展开了。\n泼一些冷水 DS R1的幻觉挺严重的，不论是使用体验上，还是从Vectara’s HHEM的幻觉评测指标上看。\n（from DeepSeek-R1 hallucinates more than DeepSeek-V3）\n对齐不足。从现有的工作和实际效果上来看，DS在模型的对齐方面做的可能还不够。当然，这是把双刃剑，没有了限制，使其表现的更像人类的回答而不是AI，甚至有些细思极恐的回答，于是DS能够火出圈。关于reasoning model的安全性和对齐方面工作，大家也都还在摸索阶段，可以参考OpenAI的Deliberative Alignment 相关工作。\nR1解题coding可以，但follow-instruction 有点问题； 于是，更多是将R1作为planner用于任务规划和意图识别，从成本上考虑，短期不会替换之前的workflow和RAG设计，当然长期来看，一定会有超出workflow范畴的真正agent出现。\nDS R1所带来的影响 更高的回答准确率，代码质量等\n大大降低prompting的门槛，用户意图识别效果更好（如果不考虑成本的话）\n给推理模型加上工具调用，而不仅仅是思考（这不就有deep research出现了嘛）\n指明了RL范式：只要给问题和答案， 中间过程交给RL，大力飞砖\n相关资料汇总 技术报告：https://arxiv.org/abs/2501.12948\nHuggingface：https://huggingface.co/deepseek-ai/DeepSeek-R1\n一些关于R1的开源复刻工作\u0026信息汇总：\nOpen-R1: Open-R1: a fully open reproduction of DeepSeek-R1\nRAGEN： RAGEN: A General-Purpose Reasoning Agent Training Framework\nRun DeepSeek R1 Dynamic 1.58-bit\nOpen Thoughts: https://github.com/open-thoughts/open-thoughts?tab=readme-ov-file\nhttps://xcn2d971vuw4.feishu.cn/wiki/RaC2w1iiFijAa1kVJUjcp3agn8e\nhttps://github.com/ninehills/blog/issues/121\nPrimers • DeepSeek R1\nDeepSeek-R1: Incentivizing Reasoning Capability in Large Language Models via Reinforcement Learning — Paper Understanding\nAn Analysis of DeepSeek’s R1-Zero and R1\n开发团队的Gen-AI使用指南 这是一些关于一个开发团队如何使用，和高效使用Gen-AI的不完全指南\n大体而言， 开发者使用AI通常有以下几个场景：\n高质量，有效率的coding\n完善的开发文档，设计文档，测试用例\n快速完成想法验证\n当然，一切的前提是，你有LLM可用\nPrerequisite：模型API服务 当下模型服务有两大类 付费LLM-API 和基于本地私有化部署的方案（基于CPU或基于GPU）\n采用在互联网上模型服务商所提供的模型API服务（如openAI，等），该方案适合绝大多数开发者，毕竟好的硬件设备并不是所有人都负担的起，其次，对于数据隐私有执念的，或是有足够硬件设备者，可以尝试采用本地模型部署，但由于本地硬件条件有限，一般只能部署开源的，参数量不大的模型；\n具体而言，对于绝大多数模型服务商提供的模型服务，一般都支持统一的openAI chat-completion API 格式，支持tool-using，多模态使用，均可以使用openAI client调用；这对于Gen-AI应用开发而言是非常方便的事情，切换模型供应商唯一需要修改的只有API-KEY和BASE_URL；\n而模型服务商又可分为3大类（或者更多？）\n闭源模型的API服务（openAI，Anthropic）\n开源模型的Maas 服务商 （Groq，SiliconFlow和各大云厂商）\nLLM-API 聚合平台 （OpenRouter）\n以下是整理的常见模型服务商：\n分类 服务商 说明 链接 官方版本（数据安全） OpenAI o3 系列（推理模型适合用于 bug 和问题分析）o1 系列，GPT-4o - Anthropic Claude-3.5-Sonnet（代码质量高） Anthropic Azure OpenAI 已停止对境内个人开发者开放服务，需要同合作伙伴商公对公签合同 - Gemini 提供一定的免费额度可使用 Gemini DeepSeek DS R1（个人信息认证后可使用，貌似还未恢复服务） DeepSeek 阿里云 Qwen2.5-max 阿里云 Maas 服务商 Groq 速度飞快，开源模型 Groq SiliconFlow 国内的 Maas 服务商，支持大多数开源模型 SiliconFlow 非官方 API 聚合平台 OpenRouter 最大的 API 聚合平台之一，支持市面上绝大多数模型服务（安全性、隐私性需自行考虑） OpenRouter Prerequisite：私有化部署 对于本地推理方案，推荐 ollama （cpu）和vllm，sglang （GPU）；\nollama：https://ollama.com/；\nvllm：https://docs.vllm.ai/en/latest/getting_started/quickstart.html\nsglang：https://github.com/sgl-project/sglang\n不过在采用私有化部署之前，需要确认的一件事是：判断硬件所支持的最大参数量模型？\nLLM推理时，显存占用来源有：推理精度，模型大小，context长度\n简化计算：在FP16精度推理时,显存占用约为模型参数量的2倍(考虑中间激活值后可能接近2.5倍)。例如,7B参数的模型,纯参数显存占用约14GB(7B×2bytes),实际使用中因激活值等开销可能达到14-17GB;若采用int8量化,参数显存可减半。\n推荐：分析transformer模型的参数量、计算量、中间激活、KV cache\n此外，还需要搞清楚有哪些模型是DeepSeek R1？所谓满血版R1指的是谁？\n从DS在HF的官方仓库可以看到：\n满血版本指的是FP16精度下推理的DeepSeek-R1\n剩下的除了R1-zero是实验产物外，剩下都是通过R1在不同参数量的Qwen和Llama上蒸馏出来的reasoning模型；\n对于满血版本，在FP16上推理，至少需要两台8卡H20服务器\n而GGUF、AWQ、GPTQ 等则是适用于不同设备、不同框架的量化版本权重（Quantization）\n以Ollama为例，在mac M3电脑上启动 DS-R1 14B的蒸馏模型\nollama run deepseek-r1:14b 这里选择的原始模型是deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\n不过是基于GGUF的Q4_K 版本，需要至少9GB的内存；\n基于本地ollama启动的deepseek R1（蒸馏版本）对话：\nfrom openai import OpenAI client = OpenAI( base_url = 'http://localhost:11434/v1', api_key='ollama', # required, but unused ) response = client.chat.completions.create( model=\"deepseek-r1:14b\", messages=[ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] ) print(response.choices[0].message.content) 若采用vllm在GPU上推理模型时，需要额外增加参数--enable-reasoning --reasoning-parser deepseek_r1来支持R1 系列模型的Reasoning Outputs。\n一些支持自定义API的chatbot UI工具：\nCherry Studio\nChatWise\nanythingllm\nopenChat\n…\n常见的AI-coding 编辑器 代码自动补全，基于代码对话，自动错误识别，项目级别代码阅读和修改，代码建议\n工具名称 功能概览 主要特点 收费情况 开源情况 Cursor AI 基于VS Code的AI编辑器，集成GPT-4、Claude 3.5等模型 多行编辑与智能重写、自然语言编程、全局代码库问答、图像支持等 免费版、Pro版(20美元/月)、Business版(40美元/用户/月)，额外收费（按次计费） 客户端非完全开源，旧版本部分代码可见，依赖专有AI模型 GitHub Copilot 代码补全、PR支持、智能聊天、企业级功能（知识库集成、定制模型） 支持多IDE、跨文件修改、Copilot Chat、PR生成等 免费版、Pro版(10美元/月)、Business版(19美元/用户/月)、Enterprise版(39美元/用户/月) 非开源，提供FauxPilot、Tabby等开源替代方案 Codeium AI代码补全、上下文感知、多语言支持、智能聊天 支持40+开发环境、GPT-4优化、隐私与安全保障 免费版、团队版(12美元/用户/月)、企业版（定制化定价） 部分IDE插件开源（MIT协议），核心服务闭源 Continue 代码补全、上下文感知聊天、代码重写、自定义模型集成 本地部署方案、低延迟、隐私保护、多语言支持 基础功能免费，企业版定制化定价（需联系销售） 开源，Apache 2.0协议，支持自定义模型接入 Cline 支持多模型、终端命令执行、浏览器自动化、智能上下文管理 支持本地模型、API成本监控、沙盒安全机制、跨平台开发 开源（Apache 2.0协议），API成本自行承担，企业版(79美元/月起) 完全开源，Apache 2.0协议，支持自定义工具服务器（GitHub） TabbyML 本地化代码补全、问答引擎、AI实时交互 本地部署、支持多语言和IDE插件，定制化模型集成和GPU部署 社区版免费、团队版(19美元/用户/月)、企业版定制化计费 完全开源，Apache 2.0协议，支持自定义模型集成与本地GPU部署 Windsurf Cascade Flow系统、多文件编辑、智能代码辅助、终端指令生成 AI代理、上下文感知、Supercomplete预测、实时错误修复、隐私保护 免费版、Pro版(15美元/月)、Pro Ultimate版(60美元/月)；新用户可免费试用2个月 当前版本未开源，基于VS Code架构，核心AI功能为闭源实现 如何Coding with AI：正确打开方式 如何使用AI，方法论比工具重要\nThe reality is that AI is like having a very eager junior developer on your team. … The more you know, the better you can guide them.\nI’ve watched senior engineers use AI to: Rapidly prototype ideas they already understandGenerate basic implementations they can then refineExplore alternative approaches to known problemsAutomate routine coding tasks … Meanwhile, juniors often: Accept incorrect or outdated solutionsMiss critical security and performance considerationsStruggle to debug AI-generated codeBuild fragile systems they don’t fully understand\n（from How AI-assisted coding will change software engineering: hard truths）\nSenior 工程师更能从AI 辅助编程中获益，而非初学者。\nSenior 工程师能够判断AI的结果是否正确，和更加有针对性的提问，从而更好的发挥出AI的作用\n最重要的是，senior工程师更多是利用AI作头脑风暴和原型验证，在1小时内完成过去3天的原型验证，从而大大减少走弯路的时间；这种\"加速已知，探索可能\"的范式转变，正在重构传统研发流程的边界\n相反的，Junior工程师往往无法很好的判断AI给出的代码是否正确或者何时，往往只是AI代码的搬运工，同时，往往无法很好的向AI进行提问\n再者，开发工程师的工作不只是开发，约占1/6左右，剩下还有大量的撰写文档、设计、沟通交流、看文档、code review等，AI虽然可以帮助完成部分简单和重复的任务，很显然，AI远没有达到替代人的程度，至少是当下，AI仍然需要人类的指导和判断。\n只是当下，对于Junior工程师的培养将会是个问题。\nMy beehive-kicking post’s main premise is pretty simple and can be visualized in terms of two different kinds of task that arise on software projects.\nWe often give these leaf node tasks to junior developers because the scope is small. … LLMs can now execute most of the leaf tasks and even some higher-level interior tasks … Which are not the kind of task that you typically give junior developers. … Junior devs are deeply affected, though, and it’s a concern.\nYou are getting left behind if you do not adopt chat-based programming as your primary modality.\n（from The Death of the Stubborn Developer）\n过去培养新人时，通常安排其承担简单且独立的\"leaf node\"任务，通过项目实践积累经验，实现能力提升。然而，随着AI技术普及，这些基础任务已可被高效且精准地完成，新人面临的处境变得愈发尴尬，失去通过基础任务积累系统认知的机会。\n当前企业面临双重挑战，既要维持业务效率，又需保障工程师培养体系的可持续性，二者并非绝对对立，但需重新设计技术成长阶梯以实现平衡。\n技术债管理能力正成为团队竞争力的关键分水岭。AI技术将加剧低技术债务团队与高技术债务团队间的马太效应。\nthat generative AI dramatically widens the gap in velocity between ‘low-debt’ coding and ‘high-debt’ coding.\nIn other words, the penalty for having a ‘high-debt’ codebase is now larger than ever.\nHowever, in ‘high-debt’ environments with subtle control flow, long-range dependencies, and unexpected patterns, they struggle to generate a useful response.\nDay-to-day feature work should then be done on top of this foundation with maximum leverage from generative AI tooling.\n（from AI Makes Tech Debt More Expensive）\n高技术债务团队因代码结构混乱、模式不统一（如多重继承滥用、接口定义缺失），导致AI难以有效解析上下文逻辑。开发人员不得不耗费大量精力处理历史遗留问题（如兼容性适配、脆弱性修补），形成技术维护的恶性循环。\n低技术债务团队凭借清晰的架构设计（模块化、标准化接口），使AI辅助开发工具能准确识别代码意图，快速完成功能扩展与问题定位。这种优势使其可将资源集中投入创新性工作，形成技术演进的正向循环。\n个人的一些建议：\n明确LLM的认知边界，用结构化指令替代模糊需求\n用生成结果反推思维盲区，意识到想法中的不足之处（stay humble）\n对存疑输出实施交叉验证，批判性接受\n新人学习策略：利用AI工具学习代码而不是复制代码，多追问为什么\n在未来，人机协同范式将重塑人才能力评价体系，一些核心素养将成为关键竞争力。\n重中之重是语言表达和写作能力。从当前实践和身边的例子中，发现一个典型困境：诸多理工科从业者虽具备缜密的逻辑分析能力，却难以将复杂需求转化为精准的指令表述。这种表达能力缺失导致其在使用生成式AI时频繁遭遇预期偏差，既影响工作效率，又易形成对技术效能的误判。或许这已经是这个社会的通病了。即便是具有一定“读心”能力的R1模型出现，Gen-AI的使用依旧还是有一定门槛的。\n再者，批判性思维的培养也非常重要；当前Gen-AI使用者呈现明显的认知极化现象：部分因遭遇AI失误而全盘否定其应用价值，表现为技术抗拒倾向；另一极端则对AI输出盲目采信，缺乏基本的内容鉴别能力。真正科学的态度应当是在理解AI能力边界的基础上，合理利用其优势，同时保持独立思考和批判性判断。这正是批判性思维的核心价值所在——面对AI生成内容时，能够主动分析、质疑、验证信息的真实性和可靠性，从而在技术应用中保持理性、客观的态度。\n除此之外，并不需要去害怕和担心AI取代人，开发者群体应建立正确的工具认知：编程能力本质上是解决问题的工具而非目的本身。AI作为效率倍增器，其价值在于辅助人类突破效率边界。真正需要持续积累的是问题抽象能力、解决方案架构能力以及行业专有知识库——这些通过实践沉淀的思维链（CoT）构成了人类认知的护城河，是当前AI技术难以企及的领域。保持开放的技术观，聚焦能力提升而非技术替代焦虑，避免因FOMO（Fear of missing out）而被人割韭菜。\nAI赋能的超级个体正在重构生产组织方式。在过去，企业依赖层级架构，和明确的分工，随着AI工具的广泛应用， 个体的生产力得到了指数级提升，许多过去需要团队协作才能完成的任务，如今单个个体借助AI即可高效完成。这种能力的跃迁，使得传统组织架构的效率优势逐渐被削弱，甚至在某些场景下变得冗余。在这种背景下，生产力关系的重构成为必然趋势。组织形态向更加扁平化、小型化的方向演进，扁平化意味着组织内部的决策链条缩短，信息流转更加高效，个体拥有更大的自主权和决策空间，而非将大量时间用于无效的沟通上。未来，个人或小型团队借助AI工具，可以像过去的大型企业一样高效运作，甚至在某些领域超越传统组织的效率。\n一些补充 领域Benchmark构建非常重要。当前针对法律、医疗等垂直领域已形成专业评估体系，但多数行业仍缺乏系统的LLM评估标准，导致在模型选型时过度依赖个体经验判断。\n重新审视专业壁垒:预训练模型可能已覆盖领域基础知识体系,现存\"专业门槛\"或存在人为构建的术语壁垒；领域内高质量的CoT数据，思考方式才是关键\n随着LLM能力的提升，过去我们精心设计的许多工程方案可能会变得不再必要，甚至过时。不断学习和适应，不要固步自封，技术迭代是以天为单位的；拥抱和参与开源，而不是技术封建主义。\nLLM reasoning 能力提升后，短期内，RAG，Agent， workflow不会有太大变化\nPost-training很重要\n同时间段开源的Qwen/Qwen2.5-VL-72B-Instruct 也值得关注\n",
  "wordCount" : "774",
  "inLanguage": "en",
  "image": "https://niraya666.github.io/images/papermod-cover.png","datePublished": "2025-02-23T23:00:00+08:00",
  "dateModified": "2025-02-23T23:00:00+08:00",
  "author":{
    "@type": "Person",
    "name": "Theme PaperMod"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://niraya666.github.io/posts/%E5%BD%93ai%E5%BC%80%E5%A7%8B%E5%B1%95%E7%8E%B0%E9%A1%BF%E6%82%9F%E6%97%B6%E5%88%BB%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "LZY Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://niraya666.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://niraya666.github.io/" accesskey="h" title="LZY Blog (Alt + H)">LZY Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://niraya666.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/musik/" title="musik!">
                    <span>musik!</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/monthly/" title="月刊">
                    <span>月刊</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/essay/" title="杂文">
                    <span>杂文</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/travel/" title="游记">
                    <span>游记</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://niraya666.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://niraya666.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      当AI开始展现&#34;顿悟时刻&#34;意味着什么
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2025-02-23 23:00:00 +0800 CST'>February 23, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Theme PaperMod

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e5%86%99%e5%9c%a8%e5%89%8d%e9%9d%a2" aria-label="写在前面">写在前面</a></li>
                <li>
                    <a href="#about-ds-r1" aria-label="About DS R1">About DS R1</a><ul>
                        
                <li>
                    <a href="#%e4%bb%80%e4%b9%88%e6%98%afreasoning-model" aria-label="什么是Reasoning model">什么是Reasoning model</a></li>
                <li>
                    <a href="#ds-r1%e5%81%9a%e4%ba%86%e4%bb%80%e4%b9%88" aria-label="DS R1做了什么">DS R1做了什么</a></li>
                <li>
                    <a href="#%e6%84%8f%e4%b9%89%e5%92%8c%e9%9c%80%e8%a6%81%e6%be%84%e6%b8%85%e7%9a%84%e5%86%85%e5%ae%b9" aria-label="意义和需要澄清的内容">意义和需要澄清的内容</a></li>
                <li>
                    <a href="#%e6%b3%bc%e4%b8%80%e4%ba%9b%e5%86%b7%e6%b0%b4" aria-label="泼一些冷水">泼一些冷水</a></li>
                <li>
                    <a href="#ds-r1%e6%89%80%e5%b8%a6%e6%9d%a5%e7%9a%84%e5%bd%b1%e5%93%8d" aria-label="DS R1所带来的影响">DS R1所带来的影响</a></li>
                <li>
                    <a href="#%e7%9b%b8%e5%85%b3%e8%b5%84%e6%96%99%e6%b1%87%e6%80%bb" aria-label="相关资料汇总">相关资料汇总</a></li></ul>
                </li>
                <li>
                    <a href="#%e5%bc%80%e5%8f%91%e5%9b%a2%e9%98%9f%e7%9a%84gen-ai%e4%bd%bf%e7%94%a8%e6%8c%87%e5%8d%97" aria-label="开发团队的Gen-AI使用指南">开发团队的Gen-AI使用指南</a><ul>
                        
                <li>
                    <a href="#prerequisite%e6%a8%a1%e5%9e%8bapi%e6%9c%8d%e5%8a%a1" aria-label="Prerequisite：模型API服务">Prerequisite：模型API服务</a></li>
                <li>
                    <a href="#prerequisite%e7%a7%81%e6%9c%89%e5%8c%96%e9%83%a8%e7%bd%b2" aria-label="Prerequisite：私有化部署">Prerequisite：私有化部署</a></li>
                <li>
                    <a href="#%e5%b8%b8%e8%a7%81%e7%9a%84ai-coding-%e7%bc%96%e8%be%91%e5%99%a8" aria-label="常见的AI-coding 编辑器">常见的AI-coding 编辑器</a></li>
                <li>
                    <a href="#%e5%a6%82%e4%bd%95coding-with-ai%e6%ad%a3%e7%a1%ae%e6%89%93%e5%bc%80%e6%96%b9%e5%bc%8f" aria-label="如何Coding with AI：正确打开方式">如何Coding with AI：正确打开方式</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b8%80%e4%ba%9b%e8%a1%a5%e5%85%85" aria-label="一些补充">一些补充</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="写在前面">写在前面<a hidden class="anchor" aria-hidden="true" href="#写在前面">#</a></h2>
<p>本文是前段时间部门内技术分享的文字稿整理；</p>
<p>主要包含2个方面：对于R1模型的简单科普，和开发团队的gen-AI使用指南；</p>
<p>原以为春节假期能稍作休整，未曾料想deepSeek-R1在春节期间引发行业关注。节后复工，各层级领导便密集展开AI技术进展问询。</p>
<p>原计划的&quot;二月摸鱼指南&quot;彻底落空，既要向管理层科普大语言模型技术原理，又要指正领导们被各种营销号洗脑所形成的错误认知；既要推进部门AI应用培训，又要加速系统上线进程；简直了，真是TM的谢谢 DeppSeek了。</p>
<h2 id="about-ds-r1">About DS R1<a hidden class="anchor" aria-hidden="true" href="#about-ds-r1">#</a></h2>
<h3 id="什么是reasoning-model">什么是Reasoning model<a hidden class="anchor" aria-hidden="true" href="#什么是reasoning-model">#</a></h3>
<blockquote>
<p>何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；<strong>推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。</strong></p>
</blockquote>
<blockquote>
<p>In <em>Thinking, Fast and Slow</em>, Daniel Kahneman defined System 1 as the automatic, intuitive mode of thinking, and System 2 as the slower, more analytical mode. In the context of autoregressive language models, the usual inference process is akin to System 1 — models generate answers directly. Reasoning is System 2 thinking - models or systems takes time to deliberate to solve more complex problems.</p>
</blockquote>
<p>LLMs本质上是一个根据上文预测下一个token的自回归模型，那么这样的模型是否具备逻辑推理能力呢？从表现特征来看，LLMs更类似于&quot;文科生&quot;的思维模式——在应对需要复杂推理的数学演算、自然科学问题解析及代码编写等场景时，其表现往往力不从心。</p>
<p>如何让模型的推理能力提升呢？CoT（Chain of Thought， <a href="https://arxiv.org/abs/2201.11903">Wei et al. 2022</a>）即“思维链”，是一种使LLM“逐步思考”的方法。它通过要求模型展示解决问题的中间步骤来加强其逻辑推理能力，从而提高决策的质量和准确性。</p>
<p><img loading="lazy" src="/img/%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0!%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb!%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88-assets/%e6%88%aa%e5%b1%8f2024-05-08%2015.37.21.png" alt="截屏2024-05-08 15.37.21.png"  />
</p>
<p>CoT更多是从prompting角度， 要求LLM以一定的格式进行回答（“think step by step”），模型对于没有在pre-training中涉及的内容时，效果并不太好，因为过去的LLM训练过程中， 不论是pre-training（预测下一个token）还是SFT（要求模型按照一定的格式输出），都与模型的reasoning 无关，CoT所所展示出的效果，及模型展现出的“推理”，更像是某种程度的“涌现”，而非专门针对性训练，当然也有认为LLMs似乎是在背答案而非真正的推理<a href="https://aiguide.substack.com/p/can-large-language-models-reason">Can Large Language Models Reason?</a></p>
<p>自2024年9月后， OpenAI推出了 o-1 系列模型，也就是世界上第一个推理模型，同时也是第一个专门针对推理任务的模型， 只是“CloseAI” 所提供的信息非常有限， 并没有人知道其如何实现的，大家对其猜测五花八门。</p>
<p><img loading="lazy" src="https://cdn.openai.com/API/images/guides/reasoning_tokens.png" alt=""  />
</p>
<p>（from <a href="https://platform.openai.com/docs/guides/reasoning">openAI</a>）</p>
<p>这一切，直到DS R1的出现，才似乎尘埃落定。</p>
<h3 id="ds-r1做了什么">DS R1做了什么<a hidden class="anchor" aria-hidden="true" href="#ds-r1做了什么">#</a></h3>
<p>一切，从DS提供的<a href="https://arxiv.org/abs/2501.12948">论文</a>出发。</p>
<p>主要贡献有3点：</p>
<ol>
<li>
<p><strong>如何通过纯RL训练提升模型的推理能力</strong>（DeepSeek-R1-Zero）： 直接在基础模型（DeepSeek-V3-Base）上应用大规模RL，无需SFT作为预热，首次验证纯RL可激励LLM的推理能力,而非采用Reward model 或MCTS。</p>
</li>
<li>
<p><strong>如何通过冷启动数据和多阶段训练优化模型的可读性和综合性能</strong>（DeepSeek-R1）：引入少量冷启动数据（数千条长CoT示例）进行微调，再通过两阶段RL（推理优化+人类偏好对齐）和SFT提升性能与可读性</p>
</li>
<li>
<p><strong>如何将大模型的推理能力高效迁移到小模型</strong>： 将大模型（DeepSeek-R1）生成的80万条数据蒸馏到小模型（如Qwen、Llama系列），显著提升小模型推理能力，甚至超越直接对小模型应用RL的效果</p>
</li>
</ol>
<p>具体而言，对于DeepSeek-R1-Zero，采用了GRPO（Group Relative Policy Optimization，正是DS团队在其另一篇工作DeepSeekMath中所开发的方法），不同于PPO，GRPO无需critic model，降低的显存使用，同时更简化训练过程也让训练过程更高效和稳定。</p>
<p>此外， 采用FP8（8位浮点数）精度进行训练，也降低了显存占用。</p>
<p>在奖励机制设计上，采用了rule-based的设计，兼顾Accuracy reward（正确的coding或数学推理结果）与Format rewards（遵循指定输出格式，语言一致性、标记使用等）。</p>
<p>通过强制模型输出结构化内容（如<think>推理过程</think>和<answer>答案</answer>）有效引导模型行为；</p>
<p><img loading="lazy" src="/img/%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0!%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb!%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88-assets/%e6%88%aa%e5%b1%8f2025-01-23%20%e4%b8%8a%e5%8d%889.03.11.png" alt="截屏2025-01-23 上午9.03.11.png"  />
</p>
<p>DeepSeek-R1-Zero 因采用base-model RL获得，存在<strong>Language Mixing</strong> ，以及可读性差，对特定任务泛化能力差（因训练目标单一）等问题</p>
<p>DeepSeek-R1为了解决以上问题：</p>
<p>→ 引入了语言一致性奖励</p>
<p>→ 使用从RL阶段生成的checkpoint,通过拒绝采样来筛选出高质量的推理样本</p>
<p>大致流程：</p>
<p>SFT(用高质量COT启动RL，以避免早期不稳定性) → 推理强化学习 → SFT(推理+通用领域数据) → 对齐强化学习</p>
<p>同时， 将DeepSeek-R1生成的80万条数据用于微调小模型，小模型直接继承大模型的推理模式，性能远超直接对小模型应用RL。</p>
<p><img loading="lazy" src="/img/%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0!%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb!%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88-assets/Pasted%202025-02-19-17-09-18.webp" alt="Pasted 2025-02-19-17-09-18.webp"  />
</p>
<h3 id="意义和需要澄清的内容">意义和需要澄清的内容<a hidden class="anchor" aria-hidden="true" href="#意义和需要澄清的内容">#</a></h3>
<p>从意义上讲，这是首个在推理能力上与OpenAI o1系列商业模型达到同等水平的开源模型（开源模型权重和公开部分训练细节）；同时，个人认为R1-zero的意义会比R1来的更加重要，因为其完全是基于rule-base RL训练的reasoning 模型， 具备了自我纠错反思的“aha moment“，为开源社区探明了道路，而不是遮遮掩掩的（说的就是你__）；此外， 对于小模型直接用大模型蒸馏从而提升reasoning能力，而不是直接在小模型上RL，为资源受限场景下的模型优化提供了极具参考价值的技术路径。</p>
<p>一些需要澄清的点：</p>
<ol>
<li>
<p><strong>Nvidia股价大跌，不需要Nvidia了吗</strong>：从模型推理的角度，可能有其他的选择，但对于开发运维人员角度，因其生态位和开源社群，Nvidia依旧是首选；训练方面依旧是不可撼动的；</p>
</li>
<li>
<p><strong>DS是通过chatGPT蒸馏出来的？</strong>：并没有证据能够证明这一点，任何模型对于“自己是谁”的回答都是不具备任何参考价值的，往往都是幻觉。</p>
</li>
<li>
<p><strong>赢</strong>？不太希望将这件事上升到这样的高度，保持理智，不要捧杀DS，AGI的路还挺长的，任何看完之后心潮澎湃的文章多半都是新闻学的胜利和对于民族主义情绪之利用；但必须承认一点，无论是中美，还是开源闭源的差距都没有想象中的大，似乎差距正在不断缩小。</p>
</li>
<li>
<p>**教你本地部署满血版DS-R1？只要99入门到精通？<strong>少焦虑，多接触优质信息源，如Twitter(X)上一线研究员的发言讨论和TA们的blog，huggingface上的论文推荐，以及</strong><a href="https://zhuanlan.zhihu.com/p/682110383">更新：2024年AI领域最值得关注的博主和一手信息源盘点</a>；对于DS- R1所需要的推理硬件参数会在后面专门聊，这里先不展开了。</p>
</li>
</ol>
<h3 id="泼一些冷水">泼一些冷水<a hidden class="anchor" aria-hidden="true" href="#泼一些冷水">#</a></h3>
<p>DS R1的<strong>幻觉挺严重</strong>的，不论是使用体验上，还是从Vectara’s <a href="https://huggingface.co/vectara/hallucination_evaluation_model">HHEM</a>的幻觉评测指标上看。</p>
<p><img loading="lazy" src="/img/%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0!%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb!%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88-assets/%e6%88%aa%e5%b1%8f2025-02-10%20%e4%b8%8a%e5%8d%8810.26.03.png" alt="截屏2025-02-10 上午10.26.03.png"  />
</p>
<p>（from <strong><a href="https://www.vectara.com/blog/deepseek-r1-hallucinates-more-than-deepseek-v3">DeepSeek-R1 hallucinates more than DeepSeek-V3</a></strong>）</p>
<p><strong>对齐不足</strong>。从现有的工作和实际效果上来看，DS在模型的对齐方面做的可能还不够。当然，这是把双刃剑，没有了限制，使其表现的更像人类的回答而不是AI，甚至有些细思极恐的回答，于是DS能够火出圈。关于reasoning model的安全性和对齐方面工作，大家也都还在摸索阶段，可以参考OpenAI的<a href="https://openai.com/index/deliberative-alignment/">Deliberative Alignment </a>相关工作。</p>
<p>R1解题coding可以，但follow-instruction 有点问题； 于是，更多是将R1作为planner用于任务规划和意图识别，从成本上考虑，短期不会替换之前的workflow和RAG设计，当然长期来看，一定会有超出workflow范畴的真正agent出现。</p>
<h3 id="ds-r1所带来的影响">DS R1所带来的影响<a hidden class="anchor" aria-hidden="true" href="#ds-r1所带来的影响">#</a></h3>
<ul>
<li>
<p>更高的回答准确率，代码质量等</p>
</li>
<li>
<p>大大降低prompting的门槛，用户意图识别效果更好（如果不考虑成本的话）</p>
</li>
<li>
<p>给推理模型加上工具调用，而不仅仅是思考（这不就有deep research出现了嘛）</p>
</li>
<li>
<p>指明了RL范式：只要给问题和答案， 中间过程交给RL，大力飞砖</p>
</li>
</ul>
<h3 id="相关资料汇总">相关资料汇总<a hidden class="anchor" aria-hidden="true" href="#相关资料汇总">#</a></h3>
<p>技术报告：<a href="https://arxiv.org/abs/2501.12948">https://arxiv.org/abs/2501.12948</a></p>
<p>Huggingface：<a href="https://huggingface.co/deepseek-ai/DeepSeek-R1">https://huggingface.co/deepseek-ai/DeepSeek-R1</a></p>
<p>一些关于R1的开源复刻工作&amp;信息汇总：</p>
<ul>
<li>
<p>Open-R1: <strong><a href="https://huggingface.co/blog/open-r1">Open-R1: a fully open reproduction of DeepSeek-R1</a></strong></p>
</li>
<li>
<p>RAGEN： <strong><a href="https://github.com/ZihanWang314/ragen/tree/main">RAGEN: A General-Purpose Reasoning Agent Training Framework</a></strong></p>
</li>
<li>
<p><a href="https://unsloth.ai/blog/deepseekr1-dynamic">Run DeepSeek R1 Dynamic 1.58-bit</a></p>
</li>
<li>
<p>Open Thoughts: <a href="https://github.com/open-thoughts/open-thoughts?tab=readme-ov-file">https://github.com/open-thoughts/open-thoughts?tab=readme-ov-file</a></p>
</li>
<li>
<p><a href="https://xcn2d971vuw4.feishu.cn/wiki/RaC2w1iiFijAa1kVJUjcp3agn8e">https://xcn2d971vuw4.feishu.cn/wiki/RaC2w1iiFijAa1kVJUjcp3agn8e</a></p>
</li>
<li>
<p><a href="https://github.com/ninehills/blog/issues/121">https://github.com/ninehills/blog/issues/121</a></p>
</li>
<li>
<p><strong><a href="https://aman.ai/primers/ai/deepseek-R1/">Primers • DeepSeek R1</a></strong></p>
</li>
<li>
<p><strong><a href="https://medium.com/@danushidk507/deepseek-r1-incentivizing-reasoning-capability-in-large-language-models-via-reinforcement-learning-9515a28a23ad">DeepSeek-R1: Incentivizing Reasoning Capability in Large Language Models via Reinforcement Learning — Paper Understanding</a></strong></p>
</li>
<li>
<p><a href="https://arcprize.org/blog/r1-zero-r1-results-analysis">An Analysis of DeepSeek&rsquo;s R1-Zero and R1</a></p>
</li>
</ul>
<h2 id="开发团队的gen-ai使用指南">开发团队的Gen-AI使用指南<a hidden class="anchor" aria-hidden="true" href="#开发团队的gen-ai使用指南">#</a></h2>
<p>这是一些关于一个开发团队如何使用，和高效使用Gen-AI的不完全指南</p>
<p>大体而言， 开发者使用AI通常有以下几个场景：</p>
<ul>
<li>
<p>高质量，有效率的coding</p>
</li>
<li>
<p>完善的开发文档，设计文档，测试用例</p>
</li>
<li>
<p>快速完成想法验证</p>
</li>
</ul>
<p>当然，一切的前提是，你有LLM可用</p>
<h3 id="prerequisite模型api服务">Prerequisite：模型API服务<a hidden class="anchor" aria-hidden="true" href="#prerequisite模型api服务">#</a></h3>
<p>当下模型服务有两大类 <strong>付费LLM-API</strong> 和基于<strong>本地私有化部署</strong>的方案（基于CPU或基于GPU）</p>
<p>采用在互联网上模型服务商所提供的模型API服务（如openAI，等），该方案适合绝大多数开发者，毕竟好的硬件设备并不是所有人都负担的起，其次，对于数据隐私有执念的，或是有足够硬件设备者，可以尝试采用本地模型部署，但由于本地硬件条件有限，一般只能部署开源的，参数量不大的模型；</p>
<p>具体而言，对于绝大多数模型服务商提供的模型服务，一般都支持统一的openAI chat-completion API 格式，支持tool-using，多模态使用，均可以使用openAI client调用；这对于Gen-AI应用开发而言是非常方便的事情，切换模型供应商唯一需要修改的只有API-KEY和BASE_URL；</p>
<p>而模型服务商又可分为3大类（或者更多？）</p>
<ul>
<li>
<p>闭源模型的API服务（openAI，Anthropic）</p>
</li>
<li>
<p>开源模型的Maas 服务商 （Groq，SiliconFlow和各大云厂商）</p>
</li>
<li>
<p>LLM-API 聚合平台 （OpenRouter）</p>
</li>
</ul>
<p>以下是整理的常见模型服务商：</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">分类</th>
          <th style="text-align: left">服务商</th>
          <th style="text-align: left">说明</th>
          <th style="text-align: left">链接</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>官方版本（数据安全）</strong></td>
          <td style="text-align: left">OpenAI</td>
          <td style="text-align: left">o3 系列（推理模型适合用于 bug 和问题分析）o1 系列，GPT-4o</td>
          <td style="text-align: left">-</td>
      </tr>
      <tr>
          <td style="text-align: left"></td>
          <td style="text-align: left">Anthropic</td>
          <td style="text-align: left">Claude-3.5-Sonnet（代码质量高）</td>
          <td style="text-align: left"><a href="https://console.anthropic.com/settings/keys">Anthropic</a></td>
      </tr>
      <tr>
          <td style="text-align: left"></td>
          <td style="text-align: left">Azure OpenAI</td>
          <td style="text-align: left">已停止对境内个人开发者开放服务，需要同合作伙伴商公对公签合同</td>
          <td style="text-align: left">-</td>
      </tr>
      <tr>
          <td style="text-align: left"></td>
          <td style="text-align: left">Gemini</td>
          <td style="text-align: left">提供一定的免费额度可使用</td>
          <td style="text-align: left"><a href="https://ai.google.dev/">Gemini</a></td>
      </tr>
      <tr>
          <td style="text-align: left"></td>
          <td style="text-align: left">DeepSeek</td>
          <td style="text-align: left">DS R1（个人信息认证后可使用，貌似还未恢复服务）</td>
          <td style="text-align: left"><a href="https://platform.deepseek.com/api_keys">DeepSeek</a></td>
      </tr>
      <tr>
          <td style="text-align: left"></td>
          <td style="text-align: left">阿里云</td>
          <td style="text-align: left">Qwen2.5-max</td>
          <td style="text-align: left"><a href="https://account.aliyun.com/">阿里云</a></td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Maas 服务商</strong></td>
          <td style="text-align: left">Groq</td>
          <td style="text-align: left">速度飞快，开源模型</td>
          <td style="text-align: left"><a href="https://console.groq.com/playground">Groq</a></td>
      </tr>
      <tr>
          <td style="text-align: left"></td>
          <td style="text-align: left">SiliconFlow</td>
          <td style="text-align: left">国内的 Maas 服务商，支持大多数开源模型</td>
          <td style="text-align: left"><a href="https://cloud.siliconflow.cn/account/ak">SiliconFlow</a></td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>非官方 API 聚合平台</strong></td>
          <td style="text-align: left">OpenRouter</td>
          <td style="text-align: left">最大的 API 聚合平台之一，支持市面上绝大多数模型服务（安全性、隐私性需自行考虑）</td>
          <td style="text-align: left"><a href="https://openrouter.ai/settings/keys">OpenRouter</a></td>
      </tr>
  </tbody>
</table>
<h3 id="prerequisite私有化部署">Prerequisite：私有化部署<a hidden class="anchor" aria-hidden="true" href="#prerequisite私有化部署">#</a></h3>
<p>对于本地推理方案，推荐 ollama （cpu）和vllm，sglang （GPU）；</p>
<p>ollama：<a href="https://ollama.com/">https://ollama.com/</a>；</p>
<p>vllm：<a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html">https://docs.vllm.ai/en/latest/getting_started/quickstart.html</a></p>
<p>sglang：<a href="https://github.com/sgl-project/sglang">https://github.com/sgl-project/sglang</a></p>
<p>不过在采用私有化部署之前，需要确认的一件事是：<strong>判断硬件所支持的最大参数量模型？</strong></p>
<p>LLM推理时，显存占用来源有：<strong>推理精度，模型大小，context长度</strong></p>
<p><strong>简化计算</strong>：在FP16精度推理时,显存占用约为模型参数量的2倍(考虑中间激活值后可能接近2.5倍)。例如,7B参数的模型,纯参数显存占用约14GB(7B×2bytes),实际使用中因激活值等开销可能达到14-17GB;若采用int8量化,参数显存可减半。</p>
<p>推荐：<strong><a href="https://zhuanlan.zhihu.com/p/624740065">分析transformer模型的参数量、计算量、中间激活、KV cache</a></strong></p>
<p>此外，还需要搞清楚有哪些模型是DeepSeek R1？所谓满血版R1指的是谁？</p>
<p>从DS在HF的<a href="https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d">官方仓库</a>可以看到：</p>
<p><img loading="lazy" src="/img/%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0!%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb!%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88-assets/%e6%88%aa%e5%b1%8f2025-02-21%20%e4%b8%8b%e5%8d%883.59.37.png" alt="截屏2025-02-21 下午3.59.37.png"  />
</p>
<p><strong>满血版本指的是FP16精度下推理的DeepSeek-R1</strong></p>
<p>剩下的除了R1-zero是实验产物外，剩下都是通过R1在不同参数量的Qwen和Llama上蒸馏出来的reasoning模型；</p>
<p>对于满血版本，在FP16上推理，至少需要两台8卡H20服务器</p>
<p>而GGUF、AWQ、GPTQ 等则是适用于不同设备、不同框架的量化版本权重（Quantization）</p>
<p>以Ollama为例，在mac M3电脑上启动 DS-R1 14B的蒸馏模型</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ollama run deepseek-r1:14b
</span></span></code></pre></div><p>这里选择的原始模型是<code>deepseek-ai/DeepSeek-R1-Distill-Qwen-14B</code></p>
<p>不过是基于GGUF的Q4_K 版本，需要至少9GB的内存；</p>
<p>基于本地ollama启动的deepseek R1（蒸馏版本）对话：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;http://localhost:11434/v1&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">api_key</span><span class="o">=</span><span class="s1">&#39;ollama&#39;</span><span class="p">,</span> <span class="c1"># required, but unused</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">model</span><span class="o">=</span><span class="s2">&#34;deepseek-r1:14b&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;system&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;You are a helpful assistant.&#34;</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;Who won the world series in 2020?&#34;</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</span></span></code></pre></div><p>若采用vllm在GPU上推理模型时，需要额外增加参数<code>--enable-reasoning --reasoning-parser deepseek_r1</code>来支持R1 系列模型的Reasoning Outputs。</p>
<p>一些支持自定义API的chatbot UI工具：</p>
<ul>
<li>
<p><a href="https://github.com/CherryHQ/cherry-studio">Cherry Studio</a></p>
</li>
<li>
<p><a href="https://chatwise.app/">ChatWise</a></p>
</li>
<li>
<p><a href="https://anythingllm.com/">anythingllm</a></p>
</li>
<li>
<p>openChat</p>
</li>
<li>
<p>…</p>
</li>
</ul>
<h3 id="常见的ai-coding-编辑器">常见的AI-coding 编辑器<a hidden class="anchor" aria-hidden="true" href="#常见的ai-coding-编辑器">#</a></h3>
<p>代码自动补全，基于代码对话，自动错误识别，项目级别代码阅读和修改，代码建议</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">工具名称</th>
          <th style="text-align: left">功能概览</th>
          <th style="text-align: left">主要特点</th>
          <th style="text-align: left">收费情况</th>
          <th style="text-align: left">开源情况</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>Cursor AI</strong></td>
          <td style="text-align: left">基于VS Code的AI编辑器，集成GPT-4、Claude 3.5等模型</td>
          <td style="text-align: left">多行编辑与智能重写、自然语言编程、全局代码库问答、图像支持等</td>
          <td style="text-align: left">免费版、Pro版(20美元/月)、Business版(40美元/用户/月)，额外收费（按次计费）</td>
          <td style="text-align: left">客户端非完全开源，旧版本部分代码可见，依赖专有AI模型</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>GitHub Copilot</strong></td>
          <td style="text-align: left">代码补全、PR支持、智能聊天、企业级功能（知识库集成、定制模型）</td>
          <td style="text-align: left">支持多IDE、跨文件修改、Copilot Chat、PR生成等</td>
          <td style="text-align: left">免费版、Pro版(10美元/月)、Business版(19美元/用户/月)、Enterprise版(39美元/用户/月)</td>
          <td style="text-align: left">非开源，提供FauxPilot、Tabby等开源替代方案</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Codeium</strong></td>
          <td style="text-align: left">AI代码补全、上下文感知、多语言支持、智能聊天</td>
          <td style="text-align: left">支持40+开发环境、GPT-4优化、隐私与安全保障</td>
          <td style="text-align: left">免费版、团队版(12美元/用户/月)、企业版（定制化定价）</td>
          <td style="text-align: left">部分IDE插件开源（MIT协议），核心服务闭源</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Continue</strong></td>
          <td style="text-align: left">代码补全、上下文感知聊天、代码重写、自定义模型集成</td>
          <td style="text-align: left">本地部署方案、低延迟、隐私保护、多语言支持</td>
          <td style="text-align: left">基础功能免费，企业版定制化定价（需联系销售）</td>
          <td style="text-align: left">开源，Apache 2.0协议，支持自定义模型接入</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Cline</strong></td>
          <td style="text-align: left">支持多模型、终端命令执行、浏览器自动化、智能上下文管理</td>
          <td style="text-align: left">支持本地模型、API成本监控、沙盒安全机制、跨平台开发</td>
          <td style="text-align: left">开源（Apache 2.0协议），API成本自行承担，企业版(79美元/月起)</td>
          <td style="text-align: left">完全开源，Apache 2.0协议，支持自定义工具服务器（GitHub）</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>TabbyML</strong></td>
          <td style="text-align: left">本地化代码补全、问答引擎、AI实时交互</td>
          <td style="text-align: left">本地部署、支持多语言和IDE插件，定制化模型集成和GPU部署</td>
          <td style="text-align: left">社区版免费、团队版(19美元/用户/月)、企业版定制化计费</td>
          <td style="text-align: left">完全开源，Apache 2.0协议，支持自定义模型集成与本地GPU部署</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Windsurf</strong></td>
          <td style="text-align: left">Cascade Flow系统、多文件编辑、智能代码辅助、终端指令生成</td>
          <td style="text-align: left">AI代理、上下文感知、Supercomplete预测、实时错误修复、隐私保护</td>
          <td style="text-align: left">免费版、Pro版(15美元/月)、Pro Ultimate版(60美元/月)；新用户可免费试用2个月</td>
          <td style="text-align: left">当前版本未开源，基于VS Code架构，核心AI功能为闭源实现</td>
      </tr>
  </tbody>
</table>
<h3 id="如何coding-with-ai正确打开方式">如何Coding with AI：正确打开方式<a hidden class="anchor" aria-hidden="true" href="#如何coding-with-ai正确打开方式">#</a></h3>
<p>如何使用AI，方法论比工具重要</p>
<blockquote>
<p>The reality is that AI is like having a very eager junior developer on your team. … <strong>The more you know, the better you can guide them.</strong></p>
</blockquote>
<blockquote>
<p>I&rsquo;ve watched <strong>senior engineers</strong> use AI to: <strong>Rapidly prototype ideas</strong> they already understandGenerate basic implementations they can then refineExplore alternative approaches to known problemsAutomate routine coding tasks … Meanwhile, <strong>juniors often: Accept incorrect or outdated solutionsMiss</strong> critical security and performance considerationsStruggle to debug AI-generated codeBuild fragile systems they don&rsquo;t fully understand</p>
</blockquote>
<p>（from <a href="https://newsletter.pragmaticengineer.com/p/how-ai-will-change-software-engineering">How AI-assisted coding will change software engineering: hard truths</a>）</p>
<p><strong>Senior 工程师更能从AI 辅助编程中获益</strong>，而非初学者。</p>
<p><strong>Senior</strong> 工程师能够判断AI的结果是否正确，和更加有针对性的提问，从而更好的发挥出AI的作用</p>
<p>最重要的是，senior工程师更多是利用AI作头脑风暴和原型验证，在1小时内完成过去3天的原型验证，从而大大减少走弯路的时间；这种&quot;加速已知，探索可能&quot;的范式转变，正在重构传统研发流程的边界</p>
<p>相反的，Junior工程师往往无法很好的判断AI给出的代码是否正确或者何时，往往只是AI代码的搬运工，同时，往往无法很好的向AI进行提问</p>
<p>再者，开发工程师的工作不只是开发，约占1/6左右，剩下还有大量的撰写文档、设计、沟通交流、看文档、code review等，AI虽然可以帮助完成部分简单和重复的任务，很显然，AI远没有达到替代人的程度，至少是当下，AI仍然需要人类的指导和判断。</p>
<p>只是当下，<strong>对于Junior工程师的培养将会是个问题</strong>。</p>
<blockquote>
<p>My beehive-kicking post’s main premise is pretty simple and can be visualized in terms of two different kinds of task that arise on software projects.</p>
</blockquote>
<blockquote>
<p>We often give these <strong>leaf node tasks to junior developers</strong> because the scope is small. … LLMs can now execute most of the leaf tasks and even some higher-level interior tasks … Which are not the kind of task that you typically give junior developers. … Junior devs are deeply affected, though, and it’s a concern.</p>
</blockquote>
<blockquote>
<p>You are getting left behind if you do not adopt chat-based programming as your primary modality.</p>
</blockquote>
<p>（from <a href="https://steve-yegge.medium.com/the-death-of-the-stubborn-developer-b5e8f78d326b">The Death of the Stubborn Developer</a>）</p>
<p>过去培养新人时，通常安排其承担简单且独立的&quot;leaf node&quot;任务，通过项目实践积累经验，实现能力提升。然而，随着AI技术普及，这些基础任务已可被高效且精准地完成，新人面临的处境变得愈发尴尬，失去通过基础任务积累系统认知的机会。</p>
<p>当前企业面临双重挑战，既要维持业务效率，又需保障工程师培养体系的可持续性，二者并非绝对对立，但需重新设计技术成长阶梯以实现平衡。</p>
<p><strong>技术债管理能力正成为团队竞争力的关键分水岭</strong>。AI技术将加剧低技术债务团队与高技术债务团队间的马太效应。</p>
<blockquote>
<p>that <strong>generative AI dramatically widens the gap in velocity between ‘low-debt’ coding and ‘high-debt’ coding</strong>.</p>
</blockquote>
<blockquote>
<p>In other words, the penalty for having a ‘high-debt’ codebase is now larger than ever.</p>
</blockquote>
<blockquote>
<p>However, in ‘high-debt’ environments with subtle control flow, long-range dependencies, and unexpected patterns, they struggle to generate a useful response.</p>
</blockquote>
<blockquote>
<p>Day-to-day feature work should then be done on top of this foundation with maximum leverage from generative AI tooling.</p>
</blockquote>
<p>（from <a href="https://www.gauge.sh/blog/ai-makes-tech-debt-more-expensive">AI Makes Tech Debt More Expensive</a>）</p>
<ul>
<li>
<p>高技术债务团队因代码结构混乱、模式不统一（如多重继承滥用、接口定义缺失），导致AI难以有效解析上下文逻辑。开发人员不得不耗费大量精力处理历史遗留问题（如兼容性适配、脆弱性修补），形成<strong>技术维护的恶性循环</strong>。</p>
</li>
<li>
<p>低技术债务团队凭借清晰的架构设计（模块化、标准化接口），使AI辅助开发工具能准确识别代码意图，快速完成功能扩展与问题定位。这种优势使其可将资源集中投入创新性工作，形成<strong>技术演进的正向循环</strong>。</p>
</li>
</ul>
<p>个人的一些建议：</p>
<ul>
<li>
<p>明确LLM的认知边界，用结构化指令替代模糊需求</p>
</li>
<li>
<p>用生成结果反推思维盲区，意识到想法中的不足之处（stay humble）</p>
</li>
<li>
<p>对存疑输出实施交叉验证，批判性接受</p>
</li>
<li>
<p>新人学习策略：利用AI工具学习代码而不是复制代码，多追问为什么</p>
</li>
</ul>
<p>在未来，人机协同范式将重塑人才能力评价体系，一些核心素养将成为关键竞争力。</p>
<p>重中之重是语言表达和写作能力。从当前实践和身边的例子中，发现一个典型困境：诸多理工科从业者虽具备缜密的逻辑分析能力，却难以将复杂需求转化为精准的指令表述。这种表达能力缺失导致其在使用生成式AI时频繁遭遇预期偏差，既影响工作效率，又易形成对技术效能的误判。或许这已经是这个社会的通病了。即便是具有一定“读心”能力的R1模型出现，Gen-AI的使用依旧还是有一定门槛的。</p>
<p>再者，批判性思维的培养也非常重要；当前Gen-AI使用者呈现明显的认知极化现象：部分因遭遇AI失误而全盘否定其应用价值，表现为技术抗拒倾向；另一极端则对AI输出盲目采信，缺乏基本的内容鉴别能力。真正科学的态度应当是在理解AI能力边界的基础上，合理利用其优势，同时保持独立思考和批判性判断。这正是批判性思维的核心价值所在——面对AI生成内容时，能够主动分析、质疑、验证信息的真实性和可靠性，从而在技术应用中保持理性、客观的态度。</p>
<p>除此之外，并不需要去害怕和担心AI取代人，开发者群体应建立正确的工具认知：编程能力本质上是解决问题的工具而非目的本身。AI作为效率倍增器，其价值在于辅助人类突破效率边界。真正需要持续积累的是问题抽象能力、解决方案架构能力以及行业专有知识库——这些通过实践沉淀的思维链（CoT）构成了人类认知的护城河，是当前AI技术难以企及的领域。保持开放的技术观，聚焦能力提升而非技术替代焦虑，避免因FOMO（Fear of missing out）而被人割韭菜。</p>
<p>AI赋能的超级个体正在重构生产组织方式。在过去，企业依赖层级架构，和明确的分工，随着AI工具的广泛应用， 个体的生产力得到了指数级提升，许多过去需要团队协作才能完成的任务，如今单个个体借助AI即可高效完成。这种能力的跃迁，使得传统组织架构的效率优势逐渐被削弱，甚至在某些场景下变得冗余。在这种背景下，生产力关系的重构成为必然趋势。组织形态向更加扁平化、小型化的方向演进，扁平化意味着组织内部的决策链条缩短，信息流转更加高效，个体拥有更大的自主权和决策空间，而非将大量时间用于无效的沟通上。未来，个人或小型团队借助AI工具，可以像过去的大型企业一样高效运作，甚至在某些领域超越传统组织的效率。</p>
<h2 id="一些补充">一些补充<a hidden class="anchor" aria-hidden="true" href="#一些补充">#</a></h2>
<p>领域Benchmark构建非常重要。当前针对法律、医疗等垂直领域已形成专业评估体系，但多数行业仍缺乏系统的LLM评估标准，导致在模型选型时过度依赖个体经验判断。</p>
<p>重新审视专业壁垒:预训练模型可能已覆盖领域基础知识体系,现存&quot;专业门槛&quot;或存在人为构建的术语壁垒；<strong>领域内高质量的CoT数据，思考方式才是关键</strong></p>
<p>随着LLM能力的提升，过去我们精心设计的许多工程方案可能会变得不再必要，甚至过时。不断学习和适应，不要固步自封，技术迭代是以天为单位的；拥抱和参与开源，而不是技术封建主义。</p>
<p>LLM reasoning 能力提升后，短期内，RAG，Agent， workflow不会有太大变化</p>
<p>Post-training很重要</p>
<p>同时间段开源的Qwen/Qwen2.5-VL-72B-Instruct 也值得关注</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://niraya666.github.io/tags/%E6%9D%82/">杂</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://niraya666.github.io/posts/rlhf-%E4%B9%8B%E8%B7%AF%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0%E4%B9%8B%E4%B8%8A%E7%AF%87/">
    <span class="title">Next »</span>
    <br>
    <span>RLHF 之路：强化学习复习之上篇</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 当AI开始展现&#34;顿悟时刻&#34;意味着什么 on x"
            href="https://x.com/intent/tweet/?text=%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0%22%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb%22%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88&amp;url=https%3a%2f%2fniraya666.github.io%2fposts%2f%25E5%25BD%2593ai%25E5%25BC%2580%25E5%25A7%258B%25E5%25B1%2595%25E7%258E%25B0%25E9%25A1%25BF%25E6%2582%259F%25E6%2597%25B6%25E5%2588%25BB%25E6%2584%258F%25E5%2591%25B3%25E7%259D%2580%25E4%25BB%2580%25E4%25B9%2588%2f&amp;hashtags=%e6%9d%82">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 当AI开始展现&#34;顿悟时刻&#34;意味着什么 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fniraya666.github.io%2fposts%2f%25E5%25BD%2593ai%25E5%25BC%2580%25E5%25A7%258B%25E5%25B1%2595%25E7%258E%25B0%25E9%25A1%25BF%25E6%2582%259F%25E6%2597%25B6%25E5%2588%25BB%25E6%2584%258F%25E5%2591%25B3%25E7%259D%2580%25E4%25BB%2580%25E4%25B9%2588%2f&amp;title=%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0%22%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb%22%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88&amp;summary=%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0%22%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb%22%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88&amp;source=https%3a%2f%2fniraya666.github.io%2fposts%2f%25E5%25BD%2593ai%25E5%25BC%2580%25E5%25A7%258B%25E5%25B1%2595%25E7%258E%25B0%25E9%25A1%25BF%25E6%2582%259F%25E6%2597%25B6%25E5%2588%25BB%25E6%2584%258F%25E5%2591%25B3%25E7%259D%2580%25E4%25BB%2580%25E4%25B9%2588%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 当AI开始展现&#34;顿悟时刻&#34;意味着什么 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fniraya666.github.io%2fposts%2f%25E5%25BD%2593ai%25E5%25BC%2580%25E5%25A7%258B%25E5%25B1%2595%25E7%258E%25B0%25E9%25A1%25BF%25E6%2582%259F%25E6%2597%25B6%25E5%2588%25BB%25E6%2584%258F%25E5%2591%25B3%25E7%259D%2580%25E4%25BB%2580%25E4%25B9%2588%2f&title=%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0%22%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb%22%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 当AI开始展现&#34;顿悟时刻&#34;意味着什么 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fniraya666.github.io%2fposts%2f%25E5%25BD%2593ai%25E5%25BC%2580%25E5%25A7%258B%25E5%25B1%2595%25E7%258E%25B0%25E9%25A1%25BF%25E6%2582%259F%25E6%2597%25B6%25E5%2588%25BB%25E6%2584%258F%25E5%2591%25B3%25E7%259D%2580%25E4%25BB%2580%25E4%25B9%2588%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 当AI开始展现&#34;顿悟时刻&#34;意味着什么 on whatsapp"
            href="https://api.whatsapp.com/send?text=%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0%22%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb%22%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88%20-%20https%3a%2f%2fniraya666.github.io%2fposts%2f%25E5%25BD%2593ai%25E5%25BC%2580%25E5%25A7%258B%25E5%25B1%2595%25E7%258E%25B0%25E9%25A1%25BF%25E6%2582%259F%25E6%2597%25B6%25E5%2588%25BB%25E6%2584%258F%25E5%2591%25B3%25E7%259D%2580%25E4%25BB%2580%25E4%25B9%2588%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 当AI开始展现&#34;顿悟时刻&#34;意味着什么 on telegram"
            href="https://telegram.me/share/url?text=%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0%22%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb%22%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88&amp;url=https%3a%2f%2fniraya666.github.io%2fposts%2f%25E5%25BD%2593ai%25E5%25BC%2580%25E5%25A7%258B%25E5%25B1%2595%25E7%258E%25B0%25E9%25A1%25BF%25E6%2582%259F%25E6%2597%25B6%25E5%2588%25BB%25E6%2584%258F%25E5%2591%25B3%25E7%259D%2580%25E4%25BB%2580%25E4%25B9%2588%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 当AI开始展现&#34;顿悟时刻&#34;意味着什么 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=%e5%bd%93AI%e5%bc%80%e5%a7%8b%e5%b1%95%e7%8e%b0%22%e9%a1%bf%e6%82%9f%e6%97%b6%e5%88%bb%22%e6%84%8f%e5%91%b3%e7%9d%80%e4%bb%80%e4%b9%88&u=https%3a%2f%2fniraya666.github.io%2fposts%2f%25E5%25BD%2593ai%25E5%25BC%2580%25E5%25A7%258B%25E5%25B1%2595%25E7%258E%25B0%25E9%25A1%25BF%25E6%2582%259F%25E6%2597%25B6%25E5%2588%25BB%25E6%2584%258F%25E5%2591%25B3%25E7%259D%2580%25E4%25BB%2580%25E4%25B9%2588%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
<div id="utterances">
  <script src="https://utteranc.es/client.js"
        repo="https://github.com/Niraya666/niraya666.github.io.git"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
  </script>
</div>


<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      packages: {'[+]': ['ams']}
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://niraya666.github.io/">LZY Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
