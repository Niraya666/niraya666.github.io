<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Posts | LZY Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - LZY Blog">
<meta name="author" content="Theme PaperMod">
<link rel="canonical" href="https://niraya666.github.io/posts/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://niraya666.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://niraya666.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://niraya666.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://niraya666.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://niraya666.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://niraya666.github.io/posts/index.xml">
<link rel="alternate" hreflang="en" href="https://niraya666.github.io/posts/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Posts" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://niraya666.github.io/posts/" />
<meta property="og:image" content="https://niraya666.github.io/images/papermod-cover.png" />


<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://niraya666.github.io/images/papermod-cover.png" />
<meta name="twitter:title" content="Posts"/>
<meta name="twitter:description" content=""/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://niraya666.github.io/posts/"
    }
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://niraya666.github.io/" accesskey="h" title="LZY Blog (Alt + H)">LZY Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://niraya666.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/posts/" title="AI">
                    <span class="active">AI</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/musik/" title="Musik!">
                    <span>Musik!</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/monthly/" title="月刊">
                    <span>月刊</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/essay/" title="杂文">
                    <span>杂文</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/travel/" title="游记">
                    <span>游记</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header"><div class="breadcrumbs"><a href="https://niraya666.github.io/">Home</a></div>
  <h1>
    Posts
    <a href="/posts/index.xml" title="RSS" aria-label="RSS">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
        stroke-linecap="round" stroke-linejoin="round" height="23">
        <path d="M4 11a9 9 0 0 1 9 9" />
        <path d="M4 4a16 16 0 0 1 16 16" />
        <circle cx="5" cy="19" r="1" />
      </svg>
    </a>
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">LangMem: 一些学习笔记
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>本文是我在阅读 LangMem 的源码与相关文档过程中整理的一些学习笔记。
一直以来，我对智能体（Agent）的记忆机制充满好奇：理想的 memory 应该具备怎样的结构？又该如何设计？目前市面上关于 memory 的实现大多中规中矩，尚未看到令人眼前一亮的方案。为此，我决定多参考一些开源项目，以期获得新的灵感。
总体来看，LangMem 作为 LangChain 推出的一款 memory 框架，设计上较为常规，虽有部分值得借鉴之处，但亮点不多，不建议投入过多时间深入研究。同时，与 LangChain 的其他项目类似，其代码结构和文档编写较为混乱，阅读体验不佳。
Core-Concepts core-concepts 在LangMem所设计的memory体系中， 定义了几种不同的Typical Storage Pattern：Collection 、 Profiles和Procedural
Collection Collection 主要用于存储不受限制的知识，适用于需要长期积累和检索的信息。每条记忆被存储为独立的文档或记录，可以在需要时进行搜索和回忆；
适用场景：记录用户的长期知识，例如用户的兴趣、职业背景、技能等
更新方式：需要合并新信息，避免重复或冲突
检索方式：通过语义搜索或关键词匹配来查找，结合记忆的重要性和使用频率来优化检索结果
Profiles 存储结构化的用户信息，例如用户的姓名、语言偏好、沟通风格等。与 Collection 不同，Profile 只存储最新的状态，而不是累积所有历史信息。Profile 作为单一文档存储，每次更新时都会覆盖旧数据
适用场景：适用于需要快速访问当前状态的应用，例如个性化推荐、用户设置；适用于需要严格定义数据结构的场景，例如用户档案、系统配置；
更新方式：不会创建新记录，而是直接更新现有的 Profile；适用于只关心最新状态的应用，而不是历史；
检索方式：直接查找用户的 Profile
Procedural Memory 类似于人类的工作记忆，用于存储如何执行任务的知识，主要体现在system prompts 和行为优化上
适用场景：需要长期优化 Agent行为和交互方式，少走弯路
总结
Memory Type 用途 智能体示例 典型存储模式 Semantic Facts &amp; Knowledge User preferences; knowledge triplets Profile或Collection Episodic Past Experiences Few-shot examples; 过往对话摘要 Collection Procedural System Behavior Core personality and response patterns Prompt rules或Collection Writing memories 提供了两种写入memory的方法：及时写入（适用于要求即时记忆反映的场景）和一段时间后的异步写入（适用于高效处理和存储大量信息的场景）
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-04-10 10:44:00 +0800 CST'>April 10, 2025</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Theme PaperMod</footer>
  <a class="entry-link" aria-label="post link to LangMem: 一些学习笔记" href="https://niraya666.github.io/posts/langmem-%E4%B8%80%E4%BA%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">RAG工具箱：基于多模态大模型的文档解析方案（2025版）
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>Updated on 2025-03-29: Add SmolDocling &amp; VLM Summary
技术迭代速度之快令人惊叹，前作 RAG工具箱：文档解析与表格处理 在短短数月内已显现出代际差距，尽管前作也仅仅只是抛砖引玉式地讨论了pdf的解析方案，不过在新技术的面前，既有的复杂解析架构逐渐失去存在价值，也被端到端范式所取代。在笔者看来，基于多模态大模型的端到端文档解析方案，将成为最优解。
本文将探讨文档解析的终极形态——基于多模态大模型（VLM）的解析技术，包括Mistral-OCR、OlmOCR等前沿工具的实现与实践，并展望该领域的技术发展趋势，和对于RAG的影响。
过去的技术栈总结 在RAG系统中，文档解析质量直接决定系统上限。不同场景下的文档形态差异显著，若不能有效解决&#34;garbage in, garbage out&#34;的输入质量问题，后续处理环节将难以发挥应有价值。
传统文档解析技术长期受限于以下核心痛点：
结构化信息缺失：无法准确识别文档标题、副标题等层级结构
特殊内容处理薄弱：数学公式、专业符号解析准确率低下
复杂表格解析困境：跨页表格、合并单元格等场景支持不足
图像信息提取瓶颈：扫描文档、手写体识别效果欠佳
版式适应性问题：多栏布局、影印版本等文档格式兼容性差
从技术角度，过去文档解析的底层逻辑和框架：
纯文本解析: PyPDF, PyMuPDF只能解析pdf中的文字,对于公式表格和复杂排版解析无能,对于扫描版低质量的pdf无能为力
OCR方案（PaddleOCR等）: 首先使用目标检测模型对文档布局进行分析，识别出标题、表格等关键元素的位置，然后在这些位置上使用OCR技术提取文字；由于需要调用多个模型，整套系统非常复杂；
基于transformer 的解析方案（代表: Dount, Nougat）：专门针对英文的学术文章做的训练, 能够将pdf文章整理成Markdown或Latex格式；但对于其他语言和其他类型的文档泛化效果很差；
随着模型能力提升，采用VLM做解析是非常自然的想法，尽管GPT-4o的发布使该技术获得广泛关注，但其高昂的API成本制约了实际应用。值得庆幸的是，开源社区的技术突破正在改变这一局面：不论是LLM基座模型多模态理解能力的增强，还是视觉编码器的提升，至少在当下，开源VLM已具备实用级文档解析能力，而无需针对下游任务的微调，同时成本上已经在可接受范围了。
Benchmark 为了判断一个模型是否适合Document Parsing，需要benchmark测试分数，作为模型挑选的标准。
现阶段，针对LLMs在OCR、文档信息提取场景下主要采用以下几个常见的bench
OCRBench、OCRBench-V2
OmniDocBench
CC-OCR
…and more
（关于benchmark的具体内容见附录）
这些bench都基本上包含了通用场景下的OCR能力， 多语言的文档解析能力的测试，能够一定程度上作为模型筛选的关注首选
当然，除了模型能力以外，还需要关注模型的参数量，因为与其成本和latency息息相关。
不过，对于每一个具体场景，还是需要构建自己的测试集用于判断模型是否能够胜任任务， 因为benchmark所包含的测试场景数据，分布语言等等和具体的场景不见得完全一样。
根据benchmark和实际测试结果，目前几个值得关注的开源VLM：
Qwen2.5-VL
Phi-4-multimodal
Llama 3.2 Vision
olmocr
and more …
Qwen2.5-VL系列模型 cookbook
Blog
Technical Report
这应该是开源的模型中，效果排前列的多模态模型（截止至今），同时还具备了多种参数量（3B，7B，72B）可选择。
在Technical Report 中一些和document-parse有关的内容：
在第一阶段视觉预训练中（仅训练ViT），针对Document Parsing，设计了一套标准化的HTML标签体系，包含：段落（p&gt;）、表格（&lt;table&gt;）、图表（&lt;div class=&#34;chart&#34;&gt;）、公式（&lt;div class=&#34;formula&#34;&gt;）、图像标注（&lt;div class=&#34;image caption&#34;&gt;）、OCR文本（&lt;div class=&#34;image ocr&#34;&gt;）、乐谱（&lt;div class=&#34;music sheet&#34;&gt;）、化学式（&lt;div class=&#34;chemical formula&#34;&gt;）等模块。每个模块均通过 data-bbox 属性标注其原始坐标位置，保留空间布局信息; 同时所有文档元素的布局信息（如位置、尺寸）通过原生分辨率下的绝对坐标直接编码到HTML标签中，使模型能同时学习内容语义和空间关系
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-03-12 16:44:00 +0800 CST'>March 12, 2025</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Theme PaperMod</footer>
  <a class="entry-link" aria-label="post link to RAG工具箱：基于多模态大模型的文档解析方案（2025版）" href="https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%87%E6%A1%A3%E8%A7%A3%E6%9E%90%E6%96%B9%E6%A1%882025%E7%89%88/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">RAG工具箱：RAG Tutorial for Beginner
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>一些适合入门的RAG材料
原理、科普 Retrieval Augmented Generation (RAG) for LLMs
Langchain|Retrieval augmented generation (RAG)
A Practitioners Guide to Retrieval Augmented Generation (RAG)
RAG for Beginners: The Complete Guide to Retrieval Augmented Generation
What is Retrieval Augmented Generation (RAG)?
Retrieval augmented generation (RAG)
思考题：
Why RAG？ RAG解决了什么问题？RAG和SFT如何选择？RAG的优势？
什么样的问题是RAG无法解决的？什么样的数据适合使用RAG
为什么要做chunking？chunk-size受那些因素制约？
什么是embedding？向量库在做什么？一定要做语义匹配吗？什么是reranking？
如何evaluate 检索效果的好坏 ？
RAG中，LLMs起到的作用？
Hands-On 前置任务 获取模型服务：
获得LLMs供应商API： 推荐 OpenRouter（仅LLMs，需要梯子，境外信用卡或Crypto），SilconFlow（LLMs&#43;embedding,无需梯子,有送token），Groq（仅LLMs, 需梯子，速度快，免费）
或采用本地部署： 推荐Ollama
例子,采用openRouter API实现LLM对话：
from openai import OpenAI client = OpenAI( base_url=&#34;https://openrouter.ai/api/v1&#34;, api_key=&#34;&lt;OPENROUTER_API_KEY&gt;&#34;, ) completion = client.chat.completions.create( model=&#34;openai/gpt-4o&#34;, messages=[ { &#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;What is the meaning of life?&#34; } ] ) print(completion.choices[0].message.content) 例子：基于本地ollama启动的deepseek R1（蒸馏版本）对话
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-03-11 19:24:00 +0800 CST'>March 11, 2025</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Theme PaperMod</footer>
  <a class="entry-link" aria-label="post link to RAG工具箱：RAG Tutorial for Beginner" href="https://niraya666.github.io/posts/rag-tutorial-for-beginner/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">当AI开始展现&#34;顿悟时刻&#34;意味着什么
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>写在前面 本文是前段时间部门内技术分享的文字稿整理；
主要包含2个方面：对于R1模型的简单科普，和开发团队的gen-AI使用指南；
原以为春节假期能稍作休整，未曾料想deepSeek-R1在春节期间引发行业关注。节后复工，各层级领导便密集展开AI技术进展问询。
原计划的&#34;二月摸鱼指南&#34;彻底落空，既要向管理层科普大语言模型技术原理，又要指正领导们被各种营销号洗脑所形成的错误认知；既要推进部门AI应用培训，又要加速系统上线进程；简直了，真是TM的谢谢 DeppSeek了。
About DS R1 什么是Reasoning model 何为推理（reasoning）：是对信息进行处理和推断，形成判断或结论的过程；推理通常是一个包含多个推断步骤的过程。推理通常被认为需要抽象思维——也就是说，推理的能力不局限于具体的例子，而是更为普遍的。
In Thinking, Fast and Slow, Daniel Kahneman defined System 1 as the automatic, intuitive mode of thinking, and System 2 as the slower, more analytical mode. In the context of autoregressive language models, the usual inference process is akin to System 1 — models generate answers directly. Reasoning is System 2 thinking - models or systems takes time to deliberate to solve more complex problems.
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-02-23 23:00:00 +0800 CST'>February 23, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Theme PaperMod</footer>
  <a class="entry-link" aria-label="post link to 当AI开始展现&#34;顿悟时刻&#34;意味着什么" href="https://niraya666.github.io/posts/%E5%BD%93ai%E5%BC%80%E5%A7%8B%E5%B1%95%E7%8E%B0%E9%A1%BF%E6%82%9F%E6%97%B6%E5%88%BB%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">RLHF 之路：强化学习复习之上篇
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>写在前面 决定开启一个新系列，是时候系统性地学习一下 Alignment、RLHF 等相关内容了。
学习过程中，经常会在一些公式推导上卡住，可能是因为之前的基础不够扎实，加上学过的内容遗忘较多。 于是，希望通过这一系列的笔记，帮助自己系统地回顾RL、和学习RLHF等内容。（顺带把之前手写的笔记电子化）
主要的教材来自：
Reinforcement Learning: An Introduction
B站UP主 shuhuai008 的系列推导视频
本篇笔记将包含以下的内容：
MDP
DP
Monte Carlo Methods
TD方法
马尔可夫决策过程(Markov Decision Process，MDP) MDPs are meant to be a straightforward framing of the problem of learning from interaction to achieve a goal.
相关概念 随机变量（Random Variance）： ( $X, \ y, \ x \perp y$)，随机变量之间存在的独立性。
随机过程（Stochastic Process）： ${S_t}_{t=1}^{\infty}$ 一个时间序列的随机变量集合，通常用来描述随着时间变化的状态。
Markov链/过程（Markov Chain/Process）：强调了Markov性质（Markov Property），即未来的状态仅依赖于当前状态而与过去无关，形式化地表示为：
$$ P(S_{t&#43;1}|S_t, S_{t-1}, …,S_1) = P(S_{t&#43;1}|S_{t}) $$
状态空间模型（State Space Model）： Markov Chain &#43; Observation； 如 HMM， Kalman Filter，particle Filter。
...</p>
  </div>
  <footer class="entry-footer"><span title='2025-01-23 15:21:00 +0800 CST'>January 23, 2025</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Theme PaperMod</footer>
  <a class="entry-link" aria-label="post link to RLHF 之路：强化学习复习之上篇" href="https://niraya666.github.io/posts/rlhf-%E4%B9%8B%E8%B7%AF%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0%E4%B9%8B%E4%B8%8A%E7%AF%87/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Milvus-2.5版本：学习笔记和备忘录
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>几年前初识 Milvus 的契机，来源于开发一个图像相似检索的应用，当时市面上向量库的可选择项并不像现在这么多，且功能也仅限于单纯的向量检索。
鉴于最近有业务更新的需要，和打算重构一下之前做的RAG项目，再次有机会深入学习 Milvus，探索其在新功能和实际应用上的更多可能性。
本篇笔记，仅作为学习笔记，更多是记录一些 Milvus从2.0 到2.5 的变化， 和一些动手实践的记录，便于之后的查阅。
一些概念 Collections, Schema and index Collection是Milvus中的一个二维表格，具有固定的列和可变的行。每一列代表一个字段(field)，每一行代表一个实体(entity)
Schema和字段 Collection需要一个schema来定义其结构
索引 在特定字段上创建索引可以提高搜索效率。建议为服务所依赖的所有字段创建索引，其中向量字段的索引是必需的。
分区(Partition) 分区是Collection的子集，与其父Collection共享相同的字段集
分片(Shard) 分片是Collection的水平切片。每个分片对应一个数据输入通道。
Shard vs Partition的区别 :
分区(Partition)的作用是通过指定分区名称来减少读取负载
而分片(Shard)的作用是将写入负载分散到多个服务器分布式架构中的应用 在分布式系统中，分片是实现水平扩展的重要机制。通过将数据分布到多个节点，可以充分利用集群的并行计算潜力，提高系统的写入性能
MilvusClient vs Connection MilvusClient
定位：更高级封装，提供一体化的操作接口。简化了与 Milvus 的交互流程， 提供更直观和结构化的操作方式，便于新手快速上手，内置了对连接的管理和操作，减少手动处理的复杂性。
from pymilvus import MilvusClient # 创建客户端并连接到 Milvus client = MilvusClient(uri=&#34;http://localhost:19530&#34;) # 创建集合 client.create_collection( name=&#34;example_collection&#34;, schema={&#34;fields&#34;: [{&#34;name&#34;: &#34;vector&#34;, &#34;type&#34;: &#34;FLOAT_VECTOR&#34;, &#34;params&#34;: {&#34;dim&#34;: 128}}]} ) # 插入数据 client.insert(&#34;example_collection&#34;, data={&#34;vector&#34;: [[0.1] * 128, [0.2] * 128]}) # 搜索 results = client.search(&#34;example_collection&#34;, data=[[0.1] * 128]) print(results) Connection
定位：基础连接操作，需要通过 connect 方法创建并维护连接。提供更底层的控制，适合灵活、自定义的操作。
from pymilvus import connections, Collection, FieldSchema, CollectionSchema # 创建连接 connections.connect(alias=&#34;default&#34;, host=&#34;localhost&#34;, port=&#34;19530&#34;) # 创建集合 fields = [ FieldSchema(name=&#34;vector&#34;, dtype=&#34;FLOAT_VECTOR&#34;, dim=128) ] schema = CollectionSchema(fields, description=&#34;example collection&#34;) collection = Collection(name=&#34;example_collection&#34;, schema=schema) # 插入数据 collection.insert([[0.1] * 128, [0.2] * 128]) # 搜索 collection.load() results = collection.search([[0.1] * 128], anns_field=&#34;vector&#34;, limit=10) print(results) Schema Schema 用于定义collection及其字段的属性
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-12-25 15:49:00 +0800 CST'>December 25, 2024</span>&nbsp;·&nbsp;15 min&nbsp;·&nbsp;Theme PaperMod</footer>
  <a class="entry-link" aria-label="post link to Milvus-2.5版本：学习笔记和备忘录" href="https://niraya666.github.io/posts/milvus-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%92%8C%E5%A4%87%E5%BF%98%E5%BD%95%E4%BB%8E2.0-%E5%88%B02.5%E7%89%88%E6%9C%AC%E7%9A%84%E4%BB%8E%E5%A4%B4%E5%AD%A6%E4%B9%A0/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Agent 学习笔记：框架 ｜ openAI Swarm
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>开篇 “CloseAI” 终于又开源了新的项目，可惜OpenAI明确表示，Swarm是一个实验性框架，主要用于教育目的，不适合生产环境，也没有官方支持。不过从这样一个实验性的框架，至少能够了解到OpenAI对于Agent上的一些理解，对于Agent设计上能够有所帮助和借鉴。
Routines and Handoffs 根据openAI cookbook: Orchestrating Agents: Routines and Handoffs**，**理解这个框架前首先需要理解的两个概念： Routines 和 Handoffs。
The notion of a “routine” is not strictly defined, and instead meant to capture the idea of a set of steps. Concretely, let’s define a routine to be a list of instructions in natural language (which we’ll represent with a system prompt), along with the tools necessary to complete them.
Routines（常规）：是由一系列步骤构成的流程，可以理解为给定任务的执行步骤，包括对话系统中指令和所需工具的组合。从代码实现上，基本上就是围绕着openAI 的 openai.chat.completions.createAPI的一系列内容， 对话、工具调用等。换句话说，routines只是具有对话&#43;工具调用的chatbot，这也是openAI对于Agent的基础抽象。
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-11 11:10:00 +0800 CST'>November 11, 2024</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;Theme PaperMod</footer>
  <a class="entry-link" aria-label="post link to Agent 学习笔记：框架 ｜ openAI Swarm" href="https://niraya666.github.io/posts/agent-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%A1%86%E6%9E%B6--openai-swarm/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">RAG工具箱：Query Enhancement
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>引言 首先，从最简单的RAG（Retrieval-Augmented Generation）谈起。
RAG结合了信息检索与生成模型，先通过用户的原始问题query 在知识库中检索与相关的文档，再利用生成模型（如ChatGPT）生成回答。最简单的RAG版本通常被称为Naive-RAG，虽然Naive-RAG能够处理一些简单的问题，但在真实场景下，用户提出的问题往往更加复杂多样，远远超出系统最初设计的预期范围。
在用户与RAG系统交互时，往往会遇到以下几种常见问题：
表达模糊不清：用户在描述问题时，往往难以精准表达自己的需求。他们可能仅使用几个词组或片段，导致系统难以理解用户的真实意图。
依赖上下文：用户的问题经常依赖之前的对话或背景信息，而系统只接收到当前的孤立问题，缺少关键的上下文支持，无法给出准确的答案。
复杂多层次问题：某些问题本身复杂，包含多个子问题或需要推理、逻辑分析。Naive-RAG依赖简单的关键词匹配或语义匹配，无法很好地处理这类复杂的需求。
面对这些挑战，Naive-RAG的局限性变得明显：仅仅依靠用户的原始query无法应对多样化的提问场景。那么，如何提升RAG系统的检索能力，增强对复杂问题的处理呢？这时就需要引入Query-Enhancement技术。
Query-Enhancement，顾名思义，是对用户的原始query进行增强处理。它的核心思想是：不要直接使用用户的原始query进行相关文档的检索，而是通过某种技术手段对query进行改写、扩展或优化，从而生成一个更适合检索的query。这种技术在不同场景下有不同的命名，如query rewrite或query reformulation，但核心目标都是一致的——根据用户的初始输入，生成一个更符合检索需求、更能提升查询准确性的新query。
通过Query-Enhancement，可以解决许多Naive-RAG无法处理的问题。例如，针对模糊或简短的提问，增强后的query可以通过添加上下文或关键词来丰富信息内容；对于复杂的多层次问题，增强后的query可以拆解为多个子问题，逐步进行检索与推理。
本文将深入探讨不同的Query-Enhancement技术方案，并分析这些技术如何根据原始query生成更高效的查询，帮助RAG系统在复杂场景下提供更精确的答案。
Query Rewrite Because the original query can not be always optimal to retrieve for the LLM, especially in the real world… we first prompt an LLM to rewrite the queries, then conduct retrieval-augmented reading.
Query Rewrite的目的是将用户模糊、不明确或不完整的查询转换为更适合检索的形式，以提升检索效率和准确性。
仅使用原始query的缺点：
查询常常模糊、不具体或不完整，导致难以找到有效的检索结果。
缺乏明确术语，无法有效从大型数据集中提取相关信息。
对话上下文中的查询含义因对话历史而异，同样的表达在不同的上下文中可能有不同的意图。
输入文本与真正需要检索的知识之间不可避免地存在差距。这种差距限制了检索性能，增加了对检索能力增强和提示工程的依赖。
为了解决这些问题，检索器之前增加了一步对输入进行改写的过程，填补给定输入与检索需求之间的差距。这一步利用了LLM本身的能力对原始查询进行有针对性的改写。
比如，来自RAG_Techniques 的这段prompt：
query_rewrite_template = &#34;&#34;&#34;You are an AI assistant tasked with reformulating user queries to improve retrieval in a RAG system. Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information. Original query: {original_query} Rewritten query:&#34;&#34;&#34; 使LLM可以更加系统地将用户的原始查询改写为更符合检索需求的形式。
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-10-31 16:04:00 +0800 CST'>October 31, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Theme PaperMod</footer>
  <a class="entry-link" aria-label="post link to RAG工具箱：Query Enhancement" href="https://niraya666.github.io/posts/rag%E5%B7%A5%E5%85%B7%E7%AE%B1query-enhancement/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">LLM 输出限制：Structured Outputs、受限编码和提示词工程
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p>在使用大型语言模型（LLM）时，我们常常面临一个挑战：如何从模型输出中准确提取自己所需的信息。例如，当我们希望模型输出 JSON 格式的数据时，由于模型生成的内容并不总是稳定，可能需要额外编写大量的正则表达式来匹配并提取其中的有效信息。然而，由于 LLM 的能力，导致其输出结构并不永远可靠。
现阶段， 让LLM按要求生成特定格式文本的主要方法有几种种：
微调：使模型的输出遵循特定格式
OpenAI Json-mode/Structured Outputs/function-calling: 这些功能允许模型生成更严格、结构化的输出，但受限于openAI平台。
格式约束：在decoding阶段进行约束，限制模型的输出，
Prompt Engineering： 最简单的办法，但不稳定。
多阶段prompting： 通过多个步骤的提示逐步引导模型生成所需的格式。
本文将聚焦在Structured Outputs， 受限编码， 和prompt-engineering的角度，探讨它们在生成特定格式文本中的应用和效果。
Json Mode 仅特定模型和平台支持
以openAI 为例， 在openai.chat.completions.create 参数中增加response_format={&#34;type&#34;:&#34;json_object&#34;} 即可（具体参见：response_format ）。
需要在prompt中要求输出json格式
不能保证完全按要求的格式结构输出
但非100%成功率，存在一些需要额外检测和适当处理的edge case。
Handling edge cases 根据OpenAI官方文档提供的处理方案 https://platform.openai.com/docs/guides/structured-outputs/json-mode we_did_not_specify_stop_tokens = True try: response = client.chat.completions.create( model=&#34;gpt-3.5-turbo-0125&#34;, messages=[ {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are a helpful assistant designed to output JSON.&#34;}, {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Who won the world series in 2020? Please respond in the format {winner: ...}&#34;} ], response_format={&#34;type&#34;: &#34;json_object&#34;} ) # Check if the conversation was too long for the context window, resulting in incomplete JSON if response.choices[0].message.finish_reason == &#34;length&#34;: # your code should handle this error case pass # Check if the OpenAI safety system refused the request and generated a refusal instead if response.choices[0].message[0].get(&#34;refusal&#34;): # your code should handle this error case # In this case, the .content field will contain the explanation (if any) that the model generated for why it is refusing print(response.choices[0].message[0][&#34;refusal&#34;]) # Check if the model&#39;s output included restricted content, so the generation of JSON was halted and may be partial if response.choices[0].message.finish_reason == &#34;content_filter&#34;: # your code should handle this error case pass if response.choices[0].message.finish_reason == &#34;stop&#34;: # In this case the model has either successfully finished generating the JSON object according to your schema, or the model generated one of the tokens you provided as a &#34;stop token&#34; if we_did_not_specify_stop_tokens: # If you didn&#39;t specify any stop tokens, then the generation is complete and the content key will contain the serialized JSON object # This is guaranteed to parse successfully and should now contain &#34;{&#34;winner&#34;: &#34;Los Angeles Dodgers&#34;}&#34; print(response.choices[0].message.content) else: # Check if the response.choices[0].message.content ends with one of your stop tokens and handle appropriately pass except Exception as e: # Your code should handle errors here, for example a network error calling the API print(e) 使用pydantic的方案 使用pydantic的方案 from pydantic import BaseModel, EmailStr, ValidationError # 定义你期望的 JSON 数据模型 class UserModel(BaseModel): name: str age: int email: EmailStr # 检查 JSON 是否符合模型的函数 def validate_json(json_str): try: # 将输入的 JSON 字符串转换为 UserModel 实例 user = UserModel.parse_raw(json_str) # 如果验证通过，返回字典 return user.dict() except ValidationError as ve: print(f&#34;JSON validation error: {ve.json()}&#34;) return None # 示例用法 json_str = &#39;{&#34;name&#34;: &#34;John Doe&#34;, &#34;email&#34;: &#34;john.doe@example.com&#34;}&#39; validated_json = validate_json(json_str) if validated_json is not None: print(&#34;JSON is valid and conforms to the schema:&#34;) print(validated_json) else: print(&#34;JSON is invalid.&#34;) Json-Mode 更多是对于输出json的格式进行检查(即Json格式的有效性)
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-08-21 14:49:00 +0800 CST'>August 21, 2024</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;Theme PaperMod</footer>
  <a class="entry-link" aria-label="post link to LLM 输出限制：Structured Outputs、受限编码和提示词工程" href="https://niraya666.github.io/posts/llm-%E8%BE%93%E5%87%BA%E9%99%90%E5%88%B6structured-outputs%E5%8F%97%E9%99%90%E7%BC%96%E7%A0%81%E5%92%8C%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">RAG工具箱：检索
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h2>
  </header>
  <div class="entry-content">
    <p> If you want to make a good RAG tool that uses your documentation, you should start by making a search engine over those documents that would be good enough for a human to use themselves. This is likely something your organization has considered before, and if it doesn’t exist it’s because building a good search engine has traditionally been a significant undertaking.
— from Build a search engine, not a vector DB
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-07-25 17:08:00 +0800 CST'>July 25, 2024</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Theme PaperMod</footer>
  <a class="entry-link" aria-label="post link to RAG工具箱：检索" href="https://niraya666.github.io/posts/rag%E6%A3%80%E7%B4%A2/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="https://niraya666.github.io/posts/page/2/">Next&nbsp;2/2&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://niraya666.github.io/">LZY Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
