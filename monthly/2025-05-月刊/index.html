<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>2025-05 月刊 | LZY Blog</title>
<meta name="keywords" content="月刊">
<meta name="description" content="值得关注的模型和新技术
Google 2025 I/O 大会：
I/O 2025
Google在2025年I/O大会上全面展示了AI的最新进展和深度整合战略，涵盖基础模型迭代（如Gemini 2.5、Gemini Diffusion、Gemma 3n、Veo 3和Imagen 4）及多模态创新
OpenAI codex
Introducing Codex
OpenAI 于 2025年5月16日推出了 Codex 软件工程代理及其驱动模型 codex-1 和 codex-mini-latest，专注提升软件开发的自动化与效率。codex-1 基于 o3 模型，优化并行处理、多轮测试和复杂项目支持，擅长代码生成、Bug 修复等任务；codex-mini-latest 则主打低延迟，适合快速命令行操作。Codex 平台通过云端隔离沙箱，安全模拟真实开发环境，自动化完成如重构、测试编写等任务，支持细致行为定制。
Claude 4
Introducing Claude 4
Anthropic 于2025年5月22日发布了新一代 Claude 4 系列模型，包括 Claude Opus 4 和 Claude Sonnet 4，重点提升了编码、高级推理和对AI代理的支持能力。Opus 4 在行业编码基准测试中表现领先，拥有更强的内存与持续任务能力，并大幅减少“抄近路”行为，专注于高复杂任务和AI代理核心场景。Sonnet 4 则在提升推理与指令遵循能力的同时，平衡了性能与效率。
DeepSeek-R1-0528
Huggingface： deepseek-ai/DeepSeek-R1-0528
通过强化学习与算法优化实现推理能力提升，单问题推理深度翻倍（平均Token量从12K→23K），更强的数学、编码能力，并支持工具调用，大幅降低幻觉。同时开源了蒸馏小模型模型 deepseek-ai/DeepSeek-R1-0528-Qwen3-8B。
Flowith Neo
Flowith Neo 是 Flowith 团队推出的新一代 AI 智能代理，专为自动化复杂、长流程任务设计。其核心技术包括支持无限步骤的持续云端执行、强大的上下文保持能力、灵活调用多种外部工具，以及可视化工作流和自反思机制，显著提升流程的连贯性和可靠性。
值得关注的开源项目
DeerFlow
Github: github.com/bytedance/deer-flow
由字节跳动开源的，基于LangStack 开发的Deep Research 开源项目，支持深度研究、MCP 集成、报告 AI 增强编辑以及播客生成等功能，通过Docker compose一键启动。">
<meta name="author" content="Theme PaperMod">
<link rel="canonical" href="https://niraya666.github.io/monthly/2025-05-%E6%9C%88%E5%88%8A/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://niraya666.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://niraya666.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://niraya666.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://niraya666.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://niraya666.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://niraya666.github.io/monthly/2025-05-%E6%9C%88%E5%88%8A/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="2025-05 月刊" />
<meta property="og:description" content="值得关注的模型和新技术
Google 2025 I/O 大会：
I/O 2025
Google在2025年I/O大会上全面展示了AI的最新进展和深度整合战略，涵盖基础模型迭代（如Gemini 2.5、Gemini Diffusion、Gemma 3n、Veo 3和Imagen 4）及多模态创新
OpenAI codex
Introducing Codex
OpenAI 于 2025年5月16日推出了 Codex 软件工程代理及其驱动模型 codex-1 和 codex-mini-latest，专注提升软件开发的自动化与效率。codex-1 基于 o3 模型，优化并行处理、多轮测试和复杂项目支持，擅长代码生成、Bug 修复等任务；codex-mini-latest 则主打低延迟，适合快速命令行操作。Codex 平台通过云端隔离沙箱，安全模拟真实开发环境，自动化完成如重构、测试编写等任务，支持细致行为定制。
Claude 4
Introducing Claude 4
Anthropic 于2025年5月22日发布了新一代 Claude 4 系列模型，包括 Claude Opus 4 和 Claude Sonnet 4，重点提升了编码、高级推理和对AI代理的支持能力。Opus 4 在行业编码基准测试中表现领先，拥有更强的内存与持续任务能力，并大幅减少“抄近路”行为，专注于高复杂任务和AI代理核心场景。Sonnet 4 则在提升推理与指令遵循能力的同时，平衡了性能与效率。
DeepSeek-R1-0528
Huggingface： deepseek-ai/DeepSeek-R1-0528
通过强化学习与算法优化实现推理能力提升，单问题推理深度翻倍（平均Token量从12K→23K），更强的数学、编码能力，并支持工具调用，大幅降低幻觉。同时开源了蒸馏小模型模型 deepseek-ai/DeepSeek-R1-0528-Qwen3-8B。
Flowith Neo
Flowith Neo 是 Flowith 团队推出的新一代 AI 智能代理，专为自动化复杂、长流程任务设计。其核心技术包括支持无限步骤的持续云端执行、强大的上下文保持能力、灵活调用多种外部工具，以及可视化工作流和自反思机制，显著提升流程的连贯性和可靠性。
值得关注的开源项目
DeerFlow
Github: github.com/bytedance/deer-flow
由字节跳动开源的，基于LangStack 开发的Deep Research 开源项目，支持深度研究、MCP 集成、报告 AI 增强编辑以及播客生成等功能，通过Docker compose一键启动。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://niraya666.github.io/monthly/2025-05-%E6%9C%88%E5%88%8A/" />
<meta property="og:image" content="https://niraya666.github.io/img/monthly/2025-05/332F56A7-A497-49D6-A2C1-3CAFB6200C0F_1_105_c.jpeg" /><meta property="article:section" content="monthly" />
<meta property="article:published_time" content="2025-05-30T14:00:00+08:00" />
<meta property="article:modified_time" content="2025-05-30T14:00:00+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://niraya666.github.io/img/monthly/2025-05/332F56A7-A497-49D6-A2C1-3CAFB6200C0F_1_105_c.jpeg" />
<meta name="twitter:title" content="2025-05 月刊"/>
<meta name="twitter:description" content="值得关注的模型和新技术
Google 2025 I/O 大会：
I/O 2025
Google在2025年I/O大会上全面展示了AI的最新进展和深度整合战略，涵盖基础模型迭代（如Gemini 2.5、Gemini Diffusion、Gemma 3n、Veo 3和Imagen 4）及多模态创新
OpenAI codex
Introducing Codex
OpenAI 于 2025年5月16日推出了 Codex 软件工程代理及其驱动模型 codex-1 和 codex-mini-latest，专注提升软件开发的自动化与效率。codex-1 基于 o3 模型，优化并行处理、多轮测试和复杂项目支持，擅长代码生成、Bug 修复等任务；codex-mini-latest 则主打低延迟，适合快速命令行操作。Codex 平台通过云端隔离沙箱，安全模拟真实开发环境，自动化完成如重构、测试编写等任务，支持细致行为定制。
Claude 4
Introducing Claude 4
Anthropic 于2025年5月22日发布了新一代 Claude 4 系列模型，包括 Claude Opus 4 和 Claude Sonnet 4，重点提升了编码、高级推理和对AI代理的支持能力。Opus 4 在行业编码基准测试中表现领先，拥有更强的内存与持续任务能力，并大幅减少“抄近路”行为，专注于高复杂任务和AI代理核心场景。Sonnet 4 则在提升推理与指令遵循能力的同时，平衡了性能与效率。
DeepSeek-R1-0528
Huggingface： deepseek-ai/DeepSeek-R1-0528
通过强化学习与算法优化实现推理能力提升，单问题推理深度翻倍（平均Token量从12K→23K），更强的数学、编码能力，并支持工具调用，大幅降低幻觉。同时开源了蒸馏小模型模型 deepseek-ai/DeepSeek-R1-0528-Qwen3-8B。
Flowith Neo
Flowith Neo 是 Flowith 团队推出的新一代 AI 智能代理，专为自动化复杂、长流程任务设计。其核心技术包括支持无限步骤的持续云端执行、强大的上下文保持能力、灵活调用多种外部工具，以及可视化工作流和自反思机制，显著提升流程的连贯性和可靠性。
值得关注的开源项目
DeerFlow
Github: github.com/bytedance/deer-flow
由字节跳动开源的，基于LangStack 开发的Deep Research 开源项目，支持深度研究、MCP 集成、报告 AI 增强编辑以及播客生成等功能，通过Docker compose一键启动。"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Monthlies",
      "item": "https://niraya666.github.io/monthly/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "2025-05 月刊",
      "item": "https://niraya666.github.io/monthly/2025-05-%E6%9C%88%E5%88%8A/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "2025-05 月刊",
  "name": "2025-05 月刊",
  "description": "值得关注的模型和新技术 Google 2025 I/O 大会： I/O 2025\nGoogle在2025年I/O大会上全面展示了AI的最新进展和深度整合战略，涵盖基础模型迭代（如Gemini 2.5、Gemini Diffusion、Gemma 3n、Veo 3和Imagen 4）及多模态创新\nOpenAI codex Introducing Codex\nOpenAI 于 2025年5月16日推出了 Codex 软件工程代理及其驱动模型 codex-1 和 codex-mini-latest，专注提升软件开发的自动化与效率。codex-1 基于 o3 模型，优化并行处理、多轮测试和复杂项目支持，擅长代码生成、Bug 修复等任务；codex-mini-latest 则主打低延迟，适合快速命令行操作。Codex 平台通过云端隔离沙箱，安全模拟真实开发环境，自动化完成如重构、测试编写等任务，支持细致行为定制。\nClaude 4 Introducing Claude 4\nAnthropic 于2025年5月22日发布了新一代 Claude 4 系列模型，包括 Claude Opus 4 和 Claude Sonnet 4，重点提升了编码、高级推理和对AI代理的支持能力。Opus 4 在行业编码基准测试中表现领先，拥有更强的内存与持续任务能力，并大幅减少“抄近路”行为，专注于高复杂任务和AI代理核心场景。Sonnet 4 则在提升推理与指令遵循能力的同时，平衡了性能与效率。\nDeepSeek-R1-0528 Huggingface： deepseek-ai/DeepSeek-R1-0528\n通过强化学习与算法优化实现推理能力提升，单问题推理深度翻倍（平均Token量从12K→23K），更强的数学、编码能力，并支持工具调用，大幅降低幻觉。同时开源了蒸馏小模型模型 deepseek-ai/DeepSeek-R1-0528-Qwen3-8B。\nFlowith Neo Flowith Neo 是 Flowith 团队推出的新一代 AI 智能代理，专为自动化复杂、长流程任务设计。其核心技术包括支持无限步骤的持续云端执行、强大的上下文保持能力、灵活调用多种外部工具，以及可视化工作流和自反思机制，显著提升流程的连贯性和可靠性。\n值得关注的开源项目 DeerFlow Github: github.com/bytedance/deer-flow\n由字节跳动开源的，基于LangStack 开发的Deep Research 开源项目，支持深度研究、MCP 集成、报告 AI 增强编辑以及播客生成等功能，通过Docker compose一键启动。\n",
  "keywords": [
    "月刊"
  ],
  "articleBody": "值得关注的模型和新技术 Google 2025 I/O 大会： I/O 2025\nGoogle在2025年I/O大会上全面展示了AI的最新进展和深度整合战略，涵盖基础模型迭代（如Gemini 2.5、Gemini Diffusion、Gemma 3n、Veo 3和Imagen 4）及多模态创新\nOpenAI codex Introducing Codex\nOpenAI 于 2025年5月16日推出了 Codex 软件工程代理及其驱动模型 codex-1 和 codex-mini-latest，专注提升软件开发的自动化与效率。codex-1 基于 o3 模型，优化并行处理、多轮测试和复杂项目支持，擅长代码生成、Bug 修复等任务；codex-mini-latest 则主打低延迟，适合快速命令行操作。Codex 平台通过云端隔离沙箱，安全模拟真实开发环境，自动化完成如重构、测试编写等任务，支持细致行为定制。\nClaude 4 Introducing Claude 4\nAnthropic 于2025年5月22日发布了新一代 Claude 4 系列模型，包括 Claude Opus 4 和 Claude Sonnet 4，重点提升了编码、高级推理和对AI代理的支持能力。Opus 4 在行业编码基准测试中表现领先，拥有更强的内存与持续任务能力，并大幅减少“抄近路”行为，专注于高复杂任务和AI代理核心场景。Sonnet 4 则在提升推理与指令遵循能力的同时，平衡了性能与效率。\nDeepSeek-R1-0528 Huggingface： deepseek-ai/DeepSeek-R1-0528\n通过强化学习与算法优化实现推理能力提升，单问题推理深度翻倍（平均Token量从12K→23K），更强的数学、编码能力，并支持工具调用，大幅降低幻觉。同时开源了蒸馏小模型模型 deepseek-ai/DeepSeek-R1-0528-Qwen3-8B。\nFlowith Neo Flowith Neo 是 Flowith 团队推出的新一代 AI 智能代理，专为自动化复杂、长流程任务设计。其核心技术包括支持无限步骤的持续云端执行、强大的上下文保持能力、灵活调用多种外部工具，以及可视化工作流和自反思机制，显著提升流程的连贯性和可靠性。\n值得关注的开源项目 DeerFlow Github: github.com/bytedance/deer-flow\n由字节跳动开源的，基于LangStack 开发的Deep Research 开源项目，支持深度研究、MCP 集成、报告 AI 增强编辑以及播客生成等功能，通过Docker compose一键启动。\nFlowGram.AI Github: github.com/bytedance/flowgram.ai\nFlowGram.AI 是由字节跳动推出的一款基于节点的可视化流程构建引擎，支持固定布局和自由连接布局两种模式，帮助开发者快速创建清晰输入输出的交互式工作流。\nMCP Server Chart Github: github.com/antvis/mcp-server-chart\nMCP Server Chart 是一个基于 AntV 的可视化MCP server，支持通过 AI 工具生成 15+ 种图表类型（如面积图、柱状图、折线图、词云等），并兼容 SSE 和 Streamable 协议，可无缝集成到 Claude、VSCode、Cline 等桌面或在线平台.\nRL-Factory Github: github.com/Simple-Efficient/RL-Factory\nRL-Factory 是一个专为代理强化学习（Agent Learning）设计的高效框架，通过解耦环境与强化学习后训练流程，让用户仅需配置工具和奖励函数即可快速训练智能体。其核心优势包括：易用性（支持一键式Qwen3模型训练及多轮工具调用，内置模型评估奖励机制）、高效性（异步工具调用和奖励计算使训练速度提升2倍）、模型支持（当前原生支持Qwen3系列模型，如Qwen3-4B/8B，并计划扩展至Deepseek、Llama等主流模型）。框架提供端到端检索模型训练能力（通过rag_server），并计划集成WebUI实现全流程可视化管理\n值得关注的研究和论文 EfficientLLM: Efficiency in Large Language Models arXiv:2505.13840\nNo One-Size-Fits-All Solution: 没有免费午餐,任何效率提升都伴随着其他方面的代价\nMoE架构虽然能提升模型性能并减少每token的FLOPs，但会使峰值VRAM使用量增加约40%\nint4可节省高达3.9倍的内存占用和能耗，但会导致任务平均准确率下降约3-5%\nOptima are Task- and Scale-Dependent: 效率最优解高度依赖于具体情境\nMQA在内存受限设备上提供了最佳的内存-延迟边界；MLA在质量关键任务中产生最低的困惑度；NSA能耗最低 对于1B-3B模型，LoRA及其变体（如DoRA）在特定内存约束下损失最低；对于超过14B参数的模型，RSLoRA在效率上（更低延迟和功耗）超过了LoRA。参数冻结在微调过程中端到端延迟最低 int4训练后量化能显著提升内存效率（最高减少3.9倍内存占用）和推理吞吐量（在内存受限条件下可提升3倍），同时模型性能仅有轻微下降（平均任务得分下降3-5个百分点）；bfloat16在Hopper架构GPU上一致优于float16 Broad Applicability Across Modalities：\n在LLM上验证的效率技术能有效迁移到LVM和VLM MQA/GQA能提高LVM的生成质量 PEFT方法在LVM和VLM上也实现了良好的性能-效率权衡 Nemotron-Research-Tool-N1: Exploring Tool-Using Language Models with Reinforced Reasoning Paper\n使用RL 提升LLM的tool-using能力\n解决的问题：\nSFT tool-using 需要大量数据标注 目前方法面对OOD数据表现不佳 具体实现\n基于Qwen2.5-7B/14B-Instruct，采用GRPO 策略模型输出包含两部分：：用标签包裹的自然语言推理 和 用标签包裹的JSON格式工具名及参数 奖励设计： 格式正确性 工具调用正确性：工具名与参数需与真实值完全匹配（通过字典格式验证） 无需预训练SFT，直接从原始数据进行RL训练 数据：整合xLAM和ToolACE数据集，过滤无效工具调用，将多轮对话拆分为单步预测实例 有趣发现\nSFT-then-RL未必最优：纯RL训练优于SFT-then-RL流程（但并不显著），SFT可能阻碍RL性能 二元奖励优于细粒度奖励：细粒度奖励（如部分正确得分）易导致模型过拟合格式或局部匹配 移除格式正确性奖励，导致性能下降 类似的tool-RL方向论文：\nTORL: Scaling Tool-Integrated RL ReTool: Reinforcement Learning for Strategic tool use in LLMs ToolRL: Reward is All Tool Learning Needs Synthetic Data Generation \u0026 Multi-step RL for Reasoning \u0026 tool use LLMs Get Lost In Multi-Turn Conversation Paper\narXiv:2505.06120\n关于LLMs在多轮未完全指定对话场景下的性能退化问题\nGet lost的原因：\n过早且错误的假设：模型在对话早期基于不完整的信息做出假设，后续对话中，模型会围绕错误假设生成答案，导致最终结果完全偏离用户真实需求 未掌握完整信息时尝试完整解答：模型急于生成最终答案，即使用户尚未提供所有必要信息，；因为LLMs的训练目标不包含信息完善等内容 过度依赖之前的错误答案：模型将自己之前的错误回答视为“事实”，并在后续对话中不断强化这些错误 输出过于冗长：模型生成冗长的回答，包含无关细节或重复内容；因为训练数据中长文本占比高，且模型倾向于“过度解释”以避免遗漏 忽视中间回合的信息：模型对对话开头和结尾的信息关注度更高，但忽略中间回合的关键细节 “loss-in-the-middle” 建议：\n整合需求到单轮提示：一次性把话讲清楚 对话偏离时：重启并提供总结 Be careful： 多模型交叉验证 Temperature可以减少随机性，但即便为0也仍存在不可靠性 开发建议： 基准测试评估：增加多轮未指定任务的评估，而非仅关注单轮性能 错误识别修正，self-verification 意图识别 ZeroSearch: Incentivize the Search Capability of LLMs without Searching Paper\n解决了两个主要问题:\n从真实搜索引擎返回的文档质量往往不可预测，这会给训练过程引入噪声和不稳定性 强化学习(RL)训练需要频繁进行推演(rollout)，可能涉及数十万次搜索请求，这会产生巨大的API费用并严重限制可扩展性 创新点\n提出了ZeroSearch框架，一种不需要与真实搜索引擎交互就能增强LLM搜索能力的强化学习方法; 通过轻量级监督微调，将LLM转变为能够根据查询生成相关和噪声文档的检索模块;\n设计了Curriculum learning 的推演策略，在训练过程中逐步降低生成文档的质量，使模型逐渐适应更具挑战性的检索场景;\n引入损失屏蔽机制，确保只对模型自身生成的token应用损失计算，避免从检索模块生成的文档token影响训练稳定性\n具体实现\n搜索模拟微调\n收集LLM与真实搜索引擎交互的轨迹，根据是否导致正确答案将其标记为正面或负面样本 从这些轨迹中提取查询-文档对进行轻量级监督微调 Curriculum Search Simulation: 使用概率函数控制生成噪声文档的可能性，随着训练进行逐步增加难度,允许策略模型先学习基本输出格式和任务要求，然后逐渐适应更具挑战性的检索场景\n噪声文档生成概率：\n$$p_i = p_s + \\frac{b^{i/m} - 1}{b - 1} (p_e - p_s)$$\n奖励设计: 采用基于F1分数的奖励，平衡精确率和召回率，避免模型通过生成过长答案来提高命中率的\"reward hacking\"行为\n$$r_\\phi(x, y) = \\frac{2 \\times IN}{PN + RN}$$\n其中 IN 为模型输出与标准答案之间的重叠词数（Intersection Number），PN 和 RN 分别为模型输出的词数（Prediction Number） 和标准答案的词数（Reference Number）\n没有对输出格式单独奖励，因为实验发现模型在训练过程中能自发学会输出规范格式\nPhi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math Paper\n如何提升小型LLM（3.8B）在数学推理任务中的推理能力；\n实现：\nDistillation：利用DeepSeek-R1生成的大量多领域、多难度的CoT推理数据，对Phi-4-Mini进行中间训练，提升其基础推理能力 如果数据集包含reasoning trajectories，则直接使用，没有推理过程，则用DeepSeek-R1生成CoT推理答案，生成8个不同rollouts，最终总共收集了约160万道题、1000万个rollouts 用自动化工具检查答案是否正确，对于工具的误判复杂解答，用GPT-4o-mini再复查一遍 Rollout Preference Learning：利用大模型生成的错误推理样本，构建正确-错误的偏好对，采用DPO方法优化 RL with Verifiable Reward： 使用GRPO进一步优化，奖励函数为自动化验证工具对最终答案的判定 遇到的问题和解决方案：\n响应长度差异大导致训练不稳定：采用Prompt Optimization，在RL训练前，先用蒸馏后的模型对多个候选prompt多轮采样，只保留那些生成答案长度比较一致的prompt； 奖励一致时梯度消失问题，GRPO依赖于advantage estimate，如果同一组采样的答案奖励完全一样（比如全对或全错），就会导致梯度为零；即便将全对/全错过滤，长度差异大，梯度依然不稳定，正负样本极度不平衡，影响RL收敛：**Reward Rebalancing，**针对难题，先过采样以保证组内多样性，然后把所有正向奖励的答案都保留，再随机采样等量的负向奖励答案，保证正负样本平衡，对于太容易的题目直接过滤掉。 Exploration–Exploitation Tradeoff，RL训练需要exploration才能找到高奖励策略，通常用高温度采样促进探索，但实际评测时往往用低温度来减少输出波动：Temperature Annealing，训练初期用高温度（1.0）促进探索，随着训练进展，线性降低温度到0.6，后期固定为0.6，逐步过渡到exploitation UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities Paper\n如何让RAG系统能灵活地从多种模态和多种粒度的知识库中检索最合适的信息，提升事实准确性和适应性。 现有“统一嵌入空间”的多模态检索方法存在“模态鸿沟”（modality gap），即检索时更倾向于返回与查询同模态的数据，导致跨模态检索效果差。 主要创新点\nModality-aware Routing：不再强行将所有模态数据压缩到同一个嵌入空间，而是为每种模态（文本、图片、视频）分别维护独立的检索空间，通过一个“路由”模块，根据查询内容动态判断最适合的模态和粒度，然后只在对应的知识库中检索。 Granularity-aware Retrieval：每种模态下进一步细分粒度：如文本分为段落级、文档级，视频分为片段级、完整视频级，图片本身为最细粒度，路由不仅判断模态，还能判断所需的粒度，提升检索的相关性和生成质量 路由器设计：支持“零训练”路由（用大模型如GPT-4o直接prompt分类）和“有监督训练”路由（用DistilBERT、T5-Large等模型训练分类器） 具体实现\n路由： 输入查询后，路由器首先判断该问题是否需要外部检索，若需检索，则进一步判断最合适的模态（文本/图片/视频）和粒度（段落/文档/片段/完整视频） 分模态检索：每种模态有独立的检索器和嵌入空间，避免模态混淆 生成回答：检索到的内容与原始查询一起输入到多模态大模型（LVLM）中，生成最终回答 推荐内容 Huggingface 官方推出的MCP教程: MCP Course\nDeepleaning.AI 同Anthropic 联手推出的MCP课程： MCP: Build Rich-Context AI Apps with Anthropic\nAI Engineering Transition Path\nAI Red Teaming Playground Labs\n影音记录 精选歌单 Live演出 05.08 Adam Fischer-杜塞尔多夫交响乐团《马勒第九交响》 05.09 Honeydip 05.10 Hans Zimmer 05.16 Envy 05.23 Sea Power 05.24-05.25 Offside Festival 05.28 Maruja 书\u0026阅读摘录 Why Cline Doesn’t Index Your Codebase (And Why That’s a Good Thing) Why RAG Breaks Down for Code … The approach seems straightforward – chunk your data, create embeddings, store them in a vector database, and retrieve relevant pieces when needed. … But code isn’t like other data. It’s interconnected, constantly evolving, and often contains your most sensitive intellectual property. When you apply traditional RAG approaches to codebases, three critical problems emerge:\nCode Doesn’t Think in Chunks … when you chunk code for embeddings, you’re literally tearing apart its logic. … Indexes Decay While Code Evolves … An index, by definition, is a snapshot frozen in time. The code inevitably drifts out of sync. … Cline’s Approach: Think Like a Developer, Act Like a Developer … Starting with Structure, Not Snippets … Discovery, Not Retrieval\nIf you’re an engineer who’s feeling hesitant or overwhelmed by… stop treating AI like a vending machine for code. Think of AI as a highly skilled (but forgetful) pair programmer. Planning before AI writes any code. Frontload all relevant context – files, existing patterns, overall goals. Then, collaboratively develop a strategy with your AI.\nUse “Rules Files” – essentially custom instructions – to persistently guide AI behavior. Complement Rules Files with “Memory Banks.” This allows the AI to “remember” critical project details, patterns, and decisions over time.\n万字干货！如何让用户体验良好的同时，提高产品转化率？ 确实能带来短期转化，但问题是只要用户反感一次，就很难再赢回来了\n结论：良好的用户引导应以用户利益为核心\n用户引导不该是“温柔的陷阱”，而应该是“清晰的邀请”；产品设计也不该是“只求你上钩”，而应该是“愿你心甘情愿留下”\nAvoiding Skill Atrophy in the Age of AI we may be increasing productivity, but at risk of losing our edge to skill atrophy if we’re not careful.\nThis cognitive offloading - relying on external tools to handle mental tasks - has plenty of precedents.\ntempt us to “turn off our brain” for routine coding tasks. … “I’ve become a human clipboard”\nUsing AI as a collaborator, not a crutch Use AI to augment, not replace, code review. Pair program with the AI.\nAI Agent 新探索：构建 AI 原生团队，使能 AI 员工 为什么目前的 AI 无法成为靠谱的数字员工: 首先是企业知识未文档化的问题…很少有系统性的文档记录… 工具与系统的操作障碍严重限制了 AI 的能力发挥 AI Agent 缺少执行持续任务的机制 AI 缺少长期记忆机制，难以累积经验和知识\n要让 AI 成为有效的团队成员，首先要解决的不是 AI 技术本身，而是企业知识管理的问题。 要真正发挥 AI 的潜力，我们不仅需要提升 AI 的能力，还需要改造现有的工具和系统 然而，许多企业的 CI/CD 管道不完善或不存在…环境配置往往是手动完成的，难以复制。 … 原因很简单： B 团队的知识是可检索的，而 A 团队的知识被锁在人脑和私人对话中 … 而在 AI 原生团队中，知识必须从个人大脑转移到共享资源 — “团队知道某事” 增加了整体效能。 … Markdown 与 Git 等版本控制系统兼容性更好，支持差异对比和协作编辑，这对团队知识管理至关重要。 … 为内部系统提供 API 接口\n即使是最聪明的开发者（或 AI）也需要适当的测试条件。 测试驱动开发(TDD)的理念在 AI 时代变得更加重要 … 在 AI 时代，这变成了”人机四眼”—AI 生成的代码需要人类审查，人类编写的复杂代码可由 AI 辅助检查。\n它核心理念是”要想真正学会，就要能教会他人”。 要求 AI 在接受任务后首先生成一份 “工作理解文档”，包括： 目标概述：一句话总结任务目标上下文理解：相关背景和约束澄清问题：需要进一步明确的事项初步方案：可能的实现路径预期成果：如何评判成功 … 与其说我们在教 AI 如何更好地执行任务，不如说我们在教它如何更好地理解任务\n主动性不足是限制 AI 成为真正团队成员的另一大障 … 一个沉默地陷入困境的员工比一个主动寻求帮助的员工更让人担忧。 … 而优秀的数字员工则会明确描述问题所在，提出可能的解决路径，并寻求必要的帮助。\n从系统安全角度看，这涉及到”环境状态管理”—对工作环境变化的监控和保护能力。 … 变更范围评估：此操作会影响哪些系统组件？风险等级判定：操作可能导致的最坏结果是什么？可逆性分析：如果出错，恢复难度有多大？备选方案考虑：是否存在风险更低的替代方法？\n",
  "wordCount" : "795",
  "inLanguage": "en",
  "image":"https://niraya666.github.io/img/monthly/2025-05/332F56A7-A497-49D6-A2C1-3CAFB6200C0F_1_105_c.jpeg","datePublished": "2025-05-30T14:00:00+08:00",
  "dateModified": "2025-05-30T14:00:00+08:00",
  "author":{
    "@type": "Person",
    "name": "Theme PaperMod"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://niraya666.github.io/monthly/2025-05-%E6%9C%88%E5%88%8A/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "LZY Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://niraya666.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://niraya666.github.io/" accesskey="h" title="LZY Blog (Alt + H)">LZY Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://niraya666.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/posts/" title="AI">
                    <span>AI</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/musik/" title="Musik!">
                    <span>Musik!</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/monthly/" title="月刊">
                    <span>月刊</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/essay/" title="杂文">
                    <span>杂文</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/travel/" title="游记">
                    <span>游记</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/travel-map/" title="足迹">
                    <span>足迹</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://niraya666.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://niraya666.github.io/monthly/">Monthlies</a></div>
    <h1 class="post-title entry-hint-parent">
      2025-05 月刊
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2025-05-30 14:00:00 +0800 CST'>May 30, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Theme PaperMod

</div>
  </header> 
<figure class="entry-cover"><a href="https://niraya666.github.io/img/monthly/2025-05/332F56A7-A497-49D6-A2C1-3CAFB6200C0F_1_105_c.jpeg" target="_blank"
            rel="noopener noreferrer"><img loading="eager" src="https://niraya666.github.io/img/monthly/2025-05/332F56A7-A497-49D6-A2C1-3CAFB6200C0F_1_105_c.jpeg" alt="摄于 径山花海"></a>
        <p>摄于 径山花海</p>
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e5%80%bc%e5%be%97%e5%85%b3%e6%b3%a8%e7%9a%84%e6%a8%a1%e5%9e%8b%e5%92%8c%e6%96%b0%e6%8a%80%e6%9c%af" aria-label="值得关注的模型和新技术">值得关注的模型和新技术</a><ul>
                        
                <li>
                    <a href="#google-2025-io-%e5%a4%a7%e4%bc%9a" aria-label="Google 2025 I/O 大会：">Google 2025 I/O 大会：</a></li>
                <li>
                    <a href="#openai-codex" aria-label="OpenAI codex">OpenAI codex</a></li>
                <li>
                    <a href="#claude-4" aria-label="Claude 4">Claude 4</a></li>
                <li>
                    <a href="#deepseek-r1-0528" aria-label="DeepSeek-R1-0528">DeepSeek-R1-0528</a></li>
                <li>
                    <a href="#flowith-neo" aria-label="Flowith Neo">Flowith Neo</a></li></ul>
                </li>
                <li>
                    <a href="#%e5%80%bc%e5%be%97%e5%85%b3%e6%b3%a8%e7%9a%84%e5%bc%80%e6%ba%90%e9%a1%b9%e7%9b%ae" aria-label="值得关注的开源项目">值得关注的开源项目</a><ul>
                        
                <li>
                    <a href="#deerflow" aria-label="DeerFlow">DeerFlow</a></li>
                <li>
                    <a href="#flowgramai" aria-label="FlowGram.AI">FlowGram.AI</a></li>
                <li>
                    <a href="#mcp-server-chart" aria-label="MCP Server Chart">MCP Server Chart</a></li>
                <li>
                    <a href="#rl-factory" aria-label="RL-Factory">RL-Factory</a></li></ul>
                </li>
                <li>
                    <a href="#%e5%80%bc%e5%be%97%e5%85%b3%e6%b3%a8%e7%9a%84%e7%a0%94%e7%a9%b6%e5%92%8c%e8%ae%ba%e6%96%87" aria-label="值得关注的研究和论文">值得关注的研究和论文</a><ul>
                        
                <li>
                    <a href="#efficientllm-efficiency-in-large-language-models" aria-label="EfficientLLM: Efficiency in Large Language Models">EfficientLLM: Efficiency in Large Language Models</a></li>
                <li>
                    <a href="#nemotron-research-tool-n1-exploring-tool-using-language-models-with-reinforced-reasoning" aria-label="Nemotron-Research-Tool-N1: Exploring Tool-Using Language Models with Reinforced Reasoning">Nemotron-Research-Tool-N1: Exploring Tool-Using Language Models with Reinforced Reasoning</a></li>
                <li>
                    <a href="#llms-get-lost-in-multi-turn-conversation" aria-label="LLMs Get Lost In Multi-Turn Conversation">LLMs Get Lost In Multi-Turn Conversation</a></li></ul>
                </li>
                <li>
                    <a href="#zerosearch-incentivize-the-search-capability-of-llms-without-searching" aria-label="ZeroSearch: Incentivize the Search Capability of LLMs without Searching">ZeroSearch: Incentivize the Search Capability of LLMs without Searching</a><ul>
                        
                <li>
                    <a href="#phi-4-mini-reasoning-exploring-the-limits-of-small-reasoning-language-models-in-math" aria-label="Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math">Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math</a></li>
                <li>
                    <a href="#universalrag-retrieval-augmented-generation-over-multiple-corpora-with-diverse-modalities-and-granularities" aria-label="UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities">UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities</a></li></ul>
                </li>
                <li>
                    <a href="#%e6%8e%a8%e8%8d%90%e5%86%85%e5%ae%b9" aria-label="推荐内容">推荐内容</a></li>
                <li>
                    <a href="#%e5%bd%b1%e9%9f%b3%e8%ae%b0%e5%bd%95" aria-label="影音记录">影音记录</a><ul>
                        
                <li>
                    <a href="#%e7%b2%be%e9%80%89%e6%ad%8c%e5%8d%95" aria-label="精选歌单">精选歌单</a></li>
                <li>
                    <a href="#live%e6%bc%94%e5%87%ba" aria-label="Live演出">Live演出</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a6%e9%98%85%e8%af%bb%e6%91%98%e5%bd%95" aria-label="书&amp;阅读摘录">书&amp;阅读摘录</a><ul>
                        
                <li>
                    <a href="#why-cline-doesnt-index-your-codebase-and-why-thats-a-good-thinghttpsclinebotblogwhy-cline-doesnt-index-your-codebase-and-why-thats-a-good-thing" aria-label="Why Cline Doesn&rsquo;t Index Your Codebase (And Why That&rsquo;s a Good Thing)">Why Cline Doesn&rsquo;t Index Your Codebase (And Why That&rsquo;s a Good Thing)</a></li>
                <li>
                    <a href="#if-youre-an-engineer-whos-feeling-hesitant-or-overwhelmed-byhttpsxcomclinestatus1922846215894597996" aria-label="If you&rsquo;re an engineer who&rsquo;s feeling hesitant or overwhelmed by…">If you&rsquo;re an engineer who&rsquo;s feeling hesitant or overwhelmed by…</a></li>
                <li>
                    <a href="#%e4%b8%87%e5%ad%97%e5%b9%b2%e8%b4%a7%e5%a6%82%e4%bd%95%e8%ae%a9%e7%94%a8%e6%88%b7%e4%bd%93%e9%aa%8c%e8%89%af%e5%a5%bd%e7%9a%84%e5%90%8c%e6%97%b6%e6%8f%90%e9%ab%98%e4%ba%a7%e5%93%81%e8%bd%ac%e5%8c%96%e7%8e%87httpswwwuisdccomux-rights-balance" aria-label="万字干货！如何让用户体验良好的同时，提高产品转化率？">万字干货！如何让用户体验良好的同时，提高产品转化率？</a></li>
                <li>
                    <a href="#avoiding-skill-atrophy-in-the-age-of-aihttpsaddyosubstackcompavoiding-skill-atrophy-in-the-age" aria-label="Avoiding Skill Atrophy in the Age of AI">Avoiding Skill Atrophy in the Age of AI</a></li>
                <li>
                    <a href="#ai-agent-%e6%96%b0%e6%8e%a2%e7%b4%a2%e6%9e%84%e5%bb%ba-ai-%e5%8e%9f%e7%94%9f%e5%9b%a2%e9%98%9f%e4%bd%bf%e8%83%bd-ai-%e5%91%98%e5%b7%a5httpszhuanlanzhihucomp1890451189029659278" aria-label="AI Agent 新探索：构建 AI 原生团队，使能 AI 员工">AI Agent 新探索：构建 AI 原生团队，使能 AI 员工</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="值得关注的模型和新技术">值得关注的模型和新技术<a hidden class="anchor" aria-hidden="true" href="#值得关注的模型和新技术">#</a></h1>
<h2 id="google-2025-io-大会">Google 2025 I/O 大会：<a hidden class="anchor" aria-hidden="true" href="#google-2025-io-大会">#</a></h2>
<p><a href="https://blog.google/technology/developers/google-io-2025-collection/">I/O 2025</a></p>
<p>Google在2025年I/O大会上全面展示了AI的最新进展和深度整合战略，涵盖基础模型迭代（如Gemini 2.5、Gemini Diffusion、Gemma 3n、Veo 3和Imagen 4）及多模态创新</p>
<h2 id="openai-codex">OpenAI codex<a hidden class="anchor" aria-hidden="true" href="#openai-codex">#</a></h2>
<p><a href="https://openai.com/index/introducing-codex/">Introducing Codex</a></p>
<p>OpenAI 于 2025年5月16日推出了 Codex 软件工程代理及其驱动模型 codex-1 和 codex-mini-latest，专注提升软件开发的自动化与效率。codex-1 基于 o3 模型，优化并行处理、多轮测试和复杂项目支持，擅长代码生成、Bug 修复等任务；codex-mini-latest 则主打低延迟，适合快速命令行操作。Codex 平台通过云端隔离沙箱，安全模拟真实开发环境，自动化完成如重构、测试编写等任务，支持细致行为定制。</p>
<h2 id="claude-4">Claude 4<a hidden class="anchor" aria-hidden="true" href="#claude-4">#</a></h2>
<p><a href="https://www.anthropic.com/news/claude-4">Introducing Claude 4</a></p>
<p>Anthropic 于2025年5月22日发布了新一代 Claude 4 系列模型，包括 Claude Opus 4 和 Claude Sonnet 4，重点提升了编码、高级推理和对AI代理的支持能力。Opus 4 在行业编码基准测试中表现领先，拥有更强的内存与持续任务能力，并大幅减少“抄近路”行为，专注于高复杂任务和AI代理核心场景。Sonnet 4 则在提升推理与指令遵循能力的同时，平衡了性能与效率。</p>
<h2 id="deepseek-r1-0528"><strong>DeepSeek-R1-0528</strong><a hidden class="anchor" aria-hidden="true" href="#deepseek-r1-0528">#</a></h2>
<p>Huggingface： <a href="https://huggingface.co/deepseek-ai/DeepSeek-R1-0528">deepseek-ai/DeepSeek-R1-0528</a></p>
<p>通过强化学习与算法优化实现推理能力提升，单问题推理深度翻倍（平均Token量从12K→23K），更强的数学、编码能力，并支持工具调用，大幅降低幻觉。同时开源了蒸馏小模型模型 <a href="https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B">deepseek-ai/DeepSeek-R1-0528-Qwen3-8B</a>。</p>
<h2 id="flowith-neo"><strong>Flowith Neo</strong><a hidden class="anchor" aria-hidden="true" href="#flowith-neo">#</a></h2>
<p>Flowith Neo 是 Flowith 团队推出的新一代 AI 智能代理，专为自动化复杂、长流程任务设计。其核心技术包括支持无限步骤的持续云端执行、强大的上下文保持能力、灵活调用多种外部工具，以及可视化工作流和自反思机制，显著提升流程的连贯性和可靠性。</p>
<h1 id="值得关注的开源项目">值得关注的开源项目<a hidden class="anchor" aria-hidden="true" href="#值得关注的开源项目">#</a></h1>
<h2 id="deerflow"><strong>DeerFlow</strong><a hidden class="anchor" aria-hidden="true" href="#deerflow">#</a></h2>
<p>Github: <a href="https://github.com/bytedance/deer-flow">github.com/bytedance/deer-flow</a></p>
<p>由字节跳动开源的，基于LangStack 开发的Deep Research 开源项目，支持深度研究、MCP 集成、报告 AI 增强编辑以及播客生成等功能，通过Docker compose一键启动。</p>
<h2 id="flowgramai"><strong>FlowGram.AI</strong><a hidden class="anchor" aria-hidden="true" href="#flowgramai">#</a></h2>
<p>Github: <a href="http://github.com/bytedance/flowgram.ai">github.com/bytedance/flowgram.ai</a></p>
<p>FlowGram.AI 是由字节跳动推出的一款基于节点的可视化流程构建引擎，支持<strong>固定布局</strong>和<strong>自由连接布局</strong>两种模式，帮助开发者快速创建清晰输入输出的交互式工作流。</p>
<h2 id="mcp-server-chart"><strong>MCP Server Chart</strong><a hidden class="anchor" aria-hidden="true" href="#mcp-server-chart">#</a></h2>
<p>Github: <a href="http://github.com/antvis/mcp-server-chart">github.com/antvis/mcp-server-chart</a></p>
<p>MCP Server Chart 是一个基于 AntV 的可视化MCP server，支持通过 AI 工具生成 15+ 种图表类型（如面积图、柱状图、折线图、词云等），并兼容 SSE 和 Streamable 协议，可无缝集成到 Claude、VSCode、Cline 等桌面或在线平台.</p>
<h2 id="rl-factory">RL-Factory<a hidden class="anchor" aria-hidden="true" href="#rl-factory">#</a></h2>
<p>Github: <a href="https://github.com/Simple-Efficient/RL-Factory">github.com/Simple-Efficient/RL-Factory</a></p>
<p>RL-Factory 是一个专为代理强化学习（Agent Learning）设计的高效框架，通过解耦环境与强化学习后训练流程，让用户仅需配置工具和奖励函数即可快速训练智能体。其核心优势包括：<strong>易用性</strong>（支持一键式Qwen3模型训练及多轮工具调用，内置模型评估奖励机制）、<strong>高效性</strong>（异步工具调用和奖励计算使训练速度提升2倍）、<strong>模型支持</strong>（当前原生支持Qwen3系列模型，如Qwen3-4B/8B，并计划扩展至Deepseek、Llama等主流模型）。框架提供端到端检索模型训练能力（通过rag_server），并计划集成WebUI实现全流程可视化管理</p>
<h1 id="值得关注的研究和论文">值得关注的研究和论文<a hidden class="anchor" aria-hidden="true" href="#值得关注的研究和论文">#</a></h1>
<h2 id="efficientllm-efficiency-in-large-language-models"><strong>EfficientLLM: Efficiency in Large Language Models</strong><a hidden class="anchor" aria-hidden="true" href="#efficientllm-efficiency-in-large-language-models">#</a></h2>
<p>arXiv:<a href="https://arxiv.org/abs/2505.13840">2505.13840</a></p>
<p><strong>No One-Size-Fits-All Solution: 没有免费午餐</strong>,任何效率提升都伴随着其他方面的代价</p>
<blockquote>
<p>MoE架构虽然能提升模型性能并减少每token的FLOPs，但会使峰值VRAM使用量增加约40%</p>
</blockquote>
<blockquote>
<p>int4可节省高达3.9倍的内存占用和能耗，但会导致任务平均准确率下降约3-5%</p>
</blockquote>
<p><strong>Optima are Task- and Scale-Dependent:</strong> 效率最优解高度依赖于具体情境</p>
<ul>
<li>MQA在内存受限设备上提供了最佳的内存-延迟边界；MLA在质量关键任务中产生最低的困惑度；NSA能耗最低</li>
<li>对于1B-3B模型，LoRA及其变体（如DoRA）在特定内存约束下损失最低；对于超过14B参数的模型，<a href="https://huggingface.co/blog/damjan-k/rslora">RSLoRA</a>在效率上（更低延迟和功耗）超过了LoRA。参数冻结在微调过程中端到端延迟最低</li>
<li>int4训练后量化能显著提升内存效率（最高减少3.9倍内存占用）和推理吞吐量（在内存受限条件下可提升3倍），同时模型性能仅有轻微下降（平均任务得分下降3-5个百分点）；bfloat16在Hopper架构GPU上一致优于float16</li>
</ul>
<p><strong>Broad Applicability Across Modalities：</strong></p>
<ul>
<li>在LLM上验证的效率技术能有效迁移到LVM和VLM</li>
<li>MQA/GQA能提高LVM的生成质量</li>
<li>PEFT方法在LVM和VLM上也实现了良好的性能-效率权衡</li>
</ul>
<h2 id="nemotron-research-tool-n1-exploring-tool-using-language-models-with-reinforced-reasoning">Nemotron-Research-Tool-N1: Exploring Tool-Using Language Models with Reinforced Reasoning<a hidden class="anchor" aria-hidden="true" href="#nemotron-research-tool-n1-exploring-tool-using-language-models-with-reinforced-reasoning">#</a></h2>
<p><a href="https://arxiv.org/abs/2505.00024">Paper</a></p>
<p>使用RL 提升LLM的tool-using能力</p>
<p>解决的问题：</p>
<ul>
<li>SFT tool-using 需要大量数据标注</li>
<li>目前方法面对OOD数据表现不佳</li>
</ul>
<p><strong>具体实现</strong></p>
<ul>
<li>基于Qwen2.5-7B/14B-Instruct，采用GRPO</li>
<li>策略模型输出包含两部分：：用<code>&lt;thinking&gt;</code>标签包裹的自然语言推理 和 用<code>&lt;tool_call&gt;</code>标签包裹的JSON格式工具名及参数</li>
<li>奖励设计：
<ul>
<li>格式正确性</li>
<li>工具调用正确性：工具名与参数需与真实值完全匹配（通过字典格式验证）</li>
</ul>
</li>
<li>无需预训练SFT，直接从原始数据进行RL训练</li>
<li>数据：整合xLAM和ToolACE数据集，过滤无效工具调用，将多轮对话拆分为单步预测实例</li>
</ul>
<p><strong>有趣发现</strong></p>
<ul>
<li><strong>SFT-then-RL未必最优</strong>：纯RL训练优于SFT-then-RL流程（但并不显著），SFT可能阻碍RL性能</li>
<li><strong>二元奖励优于细粒度奖励</strong>：细粒度奖励（如部分正确得分）易导致模型过拟合格式或局部匹配</li>
<li>移除格式正确性奖励，导致性能下降</li>
</ul>
<p>类似的tool-RL方向论文：</p>
<ul>
<li><a href="https://arxiv.org/abs/2503.23383">TORL: Scaling Tool-Integrated RL</a></li>
<li><a href="https://arxiv.org/abs/2504.11536">ReTool: Reinforcement Learning for Strategic tool use in LLMs</a></li>
<li><a href="https://arxiv.org/abs/2504.13958">ToolRL: Reward is All Tool Learning Needs</a></li>
<li><a href="https://arxiv.org/abs/2504.04736">Synthetic Data Generation &amp; Multi-step RL for Reasoning &amp; tool use</a></li>
</ul>
<h2 id="llms-get-lost-in-multi-turn-conversation">LLMs Get Lost In Multi-Turn Conversation<a hidden class="anchor" aria-hidden="true" href="#llms-get-lost-in-multi-turn-conversation">#</a></h2>
<p><a href="https://arxiv.org/html/2505.06120v1">Paper</a></p>
<p>arXiv:2505.06120</p>
<p><img loading="lazy" src="https://arxiv.org/html/2505.06120v1/x1.png" alt=""  />
</p>
<p>关于LLMs在<strong>多轮未完全指定对话场景下的性能退化问题</strong></p>
<p>Get lost的原因：</p>
<ul>
<li><strong>过早且错误的假设</strong>：模型在对话早期基于不完整的信息做出假设，后续对话中，模型会围绕错误假设生成答案，导致最终结果完全偏离用户真实需求</li>
<li><strong>未掌握完整信息时尝试完整解答</strong>：模型急于生成最终答案，即使用户尚未提供所有必要信息，；因为LLMs的训练目标不包含信息完善等内容</li>
<li><strong>过度依赖之前的错误答案</strong>：模型将自己之前的错误回答视为“事实”，并在后续对话中不断强化这些错误</li>
<li><strong>输出过于冗长</strong>：模型生成冗长的回答，包含无关细节或重复内容；因为训练数据中长文本占比高，且模型倾向于“过度解释”以避免遗漏</li>
<li><strong>忽视中间回合的信息</strong>：模型对对话开头和结尾的信息关注度更高，但忽略中间回合的关键细节 “loss-in-the-middle”</li>
</ul>
<p>建议：</p>
<ul>
<li><strong>整合需求到单轮提示：一次性把话讲清楚</strong></li>
<li><strong>对话偏离时：重启并提供总结</strong></li>
<li><strong>Be careful</strong>：
<ul>
<li>多模型交叉验证</li>
<li>Temperature可以减少随机性，但即便为0也仍存在不可靠性</li>
</ul>
</li>
<li>开发建议：
<ul>
<li>基准测试评估：增加多轮未指定任务的评估，而非仅关注单轮性能</li>
<li>错误识别修正，self-verification</li>
<li>意图识别</li>
</ul>
</li>
</ul>
<h1 id="zerosearch-incentivize-the-search-capability-of-llms-without-searching">ZeroSearch: Incentivize the Search Capability of LLMs without Searching<a hidden class="anchor" aria-hidden="true" href="#zerosearch-incentivize-the-search-capability-of-llms-without-searching">#</a></h1>
<p><a href="https://arxiv.org/html/2505.04588v1">Paper</a></p>
<p>解决了两个主要问题:</p>
<ul>
<li>从真实搜索引擎返回的文档质量往往不可预测，这会给训练过程引入噪声和不稳定性</li>
<li>强化学习(RL)训练需要频繁进行推演(rollout)，可能涉及数十万次搜索请求，这会产生巨大的API费用并严重限制可扩展性</li>
</ul>
<p><strong>创新点</strong></p>
<p>提出了ZeroSearch框架，<strong>一种不需要与真实搜索引擎交互就能增强LLM搜索能力的强化学习方法</strong>; 通过轻量级监督微调，将LLM转变为能够根据查询生成相关和噪声文档的检索模块;</p>
<p>设计了Curriculum learning 的推演策略，在训练过程中逐步降低生成文档的质量，使模型逐渐适应更具挑战性的检索场景;</p>
<p>引入损失屏蔽机制，确保只对模型自身生成的token应用损失计算，避免从检索模块生成的文档token影响训练稳定性</p>
<p><strong>具体实现</strong></p>
<p><img loading="lazy" src="https://arxiv.org/html/2505.04588v1/x1.png" alt=""  />
</p>
<ul>
<li>
<p><strong>搜索模拟微调</strong></p>
<ul>
<li>收集LLM与真实搜索引擎交互的轨迹，根据是否导致正确答案将其标记为正面或负面样本</li>
<li>从这些轨迹中提取查询-文档对进行轻量级监督微调</li>
</ul>
</li>
<li>
<p><strong>Curriculum Search Simulation:</strong> 使用概率函数控制生成噪声文档的可能性，随着训练进行逐步增加难度,允许策略模型先学习基本输出格式和任务要求，然后逐渐适应更具挑战性的检索场景</p>
<p>噪声文档生成概率：</p>
</li>
</ul>
<p>$$p_i = p_s + \frac{b^{i/m} - 1}{b - 1} (p_e - p_s)$$</p>
<ul>
<li>
<p><strong>奖励设计:</strong> 采用基于F1分数的奖励，平衡精确率和召回率，避免模型通过生成过长答案来提高命中率的&quot;reward hacking&quot;行为</p>
<p>$$r_\phi(x, y) = \frac{2 \times IN}{PN + RN}$$</p>
<p>其中 IN 为模型输出与标准答案之间的重叠词数（Intersection Number），PN 和  RN 分别为模型输出的词数（Prediction Number） 和标准答案的词数（Reference Number）</p>
<p><strong>没有对输出格式单独奖励</strong>，因为实验发现模型在训练过程中能自发学会输出规范格式</p>
</li>
</ul>
<h2 id="phi-4-mini-reasoning-exploring-the-limits-of-small-reasoning-language-models-in-math">Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math<a hidden class="anchor" aria-hidden="true" href="#phi-4-mini-reasoning-exploring-the-limits-of-small-reasoning-language-models-in-math">#</a></h2>
<p><a href="https://arxiv.org/html/2504.21233v1">Paper</a></p>
<p>如何提升小型LLM（3.8B）在数学推理任务中的推理能力；</p>
<p>实现：</p>
<ul>
<li><strong>Distillation</strong>：利用DeepSeek-R1生成的大量多领域、多难度的CoT推理数据，对Phi-4-Mini进行中间训练，提升其基础推理能力
<ul>
<li>如果数据集包含reasoning trajectories，则直接使用，没有推理过程，则用DeepSeek-R1生成CoT推理答案，生成8个不同rollouts，最终总共收集了约160万道题、1000万个rollouts</li>
<li>用自动化工具检查答案是否正确，对于工具的误判复杂解答，用GPT-4o-mini再复查一遍</li>
</ul>
</li>
<li><strong>Rollout Preference Learning</strong>：利用大模型生成的错误推理样本，构建正确-错误的偏好对，采用DPO方法优化</li>
<li><strong>RL with Verifiable Reward</strong>： 使用GRPO进一步优化，奖励函数为自动化验证工具对最终答案的判定</li>
</ul>
<p>遇到的问题和解决方案：</p>
<ul>
<li><strong>响应长度差异大导致训练不稳定</strong>：采用<strong>Prompt Optimization</strong>，在RL训练前，先用蒸馏后的模型对多个候选prompt多轮采样，只保留那些生成答案长度比较一致的prompt；</li>
<li><strong>奖励一致时梯度消失问题</strong>，GRPO依赖于advantage estimate，如果同一组采样的答案奖励完全一样（比如全对或全错），就会导致梯度为零；即便将全对/全错过滤，长度差异大，梯度依然不稳定，正负样本极度不平衡，影响RL收敛：**Reward Rebalancing，**针对难题，先过采样以保证组内多样性，然后把所有正向奖励的答案都保留，再随机采样等量的负向奖励答案，保证正负样本平衡，对于太容易的题目直接过滤掉。</li>
<li><strong>Exploration–Exploitation Tradeoff</strong>，RL训练需要exploration才能找到高奖励策略，通常用高温度采样促进探索，但实际评测时往往用低温度来减少输出波动：<strong>Temperature Annealing</strong>，训练初期用高温度（1.0）促进探索，随着训练进展，线性降低温度到0.6，后期固定为0.6，逐步过渡到exploitation</li>
</ul>
<h2 id="universalrag-retrieval-augmented-generation-over-multiple-corpora-with-diverse-modalities-and-granularities">UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities<a hidden class="anchor" aria-hidden="true" href="#universalrag-retrieval-augmented-generation-over-multiple-corpora-with-diverse-modalities-and-granularities">#</a></h2>
<p><a href="https://arxiv.org/pdf/2504.20734">Paper</a></p>
<ul>
<li>如何让RAG系统能灵活地从多种模态和多种粒度的知识库中检索最合适的信息，提升事实准确性和适应性。</li>
<li>现有“统一嵌入空间”的多模态检索方法存在“模态鸿沟”（modality gap），即检索时更倾向于返回与查询同模态的数据，导致跨模态检索效果差。</li>
</ul>
<p><strong>主要创新点</strong></p>
<ul>
<li><strong>Modality-aware Routing</strong>：不再强行将所有模态数据压缩到同一个嵌入空间，而是为每种模态（文本、图片、视频）分别维护独立的检索空间，通过一个“路由”模块，根据查询内容动态判断最适合的模态和粒度，然后只在对应的知识库中检索。</li>
<li><strong>Granularity-aware Retrieval</strong>：每种模态下进一步细分粒度：如文本分为段落级、文档级，视频分为片段级、完整视频级，图片本身为最细粒度，路由不仅判断模态，还能判断所需的粒度，提升检索的相关性和生成质量</li>
<li><strong>路由器设计</strong>：支持“零训练”路由（用大模型如GPT-4o直接prompt分类）和“有监督训练”路由（用DistilBERT、T5-Large等模型训练分类器）</li>
</ul>
<p><strong>具体实现</strong></p>
<ul>
<li><strong>路由</strong>： 输入查询后，路由器首先判断该问题是否需要外部检索，若需检索，则进一步判断最合适的模态（文本/图片/视频）和粒度（段落/文档/片段/完整视频）</li>
<li><strong>分模态检索</strong>：每种模态有独立的检索器和嵌入空间，避免模态混淆</li>
<li><strong>生成回答</strong>：检索到的内容与原始查询一起输入到多模态大模型（LVLM）中，生成最终回答</li>
</ul>
<h1 id="推荐内容">推荐内容<a hidden class="anchor" aria-hidden="true" href="#推荐内容">#</a></h1>
<p>Huggingface 官方推出的MCP教程: <a href="https://huggingface.co/learn/mcp-course/unit0/introduction">MCP Course</a></p>
<p>Deepleaning.AI 同Anthropic 联手推出的MCP课程： <a href="https://www.deeplearning.ai/short-courses/mcp-build-rich-context-ai-apps-with-anthropic/"><strong>MCP: Build Rich-Context AI Apps with Anthropic</strong></a></p>
<p><a href="github.com/InterviewReady/ai-engineering-resources">AI Engineering Transition Path</a></p>
<p><a href="https://github.com/microsoft/AI-Red-Teaming-Playground-Labs">AI Red Teaming Playground Labs</a></p>
<hr>
<h1 id="影音记录">影音记录<a hidden class="anchor" aria-hidden="true" href="#影音记录">#</a></h1>
<h2 id="精选歌单">精选歌单<a hidden class="anchor" aria-hidden="true" href="#精选歌单">#</a></h2>
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/6RUJy9JgajUYWXlkbyHAvf?utm_source=generator" width="100%" height="450" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
<h2 id="live演出">Live演出<a hidden class="anchor" aria-hidden="true" href="#live演出">#</a></h2>
<ul>
<li>05.08 Adam Fischer-杜塞尔多夫交响乐团《马勒第九交响》</li>
<li>05.09 Honeydip</li>
<li>05.10 Hans Zimmer</li>
<li>05.16 Envy</li>
<li>05.23 Sea Power</li>
<li>05.24-05.25 Offside Festival</li>
<li>05.28 Maruja</li>
</ul>
<h1 id="书阅读摘录">书&amp;阅读摘录<a hidden class="anchor" aria-hidden="true" href="#书阅读摘录">#</a></h1>
<h2 id="why-cline-doesnt-index-your-codebase-and-why-thats-a-good-thinghttpsclinebotblogwhy-cline-doesnt-index-your-codebase-and-why-thats-a-good-thing"><a href="https://cline.bot/blog/why-cline-doesnt-index-your-codebase-and-why-thats-a-good-thing">Why Cline Doesn&rsquo;t Index Your Codebase (And Why That&rsquo;s a Good Thing)</a><a hidden class="anchor" aria-hidden="true" href="#why-cline-doesnt-index-your-codebase-and-why-thats-a-good-thinghttpsclinebotblogwhy-cline-doesnt-index-your-codebase-and-why-thats-a-good-thing">#</a></h2>
<blockquote>
<p>Why RAG Breaks Down for Code
…
The approach seems straightforward – chunk your data, create embeddings, store them in a vector database, and retrieve relevant pieces when needed.
…
But code isn&rsquo;t like other data. It&rsquo;s interconnected, constantly evolving, and often contains your most sensitive intellectual property. When you apply traditional RAG approaches to codebases, three critical problems emerge:</p>
</blockquote>
<ol>
<li><strong>Code Doesn&rsquo;t Think in Chunks</strong>
…
when you chunk code for embeddings, you&rsquo;re literally tearing apart its logic.
…</li>
<li><strong>Indexes Decay While Code Evolves</strong>
…
An index, by definition, is a snapshot frozen in time. The code inevitably drifts out of sync.
…</li>
</ol>
<blockquote>
</blockquote>
<blockquote>
<p>Cline&rsquo;s Approach: Think Like a Developer, Act Like a Developer
…
Starting with Structure, Not Snippets
…
Discovery, Not Retrieval</p>
</blockquote>
<h2 id="if-youre-an-engineer-whos-feeling-hesitant-or-overwhelmed-byhttpsxcomclinestatus1922846215894597996"><a href="https://x.com/cline/status/1922846215894597996">If you&rsquo;re an engineer who&rsquo;s feeling hesitant or overwhelmed by…</a><a hidden class="anchor" aria-hidden="true" href="#if-youre-an-engineer-whos-feeling-hesitant-or-overwhelmed-byhttpsxcomclinestatus1922846215894597996">#</a></h2>
<blockquote>
<p>stop treating AI like a vending machine for code.
Think of AI as a highly skilled (but forgetful) pair programmer.
Planning before AI writes any code. Frontload all relevant context &ndash; files, existing patterns, overall goals. Then, collaboratively develop a strategy with your AI.</p>
</blockquote>
<blockquote>
<p>Use &ldquo;Rules Files&rdquo; &ndash; essentially custom instructions &ndash; to persistently guide AI behavior.
Complement Rules Files with &ldquo;Memory Banks.”
This allows the AI to &ldquo;remember&rdquo; critical project details, patterns, and decisions over time.</p>
</blockquote>
<h2 id="万字干货如何让用户体验良好的同时提高产品转化率httpswwwuisdccomux-rights-balance"><a href="https://www.uisdc.com/ux-rights-balance">万字干货！如何让用户体验良好的同时，提高产品转化率？</a><a hidden class="anchor" aria-hidden="true" href="#万字干货如何让用户体验良好的同时提高产品转化率httpswwwuisdccomux-rights-balance">#</a></h2>
<blockquote>
<p>确实能带来短期转化，但问题是只要用户反感一次，就很难再赢回来了</p>
</blockquote>
<blockquote>
<p>结论：良好的用户引导应以用户利益为核心</p>
</blockquote>
<blockquote>
<p>用户引导不该是“温柔的陷阱”，而应该是“清晰的邀请”；产品设计也不该是“只求你上钩”，而应该是“愿你心甘情愿留下”</p>
</blockquote>
<h2 id="avoiding-skill-atrophy-in-the-age-of-aihttpsaddyosubstackcompavoiding-skill-atrophy-in-the-age"><a href="https://addyo.substack.com/p/avoiding-skill-atrophy-in-the-age">Avoiding Skill Atrophy in the Age of AI</a><a hidden class="anchor" aria-hidden="true" href="#avoiding-skill-atrophy-in-the-age-of-aihttpsaddyosubstackcompavoiding-skill-atrophy-in-the-age">#</a></h2>
<blockquote>
<p>we may be increasing productivity, but at risk of losing our edge to skill atrophy if we’re not careful.</p>
</blockquote>
<blockquote>
<p>This cognitive offloading - relying on external tools to handle mental tasks - has plenty of precedents.</p>
</blockquote>
<blockquote>
<p>tempt us to “turn off our brain” for routine coding tasks.
…
“I’ve become a human clipboard”</p>
</blockquote>
<blockquote>
<p>Using AI as a collaborator, not a crutch
Use AI to augment, not replace, code review.
Pair program with the AI.</p>
</blockquote>
<h2 id="ai-agent-新探索构建-ai-原生团队使能-ai-员工httpszhuanlanzhihucomp1890451189029659278"><a href="https://zhuanlan.zhihu.com/p/1890451189029659278">AI Agent 新探索：构建 AI 原生团队，使能 AI 员工</a><a hidden class="anchor" aria-hidden="true" href="#ai-agent-新探索构建-ai-原生团队使能-ai-员工httpszhuanlanzhihucomp1890451189029659278">#</a></h2>
<blockquote>
<p><strong>为什么目前的 AI 无法成为靠谱的数字员工</strong>:
首先是企业知识未文档化的问题…很少有系统性的文档记录…
工具与系统的操作障碍严重限制了 AI 的能力发挥
AI Agent 缺少执行持续任务的机制
AI 缺少长期记忆机制，难以累积经验和知识</p>
</blockquote>
<blockquote>
<p>要让 AI 成为有效的团队成员，首先要解决的不是 AI 技术本身，而是企业知识管理的问题。
要真正发挥 AI 的潜力，我们不仅需要提升 AI 的能力，还需要改造现有的工具和系统
然而，许多企业的 CI/CD 管道不完善或不存在…环境配置往往是手动完成的，难以复制。
…
原因很简单： B 团队的知识是可检索的，而 A 团队的知识被锁在人脑和私人对话中
…
而在 AI 原生团队中，知识必须从个人大脑转移到共享资源 — “团队知道某事” 增加了整体效能。
…
Markdown 与 Git 等版本控制系统兼容性更好，支持差异对比和协作编辑，这对团队知识管理至关重要。
…
为内部系统提供 API 接口</p>
</blockquote>
<blockquote>
<p>即使是最聪明的开发者（或 AI）也需要适当的测试条件。
测试驱动开发(TDD)的理念在 AI 时代变得更加重要
…
在 AI 时代，这变成了”人机四眼”—AI 生成的代码需要人类审查，人类编写的复杂代码可由 AI 辅助检查。</p>
</blockquote>
<blockquote>
<p>它核心理念是”要想真正学会，就要能教会他人”。
要求 AI 在接受任务后首先生成一份 “工作理解文档”，包括：
目标概述：一句话总结任务目标上下文理解：相关背景和约束澄清问题：需要进一步明确的事项初步方案：可能的实现路径预期成果：如何评判成功
…
与其说我们在教 AI 如何更好地执行任务，不如说我们在教它如何更好地理解任务</p>
</blockquote>
<blockquote>
<p>主动性不足是限制 AI 成为真正团队成员的另一大障
…
一个沉默地陷入困境的员工比一个主动寻求帮助的员工更让人担忧。
…
而优秀的数字员工则会明确描述问题所在，提出可能的解决路径，并寻求必要的帮助。</p>
</blockquote>
<blockquote>
<p>从系统安全角度看，这涉及到”环境状态管理”—对工作环境变化的监控和保护能力。
…
变更范围评估：此操作会影响哪些系统组件？风险等级判定：操作可能导致的最坏结果是什么？可逆性分析：如果出错，恢复难度有多大？备选方案考虑：是否存在风险更低的替代方法？</p>
</blockquote>
<hr>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://niraya666.github.io/tags/%E6%9C%88%E5%88%8A/">月刊</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-05 月刊 on x"
            href="https://x.com/intent/tweet/?text=2025-05%20%e6%9c%88%e5%88%8a&amp;url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-05-%25E6%259C%2588%25E5%2588%258A%2f&amp;hashtags=%e6%9c%88%e5%88%8a">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-05 月刊 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-05-%25E6%259C%2588%25E5%2588%258A%2f&amp;title=2025-05%20%e6%9c%88%e5%88%8a&amp;summary=2025-05%20%e6%9c%88%e5%88%8a&amp;source=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-05-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-05 月刊 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-05-%25E6%259C%2588%25E5%2588%258A%2f&title=2025-05%20%e6%9c%88%e5%88%8a">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-05 月刊 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-05-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-05 月刊 on whatsapp"
            href="https://api.whatsapp.com/send?text=2025-05%20%e6%9c%88%e5%88%8a%20-%20https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-05-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-05 月刊 on telegram"
            href="https://telegram.me/share/url?text=2025-05%20%e6%9c%88%e5%88%8a&amp;url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-05-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-05 月刊 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=2025-05%20%e6%9c%88%e5%88%8a&u=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-05-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
<div id="utterances">
  <script src="https://utteranc.es/client.js"
        repo="Niraya666/niraya666.github.io"
        issue-term="pathname"
        theme="preferred-color-scheme"
        crossorigin="anonymous"
        async>
  </script>
</div>


<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      packages: {'[+]': ['ams']}
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2026 <a href="https://niraya666.github.io/">LZY Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
