<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>2025-12 月刊 | LZY Blog</title>
<meta name="keywords" content="月刊">
<meta name="description" content="值得关注的模型和新技术
DeepSeek-V3.2
Qwen/Qwen-Image-Layered
zai-org/GLM-4.7
MiniMaxAI/MiniMax-M2.1
Jina-VLM
SAM Audio
值得关注的开源项目
Awesome Claude Skills: A curated list of Claude Skills.
Minne: a read-it-later &amp; personal knowledge management solution
Ebook-MCP: A MCP server that supports mainstream eBook formats including EPUB, PDF and more. Simplify your eBook user experience with LLM.
vibe-vibe: 首个系统化 Vibe Coding 开源教程
data-juicer: Data processing for and with foundation models
open-ptc-agent: An open source implementation of code execution with MCP (Programatic Tool Calling)">
<meta name="author" content="Theme PaperMod">
<link rel="canonical" href="https://niraya666.github.io/monthly/2025-12-%E6%9C%88%E5%88%8A/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://niraya666.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://niraya666.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://niraya666.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://niraya666.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://niraya666.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://niraya666.github.io/monthly/2025-12-%E6%9C%88%E5%88%8A/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="2025-12 月刊" />
<meta property="og:description" content="值得关注的模型和新技术
DeepSeek-V3.2
Qwen/Qwen-Image-Layered
zai-org/GLM-4.7
MiniMaxAI/MiniMax-M2.1
Jina-VLM
SAM Audio
值得关注的开源项目
Awesome Claude Skills: A curated list of Claude Skills.
Minne: a read-it-later &amp; personal knowledge management solution
Ebook-MCP: A MCP server that supports mainstream eBook formats including EPUB, PDF and more. Simplify your eBook user experience with LLM.
vibe-vibe: 首个系统化 Vibe Coding 开源教程
data-juicer: Data processing for and with foundation models
open-ptc-agent: An open source implementation of code execution with MCP (Programatic Tool Calling)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://niraya666.github.io/monthly/2025-12-%E6%9C%88%E5%88%8A/" />
<meta property="og:image" content="https://niraya666.github.io/img/monthly/2025-07/D21E5120-27F7-4233-A9DF-B07DB353604D_1_102_o.jpeg" /><meta property="article:section" content="monthly" />
<meta property="article:published_time" content="2025-12-30T20:05:00+08:00" />
<meta property="article:modified_time" content="2025-12-30T20:05:00+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://niraya666.github.io/img/monthly/2025-07/D21E5120-27F7-4233-A9DF-B07DB353604D_1_102_o.jpeg" />
<meta name="twitter:title" content="2025-12 月刊"/>
<meta name="twitter:description" content="值得关注的模型和新技术
DeepSeek-V3.2
Qwen/Qwen-Image-Layered
zai-org/GLM-4.7
MiniMaxAI/MiniMax-M2.1
Jina-VLM
SAM Audio
值得关注的开源项目
Awesome Claude Skills: A curated list of Claude Skills.
Minne: a read-it-later &amp; personal knowledge management solution
Ebook-MCP: A MCP server that supports mainstream eBook formats including EPUB, PDF and more. Simplify your eBook user experience with LLM.
vibe-vibe: 首个系统化 Vibe Coding 开源教程
data-juicer: Data processing for and with foundation models
open-ptc-agent: An open source implementation of code execution with MCP (Programatic Tool Calling)"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Monthlies",
      "item": "https://niraya666.github.io/monthly/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "2025-12 月刊",
      "item": "https://niraya666.github.io/monthly/2025-12-%E6%9C%88%E5%88%8A/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "2025-12 月刊",
  "name": "2025-12 月刊",
  "description": "值得关注的模型和新技术 DeepSeek-V3.2\nQwen/Qwen-Image-Layered\nzai-org/GLM-4.7\nMiniMaxAI/MiniMax-M2.1\nJina-VLM\nSAM Audio\n值得关注的开源项目 Awesome Claude Skills: A curated list of Claude Skills.\nMinne: a read-it-later \u0026amp; personal knowledge management solution\nEbook-MCP: A MCP server that supports mainstream eBook formats including EPUB, PDF and more. Simplify your eBook user experience with LLM.\nvibe-vibe: 首个系统化 Vibe Coding 开源教程\ndata-juicer: Data processing for and with foundation models\nopen-ptc-agent: An open source implementation of code execution with MCP (Programatic Tool Calling)\n",
  "keywords": [
    "月刊"
  ],
  "articleBody": "值得关注的模型和新技术 DeepSeek-V3.2\nQwen/Qwen-Image-Layered\nzai-org/GLM-4.7\nMiniMaxAI/MiniMax-M2.1\nJina-VLM\nSAM Audio\n值得关注的开源项目 Awesome Claude Skills: A curated list of Claude Skills.\nMinne: a read-it-later \u0026 personal knowledge management solution\nEbook-MCP: A MCP server that supports mainstream eBook formats including EPUB, PDF and more. Simplify your eBook user experience with LLM.\nvibe-vibe: 首个系统化 Vibe Coding 开源教程\ndata-juicer: Data processing for and with foundation models\nopen-ptc-agent: An open source implementation of code execution with MCP (Programatic Tool Calling)\nAgent-Skills-for-Context-Engineering: A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems.\n值得关注的研究和论文 DeepSeek V3.2 DeepSeek稀疏注意力（DSA） RL协议 Agent任务合成流水线 DeepSeek-V3.2-Speciale： 放宽了长度限制，推理能力增强 DSA\nWhy：解决长序列的计算复杂度\n$O(L^2) -\u003e O(Lk)$\n其中 $k \\ll L$\n通过稀疏化机制减少计算量\nLightning Indexer： 用于计算当前 Query Token 与前序 Token 之间的索引评分 I_{t,s} 。使用 ReLU 作为激活函数，且只包含少量的 Head\nFine-grained Token Selection：基于索引器的评分，只检索 Top-k 个分数最高的 KV 条目\nCore Attention： 仅针对筛选出的这部分稀疏 KV 条目计算注意力输出，而不是针对全序列\nDSA 通过Continued Training完成：\nDense Warm-up Stage：初始化闪电索引器，保持主模型使用Dense Attention，冻结除索引器外的所有参数， 使用 KL 散度损失，强制索引器的输出分布去拟合主模型全量注意力的分布 Sparse Training Stage： 引入细粒度选择机制，让模型适配稀疏模式，开启 Top-k 选择，优化所有模型参数。索引器继续通过 KL 散度学习对齐注意力分布，而主模型则通过语言建模损失进行优化；索引器的输入会从计算图中分离，即索引器的优化仅依赖 KL 损失，不接受语言建模损失的梯度 特性 Vanilla Attention (标准) MLA (DeepSeek-V3.1) DSA (DeepSeek-V3.2) 计算复杂度 $O(L^2)$ (核心注意力) 优化了 KV 缓存，但计算仍较密集 $O(Lk)$ (核心注意力)，显著降低 16 KV 检索方式 全量检索 (Dense) 压缩/潜在向量 (Latent Vector) 稀疏检索 (Top-k Sparse) 17 实现模式 MHA (多头注意力) 支持 MHA 和 MQA 模式 强制使用 MLA 的 MQA 模式 以共享 KV 18 索引机制 无 无 引入 Lightning Indexer，虽然本身复杂度 $O(L^2)$ 但计算量极小 19 性能影响 基准 高性能 无明显降级，在长上下文任务中甚至优于旧版本 20202020 DSA 相比之前的架构，最大的区别在于引入了一个轻量级的“向导”（Indexer）来预先筛选重要的 Token，从而避免了对无关 Token 的大量无效计算。相比于 DeepSeek-V3.1 的 MLA，V3.2 的 DSA 保持了架构兼容性，仅通过训练策略的调整（引入 Indexer 和稀疏化）就实现了显著的效率提升。\n后训练\nSpecialist Distillation\n构建了多个领域的“专家模型”，然后将它们的能力迁移给主模型。（针对 数学、编程、逻辑推理、通用 Agent 任务、Agent 编码、Agent 搜索 这六个领域，分别训练了专门的专家模型），使用训练好的专家模型生成高质量的领域数据，用于微调最终的 DeepSeek-V3.2 检查点\nMixed RL Training\n这一阶段的核心策略是多任务融合，以避免分阶段训练可能导致的“灾难性遗忘”\n沿用了 GRPO 将 Reasoning、Agent 任务 和 Human Alignment的数据整合在同一个 RL 阶段进行训练 奖励： 推理和 Agent 任务： 基于规则的结果奖励，长度惩罚，语言一致性奖励 通用任务： generative reward model，针对每个 prompt 有专门的评分标准 Scaling GRPO\n稳定 GRPO 算法，防止训练崩溃\nUnbiased KL Estimate： ？ Off-Policy Sequence Masking： 推理和训练之间存在不一致（Off-policy），计算数据采样策略与当前策略的 KL 散度，并掩盖掉那些策略差异过大且优势为负的样本 Keep Routing： 强制训练时的专家路由路径与推理采样时保持一致 Keep Sampling Mask： 在训练时复用采样时的截断掩码（Top-p/Top-k mask），确保新旧策略在相同的动作空间子集上进行比较，维护重要性采样的原则 Agentic Task Synthesis\n合成数据流水线\n冷启动，通过设计包含 标签的 System Prompt，将非 Agent 的推理数据与非推理的 Agent 数据结合，引导模型在调用工具前先进行思考 合成任务：利用 DeepSeek-V3.2 构建自动化 Agent 来生成训练环境和数据 搜索 Agent： 自动挖掘长尾实体，构建问答对，并验证答案的正确性 代码 Agent： 从 GitHub 挖掘 Issue-PR 对，自动构建可执行的测试环境（包含 Python, Java, C++ 等多种语言） 通用 Agent： 自动合成超过 1800 个任务导向的环境（如旅行计划） DeepSeek-V3.2-Speciale\n解除对模型思考长度的限制，训练过程中显著降低了对生成长度的惩罚\n为了提升在复杂数学证明任务上的能力，该模型额外整合了来自 DeepSeekMath-V2 的数据集和奖励方法\n在推理能力上显著强于标准版\nHow Far Are We from Genuinely Useful Deep Research Agents? arXiv:2512.01948\n核心贡献:\nFinder (Fine-grained DEepResearch bench)： 一个细粒度的深度研究基准， 引入了419个结构化的检查清单，用于标准化评估报告的结构、分析深度和事实依据 DEFT (Deep rEsearch Failure Taxonomy)： 对深度研究智能体的失败分类学， 将错误细分为3个核心维度（推理、检索、生成）下的14种具体失败模式 DEFT 的构建\nOpen Coding， 使用5种不同的LLM作为编码员，分析失败案例，生成初始概念 Axial Coding 结合人类专家介入，计算一致性， 将概念归纳为14个轴向类别 Selective Coding， 提炼出“推理”、“检索”、“生成”三个核心维度 Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory arXiv:2511.20857\n缺乏一个统一的框架来评估智能体在部署期间（Test-time）如何检索、整合和进化其记忆\n创新点\nEvo-Memory 基准测试：提出了一个新的评估基准，将传统的静态数据集重构为顺序任务流， 要求模型在完成一个任务后，必须更新记忆以供后续任务使用\n评估框架： 归纳了一个通用的记忆智能体公式：(Search -\u003e Synthesis -\u003e Evolve)，即检索、合成上下文、进化记忆的循环\nReMem： 传统的 ReAct 只有“思考”和“行动”， ReMem 引入了 Action–Think–Memory Refine 循环，让智能体主动地推理、修剪和重组记忆\nExpRAG 基准： 一个基于检索的简单基准，专门用于检索过去的“经验”（输入-输出-反馈三元组），而不仅仅是检索知识\nReMem 的工作机制\nThink (思考)： 分解任务，规划步骤。 Act (行动)： 与环境交互。 Refine (优化)： 这是核心。智能体在每一步都会进行“元推理”（Meta-reasoning），决定哪些记忆是杂音需要删除，哪些经验值得保留或重组。 ExpRAG 的工作机制\n将每次任务的 (输入, 预测, 反馈) 作为一个经验单元存入。 在遇到新任务时，检索最相似的 k 个过往经验作为上下文参考 Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs https://alignment.anthropic.com/2025/selective-gradient-masking/\nSelective GradienT Masking (SGTM): 针对LLM中危险知识的移除问题\n在 Transformer 的每一层中，将部分注意力头和 MLP 神经元指定为“遗忘参数”，其余为“保留参数” 在训练过程中，当模型遇到被标记为“危险”的数据时，只更新“遗忘参数”（通过掩盖其他参数的梯度） 当遇到普通数据时，更新“保留参数”。 对于未标记数据，允许更新所有参数 训练结束后，直接将遗忘参数置零。这样就物理上移除了危险知识，同时保留了存储在其他参数中的通用能力。 Budget-Aware Tool-Use Enables Effective Agent Scaling arXiv:2511.17006\nReAct 模式下简单地增加工具调用预算，并不能带来性能提升；往往在预算耗尽前就过早停止搜索，或者在死胡同里浪费资源\n创新：\nBudget Tracker: 在每一轮对话中显式地告诉代理“当前已用多少资源，还剩多少资源”\nBATS (Budget-Aware Test-time Scaling) 框架：\n利用预算感知来动态调整Planning和Verification策略。它能根据剩余预算决定是Dig Deeper当前线索，还是Pivot尝试新路径。\n统一成本指标: 将“Token消耗成本”和“工具调用成本”结合的统一指标 （性价比）\nQwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management arXiv:2512.12967\n长文本数据合成管线 稳定化长文本 RL 策略 记忆增强架构（Memory Agent） 数据合成管线 核心突破在于生成需要在全局分布的证据中进行多跳关联和推理的任务\n通过将文档去构造为原子事实及其底层关系，再通过程序化手段组合成可验证的复杂问题\n合成策略： 基于知识图谱（KG）： 挖掘文档中的实体关系，构建跨文档的多跳推理路径。 基于结构化表（SQL）： 将文档中的数值信息转化为表格，通过 SQL 生成复杂的数值计算问题。 多智能体自进化（MASE）： 使用三个智能体（提问者、解答者、验证者）迭代生成并验证难度递增的问题。 验证： 知识落地检查（Knowledge Grounding Check）：移除源文档，测试模型是否仍能回答。若能回答，说明该问题依赖内部知识而非上下文，会被剔除 上下文鲁棒性检查（Contextual Robustness Check）：通过插入无关文档扩展上下文，确保问题及其答案在复杂的噪声干扰下依然稳健 长文本 RL 长文本RL存在的问题：\n奖励信号，错误答案中往往包含大量正确的推理步骤，导致模型难以区分哪些动作导致了最终的失败 长文本数据涉及多个领域且分布极不均匀，传统的随机采样会导致训练Batch内的任务分布失衡 在长序列训练中，模型很容易陷入响应长度失控或熵崩溃（过度收敛）的陷阱 创新策略：\n采样策略：不再随机选取数据，而是确保每个训练批次中平均分配五类任务 优势估计：改进了 GRPO 算法中的优势计算方式。改为**在同一任务类型内计算奖励的标准差，**隔离不同任务间的奖励噪声 Negative Gradient Clipping， 高熵（模型不确定）的负向样本会产生巨大的梯度，从而扰乱优化过程，通过裁剪或屏蔽这些高熵负面响应的梯度，可以保护模型在探索过程中的潜力 AEPO 算法： AEPO 会根据模型当前的熵动态调整训练：当熵过高（太随机）时，暂时屏蔽负向优势样本以降低熵；当熵过低（太死板）时，重新引入负向梯度以鼓励探索\nProgressive Paradigm： 从 20K 到 60K，再到 120K 输入长度的阶梯式训练；\nMemory Agent 将超长文档切片（Chunking）。 模型按顺序阅读切片，每一步输出：1. 记忆更新（提炼关键信息）；2. 导航计划（决定下一步关注什么，小本子？）。 最后基于累积的记忆生成答案。 采用多阶段融合训练：先训练全上下文推理能力，再训练记忆管理能力，最后通过模型融合（Model Merging）结合两者。 推荐内容 一篇agent-memory综述： Memory in the Age of AI Agents: A Survey\n一系列年度报告：\nOpenRouter: The 2025 State of AI Report Anthropic: How enterprises are building AI agents in 2026 OpenAI: The state of enterprise AI Langchain: State of AI Agents 如何写好Claude.md: Writing a good CLAUDE.md\nLLM 评估时的各式各样细节问题\nChasing 100% Accuracy: A Deep Dive into Debugging Kimi K2’s Tool-Calling on vLLM Why benchmarking is hard Physics of Language Models\n影音记录 精选歌单 Live演出 12.08 L’Impératrice\n12.09 Godspeed you! Black Emperor\n12.13 Diels-Alder\n书\u0026阅读摘录 面向业务落地的AI产品评测体系设计与平台实现 在AI产品落地过程中，它的不确定性、动态性和复杂性，给质量和体验保障带来了前所未有的挑战。AI产品的特性使得测试既不是简单的功能验证，也不是纯算法模型的评测\n工程产品是“需求明确 → 设计实现 → 测试验证”，AI产品则是“技术驱动 → 场景探索 → 效果迭代”的螺旋式过程。 评测需前置至需求阶段，与产品和研发共同定义“好”的标准\n在算法评测中，金标评测集可以长期复用；在agent场景：每次评测时，外部服务数据、时间、接口行为可能变化；即使输入相同，也会因为外围导致答案偏离原始金标。\n以前一个版本是一次代码发布；现在一个版本可能是：模型更换、prompt 改写、检索策略调整、工具编排改造或它们的任意组合；\n评测标准的制定从研发单一角色制定转变到产品、设计、研发、业务方（BD/运营）共同参与指标，从“研发自说自话”转向“业务-技术目标同频”，解决AI产品常见的“技术达标但体验崩坏”问题 回收研发评测、产设验收及线上运营标注数据——将优质数据沉淀为金标集\n我们推荐大部分AI产品的评测基于端到端评测\n针对有参考答案的评测，我们核心要解决的是构造一个稳定可复现的“环境”。\n我们建议按“变更范围 × 变更风险”来设计三档评测策略，并通过用例标签体系自动筛选推荐用例\n怎么评估线上效果 形成“监测-分析-优化”完整闭环\n作为一名科技从业者，如何总结你的 2025？ 在我看来，人类正面临一个自身难以克服的挑战——知识爆炸让我们都成了越来越细分的专家，而创新往往发生在知识的交叉边缘。 当一个人穷其一生都无法触及某个领域的边缘时，跨领域的创新就变得异常困难。而AI正是帮助我们突破知识壁垒，探索未知世界的很好的工具，我对这一点充满了期待。\nAI Agent 很火，但 Agent Infra 准备好了吗？ 之所以 Infra 层会有很大的变化，核心在于，AI Agent 今天的开发和落地范式，与以往的 App 完全不同了。 核心的区别就是不确定性的存在。\n但在 Agent 工程里，失败往往是模型对开发者意图的误解，或者说是概率上的「漂移」。你没办法像修水管一样去修复一个 Agent，只能像教育孩子一样，去引导它、说服它、约束它。\n现在交付的是一种概率性的能力，你很难去定义什么是绝对的「正确」。\n绝大多数工程师从入职第一天起，工作就是在确定性系统里进一步提升确定性，判断标准只有「对」和「错」。但现在我们面对的是不确定性的复杂系统，工作方式必须彻底转变。 这种转变主要体现在两点： 第一，从工程思维转向科学实验思维。而科学实验思维的核心，是建立一套评测体系，把复杂系统拆解成一个个子系统，屏蔽其他子系统的干扰，去单独评测每个子系统的影响。只有通过这种控制变量的方式，一步步摸索，才能驾驭 Agent 的复杂性； 第二，从 Day One 思维转向 Day Two 思维\nAI Infra 更关注的是模型的算力、优化和推理，如何以最快、最稳定的算力服务让模型输出内容。 而 Agent Infra 关注的是项目的最终结果输出，上层的逻辑、记忆和工具调用。如何编排、如何管理记忆、如何调用各种工具接口，如何更稳定在沙盒里运行的问题。\nAI Agent 第一次把「计算」这件事，真正意义上地民主化了。很多以前算不过账的事情，不太经济的商业模式，突然变得合理了。\nDify 认为可调试性、记忆管理和低延迟性能是下一阶段的重点。\n上下文工程：AI-Native时代的软件研发新范式 真正有价值的，不是 AI 写了多少行代码，而是——你是不是在做 AI-Native 的软件工程。\n人定边界，AI 填细节。 想业务、抽象、模型、trade-off，而不是某个库的 API 写法\n上下文就是新的源码（Context is the new Source Code）。\nAgent Engineering: A New Discipline Traditional software assumes you mostly know the inputs and can define the outputs. Agents give you neither: users can say literally anything, and the space of possible behaviors is wide open Agent engineering is the iterative process of refining non-deterministic LLM systems into reliable production experiences. It is a cyclical process: build, test, ship, observe, refine, repeat.\nWe see agent engineering as a new discipline that combines 3 skillsets working together: Product thinking defines the scope and shapes agent behavior Engineering builds the infrastructure that makes agents production-ready. Data science measures and improves agent performance over time\nLLMs are powerful enough to handle complex, multi-step workflows. We’re starting to cross the threshold where agents are delivering meaningful business value in production. Every input is an edge case. You can’t debug the old way. “Working” isn’t binary.\nTo achieve a reliable agent system, shipping is how you learn, not what you do after learning. Build your agent’s foundation. Test based on scenario you can imagine Ship to see real-world behavior Observe. Refine Repeat\nThe teams shipping reliable agents today share one thing: they’ve stopped trying to perfect agents before launch and started treating production as their primary teacher. In other words, tracing every decision, evaluating at scale, and shipping improvements in days instead of quarters.\n微信杂谈：AI 产品 \u0026 品味 agent 也只是当下使用 ai 的一种形式，形式可能会淘汰（比如大模型迭代），但底层的能力不会，应该去关注更本质的东西。\n最近和人聊到 ai 产品，在 vibe coding 大行其道的今天，其实想做出让人眼前一亮的产品，就是需要靠品味和细节来打动人。因为你能做的事情，ai 基本都能做，但是品味这个东西，只可意会不可言传，ai 很难去平衡这个度。\n“情绪价值函数”，它不是简单的对错运算，而是一些感性的东西在帮你做决策\n地下阿根廷：犹太钱庄、华人超市、摆烂的年轻人与返贫的中产 所有的热情，最终都指向了一个赤裸裸的动词：逃生。\n他们并不关心什么是 Web3，他们只关心一件事：USDT 能不能让我手里的钱不缩水。\n当穷人在用现金避税，富人在用 Crypto 转移资产时，谁成了这场危机中唯一的输家？答案令人心碎：是那些遵纪守法的「老实人」。\n中产阶级的崩溃，往往是无声的。他们不会像底层那样上街烧轮胎抗议，也不会像富人那样直接移民。他们只是默默地取消了周末的聚餐，换掉了孩子的私立学校，然后在每一个深夜焦虑地计算着下个月的账单。\n他们是这个国家最听话的纳税人，也是被收割得最彻底的一群人。\n",
  "wordCount" : "950",
  "inLanguage": "en",
  "image":"https://niraya666.github.io/img/monthly/2025-07/D21E5120-27F7-4233-A9DF-B07DB353604D_1_102_o.jpeg","datePublished": "2025-12-30T20:05:00+08:00",
  "dateModified": "2025-12-30T20:05:00+08:00",
  "author":{
    "@type": "Person",
    "name": "Theme PaperMod"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://niraya666.github.io/monthly/2025-12-%E6%9C%88%E5%88%8A/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "LZY Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://niraya666.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://niraya666.github.io/" accesskey="h" title="LZY Blog (Alt + H)">LZY Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://niraya666.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/posts/" title="AI">
                    <span>AI</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/musik/" title="Musik!">
                    <span>Musik!</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/monthly/" title="月刊">
                    <span>月刊</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/essay/" title="杂文">
                    <span>杂文</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/travel/" title="游记">
                    <span>游记</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/travel-map/" title="足迹">
                    <span>足迹</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://niraya666.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://niraya666.github.io/monthly/">Monthlies</a></div>
    <h1 class="post-title entry-hint-parent">
      2025-12 月刊
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2025-12-30 20:05:00 +0800 CST'>December 30, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Theme PaperMod

</div>
  </header> 
<figure class="entry-cover"><a href="https://niraya666.github.io/img/monthly/2025-07/D21E5120-27F7-4233-A9DF-B07DB353604D_1_102_o.jpeg" target="_blank"
            rel="noopener noreferrer"><img loading="eager" src="https://niraya666.github.io/img/monthly/2025-07/D21E5120-27F7-4233-A9DF-B07DB353604D_1_102_o.jpeg" alt="摄于 崇明岛"></a>
        <p>摄于 崇明岛</p>
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e5%80%bc%e5%be%97%e5%85%b3%e6%b3%a8%e7%9a%84%e6%a8%a1%e5%9e%8b%e5%92%8c%e6%96%b0%e6%8a%80%e6%9c%af" aria-label="值得关注的模型和新技术">值得关注的模型和新技术</a></li>
                <li>
                    <a href="#%e5%80%bc%e5%be%97%e5%85%b3%e6%b3%a8%e7%9a%84%e5%bc%80%e6%ba%90%e9%a1%b9%e7%9b%ae" aria-label="值得关注的开源项目">值得关注的开源项目</a></li>
                <li>
                    <a href="#%e5%80%bc%e5%be%97%e5%85%b3%e6%b3%a8%e7%9a%84%e7%a0%94%e7%a9%b6%e5%92%8c%e8%ae%ba%e6%96%87" aria-label="值得关注的研究和论文">值得关注的研究和论文</a><ul>
                        
                <li>
                    <a href="#deepseek-v32" aria-label="DeepSeek V3.2">DeepSeek V3.2</a></li>
                <li>
                    <a href="#how-far-are-we-from-genuinely-useful-deep-research-agents" aria-label="How Far Are We from Genuinely Useful Deep Research Agents?">How Far Are We from Genuinely Useful Deep Research Agents?</a></li>
                <li>
                    <a href="#evo-memory-benchmarking-llm-agent-test-time-learning-with-self-evolving-memory" aria-label="Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory">Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory</a></li>
                <li>
                    <a href="#beyond-data-filtering-knowledge-localization-for-capability-removal-in-llms" aria-label="Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs">Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs</a></li>
                <li>
                    <a href="#budget-aware-tool-use-enables-effective-agent-scaling" aria-label="Budget-Aware Tool-Use Enables Effective Agent Scaling">Budget-Aware Tool-Use Enables Effective Agent Scaling</a></li>
                <li>
                    <a href="#qwenlong-l15-post-training-recipe-for-long-context-reasoning-and-memory-management" aria-label="QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management">QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management</a></li></ul>
                </li>
                <li>
                    <a href="#%e6%8e%a8%e8%8d%90%e5%86%85%e5%ae%b9" aria-label="推荐内容">推荐内容</a></li>
                <li>
                    <a href="#%e5%bd%b1%e9%9f%b3%e8%ae%b0%e5%bd%95" aria-label="影音记录">影音记录</a><ul>
                        
                <li>
                    <a href="#%e7%b2%be%e9%80%89%e6%ad%8c%e5%8d%95" aria-label="精选歌单">精选歌单</a></li>
                <li>
                    <a href="#live%e6%bc%94%e5%87%ba" aria-label="Live演出">Live演出</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a6%e9%98%85%e8%af%bb%e6%91%98%e5%bd%95" aria-label="书&amp;阅读摘录">书&amp;阅读摘录</a><ul>
                        
                <li>
                    <a href="#%e9%9d%a2%e5%90%91%e4%b8%9a%e5%8a%a1%e8%90%bd%e5%9c%b0%e7%9a%84ai%e4%ba%a7%e5%93%81%e8%af%84%e6%b5%8b%e4%bd%93%e7%b3%bb%e8%ae%be%e8%ae%a1%e4%b8%8e%e5%b9%b3%e5%8f%b0%e5%ae%9e%e7%8e%b0httpsmpweixinqqcoms__bizmzizotu0ntq0ma3d3dmid2247556426idx1snd5f96700a24743c4da6f11b98866b8d8__readwiselocationpoc_tokenhkkvu2mjchuowjtzbqpzsocfprjia-adpvb8vp4z" aria-label="面向业务落地的AI产品评测体系设计与平台实现">面向业务落地的AI产品评测体系设计与平台实现</a></li>
                <li>
                    <a href="#%e4%bd%9c%e4%b8%ba%e4%b8%80%e5%90%8d%e7%a7%91%e6%8a%80%e4%bb%8e%e4%b8%9a%e8%80%85%e5%a6%82%e4%bd%95%e6%80%bb%e7%bb%93%e4%bd%a0%e7%9a%84-2025httpswwwzhihucomquestion1974931646080836522answer1985412236970328110" aria-label="作为一名科技从业者，如何总结你的 2025？">作为一名科技从业者，如何总结你的 2025？</a></li>
                <li>
                    <a href="#ai-agent-%e5%be%88%e7%81%ab%e4%bd%86-agent-infra-%e5%87%86%e5%a4%87%e5%a5%bd%e4%ba%86%e5%90%97httpsmpweixinqqcoms__bizmzg5ntc0mjgwmw3d3dmid2247521887idx1sn29d618d87583266257979b2f86c50875poc_tokenhci0u2mjkau0rq_ly_m1rduie96vqes3gvxvlr2v" aria-label="AI Agent 很火，但 Agent Infra 准备好了吗？">AI Agent 很火，但 Agent Infra 准备好了吗？</a></li>
                <li>
                    <a href="#%e4%b8%8a%e4%b8%8b%e6%96%87%e5%b7%a5%e7%a8%8bai-native%e6%97%b6%e4%bb%a3%e7%9a%84%e8%bd%af%e4%bb%b6%e7%a0%94%e5%8f%91%e6%96%b0%e8%8c%83%e5%bc%8fhttpsdeusyuapppostscontext-engineering-ai-native" aria-label="上下文工程：AI-Native时代的软件研发新范式">上下文工程：AI-Native时代的软件研发新范式</a></li>
                <li>
                    <a href="#agent-engineering-a-new-disciplinehttpsbloglangchaincomagent-engineering-a-new-discipline" aria-label="Agent Engineering: A New Discipline">Agent Engineering: A New Discipline</a></li>
                <li>
                    <a href="#%e5%be%ae%e4%bf%a1%e6%9d%82%e8%b0%88ai-%e4%ba%a7%e5%93%81--%e5%93%81%e5%91%b3httpsmpweixinqqcomsai-mhde35vnaiyiflt05bw" aria-label="微信杂谈：AI 产品 &amp; 品味">微信杂谈：AI 产品 &amp; 品味</a></li>
                <li>
                    <a href="#%e5%9c%b0%e4%b8%8b%e9%98%bf%e6%a0%b9%e5%bb%b7%e7%8a%b9%e5%a4%aa%e9%92%b1%e5%ba%84%e5%8d%8e%e4%ba%ba%e8%b6%85%e5%b8%82%e6%91%86%e7%83%82%e7%9a%84%e5%b9%b4%e8%bd%bb%e4%ba%ba%e4%b8%8e%e8%bf%94%e8%b4%ab%e7%9a%84%e4%b8%ad%e4%ba%a7httpsxcombeatingofficialstatus1997880282163134587" aria-label="地下阿根廷：犹太钱庄、华人超市、摆烂的年轻人与返贫的中产">地下阿根廷：犹太钱庄、华人超市、摆烂的年轻人与返贫的中产</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="值得关注的模型和新技术">值得关注的模型和新技术<a hidden class="anchor" aria-hidden="true" href="#值得关注的模型和新技术">#</a></h1>
<p><a href="https://huggingface.co/deepseek-ai/DeepSeek-V3.2/blob/main/assets/paper.pdf">DeepSeek-V3.2</a></p>
<p><a href="https://huggingface.co/Qwen/Qwen-Image-Layered">Qwen/Qwen-Image-Layered</a></p>
<p><a href="https://huggingface.co/zai-org/GLM-4.7">zai-org/GLM-4.7</a></p>
<p><a href="https://huggingface.co/MiniMaxAI/MiniMax-M2.1">MiniMaxAI/MiniMax-M2.1</a></p>
<p><a href="https://huggingface.co/jinaai/jina-vlm">Jina-VLM</a></p>
<p><a href="https://ai.meta.com/blog/sam-audio/">SAM Audio</a></p>
<h1 id="值得关注的开源项目">值得关注的开源项目<a hidden class="anchor" aria-hidden="true" href="#值得关注的开源项目">#</a></h1>
<p><a href="https://github.com/BehiSecc/awesome-claude-skills">Awesome Claude Skills</a>: A curated list of Claude Skills.</p>
<p><a href="https://github.com/perstarkse/minne">Minne</a>: a read-it-later &amp; personal knowledge management solution</p>
<p><a href="https://github.com/onebirdrocks/ebook-mcp?tab=readme-ov-file">Ebook-MCP</a>: A MCP server that supports mainstream eBook formats including EPUB, PDF and more. Simplify your eBook user experience with LLM.</p>
<p><a href="https://github.com/datawhalechina/vibe-vibe">vibe-vibe</a>: 首个系统化 Vibe Coding 开源教程</p>
<p><a href="https://github.com/datajuicer/data-juicer">data-juicer</a>: Data processing for and with foundation models</p>
<p><a href="https://github.com/Chen-zexi/open-ptc-agent">open-ptc-agent</a>: An open source implementation of code execution with MCP (Programatic Tool Calling)</p>
<p><a href="https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering">Agent-Skills-for-Context-Engineering</a>: A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems.</p>
<h1 id="值得关注的研究和论文">值得关注的研究和论文<a hidden class="anchor" aria-hidden="true" href="#值得关注的研究和论文">#</a></h1>
<h2 id="deepseek-v32">DeepSeek V3.2<a hidden class="anchor" aria-hidden="true" href="#deepseek-v32">#</a></h2>
<ul>
<li>DeepSeek稀疏注意力（DSA）</li>
<li>RL协议</li>
<li>Agent任务合成流水线</li>
<li>DeepSeek-V3.2-Speciale： 放宽了长度限制，推理能力增强</li>
</ul>
<p><strong>DSA</strong></p>
<p>Why：解决长序列的计算复杂度</p>
<p>$O(L^2) -&gt; O(Lk)$</p>
<p>其中 $k \ll L$</p>
<p>通过稀疏化机制减少计算量</p>
<p>Lightning Indexer： 用于计算当前 Query Token 与前序 Token 之间的索引评分 I_{t,s} 。使用 ReLU 作为激活函数，且只包含少量的 Head</p>
<p>Fine-grained Token Selection：基于索引器的评分，只检索 Top-k 个分数最高的 KV 条目</p>
<p>Core Attention： 仅针对筛选出的这部分稀疏 KV 条目计算注意力输出，而不是针对全序列</p>
<p>DSA 通过Continued Training完成：</p>
<ul>
<li>Dense Warm-up Stage：初始化闪电索引器，保持主模型使用Dense Attention，冻结除索引器外的所有参数， 使用 KL 散度损失，强制索引器的输出分布去拟合主模型全量注意力的分布</li>
<li>Sparse Training Stage： 引入细粒度选择机制，让模型适配稀疏模式，开启 Top-k 选择，优化所有模型参数。索引器继续通过 KL 散度学习对齐注意力分布，而主模型则通过语言建模损失进行优化；索引器的输入会从计算图中分离，即索引器的优化仅依赖 KL 损失，不接受语言建模损失的梯度</li>
</ul>
<table>
  <thead>
      <tr>
          <th style="text-align: left"><strong>特性</strong></th>
          <th style="text-align: left"><strong>Vanilla Attention (标准)</strong></th>
          <th style="text-align: left"><strong>MLA (DeepSeek-V3.1)</strong></th>
          <th style="text-align: left"><strong>DSA (DeepSeek-V3.2)</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>计算复杂度</strong></td>
          <td style="text-align: left">$O(L^2)$ (核心注意力)</td>
          <td style="text-align: left">优化了 KV 缓存，但计算仍较密集</td>
          <td style="text-align: left"><strong>$O(Lk)$</strong> (核心注意力)，显著降低 16</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>KV 检索方式</strong></td>
          <td style="text-align: left">全量检索 (Dense)</td>
          <td style="text-align: left">压缩/潜在向量 (Latent Vector)</td>
          <td style="text-align: left"><strong>稀疏检索 (Top-k Sparse)</strong> 17</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>实现模式</strong></td>
          <td style="text-align: left">MHA (多头注意力)</td>
          <td style="text-align: left">支持 MHA 和 MQA 模式</td>
          <td style="text-align: left">强制使用 <strong>MLA 的 MQA 模式</strong> 以共享 KV 18</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>索引机制</strong></td>
          <td style="text-align: left">无</td>
          <td style="text-align: left">无</td>
          <td style="text-align: left"><strong>引入 Lightning Indexer</strong>，虽然本身复杂度 $O(L^2)$ 但计算量极小 19</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>性能影响</strong></td>
          <td style="text-align: left">基准</td>
          <td style="text-align: left">高性能</td>
          <td style="text-align: left"><strong>无明显降级</strong>，在长上下文任务中甚至优于旧版本 20202020</td>
      </tr>
  </tbody>
</table>
<blockquote>
<p>DSA 相比之前的架构，最大的区别在于引入了一个轻量级的“向导”（Indexer）来预先筛选重要的 Token，从而避免了对无关 Token 的大量无效计算。相比于 DeepSeek-V3.1 的 MLA，V3.2 的 DSA 保持了架构兼容性，仅通过训练策略的调整（引入 Indexer 和稀疏化）就实现了显著的效率提升。</p>
</blockquote>
<p><strong>后训练</strong></p>
<p>Specialist Distillation</p>
<p>构建了多个领域的“专家模型”，然后将它们的能力迁移给主模型。（针对 <strong>数学、编程、逻辑推理、通用 Agent 任务、Agent 编码、Agent 搜索</strong> 这六个领域，分别训练了专门的专家模型），使用训练好的专家模型生成高质量的领域数据，用于微调最终的 DeepSeek-V3.2 检查点</p>
<p>Mixed RL Training</p>
<p>这一阶段的核心策略是<strong>多任务融合</strong>，以避免分阶段训练可能导致的“灾难性遗忘”</p>
<ul>
<li>沿用了 <strong>GRPO</strong></li>
<li>将 Reasoning、Agent 任务 和 Human Alignment的数据整合在同一个 RL 阶段进行训练</li>
<li>奖励：
<ul>
<li>推理和 Agent 任务： 基于规则的结果奖励，长度惩罚，语言一致性奖励</li>
<li>通用任务： generative reward model，针对每个 prompt 有专门的评分标准</li>
</ul>
</li>
</ul>
<p>Scaling GRPO</p>
<p>稳定 GRPO 算法，防止训练崩溃</p>
<ul>
<li>Unbiased KL Estimate： ？</li>
<li>Off-Policy Sequence Masking： 推理和训练之间存在不一致（Off-policy），计算数据采样策略与当前策略的 KL 散度，并<strong>掩盖掉那些策略差异过大且优势为负的样本</strong></li>
<li>Keep Routing： 强制训练时的专家路由路径与推理采样时保持一致</li>
<li>Keep Sampling Mask： 在训练时复用采样时的截断掩码（Top-p/Top-k mask），确保新旧策略在相同的动作空间子集上进行比较，维护重要性采样的原则</li>
</ul>
<p>Agentic Task Synthesis</p>
<p>合成数据流水线</p>
<ul>
<li>冷启动，通过设计包含 <code>&lt;think&gt;</code> 标签的 System Prompt，将非 Agent 的推理数据与非推理的 Agent 数据结合，引导模型在调用工具前先进行思考</li>
<li>合成任务：利用 DeepSeek-V3.2 构建自动化 Agent 来生成训练环境和数据
<ul>
<li><strong>搜索 Agent：</strong> 自动挖掘长尾实体，构建问答对，并验证答案的正确性</li>
<li><strong>代码 Agent：</strong> 从 GitHub 挖掘 Issue-PR 对，自动构建可执行的测试环境（包含 Python, Java, C++ 等多种语言）</li>
<li><strong>通用 Agent：</strong> 自动合成超过 1800 个任务导向的环境（如旅行计划）</li>
</ul>
</li>
</ul>
<p>DeepSeek-V3.2-Speciale</p>
<p>解除对模型思考长度的限制，训练过程中显著<strong>降低了对生成长度的惩罚</strong></p>
<p>为了提升在复杂数学证明任务上的能力，该模型额外整合了来自 <strong>DeepSeekMath-V2</strong> 的数据集和奖励方法</p>
<p>在推理能力上显著强于标准版</p>
<h2 id="how-far-are-we-from-genuinely-useful-deep-research-agents">How Far Are We from Genuinely Useful Deep Research Agents?<a hidden class="anchor" aria-hidden="true" href="#how-far-are-we-from-genuinely-useful-deep-research-agents">#</a></h2>
<p>arXiv:<a href="https://arxiv.org/abs/2512.01948">2512.01948</a></p>
<p>核心贡献:</p>
<ul>
<li><strong>Finder (Fine-grained DEepResearch bench)：</strong> 一个细粒度的深度研究基准， 引入了419个结构化的检查清单，用于标准化评估报告的结构、分析深度和事实依据</li>
<li><strong>DEFT (Deep rEsearch Failure Taxonomy)：</strong> 对深度研究智能体的<strong>失败分类学，</strong> 将错误细分为3个核心维度（推理、检索、生成）下的14种具体失败模式</li>
</ul>
<p><img loading="lazy" src="https://arxiv.org/html/2512.01948v1/x2.png" alt=""  />
</p>
<p><strong>DEFT 的构建</strong></p>
<ul>
<li><strong>Open Coding，</strong> 使用5种不同的LLM作为编码员，分析失败案例，生成初始概念</li>
<li><strong>Axial Coding</strong> 结合人类专家介入，计算一致性， 将概念归纳为14个轴向类别</li>
<li><strong>Selective Coding，</strong> 提炼出“推理”、“检索”、“生成”三个核心维度</li>
</ul>
<h2 id="evo-memory-benchmarking-llm-agent-test-time-learning-with-self-evolving-memory">Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory<a hidden class="anchor" aria-hidden="true" href="#evo-memory-benchmarking-llm-agent-test-time-learning-with-self-evolving-memory">#</a></h2>
<p>arXiv:<a href="https://arxiv.org/abs/2511.20857">2511.20857</a></p>
<p>缺乏一个统一的框架来评估智能体在部署期间（Test-time）如何检索、整合和进化其记忆</p>
<p><strong>创新点</strong></p>
<p><strong>Evo-Memory 基准测试：<strong>提出了一个新的评估基准，将传统的静态数据集重构为</strong>顺序任务流，</strong> 要求模型在完成一个任务后，必须更新记忆以供后续任务使用</p>
<p><strong>评估框架：</strong> 归纳了一个通用的记忆智能体公式：<code>(Search -&gt; Synthesis -&gt; Evolve)</code>，即检索、合成上下文、进化记忆的循环</p>
<p>ReMem： 传统的 ReAct 只有“思考”和“行动”， ReMem 引入了 <strong>Action–Think–Memory Refine</strong> 循环，让智能体主动地推理、修剪和重组记忆</p>
<p><strong>ExpRAG 基准：</strong> 一个基于检索的简单基准，专门用于检索过去的“经验”（输入-输出-反馈三元组），而不仅仅是检索知识</p>
<p><strong>ReMem 的工作机制</strong></p>
<ol>
<li><strong>Think (思考)：</strong> 分解任务，规划步骤。</li>
<li><strong>Act (行动)：</strong> 与环境交互。</li>
<li><strong>Refine (优化)：</strong> 这是核心。智能体在每一步都会进行“元推理”（Meta-reasoning），决定哪些记忆是杂音需要删除，哪些经验值得保留或重组。</li>
</ol>
<p><strong>ExpRAG 的工作机制</strong></p>
<ul>
<li>将每次任务的 <code>(输入, 预测, 反馈)</code> 作为一个经验单元存入。</li>
<li>在遇到新任务时，检索最相似的 k 个过往经验作为上下文参考</li>
</ul>
<h2 id="beyond-data-filtering-knowledge-localization-for-capability-removal-in-llms"><strong>Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs</strong><a hidden class="anchor" aria-hidden="true" href="#beyond-data-filtering-knowledge-localization-for-capability-removal-in-llms">#</a></h2>
<p><a href="https://alignment.anthropic.com/2025/selective-gradient-masking/">https://alignment.anthropic.com/2025/selective-gradient-masking/</a></p>
<p><strong>Selective GradienT Masking (SGTM):</strong>  针对LLM中危险知识的移除问题</p>
<p><img loading="lazy" src="https://alignment.anthropic.com/2025/selective-gradient-masking/localization.png" alt=""  />
</p>
<ul>
<li>在 Transformer 的每一层中，将部分注意力头和 MLP 神经元指定为“遗忘参数”，其余为“保留参数”</li>
<li>在训练过程中，当模型遇到被标记为“危险”的数据时，<strong>只更新“遗忘参数”</strong>（通过掩盖其他参数的梯度）</li>
<li>当遇到普通数据时，更新“保留参数”。</li>
<li>对于未标记数据，允许更新所有参数</li>
<li>训练结束后，直接将<strong>遗忘参数置零</strong>。这样就物理上移除了危险知识，同时保留了存储在其他参数中的通用能力。</li>
</ul>
<h2 id="budget-aware-tool-use-enables-effective-agent-scaling">Budget-Aware Tool-Use Enables Effective Agent Scaling<a hidden class="anchor" aria-hidden="true" href="#budget-aware-tool-use-enables-effective-agent-scaling">#</a></h2>
<p>arXiv:<a href="https://arxiv.org/abs/2511.17006">2511.17006</a></p>
<p>ReAct 模式下简单地增加工具调用预算，并不能带来性能提升；往往在预算耗尽前就过早停止搜索，或者在死胡同里浪费资源</p>
<p>创新：</p>
<ul>
<li>
<p><strong>Budget Tracker</strong>: 在每一轮对话中显式地告诉代理“当前已用多少资源，还剩多少资源”</p>
</li>
<li>
<p><strong>BATS (Budget-Aware Test-time Scaling) 框架：</strong></p>
<p>利用预算感知来动态调整<strong>Planning和Verification</strong>策略。它能根据剩余预算决定是Dig Deeper当前线索，还是Pivot尝试新路径。</p>
</li>
<li>
<p><strong>统一成本指标</strong>: 将“Token消耗成本”和“工具调用成本”结合的统一指标 （性价比）</p>
</li>
</ul>
<h2 id="qwenlong-l15-post-training-recipe-for-long-context-reasoning-and-memory-management"><strong>QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management</strong><a hidden class="anchor" aria-hidden="true" href="#qwenlong-l15-post-training-recipe-for-long-context-reasoning-and-memory-management">#</a></h2>
<p>arXiv:<a href="http://arxiv.org/abs/2512.12967">2512.12967</a></p>
<ul>
<li><strong>长文本数据合成管线</strong></li>
<li><strong>稳定化长文本 RL 策略</strong></li>
<li><strong>记忆增强架构（Memory Agent）</strong></li>
</ul>
<ol>
<li><strong>数据合成管线</strong></li>
</ol>
<p>核心突破在于生成需要<strong>在全局分布的证据中进行多跳关联和推理</strong>的任务</p>
<p>通过将文档去构造为<strong>原子事实</strong>及其底层关系，再通过程序化手段组合成可验证的复杂问题</p>
<p><img loading="lazy" src="https://arxiv.org/html/2512.12967v1/x5.png" alt=""  />
</p>
<ul>
<li><strong>合成策略：</strong>
<ul>
<li><strong>基于知识图谱（KG）：</strong> 挖掘文档中的实体关系，构建跨文档的多跳推理路径。</li>
<li><strong>基于结构化表（SQL）：</strong> 将文档中的数值信息转化为表格，通过 SQL 生成复杂的数值计算问题。</li>
<li><strong>多智能体自进化（MASE）：</strong> 使用三个智能体（提问者、解答者、验证者）迭代生成并验证难度递增的问题。</li>
</ul>
</li>
<li><strong>验证：</strong>
<ul>
<li><strong>知识落地检查（Knowledge Grounding Check）</strong>：移除源文档，测试模型是否仍能回答。若能回答，说明该问题依赖内部知识而非上下文，会被剔除</li>
<li><strong>上下文鲁棒性检查（Contextual Robustness Check）</strong>：通过插入无关文档扩展上下文，确保问题及其答案在复杂的噪声干扰下依然稳健</li>
</ul>
</li>
</ul>
<p><img loading="lazy" src="https://arxiv.org/html/2512.12967v1/x6.png" alt=""  />
</p>
<ol start="2">
<li><strong>长文本 RL</strong></li>
</ol>
<p>长文本RL存在的问题：</p>
<ul>
<li>奖励信号，错误答案中往往包含大量正确的推理步骤，导致模型难以区分哪些动作导致了最终的失败</li>
<li>长文本数据涉及多个领域且分布极不均匀，传统的随机采样会导致训练Batch内的任务分布失衡</li>
<li>在长序列训练中，模型很容易陷入响应长度失控或熵崩溃（过度收敛）的陷阱</li>
</ul>
<p>创新策略：</p>
<ul>
<li><strong>采样策略</strong>：不再随机选取数据，而是确保每个训练批次中平均分配五类任务</li>
<li><strong>优势估计</strong>：改进了 GRPO 算法中的优势计算方式。改为**在同一任务类型内计算奖励的标准差，**隔离不同任务间的奖励噪声</li>
<li><strong>Negative Gradient Clipping，</strong> 高熵（模型不确定）的负向样本会产生巨大的梯度，从而扰乱优化过程，通过裁剪或屏蔽这些高熵负面响应的梯度，可以保护模型在探索过程中的潜力</li>
</ul>
<p><strong>AEPO 算法：</strong> AEPO 会根据模型当前的熵动态调整训练：当熵过高（太随机）时，暂时屏蔽负向优势样本以降低熵；当熵过低（太死板）时，重新引入负向梯度以鼓励探索</p>
<p><strong>Progressive Paradigm：</strong> 从 20K 到 60K，再到 120K 输入长度的阶梯式训练；</p>
<ol start="3">
<li><strong>Memory Agent</strong></li>
</ol>
<ul>
<li>将超长文档切片（Chunking）。</li>
<li>模型按顺序阅读切片，每一步输出：1. <strong>记忆更新</strong>（提炼关键信息）；2. <strong>导航计划</strong>（决定下一步关注什么，小本子？）。</li>
<li>最后基于累积的记忆生成答案。</li>
<li>采用<strong>多阶段融合训练</strong>：先训练全上下文推理能力，再训练记忆管理能力，最后通过模型融合（Model Merging）结合两者。</li>
</ul>
<h1 id="推荐内容">推荐内容<a hidden class="anchor" aria-hidden="true" href="#推荐内容">#</a></h1>
<p>一篇agent-memory综述： <a href="https://arxiv.org/abs/2512.13564">Memory in the Age of AI Agents: A Survey</a></p>
<p>一系列年度报告：</p>
<ul>
<li>OpenRouter:  <a href="https://openrouter.ai/announcements/the-2025-state-of-ai-report">The 2025 State of AI Report</a></li>
<li>Anthropic:  <a href="https://claude.com/blog/how-enterprises-are-building-ai-agents-in-2026">How enterprises are building AI agents in 2026</a></li>
<li>OpenAI: <a href="https://cdn.openai.com/pdf/7ef17d82-96bf-4dd1-9df2-228f7f377a29/the-state-of-enterprise-ai_2025-report.pdf">The state of enterprise AI</a></li>
<li>Langchain: <a href="https://www.langchain.com/stateofaiagents">State of AI Agents</a></li>
</ul>
<p>如何写好Claude.md: <a href="https://www.humanlayer.dev/blog/writing-a-good-claude-md">Writing a good CLAUDE.md</a></p>
<p>LLM 评估时的各式各样细节问题</p>
<ul>
<li><a href="https://blog.vllm.ai/2025/10/28/Kimi-K2-Accuracy.html">Chasing 100% Accuracy: A Deep Dive into Debugging Kimi K2&rsquo;s Tool-Calling on vLLM</a></li>
<li><a href="https://epoch.ai/gradient-updates/why-benchmarking-is-hard">Why benchmarking is hard</a></li>
</ul>
<p><a href="https://physics.allen-zhu.com/">Physics of Language Models</a></p>
<hr>
<h1 id="影音记录">影音记录<a hidden class="anchor" aria-hidden="true" href="#影音记录">#</a></h1>
<h2 id="精选歌单">精选歌单<a hidden class="anchor" aria-hidden="true" href="#精选歌单">#</a></h2>
<iframe data-testid="embed-iframe" style="border-radius:12px" src="https://open.spotify.com/embed/playlist/63ItUBFon01LuqwD0yB8bp?utm_source=generator" width="100%" height="450" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
<h2 id="live演出">Live演出<a hidden class="anchor" aria-hidden="true" href="#live演出">#</a></h2>
<p>12.08 L&rsquo;Impératrice</p>
<p>12.09 Godspeed you! Black Emperor</p>
<p>12.13 Diels-Alder</p>
<h1 id="书阅读摘录">书&amp;阅读摘录<a hidden class="anchor" aria-hidden="true" href="#书阅读摘录">#</a></h1>
<h2 id="面向业务落地的ai产品评测体系设计与平台实现httpsmpweixinqqcoms__bizmzizotu0ntq0ma3d3dmid2247556426idx1snd5f96700a24743c4da6f11b98866b8d8__readwiselocationpoc_tokenhkkvu2mjchuowjtzbqpzsocfprjia-adpvb8vp4z"><a href="https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA%3D%3D&mid=2247556426&idx=1&sn=d5f96700a24743c4da6f11b98866b8d8&__readwiseLocation=&poc_token=HKKvU2mjchuowjtZbqpZsoCfprjiA-aDpVB8VP4z"><strong>面向业务落地的AI产品评测体系设计与平台实现</strong></a><a hidden class="anchor" aria-hidden="true" href="#面向业务落地的ai产品评测体系设计与平台实现httpsmpweixinqqcoms__bizmzizotu0ntq0ma3d3dmid2247556426idx1snd5f96700a24743c4da6f11b98866b8d8__readwiselocationpoc_tokenhkkvu2mjchuowjtzbqpzsocfprjia-adpvb8vp4z">#</a></h2>
<blockquote>
<p>在AI产品落地过程中，它的不确定性、动态性和复杂性，给质量和体验保障带来了前所未有的挑战。AI产品的特性使得测试既不是简单的功能验证，也不是纯算法模型的评测</p>
</blockquote>
<blockquote>
<p>工程产品是“需求明确 → 设计实现 → 测试验证”，AI产品则是“技术驱动 → 场景探索 → 效果迭代”的螺旋式过程。
评测需前置至需求阶段，与产品和研发共同定义“好”的标准</p>
</blockquote>
<blockquote>
<p>在算法评测中，金标评测集可以长期复用；在agent场景：每次评测时，外部服务数据、时间、接口行为可能变化；即使输入相同，也会因为外围导致答案偏离原始金标。</p>
</blockquote>
<blockquote>
<p>以前一个版本是一次代码发布；现在一个版本可能是：模型更换、prompt 改写、检索策略调整、工具编排改造或它们的任意组合；</p>
</blockquote>
<blockquote>
<p>评测标准的制定从研发单一角色制定转变到产品、设计、研发、业务方（BD/运营）共同参与指标，从“研发自说自话”转向“业务-技术目标同频”，解决AI产品常见的“技术达标但体验崩坏”问题
回收研发评测、产设验收及线上运营标注数据——将优质数据沉淀为金标集</p>
</blockquote>
<blockquote>
<p>我们推荐大部分AI产品的评测基于端到端评测</p>
</blockquote>
<blockquote>
<p>针对有参考答案的评测，我们核心要解决的是构造一个稳定可复现的“环境”。</p>
</blockquote>
<blockquote>
<p>我们建议按“变更范围 × 变更风险”来设计三档评测策略，并通过用例标签体系自动筛选推荐用例</p>
</blockquote>
<blockquote>
<p>怎么评估线上效果
形成“监测-分析-优化”完整闭环</p>
</blockquote>
<h2 id="作为一名科技从业者如何总结你的-2025httpswwwzhihucomquestion1974931646080836522answer1985412236970328110"><a href="https://www.zhihu.com/question/1974931646080836522/answer/1985412236970328110"><strong>作为一名科技从业者，如何总结你的 2025？</strong></a><a hidden class="anchor" aria-hidden="true" href="#作为一名科技从业者如何总结你的-2025httpswwwzhihucomquestion1974931646080836522answer1985412236970328110">#</a></h2>
<blockquote>
<p>在我看来，人类正面临一个自身难以克服的挑战——知识爆炸让我们都成了越来越细分的专家，而创新往往发生在知识的交叉边缘。 当一个人穷其一生都无法触及某个领域的边缘时，跨领域的创新就变得异常困难。而AI正是帮助我们突破知识壁垒，探索未知世界的很好的工具，我对这一点充满了期待。</p>
</blockquote>
<h2 id="ai-agent-很火但-agent-infra-准备好了吗httpsmpweixinqqcoms__bizmzg5ntc0mjgwmw3d3dmid2247521887idx1sn29d618d87583266257979b2f86c50875poc_tokenhci0u2mjkau0rq_ly_m1rduie96vqes3gvxvlr2v"><a href="https://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw%3D%3D&mid=2247521887&idx=1&sn=29d618d87583266257979b2f86c50875&poc_token=HCi0U2mjKAu0RQ_LY_m1RdUiE96vQes3GvxvLr2v"><strong>AI Agent 很火，但 Agent Infra 准备好了吗？</strong></a><a hidden class="anchor" aria-hidden="true" href="#ai-agent-很火但-agent-infra-准备好了吗httpsmpweixinqqcoms__bizmzg5ntc0mjgwmw3d3dmid2247521887idx1sn29d618d87583266257979b2f86c50875poc_tokenhci0u2mjkau0rq_ly_m1rduie96vqes3gvxvlr2v">#</a></h2>
<blockquote>
<p>之所以 Infra 层会有很大的变化，核心在于，AI Agent 今天的开发和落地范式，与以往的 App 完全不同了。
核心的区别就是不确定性的存在。</p>
</blockquote>
<blockquote>
<p>但在 Agent 工程里，失败往往是模型对开发者意图的误解，或者说是概率上的「漂移」。你没办法像修水管一样去修复一个 Agent，只能像教育孩子一样，去引导它、说服它、约束它。</p>
</blockquote>
<blockquote>
<p>现在交付的是一种概率性的能力，你很难去定义什么是绝对的「正确」。</p>
</blockquote>
<blockquote>
<p>绝大多数工程师从入职第一天起，工作就是在确定性系统里进一步提升确定性，判断标准只有「对」和「错」。但现在我们面对的是不确定性的复杂系统，工作方式必须彻底转变。
这种转变主要体现在两点：
第一，从工程思维转向科学实验思维。而科学实验思维的核心，是建立一套评测体系，把复杂系统拆解成一个个子系统，屏蔽其他子系统的干扰，去单独评测每个子系统的影响。只有通过这种控制变量的方式，一步步摸索，才能驾驭 Agent 的复杂性；
第二，从 Day One 思维转向 Day Two 思维</p>
</blockquote>
<blockquote>
<p>AI Infra 更关注的是模型的算力、优化和推理，如何以最快、最稳定的算力服务让模型输出内容。
而 Agent Infra 关注的是项目的最终结果输出，上层的逻辑、记忆和工具调用。如何编排、如何管理记忆、如何调用各种工具接口，如何更稳定在沙盒里运行的问题。</p>
</blockquote>
<blockquote>
<p>AI Agent 第一次把「计算」这件事，真正意义上地民主化了。很多以前算不过账的事情，不太经济的商业模式，突然变得合理了。</p>
</blockquote>
<blockquote>
<p>Dify 认为可调试性、记忆管理和低延迟性能是下一阶段的重点。</p>
</blockquote>
<h2 id="上下文工程ai-native时代的软件研发新范式httpsdeusyuapppostscontext-engineering-ai-native"><a href="https://deusyu.app/posts/context-engineering-ai-native/">上下文工程：AI-Native时代的软件研发新范式</a><a hidden class="anchor" aria-hidden="true" href="#上下文工程ai-native时代的软件研发新范式httpsdeusyuapppostscontext-engineering-ai-native">#</a></h2>
<blockquote>
<p>真正有价值的，不是 AI 写了多少行代码，而是——你是不是在做 AI-Native 的软件工程。</p>
</blockquote>
<blockquote>
<p>人定边界，AI 填细节。
想业务、抽象、模型、trade-off，而不是某个库的 API 写法</p>
</blockquote>
<blockquote>
<p>上下文就是新的源码（Context is the new Source Code）。</p>
</blockquote>
<h2 id="agent-engineering-a-new-disciplinehttpsbloglangchaincomagent-engineering-a-new-discipline"><a href="https://blog.langchain.com/agent-engineering-a-new-discipline/">Agent Engineering: A New Discipline</a><a hidden class="anchor" aria-hidden="true" href="#agent-engineering-a-new-disciplinehttpsbloglangchaincomagent-engineering-a-new-discipline">#</a></h2>
<blockquote>
<p>Traditional software assumes you mostly know the inputs and can define the outputs. Agents give you neither: users can say literally anything, and the space of possible behaviors is wide open
Agent engineering is the iterative process of refining non-deterministic LLM systems into reliable production experiences. It is a cyclical process: build, test, ship, observe, refine, repeat.</p>
</blockquote>
<blockquote>
<p>We see agent engineering as a new discipline that combines 3 skillsets working together:
Product thinking defines the scope and shapes agent behavior
Engineering builds the infrastructure that makes agents production-ready.
Data science measures and improves agent performance over time</p>
</blockquote>
<blockquote>
<p>LLMs are powerful enough to handle complex, multi-step workflows.
We’re starting to cross the threshold where agents are delivering meaningful business value in production.
Every input is an edge case.
You can’t debug the old way.
“Working” isn’t binary.</p>
</blockquote>
<blockquote>
<p>To achieve a reliable agent system, shipping is how you learn, not what you do after learning.
Build your agent’s foundation.
Test based on scenario you can imagine
Ship to see real-world behavior
Observe.
Refine
Repeat</p>
</blockquote>
<blockquote>
<p>The teams shipping reliable agents today share one thing: they&rsquo;ve stopped trying to perfect agents before launch and started treating production as their primary teacher. In other words, tracing every decision, evaluating at scale, and shipping improvements in days instead of quarters.</p>
</blockquote>
<h2 id="微信杂谈ai-产品--品味httpsmpweixinqqcomsai-mhde35vnaiyiflt05bw"><a href="https://mp.weixin.qq.com/s/Ai-mHDe35VnaIyifLt05Bw">微信杂谈：AI 产品 &amp; 品味</a><a hidden class="anchor" aria-hidden="true" href="#微信杂谈ai-产品--品味httpsmpweixinqqcomsai-mhde35vnaiyiflt05bw">#</a></h2>
<blockquote>
<p>agent 也只是当下使用 ai 的一种形式，形式可能会淘汰（比如大模型迭代），但底层的能力不会，应该去关注更本质的东西。</p>
</blockquote>
<blockquote>
<p>最近和人聊到 ai 产品，在 vibe coding 大行其道的今天，其实想做出让人眼前一亮的产品，就是需要靠品味和细节来打动人。因为你能做的事情，ai 基本都能做，但是品味这个东西，只可意会不可言传，ai 很难去平衡这个度。</p>
</blockquote>
<blockquote>
<p>“情绪价值函数”，它不是简单的对错运算，而是一些感性的东西在帮你做决策</p>
</blockquote>
<h2 id="地下阿根廷犹太钱庄华人超市摆烂的年轻人与返贫的中产httpsxcombeatingofficialstatus1997880282163134587"><a href="https://x.com/BeatingOfficial/status/1997880282163134587">地下阿根廷：犹太钱庄、华人超市、摆烂的年轻人与返贫的中产</a><a hidden class="anchor" aria-hidden="true" href="#地下阿根廷犹太钱庄华人超市摆烂的年轻人与返贫的中产httpsxcombeatingofficialstatus1997880282163134587">#</a></h2>
<blockquote>
<p>所有的热情，最终都指向了一个赤裸裸的动词：逃生。</p>
</blockquote>
<blockquote>
<p>他们并不关心什么是 Web3，他们只关心一件事：USDT 能不能让我手里的钱不缩水。</p>
</blockquote>
<blockquote>
<p>当穷人在用现金避税，富人在用 Crypto 转移资产时，谁成了这场危机中唯一的输家？答案令人心碎：是那些遵纪守法的「老实人」。</p>
</blockquote>
<blockquote>
<p>中产阶级的崩溃，往往是无声的。他们不会像底层那样上街烧轮胎抗议，也不会像富人那样直接移民。他们只是默默地取消了周末的聚餐，换掉了孩子的私立学校，然后在每一个深夜焦虑地计算着下个月的账单。</p>
</blockquote>
<blockquote>
<p>他们是这个国家最听话的纳税人，也是被收割得最彻底的一群人。</p>
</blockquote>
<hr>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://niraya666.github.io/tags/%E6%9C%88%E5%88%8A/">月刊</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-12 月刊 on x"
            href="https://x.com/intent/tweet/?text=2025-12%20%e6%9c%88%e5%88%8a&amp;url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-12-%25E6%259C%2588%25E5%2588%258A%2f&amp;hashtags=%e6%9c%88%e5%88%8a">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-12 月刊 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-12-%25E6%259C%2588%25E5%2588%258A%2f&amp;title=2025-12%20%e6%9c%88%e5%88%8a&amp;summary=2025-12%20%e6%9c%88%e5%88%8a&amp;source=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-12-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-12 月刊 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-12-%25E6%259C%2588%25E5%2588%258A%2f&title=2025-12%20%e6%9c%88%e5%88%8a">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-12 月刊 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-12-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-12 月刊 on whatsapp"
            href="https://api.whatsapp.com/send?text=2025-12%20%e6%9c%88%e5%88%8a%20-%20https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-12-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-12 月刊 on telegram"
            href="https://telegram.me/share/url?text=2025-12%20%e6%9c%88%e5%88%8a&amp;url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-12-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-12 月刊 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=2025-12%20%e6%9c%88%e5%88%8a&u=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-12-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
<div id="utterances">
  <script src="https://utteranc.es/client.js"
        repo="Niraya666/niraya666.github.io"
        issue-term="pathname"
        theme="preferred-color-scheme"
        crossorigin="anonymous"
        async>
  </script>
</div>


<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      packages: {'[+]': ['ams']}
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2026 <a href="https://niraya666.github.io/">LZY Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
