<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>2025-09 月刊 | LZY Blog</title>
<meta name="keywords" content="月刊">
<meta name="description" content="值得关注的模型和新技术
Qwen3-VL
Qwen3Guard
tongyi-deep-research
EmbeddingGemma
Code World Model (CWM)
值得关注的开源项目
FineVision:Open Data Is All You Need
大麦抢票脚本
Parlant: LLM agents built for control. Designed for real-world use.
Claude Code Comprehensive Guide
Dayflow: Turns your screen activity into a clean timeline with AI summaries and distraction highlights.
值得关注的研究和论文
MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains
arXiv:2508.18260
提出了**Parallel Multi-chain Inference，**将一个复杂问题分解成多个子问题，为每个子问题启动一个独立的、并行的推理链
提出了**Adaptive Graph-based Retrieval，**与一个结构化的医学知识图谱进行交互，在推理过程中，模型可以动态地通过邻居节点扩展、多跳路径遍历等方式探索知识图谱中的实体关系和层次结构
MIRAGE框架通过四个协同工作的组件实现其功能：



Question Decomposer
Evidence Retriever：为每个子问题启动一个并行的推理链，进行一种“边思考边搜索”的循环；检索分为两种模式：Anchor Mode（当查询涉及单个实体时，检索该实体在图谱中的局部邻居信息）；Bridge Mode （当查询涉及两个实体时，在图谱中寻找连接这两个实体的关系路径）
Answer Synthesizer：收集所有并行推理链生成的答案和证据，并交叉验证
Coordinator：管理以上三个组件的执行流程

Why Language Models Hallucinate
paper">
<meta name="author" content="Theme PaperMod">
<link rel="canonical" href="https://niraya666.github.io/monthly/2025-09-%E6%9C%88%E5%88%8A/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://niraya666.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://niraya666.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://niraya666.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://niraya666.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://niraya666.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://niraya666.github.io/monthly/2025-09-%E6%9C%88%E5%88%8A/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="2025-09 月刊" />
<meta property="og:description" content="值得关注的模型和新技术
Qwen3-VL
Qwen3Guard
tongyi-deep-research
EmbeddingGemma
Code World Model (CWM)
值得关注的开源项目
FineVision:Open Data Is All You Need
大麦抢票脚本
Parlant: LLM agents built for control. Designed for real-world use.
Claude Code Comprehensive Guide
Dayflow: Turns your screen activity into a clean timeline with AI summaries and distraction highlights.
值得关注的研究和论文
MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains
arXiv:2508.18260
提出了**Parallel Multi-chain Inference，**将一个复杂问题分解成多个子问题，为每个子问题启动一个独立的、并行的推理链
提出了**Adaptive Graph-based Retrieval，**与一个结构化的医学知识图谱进行交互，在推理过程中，模型可以动态地通过邻居节点扩展、多跳路径遍历等方式探索知识图谱中的实体关系和层次结构
MIRAGE框架通过四个协同工作的组件实现其功能：



Question Decomposer
Evidence Retriever：为每个子问题启动一个并行的推理链，进行一种“边思考边搜索”的循环；检索分为两种模式：Anchor Mode（当查询涉及单个实体时，检索该实体在图谱中的局部邻居信息）；Bridge Mode （当查询涉及两个实体时，在图谱中寻找连接这两个实体的关系路径）
Answer Synthesizer：收集所有并行推理链生成的答案和证据，并交叉验证
Coordinator：管理以上三个组件的执行流程

Why Language Models Hallucinate
paper" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://niraya666.github.io/monthly/2025-09-%E6%9C%88%E5%88%8A/" />
<meta property="og:image" content="https://niraya666.github.io/img/monthly/2025-07/1A04B6BE-7882-4762-B780-F9737174D670_1_105_c.jpeg" /><meta property="article:section" content="monthly" />
<meta property="article:published_time" content="2025-09-28T20:00:00+08:00" />
<meta property="article:modified_time" content="2025-09-28T20:00:00+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://niraya666.github.io/img/monthly/2025-07/1A04B6BE-7882-4762-B780-F9737174D670_1_105_c.jpeg" />
<meta name="twitter:title" content="2025-09 月刊"/>
<meta name="twitter:description" content="值得关注的模型和新技术
Qwen3-VL
Qwen3Guard
tongyi-deep-research
EmbeddingGemma
Code World Model (CWM)
值得关注的开源项目
FineVision:Open Data Is All You Need
大麦抢票脚本
Parlant: LLM agents built for control. Designed for real-world use.
Claude Code Comprehensive Guide
Dayflow: Turns your screen activity into a clean timeline with AI summaries and distraction highlights.
值得关注的研究和论文
MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains
arXiv:2508.18260
提出了**Parallel Multi-chain Inference，**将一个复杂问题分解成多个子问题，为每个子问题启动一个独立的、并行的推理链
提出了**Adaptive Graph-based Retrieval，**与一个结构化的医学知识图谱进行交互，在推理过程中，模型可以动态地通过邻居节点扩展、多跳路径遍历等方式探索知识图谱中的实体关系和层次结构
MIRAGE框架通过四个协同工作的组件实现其功能：



Question Decomposer
Evidence Retriever：为每个子问题启动一个并行的推理链，进行一种“边思考边搜索”的循环；检索分为两种模式：Anchor Mode（当查询涉及单个实体时，检索该实体在图谱中的局部邻居信息）；Bridge Mode （当查询涉及两个实体时，在图谱中寻找连接这两个实体的关系路径）
Answer Synthesizer：收集所有并行推理链生成的答案和证据，并交叉验证
Coordinator：管理以上三个组件的执行流程

Why Language Models Hallucinate
paper"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Monthlies",
      "item": "https://niraya666.github.io/monthly/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "2025-09 月刊",
      "item": "https://niraya666.github.io/monthly/2025-09-%E6%9C%88%E5%88%8A/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "2025-09 月刊",
  "name": "2025-09 月刊",
  "description": "值得关注的模型和新技术 Qwen3-VL\nQwen3Guard\ntongyi-deep-research\nEmbeddingGemma\nCode World Model (CWM)\n值得关注的开源项目 FineVision:Open Data Is All You Need\n大麦抢票脚本\nParlant: LLM agents built for control. Designed for real-world use.\nClaude Code Comprehensive Guide\nDayflow: Turns your screen activity into a clean timeline with AI summaries and distraction highlights.\n值得关注的研究和论文 MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains arXiv:2508.18260\n提出了**Parallel Multi-chain Inference，**将一个复杂问题分解成多个子问题，为每个子问题启动一个独立的、并行的推理链\n提出了**Adaptive Graph-based Retrieval，**与一个结构化的医学知识图谱进行交互，在推理过程中，模型可以动态地通过邻居节点扩展、多跳路径遍历等方式探索知识图谱中的实体关系和层次结构\nMIRAGE框架通过四个协同工作的组件实现其功能：\nQuestion Decomposer Evidence Retriever：为每个子问题启动一个并行的推理链，进行一种“边思考边搜索”的循环；检索分为两种模式：Anchor Mode（当查询涉及单个实体时，检索该实体在图谱中的局部邻居信息）；Bridge Mode （当查询涉及两个实体时，在图谱中寻找连接这两个实体的关系路径） Answer Synthesizer：收集所有并行推理链生成的答案和证据，并交叉验证 Coordinator：管理以上三个组件的执行流程 Why Language Models Hallucinate paper\n",
  "keywords": [
    "月刊"
  ],
  "articleBody": "值得关注的模型和新技术 Qwen3-VL\nQwen3Guard\ntongyi-deep-research\nEmbeddingGemma\nCode World Model (CWM)\n值得关注的开源项目 FineVision:Open Data Is All You Need\n大麦抢票脚本\nParlant: LLM agents built for control. Designed for real-world use.\nClaude Code Comprehensive Guide\nDayflow: Turns your screen activity into a clean timeline with AI summaries and distraction highlights.\n值得关注的研究和论文 MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains arXiv:2508.18260\n提出了**Parallel Multi-chain Inference，**将一个复杂问题分解成多个子问题，为每个子问题启动一个独立的、并行的推理链\n提出了**Adaptive Graph-based Retrieval，**与一个结构化的医学知识图谱进行交互，在推理过程中，模型可以动态地通过邻居节点扩展、多跳路径遍历等方式探索知识图谱中的实体关系和层次结构\nMIRAGE框架通过四个协同工作的组件实现其功能：\nQuestion Decomposer Evidence Retriever：为每个子问题启动一个并行的推理链，进行一种“边思考边搜索”的循环；检索分为两种模式：Anchor Mode（当查询涉及单个实体时，检索该实体在图谱中的局部邻居信息）；Bridge Mode （当查询涉及两个实体时，在图谱中寻找连接这两个实体的关系路径） Answer Synthesizer：收集所有并行推理链生成的答案和证据，并交叉验证 Coordinator：管理以上三个组件的执行流程 Why Language Models Hallucinate paper\n提出了基于socio-technical视角来解释幻觉的持续存在。指出，问题的根源不仅仅在于模型或算法本身，更在于评估手段— 特别是主流的benchmark多采用非黑即白的二元评分，鼓励模型“赌一把”而不是如实承认 “不知道”。\nOn the Theoretical Limitations of Embedding-Based Retrieval arXiv:2508.21038\n基于single vector embedding的检索模型是否存在根本性的理论上限？\n对于任何固定维度的嵌入模型，都存在一些它永远无法表示和检索的“相关文档组合”，这是由向量空间本身的几何特性决定的一个根本性限制\n定义：\n将检索问题形式化为一个m \\times n的相关性矩阵 A（m个查询，n个文档）。嵌入模型的目标是学习一个得分矩阵B（由查询向量和文档向量的点积生成，m \\times n），使得B中每一行的元素排序与A一致（即相关文档的得分高于不相关文档）；\n行序保持秩 rank_rop(A)：让相关文档得分 \u003e 不相关文档得分的最低嵌入维度 d\n行级阈值秩 rank_rt(A): 对于每个查询 i，存在一个阈值 τ_i，能将相关和不相关文档的得分分开\n全局阈值秩 rank_gt(A): 存在一个全局阈值 τ 对所有查询都有效\nsign-rank rank_±(M) 定义： 给定一个矩阵M \\in {-1, 1}^{m \\times n}， \\operatorname{rank}{\\pm}(M) = \\min { \\operatorname{rank}(B) \\mid B \\in \\mathbb{R}^{m \\times n} \\text{ 并且对于所有 } i, j, \\text{ 我们有 } \\operatorname{sign}(B{ij}) = M_{ij} }\n先给出结论：由于存在sign-rank任意高的矩阵，因此对于任何给定的嵌入维度d，总会存在一个相关性矩阵（即一个检索任务）是它无法表示的\nParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute arXiv:2509.04475\n并非思考越长越好\nTunnel Vision， 即模型在生成思考过程的最初几步，一旦犯了错或选择了一条并非最优的路径，就很容易被“锁定”在这条错误的轨道上，后续无论再花多少计算量进行思考和修正，都很难再回到正确的路径上； 因此主流的sequential-thinking，基于“深度”扩展（单一路径加长）策略存在缺陷\n对此，提出了Native Parallel Thinking；\n引入一组Specialized Tokens 在推理时显式地引导模型开启第 i 条独立的思考路径 为了在汇总阶段解决位置混淆问题，引入thought embedding 通过从教师模型采样多条解题路径来构建训练数据，同时，通过两阶段的注意力掩码，确保在“并行思考”阶段各路径相互独立，在“总结”阶段又能看到所有路径的信息 Parallel Reasoning Stage：\n给定一个问题，模型输入被构造成 [问题] ... 的形式 以batch方式，同时为 P 个 Token并行生成 P 条独立的推理路径 当任意一条路径生成EOS或达到预设的Token预算时，所有路径同时停止生成，以保证各路径长度大致均衡 Summarization Stage\n上下文整合，直接复用了并行推理阶段生成的KV-Cache，无需re-prefilling。\nSFT\n使用教师模型，对一个问题多次采样，生成多条不同的解题思路，将这些思路整合成一个训练样本，格式为：[问题] [思路1] ... [思路P] [最终答案]。\n在训练时，随机选择一部分特殊Token（如从6个可用路径中随机选4个）进行训练，这使得模型能够泛化，在推理时可以生成比训练时更多的并行路径\nReinforcement Learning with Rubric Anchors arXiv:2508.12790\n如何RL的应用范围，从有明确、可自动验证答案的任务，扩展到更广泛、更主观、没有唯一正确答案的开放式任务中\n使用一套精心设计的、结构化的、可被模型理解的评分标准（Rubric），来为开放式任务的输出自动打分，并以此作为奖励信号来训练模型\nRubric System设计\n首先设计评分准则。每个准则包含多个维度（如创意性、共情能力、逻辑性），每个维度都有明确的评价标准、评分等级和权重；\n模型的输出会根据这些准则被打出一个多维度的分数向量；为了让奖励信号更有效，并非简单地加权求和，采用了更复杂的策略：\n在一些关键维度上失败，则总分直接为零 避免模型在单一维度上过度优化而忽略其他维度 在高分区间放大分数差异，提供更精细的优化梯度 训练流程\n在训练前，先用基础模型对候选数据生成回答，再用一个“批评家模型”根据准则打分，只保留得分适中的数据（去掉太简单和太难/低质量的），以提高训练效率 第一阶段：使用静态、可验证的准则，专注于训练模型遵循指令和约束的基础能力 第二阶段：使用更复杂的、甚至是针对每个样本动态生成的准则，专注于训练开放式、创意和社交等高级能力 如何避免reward-hacking： 专门设计“反作弊”的评分准则\nIs In-Context Learning Learning? arXiv:2509.10414\n在传统的机器学习中，“学习”等同于“泛化”， In-Context Learning, ICL ， 究竟算不算是一种真正的“学习”？\n实验设计\n测试了4个主流的LLM （GPT-4 Turbo、GPT-4o、Mixtral 8x7B、Phi-3.5 MoE） 设计了9个形式化的、基于合成数据的任务， 大致可分成：有限状态自动机可识别的任务（奇偶校验， 模式匹配等）和下推自动机可识别的任务（字符串反转，堆栈操作等） 所有任务的数据都是通过带概率的自动机生成的，可通过参数\\delta 控制ID和OOD数据分布 对每个任务，测试了多种提示策略， 如Modus Ponens（只给范例，没有任务描述）， Description（标准的任务描述+范例）， CoT，APO（用一个元提示让模型自己优化任务描述），Word Salad / SoT （将Description和CoT中的自然语言文本替换为随机单词） eval metrics： Accuracy，并分析其随范例数量和OOD程度关系 一些发现\n随着范例数量的增加，模型的平均准确率稳步提升，证明ICL确实在从范例中“学习”。然而，其泛化能力有限 在极限情况下，模型主要是在学习范例的结构和统计模式，而不是理解自然语言指令的语义 CoT虽然能提升解决特定问题的能力，但它也让模型过度拟合了范例的分布和推理模式，导致其在OOD场景下的泛化能力变得更差 ICL并非真正地编码数据内部的因果或逻辑关系。相反，它通过自回归的方式，对上下文中的统计特征进行一种 ad hoc encoding 推荐内容 Agentic Design Patterns\nWriting effective tools for agents — with agents\ngoogle：Startup technical guide AI agents\n5-Day AI Agents Intensive Course with Google\n影音记录 精选歌单 Live演出 09.05 downy ｜万代2F\n09.19 mammal hands ｜blue notes\n09.20 羊文学 ｜Vas est\n09.21 ひとひら　\u0026 その感激と记录｜Vas\n09.26 明日の叙景 ｜Vas\n书\u0026阅读摘录 深度｜张小珺独家对话OpenAI姚顺雨：语言推理才是AGI主线，交互创新决定创业壁垒 我反而认为模型越强创业机会越大。真正的壁垒是 设计新的交互方式。… 反而如果你只是照搬聊天式助手，很容易被 ChatGPT 替代。\n目前大多数公司还没有数据飞轮，只是依赖模型公司能力提升。要形成飞轮，必须具备：① 能够自己训练模型；② 有明确的 reward 去区分好坏数据；③ reward 与业务高度一致\n社会网络既有资源集中度，也有边缘跃迁速度。未来可能同时中心化和多元化。\n因为 AGI 需要智能、环境和用户 context 三者结合，后两者往往被忽视\n最重要的是想清楚你要为用户创造什么价值。技术是工具，理解技术趋势固然重要，但更重要的是产品敏锐度（Product Sense）和第一性思考，找到痛点并提供解决方案\n“If someone else can do it, then it’s OK to let them do it.” 这让我相信，如果别人已经在做某件事，我可以选择不去卷，而去探索更具潜力的边界，因为最终目标是为社会创造价值\n中美 Agent 创业者闭门：一线创业者的教训、抉择与机会 隐性知识的获取是一个核心挑战，尤其在2B领域。大模型能力不再是主要瓶颈，但是Agent如何能够给到大模型足够的context来实际落地，依然面临几个方面的挑战。 一是默会知识 … 二是协作需要的共识性知识 … 三是企业内部在长期实践中形成的自定义规则\n以前软件都是在做工具给人使用，因为工具直接解决问题的成本过高，问题由人来解决\nWorkflow or Agentic？ … 一个实用的选择标准，是看客户的工作是否天然由工作流驱动。对于企业里可以用非常强规则描述的工作，用Workflow去做，会更高效、准确，成本更低，合规性也更好 … 需要多步骤、灵活操作的任务，则更适合交给自主编排Agent … RPA公司沉淀的RPA资产可以转化为MCP Server中的工具，企业原先接入的系统可以直接转化为Agent落地的基础设施优势。\n对2B领域的Agent创业者而言，另一个重要决策是在客户选择上：先攻KA（大客户）还是SMB（中小客户）？ … 但KA市场有几个不可忽视的挑战：实施成本高昂、决策链条冗长、各部门利益协调复杂。很多项目最终卡在\"试点成功但无法推广\"的尴尬境地。 … 用中小企业市场快速验证产品价值和商业模式，积累标准化场景，打磨\"低实施成本加标准SOP加轻量集成\"的产品形态；同时选择性地用能量化价值的案例敲开关键大客户的大门，建立标杆项目\n但GUI操作的长期价值仍存在很大争议：GUI本质上是为人类认知优化的界面，对Agent来说并非最优路径。当Agent能直接调用API、操作服务器甚至编写代码时，绕开GUI似乎是更优解。在这种情况下，还有什么必要坚持GUI操作吗？ … 我们有两点考虑：一是现实世界过去几十年积累了大量基于GUI的应用，短期内完全绕过并不现实 … 而更深层的原因，在于GUI承载的不仅仅是操作功能，还有丰富的上下文信息。\nWriting effective tools for agents — with agents We conclude with key principles for writing high-quality tools we’ve identified along the way: Choosing the right tools to implement (and not to implement)Namespacing tools to define clear boundaries in functionalityReturning meaningful context from tools back to agentsOptimizing tool responses for token efficiencyPrompt-engineering tool descriptions and specs\nTo build effective tools for agents, we need to re-orient our software development practices from predictable, deterministic patterns to non-deterministic ones.\nWriting Code Is Easy. Reading It Isn’t. But the hard part isn’t the writing. It’s the reading. It’s the time it takes to load the mental model of the system into your head. That’s where all the cost really is.\nReading code is harder than writing it. Much harder. Writing code is forward motion: you’re laying down fresh pavement. Reading code means retracing someone else’s steps, which usually means jumping between files, chasing function calls, inferring side effects, and deciphering intentions that aren’t written down.\nUnderstanding one function often means looking at five other files. Only after all that do you have enough of a map to even begin.\nMaybe it wasn’t the tech after all The technology acted as a catalyst – a reason to look hard at how work gets done, to invest in skills, and to rethink decision-making.\nWhat the evidence does show, overwhelmingly, is that technology adoption only succeeds when it comes hand-in-hand with organisational change.\nTech without organisational change delivers little benefit\n",
  "wordCount" : "635",
  "inLanguage": "en",
  "image":"https://niraya666.github.io/img/monthly/2025-07/1A04B6BE-7882-4762-B780-F9737174D670_1_105_c.jpeg","datePublished": "2025-09-28T20:00:00+08:00",
  "dateModified": "2025-09-28T20:00:00+08:00",
  "author":{
    "@type": "Person",
    "name": "Theme PaperMod"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://niraya666.github.io/monthly/2025-09-%E6%9C%88%E5%88%8A/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "LZY Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://niraya666.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://niraya666.github.io/" accesskey="h" title="LZY Blog (Alt + H)">LZY Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://niraya666.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/posts/" title="AI">
                    <span>AI</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/musik/" title="Musik!">
                    <span>Musik!</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/monthly/" title="月刊">
                    <span>月刊</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/essay/" title="杂文">
                    <span>杂文</span>
                </a>
            </li>
            <li>
                <a href="https://niraya666.github.io/travel/" title="游记">
                    <span>游记</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://niraya666.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://niraya666.github.io/monthly/">Monthlies</a></div>
    <h1 class="post-title entry-hint-parent">
      2025-09 月刊
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2025-09-28 20:00:00 +0800 CST'>September 28, 2025</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Theme PaperMod

</div>
  </header> 
<figure class="entry-cover"><a href="https://niraya666.github.io/img/monthly/2025-07/1A04B6BE-7882-4762-B780-F9737174D670_1_105_c.jpeg" target="_blank"
            rel="noopener noreferrer"><img loading="eager" src="https://niraya666.github.io/img/monthly/2025-07/1A04B6BE-7882-4762-B780-F9737174D670_1_105_c.jpeg" alt="摄于 宁波象山"></a>
        <p>摄于 宁波象山</p>
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e5%80%bc%e5%be%97%e5%85%b3%e6%b3%a8%e7%9a%84%e6%a8%a1%e5%9e%8b%e5%92%8c%e6%96%b0%e6%8a%80%e6%9c%af" aria-label="值得关注的模型和新技术">值得关注的模型和新技术</a></li>
                <li>
                    <a href="#%e5%80%bc%e5%be%97%e5%85%b3%e6%b3%a8%e7%9a%84%e5%bc%80%e6%ba%90%e9%a1%b9%e7%9b%ae" aria-label="值得关注的开源项目">值得关注的开源项目</a></li>
                <li>
                    <a href="#%e5%80%bc%e5%be%97%e5%85%b3%e6%b3%a8%e7%9a%84%e7%a0%94%e7%a9%b6%e5%92%8c%e8%ae%ba%e6%96%87" aria-label="值得关注的研究和论文">值得关注的研究和论文</a><ul>
                        
                <li>
                    <a href="#mirage-scaling-test-time-inference-with-parallel-graph-retrieval-augmented-reasoning-chains" aria-label="MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains">MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains</a></li>
                <li>
                    <a href="#why-language-models-hallucinate" aria-label="Why Language Models Hallucinate">Why Language Models Hallucinate</a></li>
                <li>
                    <a href="#on-the-theoretical-limitations-of-embedding-based-retrieval" aria-label="On the Theoretical Limitations of Embedding-Based Retrieval">On the Theoretical Limitations of Embedding-Based Retrieval</a></li>
                <li>
                    <a href="#parathinker-native-parallel-thinking-as-a-new-paradigm-to-scale-llm-test-time-compute" aria-label="ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute">ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute</a></li>
                <li>
                    <a href="#reinforcement-learning-with-rubric-anchors" aria-label="Reinforcement Learning with Rubric Anchors">Reinforcement Learning with Rubric Anchors</a></li>
                <li>
                    <a href="#is-in-context-learning-learning" aria-label="Is In-Context Learning Learning?">Is In-Context Learning Learning?</a></li></ul>
                </li>
                <li>
                    <a href="#%e6%8e%a8%e8%8d%90%e5%86%85%e5%ae%b9" aria-label="推荐内容">推荐内容</a></li>
                <li>
                    <a href="#%e5%bd%b1%e9%9f%b3%e8%ae%b0%e5%bd%95" aria-label="影音记录">影音记录</a><ul>
                        
                <li>
                    <a href="#%e7%b2%be%e9%80%89%e6%ad%8c%e5%8d%95" aria-label="精选歌单">精选歌单</a></li>
                <li>
                    <a href="#live%e6%bc%94%e5%87%ba" aria-label="Live演出">Live演出</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%b9%a6%e9%98%85%e8%af%bb%e6%91%98%e5%bd%95" aria-label="书&amp;阅读摘录">书&amp;阅读摘录</a><ul>
                        
                <li>
                    <a href="#%e6%b7%b1%e5%ba%a6%e5%bc%a0%e5%b0%8f%e7%8f%ba%e7%8b%ac%e5%ae%b6%e5%af%b9%e8%af%9dopenai%e5%a7%9a%e9%a1%ba%e9%9b%a8%e8%af%ad%e8%a8%80%e6%8e%a8%e7%90%86%e6%89%8d%e6%98%afagi%e4%b8%bb%e7%ba%bf%e4%ba%a4%e4%ba%92%e5%88%9b%e6%96%b0%e5%86%b3%e5%ae%9a%e5%88%9b%e4%b8%9a%e5%a3%81%e5%9e%92httpsmpweixinqqcomsjfrwf16dwn1rvkw3gvy5lq" aria-label="深度｜张小珺独家对话OpenAI姚顺雨：语言推理才是AGI主线，交互创新决定创业壁垒">深度｜张小珺独家对话OpenAI姚顺雨：语言推理才是AGI主线，交互创新决定创业壁垒</a></li>
                <li>
                    <a href="#%e4%b8%ad%e7%be%8e-agent-%e5%88%9b%e4%b8%9a%e8%80%85%e9%97%ad%e9%97%a8%e4%b8%80%e7%ba%bf%e5%88%9b%e4%b8%9a%e8%80%85%e7%9a%84%e6%95%99%e8%ae%ad%e6%8a%89%e6%8b%a9%e4%b8%8e%e6%9c%ba%e4%bc%9ahttpsmpweixinqqcomsoelm54ad3qs6qpf9jibqlq" aria-label="中美 Agent 创业者闭门：一线创业者的教训、抉择与机会">中美 Agent 创业者闭门：一线创业者的教训、抉择与机会</a></li>
                <li>
                    <a href="#writing-effective-tools-for-agents--with-agentshttpswwwanthropiccomengineeringwriting-tools-for-agents" aria-label="Writing effective tools for agents — with agents">Writing effective tools for agents — with agents</a></li>
                <li>
                    <a href="#writing-code-is-easy-reading-it-isnthttpsidiallocomblogwriting-code-is-easy-reading-is-hard" aria-label="Writing Code Is Easy. Reading It Isn’t.">Writing Code Is Easy. Reading It Isn’t.</a></li>
                <li>
                    <a href="#maybe-it-wasnt-the-tech-after-allhttpsblogrobbowleynet20250904maybe-it-wasnt-the-tech-after-all" aria-label="Maybe it wasn’t the tech after all">Maybe it wasn’t the tech after all</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="值得关注的模型和新技术">值得关注的模型和新技术<a hidden class="anchor" aria-hidden="true" href="#值得关注的模型和新技术">#</a></h1>
<p><a href="https://qwen.ai/blog?id=99f0335c4ad9ff6153e517418d48535ab6d8afef&from=research.latest-advancements-list"><strong>Qwen3-VL</strong></a></p>
<p><a href="https://qwen.ai/blog?id=f0bbad0677edf58ba93d80a1e12ce458f7a80548&from=research.research-list">Qwen3Guard</a></p>
<p><a href="https://tongyi-agent.github.io/zh/blog/introducing-tongyi-deep-research/">tongyi-deep-research</a></p>
<p><a href="https://developers.googleblog.com/en/introducing-embeddinggemma/">EmbeddingGemma</a></p>
<p><a href="https://github.com/facebookresearch/cwm">Code World Model (CWM)</a></p>
<h1 id="值得关注的开源项目">值得关注的开源项目<a hidden class="anchor" aria-hidden="true" href="#值得关注的开源项目">#</a></h1>
<p><a href="https://huggingface.co/spaces/HuggingFaceM4/FineVision">FineVision:Open Data Is All You Need</a></p>
<p><a href="https://github.com/WECENG/ticket-purchase">大麦抢票脚本</a></p>
<p><a href="https://github.com/emcie-co/parlant">Parlant</a>: LLM agents built for control. Designed for real-world use.</p>
<p><a href="https://github.com/Cranot/claude-code-guide">Claude Code Comprehensive Guide</a></p>
<p><a href="https://github.com/JerryZLiu/Dayflow">Dayflow</a>: Turns your screen activity into a clean timeline with AI summaries and distraction highlights.</p>
<h1 id="值得关注的研究和论文">值得关注的研究和论文<a hidden class="anchor" aria-hidden="true" href="#值得关注的研究和论文">#</a></h1>
<h2 id="mirage-scaling-test-time-inference-with-parallel-graph-retrieval-augmented-reasoning-chains">MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains<a hidden class="anchor" aria-hidden="true" href="#mirage-scaling-test-time-inference-with-parallel-graph-retrieval-augmented-reasoning-chains">#</a></h2>
<p>arXiv:<a href="https://arxiv.org/abs/2508.18260">2508.18260</a></p>
<p>提出了**Parallel Multi-chain Inference，**将一个复杂问题分解成多个子问题，为每个子问题启动一个独立的、并行的推理链</p>
<p>提出了**Adaptive Graph-based Retrieval，**与一个结构化的医学知识图谱进行交互，在推理过程中，模型可以动态地通过邻居节点扩展、多跳路径遍历等方式探索知识图谱中的实体关系和层次结构</p>
<p>MIRAGE框架通过四个协同工作的组件实现其功能：</p>
<p><img loading="lazy" src="https://arxiv.org/html/2508.18260v1/x2.png" alt=""  />
</p>
<ul>
<li>Question Decomposer</li>
<li>Evidence Retriever：为每个子问题启动一个并行的推理链，进行一种“边思考边搜索”的循环；检索分为两种模式：Anchor Mode（当查询涉及单个实体时，检索该实体在图谱中的局部邻居信息）；Bridge Mode （当查询涉及两个实体时，在图谱中寻找连接这两个实体的关系路径）</li>
<li>Answer Synthesizer：收集所有并行推理链生成的答案和证据，并交叉验证</li>
<li>Coordinator：管理以上三个组件的执行流程</li>
</ul>
<h2 id="why-language-models-hallucinate">Why Language Models Hallucinate<a hidden class="anchor" aria-hidden="true" href="#why-language-models-hallucinate">#</a></h2>
<p><a href="https://cdn.openai.com/pdf/d04913be-3f6f-4d2b-b283-ff432ef4aaa5/why-language-models-hallucinate.pdf">paper</a></p>
<p>提出了基于socio-technical视角来解释幻觉的持续存在。指出，问题的根源不仅仅在于模型或算法本身，更在于评估手段— 特别是主流的benchmark多采用非黑即白的二元评分，鼓励模型“赌一把”而不是如实承认 “不知道”。</p>
<h2 id="on-the-theoretical-limitations-of-embedding-based-retrieval">On the Theoretical Limitations of Embedding-Based Retrieval<a hidden class="anchor" aria-hidden="true" href="#on-the-theoretical-limitations-of-embedding-based-retrieval">#</a></h2>
<p>arXiv:<a href="https://arxiv.org/abs/2508.21038">2508.21038</a></p>
<p>基于single vector embedding<strong>的检索模型是否存在根本性的理论上限？</strong></p>
<p><img loading="lazy" src="https://arxiv.org/html/2508.21038v1/x1.png" alt=""  />
</p>
<p><strong>对于任何固定维度的嵌入模型，都存在一些它永远无法表示和检索的“相关文档组合”</strong>，这是由向量空间本身的几何特性决定的一个根本性限制</p>
<p>定义：</p>
<p>将检索问题形式化为一个m \times n的相关性矩阵 A（m个查询，n个文档）。嵌入模型的目标是学习一个得分矩阵B（由查询向量和文档向量的点积生成，m \times n），使得B中每一行的元素排序与A一致（即相关文档的得分高于不相关文档）；</p>
<p><strong>行序保持秩 <code>rank_rop(A)：</code><strong>让</strong>相关文档得分 &gt; 不相关文档得分</strong>的最低嵌入维度 d</p>
<p><strong>行级阈值秩 <code>rank_rt(A)</code></strong>: 对于每个查询 i，存在一个阈值 τ_i，能将相关和不相关文档的得分分开</p>
<p><strong>全局阈值秩 <code>rank_gt(A)</code></strong>: 存在一个<strong>全局</strong>阈值 τ 对所有查询都有效</p>
<p>sign-rank <code>rank_±(M)</code> 定义： 给定一个矩阵M \in {-1, 1}^{m \times n}， \operatorname{rank}<em>{\pm}(M) = \min { \operatorname{rank}(B) \mid B \in \mathbb{R}^{m \times n} \text{ 并且对于所有 } i, j, \text{ 我们有 } \operatorname{sign}(B</em>{ij}) = M_{ij} }</p>
<p><strong>先给出结论</strong>：由于存在sign-rank任意高的矩阵，因此对于任何给定的嵌入维度d，总会存在一个相关性矩阵（即一个检索任务）是它无法表示的</p>
<h2 id="parathinker-native-parallel-thinking-as-a-new-paradigm-to-scale-llm-test-time-compute">ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute<a hidden class="anchor" aria-hidden="true" href="#parathinker-native-parallel-thinking-as-a-new-paradigm-to-scale-llm-test-time-compute">#</a></h2>
<p>arXiv:<a href="https://www.arxiv.org/abs/2509.04475">2509.04475</a></p>
<p><img loading="lazy" src="https://arxiv.org/html/2509.04475v1/figs/intro.png" alt=""  />
</p>
<p>并非思考越长越好</p>
<p>Tunnel Vision， 即模型在生成思考过程的最初几步，一旦犯了错或选择了一条并非最优的路径，就很容易被“锁定”在这条错误的轨道上，后续无论再花多少计算量进行思考和修正，都很难再回到正确的路径上； 因此主流的sequential-thinking，基于“深度”扩展（单一路径加长）策略存在缺陷</p>
<p>对此，提出了<strong>Native Parallel Thinking；</strong></p>
<ul>
<li>引入一组Specialized Tokens <code>&lt;think i&gt;</code>在推理时显式地引导模型开启第 <code>i</code> 条独立的思考路径</li>
<li>为了在汇总阶段解决位置混淆问题，引入thought embedding</li>
<li>通过从教师模型采样多条解题路径来构建训练数据，同时，通过两阶段的注意力掩码，确保在“并行思考”阶段各路径相互独立，在“总结”阶段又能看到所有路径的信息</li>
</ul>
<p><strong>Parallel Reasoning Stage：</strong></p>
<ul>
<li>给定一个问题，模型输入被构造成 <code>[问题] &lt;think 1&gt; &lt;think 2&gt; ... &lt;think P&gt;</code> 的形式</li>
<li>以batch方式，同时为 <code>P</code> 个 <code>&lt;think i&gt;</code> Token并行生成 <code>P</code> 条独立的推理路径</li>
<li>当任意一条路径生成EOS或达到预设的Token预算时，所有路径同时停止生成，以保证各路径长度大致均衡</li>
</ul>
<p><strong>Summarization Stage</strong></p>
<p>上下文整合，<strong>直接复用</strong>了并行推理阶段生成的KV-Cache，无需re-prefilling。</p>
<p><strong>SFT</strong></p>
<p>使用教师模型，对一个问题多次采样，生成多条不同的解题思路，将这些思路整合成一个训练样本，格式为：<code>[问题] &lt;think 1&gt;[思路1]&lt;/think 1&gt; ... &lt;think P&gt;[思路P]&lt;/think P&gt; &lt;summary&gt;[最终答案]&lt;/summary&gt;</code>。</p>
<p>在训练时，随机选择一部分特殊Token（如从6个可用路径中随机选4个）进行训练，这使得模型能够泛化，在推理时可以生成比训练时更多的并行路径</p>
<h2 id="reinforcement-learning-with-rubric-anchors">Reinforcement Learning with Rubric Anchors<a hidden class="anchor" aria-hidden="true" href="#reinforcement-learning-with-rubric-anchors">#</a></h2>
<p>arXiv:<a href="https://arxiv.org/abs/2508.12790">2508.12790</a></p>
<p><strong>如何RL的应用范围，从有明确、可自动验证答案的任务，扩展到更广泛、更主观、没有唯一正确答案的开放式任务中</strong></p>
<p>使用一套精心设计的、结构化的、可被模型理解的评分标准（Rubric），来为开放式任务的输出自动打分，并以此作为奖励信号来训练模型</p>
<p><strong>Rubric System设计</strong></p>
<p>首先设计评分准则。每个准则包含多个维度（如创意性、共情能力、逻辑性），每个维度都有明确的评价标准、评分等级和权重；</p>
<p>模型的输出会根据这些准则被打出一个多维度的分数向量；为了让奖励信号更有效，并非简单地加权求和，采用了更复杂的策略：</p>
<ul>
<li>在一些关键维度上失败，则总分直接为零</li>
<li>避免模型在单一维度上过度优化而忽略其他维度</li>
<li>在高分区间放大分数差异，提供更精细的优化梯度</li>
</ul>
<p><strong>训练流程</strong></p>
<ul>
<li>在训练前，先用基础模型对候选数据生成回答，再用一个“批评家模型”根据准则打分，只保留得分适中的数据（去掉太简单和太难/低质量的），以提高训练效率</li>
<li>第一阶段：使用静态、可验证的准则，专注于训练模型遵循指令和约束的基础能力</li>
<li><strong>第二阶段</strong>：使用更复杂的、甚至是针对每个样本动态生成的准则，专注于训练开放式、创意和社交等高级能力</li>
</ul>
<p>如何避免reward-hacking： 专门设计“反作弊”的评分准则</p>
<h2 id="is-in-context-learning-learning">Is In-Context Learning Learning?<a hidden class="anchor" aria-hidden="true" href="#is-in-context-learning-learning">#</a></h2>
<p>arXiv:<a href="https://arxiv.org/abs/2509.10414">2509.10414</a></p>
<p>在传统的机器学习中，“学习”等同于“泛化”， <strong>In-Context Learning, ICL ， 究竟算不算是一种真正的“学习”？</strong></p>
<p><strong>实验设计</strong></p>
<ul>
<li>测试了4个主流的LLM （GPT-4 Turbo、GPT-4o、Mixtral 8x7B、Phi-3.5 MoE）</li>
<li>设计了9个形式化的、基于合成数据的任务， 大致可分成：有限状态自动机可识别的任务（奇偶校验， 模式匹配等）和下推自动机可识别的任务（字符串反转，堆栈操作等）</li>
<li>所有任务的数据都是通过带概率的自动机生成的，可通过参数\delta 控制ID和OOD数据分布</li>
<li>对每个任务，测试了多种提示策略， 如Modus Ponens（只给范例，没有任务描述）， Description（标准的任务描述+范例）， CoT，APO（用一个元提示让模型自己优化任务描述），Word Salad / SoT （将Description和CoT中的自然语言文本替换为随机单词）</li>
<li>eval metrics： Accuracy，并分析其随范例数量和OOD程度关系</li>
</ul>
<p>一些发现</p>
<ul>
<li>随着范例数量的增加，模型的平均准确率稳步提升，证明ICL确实在从范例中“学习”。然而，其泛化能力有限</li>
<li>在极限情况下，模型主要是在学习范例的<strong>结构和统计模式</strong>，而不是理解自然语言指令的语义</li>
<li>CoT虽然能提升解决特定问题的能力，但它也让模型<strong>过度拟合</strong>了范例的分布和推理模式，导致其在OOD场景下的泛化能力变得更差</li>
<li>ICL并非真正地编码数据内部的因果或逻辑关系。相反，它通过自回归的方式，对上下文中的统计特征进行一种 ad hoc encoding</li>
</ul>
<h1 id="推荐内容">推荐内容<a hidden class="anchor" aria-hidden="true" href="#推荐内容">#</a></h1>
<p><a href="https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/preview?tab=t.0">Agentic Design Patterns</a></p>
<p><a href="https://www.anthropic.com/engineering/writing-tools-for-agents">Writing effective tools for agents — with agents</a></p>
<p><a href="https://media.licdn.com/dms/document/media/v2/D4D1FAQFqManoGTtsmQ/feedshare-document-pdf-analyzed/B4DZlsAU1FGkAY-/0/1758453662268?e=1759363200&v=beta&t=JLse1O-hbDMYQ_UN0Gi-u43fI7MB-KoG4cupQhuVf5Q">google：Startup technical guide AI agents</a></p>
<p><a href="https://rsvp.withgoogle.com/events/google-ai-agents-intensive_2025">5-Day AI Agents Intensive Course with Google</a></p>
<hr>
<h1 id="影音记录">影音记录<a hidden class="anchor" aria-hidden="true" href="#影音记录">#</a></h1>
<h2 id="精选歌单">精选歌单<a hidden class="anchor" aria-hidden="true" href="#精选歌单">#</a></h2>
<iframe data-testid="embed-iframe" style="border-radius:12px" src="https://open.spotify.com/embed/playlist/6SxyW5Ub1UNOUJaQO8PVzT?utm_source=generator" width="100%" height="450" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
<h2 id="live演出">Live演出<a hidden class="anchor" aria-hidden="true" href="#live演出">#</a></h2>
<p>09.05 downy ｜万代2F</p>
<p>09.19 mammal hands ｜blue notes</p>
<p>09.20 羊文学 ｜Vas est</p>
<p>09.21 ひとひら　&amp; その感激と记录｜Vas</p>
<p>09.26 明日の叙景 ｜Vas</p>
<h1 id="书阅读摘录">书&amp;阅读摘录<a hidden class="anchor" aria-hidden="true" href="#书阅读摘录">#</a></h1>
<h2 id="深度张小珺独家对话openai姚顺雨语言推理才是agi主线交互创新决定创业壁垒httpsmpweixinqqcomsjfrwf16dwn1rvkw3gvy5lq"><a href="https://mp.weixin.qq.com/s/jfRWf16DWN1rVKw3Gvy5lQ">深度｜张小珺独家对话OpenAI姚顺雨：语言推理才是AGI主线，交互创新决定创业壁垒</a><a hidden class="anchor" aria-hidden="true" href="#深度张小珺独家对话openai姚顺雨语言推理才是agi主线交互创新决定创业壁垒httpsmpweixinqqcomsjfrwf16dwn1rvkw3gvy5lq">#</a></h2>
<blockquote>
<p>我反而认为模型越强创业机会越大。真正的壁垒是 设计新的交互方式。… 反而如果你只是照搬聊天式助手，很容易被 ChatGPT 替代。</p>
</blockquote>
<blockquote>
<p>目前大多数公司还没有数据飞轮，只是依赖模型公司能力提升。要形成飞轮，必须具备：① 能够自己训练模型；② 有明确的 reward 去区分好坏数据；③ reward 与业务高度一致</p>
</blockquote>
<blockquote>
<p>社会网络既有资源集中度，也有边缘跃迁速度。未来可能同时中心化和多元化。</p>
</blockquote>
<blockquote>
<p>因为 AGI 需要智能、环境和用户 context 三者结合，后两者往往被忽视</p>
</blockquote>
<blockquote>
<p>最重要的是想清楚你要为用户创造什么价值。技术是工具，理解技术趋势固然重要，但更重要的是产品敏锐度（Product Sense）和第一性思考，找到痛点并提供解决方案</p>
</blockquote>
<blockquote>
<p>“If someone else can do it, then it&rsquo;s OK to let them do it.” 这让我相信，如果别人已经在做某件事，我可以选择不去卷，而去探索更具潜力的边界，因为最终目标是为社会创造价值</p>
</blockquote>
<h2 id="中美-agent-创业者闭门一线创业者的教训抉择与机会httpsmpweixinqqcomsoelm54ad3qs6qpf9jibqlq"><a href="https://mp.weixin.qq.com/s/OELm54AD3qS6qpf9jiBQLQ">中美 Agent 创业者闭门：一线创业者的教训、抉择与机会</a><a hidden class="anchor" aria-hidden="true" href="#中美-agent-创业者闭门一线创业者的教训抉择与机会httpsmpweixinqqcomsoelm54ad3qs6qpf9jibqlq">#</a></h2>
<blockquote>
<p>隐性知识的获取是一个核心挑战，尤其在2B领域。大模型能力不再是主要瓶颈，但是Agent如何能够给到大模型足够的context来实际落地，依然面临几个方面的挑战。
一是默会知识
…
二是协作需要的共识性知识
…
三是企业内部在长期实践中形成的自定义规则</p>
</blockquote>
<blockquote>
<p>以前软件都是在做工具给人使用，因为工具直接解决问题的成本过高，问题由人来解决</p>
</blockquote>
<blockquote>
<p>Workflow or Agentic？
…
一个实用的选择标准，是看客户的工作是否天然由工作流驱动。对于企业里可以用非常强规则描述的工作，用Workflow去做，会更高效、准确，成本更低，合规性也更好
…
需要多步骤、灵活操作的任务，则更适合交给自主编排Agent
…
RPA公司沉淀的RPA资产可以转化为MCP Server中的工具，企业原先接入的系统可以直接转化为Agent落地的基础设施优势。</p>
</blockquote>
<blockquote>
<p>对2B领域的Agent创业者而言，另一个重要决策是在客户选择上：先攻KA（大客户）还是SMB（中小客户）？
…
但KA市场有几个不可忽视的挑战：实施成本高昂、决策链条冗长、各部门利益协调复杂。很多项目最终卡在&quot;试点成功但无法推广&quot;的尴尬境地。
…
用中小企业市场快速验证产品价值和商业模式，积累标准化场景，打磨&quot;低实施成本加标准SOP加轻量集成&quot;的产品形态；同时选择性地用能量化价值的案例敲开关键大客户的大门，建立标杆项目</p>
</blockquote>
<blockquote>
<p>但GUI操作的长期价值仍存在很大争议：GUI本质上是为人类认知优化的界面，对Agent来说并非最优路径。当Agent能直接调用API、操作服务器甚至编写代码时，绕开GUI似乎是更优解。在这种情况下，还有什么必要坚持GUI操作吗？
…
我们有两点考虑：一是现实世界过去几十年积累了大量基于GUI的应用，短期内完全绕过并不现实
…
而更深层的原因，在于GUI承载的不仅仅是操作功能，还有丰富的上下文信息。</p>
</blockquote>
<h2 id="writing-effective-tools-for-agents--with-agentshttpswwwanthropiccomengineeringwriting-tools-for-agents"><a href="https://www.anthropic.com/engineering/writing-tools-for-agents">Writing effective tools for agents — with agents</a><a hidden class="anchor" aria-hidden="true" href="#writing-effective-tools-for-agents--with-agentshttpswwwanthropiccomengineeringwriting-tools-for-agents">#</a></h2>
<blockquote>
<p>We conclude with key principles for writing high-quality tools we’ve identified along the way:
Choosing the right tools to implement (and not to implement)Namespacing tools to define clear boundaries in functionalityReturning meaningful context from tools back to agentsOptimizing tool responses for token efficiencyPrompt-engineering tool descriptions and specs</p>
</blockquote>
<blockquote>
<p>To build effective tools for agents, we need to re-orient our software development practices from predictable, deterministic patterns to non-deterministic ones.</p>
</blockquote>
<h2 id="writing-code-is-easy-reading-it-isnthttpsidiallocomblogwriting-code-is-easy-reading-is-hard"><a href="https://idiallo.com/blog/writing-code-is-easy-reading-is-hard">Writing Code Is Easy. Reading It Isn’t.</a><a hidden class="anchor" aria-hidden="true" href="#writing-code-is-easy-reading-it-isnthttpsidiallocomblogwriting-code-is-easy-reading-is-hard">#</a></h2>
<blockquote>
<p>But the hard part isn’t the writing. It’s the reading. It’s the time it takes to load the mental model of the system into your head. That’s where all the cost really is.</p>
</blockquote>
<blockquote>
<p>Reading code is harder than writing it. Much harder. Writing code is forward motion: you’re laying down fresh pavement. Reading code means retracing someone else’s steps, which usually means jumping between files, chasing function calls, inferring side effects, and deciphering intentions that aren’t written down.</p>
</blockquote>
<blockquote>
<p>Understanding one function often means looking at five other files. Only after all that do you have enough of a map to even begin.</p>
</blockquote>
<h2 id="maybe-it-wasnt-the-tech-after-allhttpsblogrobbowleynet20250904maybe-it-wasnt-the-tech-after-all"><a href="https://blog.robbowley.net/2025/09/04/maybe-it-wasnt-the-tech-after-all/">Maybe it wasn’t the tech after all</a><a hidden class="anchor" aria-hidden="true" href="#maybe-it-wasnt-the-tech-after-allhttpsblogrobbowleynet20250904maybe-it-wasnt-the-tech-after-all">#</a></h2>
<blockquote>
<p>The technology acted as a catalyst – a reason to look hard at how work gets done, to invest in skills, and to rethink decision-making.</p>
</blockquote>
<blockquote>
<p>What the evidence does show, overwhelmingly, is that technology adoption only succeeds when it comes hand-in-hand with organisational change.</p>
</blockquote>
<blockquote>
<p>Tech without organisational change delivers little benefit</p>
</blockquote>
<hr>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://niraya666.github.io/tags/%E6%9C%88%E5%88%8A/">月刊</a></li>
    </ul>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-09 月刊 on x"
            href="https://x.com/intent/tweet/?text=2025-09%20%e6%9c%88%e5%88%8a&amp;url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-09-%25E6%259C%2588%25E5%2588%258A%2f&amp;hashtags=%e6%9c%88%e5%88%8a">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-09 月刊 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-09-%25E6%259C%2588%25E5%2588%258A%2f&amp;title=2025-09%20%e6%9c%88%e5%88%8a&amp;summary=2025-09%20%e6%9c%88%e5%88%8a&amp;source=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-09-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-09 月刊 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-09-%25E6%259C%2588%25E5%2588%258A%2f&title=2025-09%20%e6%9c%88%e5%88%8a">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-09 月刊 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-09-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-09 月刊 on whatsapp"
            href="https://api.whatsapp.com/send?text=2025-09%20%e6%9c%88%e5%88%8a%20-%20https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-09-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-09 月刊 on telegram"
            href="https://telegram.me/share/url?text=2025-09%20%e6%9c%88%e5%88%8a&amp;url=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-09-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share 2025-09 月刊 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=2025-09%20%e6%9c%88%e5%88%8a&u=https%3a%2f%2fniraya666.github.io%2fmonthly%2f2025-09-%25E6%259C%2588%25E5%2588%258A%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
<div id="utterances">
  <script src="https://utteranc.es/client.js"
        repo="https://github.com/Niraya666/niraya666.github.io.git"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
  </script>
</div>


<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      packages: {'[+]': ['ams']}
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://niraya666.github.io/">LZY Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
